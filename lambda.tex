\documentclass[numbers=enddot,12pt,final,onecolumn,notitlepage]{scrartcl}%
\usepackage[all,cmtip]{xy}
\usepackage{lscape}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{comment}
%TCIDATA{OutputFilter=latex2.dll}
%TCIDATA{Version=5.50.0.2960}
%TCIDATA{LastRevised=Tuesday, April 26, 2016 20:04:16}
%TCIDATA{SuppressPackageManagement}
%TCIDATA{<META NAME="GraphicsSave" CONTENT="32">}
%TCIDATA{<META NAME="SaveForMode" CONTENT="1">}
%TCIDATA{BibliographyScheme=Manual}
%BeginMSIPreambleData
\providecommand{\U}[1]{\protect\rule{.1in}{.1in}}
%EndMSIPreambleData
\voffset=-0.5cm
\hoffset=-1.0cm
\setlength\textheight{24cm}
\setlength\textwidth{15.5cm}
\begin{document}

\title{\fbox{$\lambda$\textbf{-rings: Definitions and basic properties}}}
\author{Darij Grinberg}
\date{Version 0.0.17, last revised
%TCIMACRO{\TeXButton{today}{\today}}%
%BeginExpansion
\today
%EndExpansion
}
\maketitle
\tableofcontents

%\begin{titlepage}
%$\ $\\[20mm]
%\begin{center}
%\textbf{\LARGE $\lambda$\textbf{-rings: Definitions and basic properties}}\\[15mm]
%\Large
%\textit{Darij Grinberg}
%\\[8mm]
%Version ***
%\end{center}
%\end{titlepage}
%\newpage
%$\ \ \ $
%\newpage


\bigskip

This is a \textbf{BETA VERSION} and has never been systematically proofread.
\textbf{Please notify me of any mistakes, typos and hard-to-understand
arguments you find!\footnote{my email address is \texttt{A@B.com}, where
\texttt{A=darijgrinberg} and \texttt{B=gmail}}}

Thanks to Martin Brandenburg for pointing out several flaws.

At the moment, section 1 is missing a proof (namely, that the representation
ring is a \textit{special} $\lambda$-ring; I actually don't know this proof)
and sections 11-... are more or less missing.

Most exercises have solutions or at least hints given at the end of this text;
however, some do not.

\bigskip

\subsection*{What is this?}

These notes try to cover some of the most important properties of $\lambda
$-rings with proofs.

They were originally meant to accompany a talk at an undergraduate seminar,
but quickly grew out of proportion to what could fit into a talk. Still they
lack in anything really deep. At the moment, most of what is written here,
except for the Todd homomorphism section, is also in Knutson's book [2],
albeit sometimes with a different proof. Part of the plan was to add some
results from Fulton/Lang [1] with better proofs, but this is not currently my
short-term objective, given that I don't understand much of [1] to begin with.
Most of the notes was written independently of Yau's 2010 text [10], but
inevitably intersects with it.

\section*{0. Notation and conventions}

Some notations that we will use later on:

\begin{itemize}
\item In the following, $\mathbb{N}$ will denote the set $\left\{
0,1,2,...\right\}  $.

\item When we say "ring", we will always mean "commutative ring with unity". A
"ring homomorphism" is always supposed to send $1$ to $1$. When we say
"$R$-algebra" (with $R$ a ring), we will always mean "commutative $R$-algebra
with unity".

\item Let $R$ be a ring. An \textit{extension ring} of $R$ will mean a ring
$S$ along with a ring monomorphism $R\rightarrow S$. (We will often sloppily
identify $R$ with a subring of $S$ if $S$ is an extension ring of $R$; we will
then also identify the polynomial ring $R\left[  T\right]  $ with a subring of
the polynomial ring $S\left[  T\right]  $, and so on.) An extension ring $S$
of $R$ is called \textit{finite-free} if and only if the $R$-module $S$ is
finite-free (i. e., a free $R$-module with a finite basis).

\item We will use multisets. If $I$ is a set, and $u_{i}$ is an object for
every $i\in I$, then we let $\left[  u_{i}\mid i\in I\right]  $ denote the
multiset formed by all the $u_{i}$ where $i$ ranges over $I$ (this multiset
will contain each object $o$ as often as it appears as an $u_{i}$ for some
$i\in I$).\newline If $I=\left\{  1,2,...,n\right\}  $ for some $n\in
\mathbb{N}$, then we also denote the multiset $\left[  u_{i}\mid i\in
I\right]  $ by $\left[  u_{1},u_{2},...,u_{n}\right]  $.

\item We have not defined $\lambda$-rings yet, but it is important to mention
some discrepancy in notation between different sources. Namely, some of the
literature (including [2], [5] and [6]) denotes as \textit{pre-}$\lambda
$\textit{-rings} what we call $\lambda$-rings and denotes as $\lambda
$\textit{-rings} what we call special $\lambda$-rings. Even worse, the
notations in [1] are totally inconsistent\footnote{Often, "$\lambda$-ring" in
[1] means "$\lambda$-ring with a positive structure" (such $\lambda$-rings are
automatically special), but sometimes it simply means "$\lambda$-ring".}.

\item Most times you read an expression with a $\sum$ or a $\prod$ sign in
mathematical literature, you know clearly what it means (e. g., the expression
$\prod\limits_{k=1}^{n}\sin k$ means the product $\left(  \sin1\right)
\cdot\left(  \sin2\right)  \cdot...\cdot\left(  \sin n\right)  $). However,
some more complicated expressions with $\sum$ and $\prod$ signs can be
ambiguous, like the expression $\prod\limits_{k=1}^{n}\sin k\cdot n$: Does
this expression mean $\left(  \prod\limits_{k=1}^{n}\sin k\right)  \cdot n$ or
$\prod\limits_{k=1}^{n}\left(  \left(  \sin k\right)  \cdot n\right)  $ ? The
answer depends on the author of the text.\newline In \textit{this} text, the
following convention should be resorted to when parsing an expression with
$\sum$ or $\prod$ signs:\newline The argument of a $\prod$ sign ends as early
as reasonably possible. Here, "reasonably possible" means that it cannot end
before the last time the index of the product appears (e. g., the argument of
$\prod\limits_{k=1}^{n}\sin k\cdot n$ cannot end before the last appearance of
$k$), that it cannot end inside a bracket (e. g., the argument of
$\prod\limits_{k=1}^{n}\left(  \left(  \sin k\right)  \cdot n\right)  $ cannot
end before the end of the $n$), that it cannot end between a symbol and its
exponent or index or between a function symbol or its arguments, and that the
usual rules of precedence have to apply. For example, the expression
$\prod\limits_{k=1}^{n}\sin k\cdot n$ has to be read as $\left(
\prod\limits_{k=1}^{n}\sin k\right)  \cdot n$, and the expression
$\prod\limits_{k=1}^{n}\sin k\cdot\left(  \cos k\right)  ^{2}k\cdot\left(
n+1\right)  kn$ has to be read as $\left(  \prod\limits_{k=1}^{n}\left(  \sin
k\cdot\left(  \cos k\right)  ^{2}\cdot\left(  n+1\right)  k\right)  \right)
n$.\newline Similar rules apply to the parsing of a sum expression.
\end{itemize}

\section{Motivations}

What is the point of $\lambda$-rings?

Fulton/Lang [1] motivate $\lambda$-rings through vector bundles. Here we are
going for a more elementary motivation, namely through representation rings in
group representation theory:

\subsection{Representation rings of groups}

Consider a finite group $G$ and a field $k$ of characteristic $0$. In
representation theory, one define the so-called \textit{representation ring}
of the group $G$ over the field $k$. This ring can be constructed as follows:

We consider only finite-dimensional representations of $G$.

Let $\operatorname*{Rep}_{k}G$ be the set of all representations of the group
$G$ over the field $k$. (We disregard the set-theoretic problematics stemming
from the notion of such a big set. If you wish, you can call it a class or a
SET instead of a set, or restrict yourself to a smaller subset containing
every representation up to isomorphism.)

Let $\operatorname*{FRep}_{k}G$ be the free abelian group on the set
$\operatorname*{Rep}_{k}G$. Let $I$ be the subgroup%
\begin{align*}
I  &  =\left\langle U-V\ \mid\ U\text{ and }V\text{ are two isomorphic
representations of }G\right\rangle \\
&  \ \ \ \ \ \ \ \ \ \ +\left\langle U\oplus V-U-V\ \mid\ U\text{ and }V\text{
are two representations of }G\right\rangle
\end{align*}
of the free abelian group $\operatorname*{FRep}_{k}G$ (written additively).
Then, $\operatorname*{FRep}_{k}G\diagup I$ is an abelian group. Whenever $U$
is a representation of $G,$ we should denote the equivalence class of
$U\in\operatorname*{FRep}_{k}G$ modulo the ideal $I$ by $\overline{U};$
however, since we are going to work in $\operatorname*{FRep}_{k}G\diagup I$
throughout this Section 1 (because there is not much of interest to do in
$\operatorname*{FRep}_{k}G$ itself), we will simply write $U$ for this
equivalence class. This means that whenever $U$ and $V$ are two isomorphic
representations of $G$, we will simply write $U=V$, and whenever $U$ and $V$
are two representations of $G$, we will simply write $U+V=U\oplus V$.

Denote by $1$ the equivalence class of the trivial representation of $G$ on
$k$ (with every element of $G$ acting as identity) modulo $I$. We now define a
ring structure on $\operatorname*{FRep}_{k}G\diagup I$ by letting $1$ be the
one of this ring, and defining the product of two representations of $G$ as
their tensor product (over $k$). This is indeed a ring structure because we
have isomorphisms%
\begin{align*}
U\otimes\left(  V\otimes W\right)   &  \cong\left(  U\otimes V\right)  \otimes
W,\\
\left(  U\oplus V\right)  \otimes W  &  \cong\left(  U\otimes W\right)
\oplus\left(  V\otimes W\right)  ,\\
U\otimes\left(  V\oplus W\right)   &  \cong\left(  U\otimes V\right)
\oplus\left(  U\otimes W\right)  ,\\
U\otimes V  &  \cong V\otimes U,\\
1\otimes U  &  \cong U\otimes1\cong U,\\
0\otimes U  &  \cong U\otimes0\cong0
\end{align*}
for any representations $U,$ $V$ and $W$, and because tensor products preserve
isomorphisms (this means that if $U$, $V$ and $W$ are three representations of
$G$ such that $V\cong W$ (as representations), then $U\otimes V\cong U\otimes
W$ and $V\otimes U\cong W\otimes U$).

The ring $\operatorname*{FRep}_{k}G\diagup I$ is called the
\textit{representation ring of the group }$G$\textit{ over the field }$k$. The
elements of $\operatorname*{FRep}_{k}G\diagup I$ are called \textit{virtual
representations}.

This ring $\operatorname*{FRep}_{k}G\diagup I$ is helpful in working with
representations. However, its ring structure does not yet reflect everything
we can do with representations. In fact, we can build direct sums of
representations (this is addition in $\operatorname*{FRep}_{k}G\diagup I$) and
we can build tensor products (this is multiplication in $\operatorname*{FRep}%
_{k}G\diagup I$), but we can also build exterior powers of representations,
and we have no idea yet what operation on $\operatorname*{FRep}_{k}G\diagup I$
this entails. So we see that the abstract notion of a ring is not enough to
understand all of representation theory. We need a notion of a ring together
with some operations that "behave like" taking exterior powers. What axioms
should these operations satisfy?

Every representation $V$ of a group $G$ satisfies $\wedge^{0}V\cong1$ and
$\wedge^{1}V\cong V$. Besides, for any two representations $V$ and $W$ of $G$
and every $k\in\mathbb{N}$, there exists an isomorphism%
\begin{equation}
\wedge^{k}\left(  V\oplus W\right)  \cong\bigoplus_{i=0}^{k}\wedge^{i}%
V\otimes\wedge^{k-i}W \label{RepThV+W}%
\end{equation}
(see Exercise 1.1). In the representation ring, this means%
\[
\wedge^{k}\left(  V+W\right)  =\sum_{i=0}^{k}\left(  \wedge^{i}V\right)
\cdot\left(  \wedge^{k-i}W\right)  .
\]
This already gives us three axioms for the operations that we want to
introduce. If we extend these three axioms to arbitrary elements of
$\operatorname*{FRep}_{k}G\diagup I$ (and not just actual representations), we
can compute $\wedge^{k}$ of virtual representations (and it turns out that it
is well-defined), and we obtain the notion of a $\lambda$\textit{-ring}.

We can still wonder whether these axioms are all that we can say about group
representations. The answer is no: In addition to the formula (\ref{RepThV+W}%
), there exist relations of the form
\begin{align}
&  \wedge^{k}\left(  V\otimes W\right)  =P_{k}\left(  \wedge^{1}V,\wedge
^{2}V,...,\wedge^{k}V,\wedge^{1}W,\wedge^{2}W,...,\wedge^{k}W\right)
\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N}\text{ and any two
representations }V\text{ and }W\text{ of }G \label{RepThVW}%
\end{align}
and%
\begin{align}
&  \wedge^{k}\left(  \wedge^{j}\left(  V\right)  \right)  =P_{k,j}\left(
\wedge^{1}V,\wedge^{2}V,...,\wedge^{kj}V\right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N},\text{ }j\in
\mathbb{N}\text{ and any representation }V\text{ of }G, \label{RepThLL}%
\end{align}
where $P_{k}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{k}%
,\beta_{1},\beta_{2},...,\beta_{k}\right]  $ and $P_{k,j}\in\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{kj}\right]  $ are "universal" polynomials
(i. e., polynomials only depending on $k$ resp. on $k$ and $j$, but not on
$V$, $W$ or $G$). These polynomials are rather hard to write down explicitly,
so it will need some theoretical preparation to define them.\footnote{Note
that these polynomials can have negative coefficients, so that the equality
(\ref{RepThVW}) does not necessarily mean an isomorphism of the kind%
\[
\wedge^{k}\left(  V\otimes W\right)  \cong\text{direct sum of some tensor
products of some }\wedge^{i}V\text{ and }\wedge^{j}W,
\]
but generally means an isomorphism of the kind%
\begin{align*}
&  \wedge^{k}\left(  V\otimes W\right)  \oplus\text{direct sum of some tensor
products of some }\wedge^{i}V\text{ and }\wedge^{j}W\\
&  \cong\text{(another) direct sum of some tensor products of some }\wedge
^{i}V\text{ and }\wedge^{j}W,
\end{align*}
and similarly (\ref{RepThLL}) has to be understood.}

These relations (\ref{RepThV+W}) and (\ref{RepThLL}), generalized to arbitrary
virtual representations, abstract to the notion of a \textit{special }%
$\lambda$\textit{-ring}. So$\ \operatorname*{FRep}_{k}G\diagup I$ is not just
a $\lambda$-ring; it is a special $\lambda$-ring. However, it has even more
structure than that: It is an \textit{augmented }$\lambda$\textit{-ring with
positive structure}. "Augmented" means the existence of a ring homomorphism
$\varepsilon:\operatorname*{FRep}_{k}G\diagup I\rightarrow\mathbb{Z}$ (a
so-called \textit{augmentation}) with certain properties; we will list these
properties later, but let us now notice that for our representation ring
$\operatorname*{FRep}_{k}G\diagup I,$ the obvious natural choice of
$\varepsilon$ is the homomorphism which maps every representation $V$ of $G$
to $\dim V\in\mathbb{Z}$. A "positive structure" is a subset of $K$ closed
under addition and multiplication and containing $1$, and satisfying other
properties; in our case, the best choice for a positive structure on
$\operatorname*{FRep}_{k}G\diagup I$ is the subset%
\[
\left\{  \overline{V}\mid V\text{ is a representation of }G\right\}
\setminus0\subseteq\operatorname*{FRep}\nolimits_{k}G\diagup I.
\]


The reader may wonder how much the ring $\operatorname*{FRep}_{k}G\diagup I$
actually tells us about representations of $G$. For example, if $U$ and $V$
are two representations of $G$ such that $\overline{U}=\overline{V}$ in
$\operatorname*{FRep}_{k}G\diagup I$, does this mean that $U\cong V$ ? It
turns out that this is true, thanks to the cancellative property of
representation theory\footnote{This is the property that whenever $U$, $V$ and
$W$ are three representations of a finite group $G$ such that $U\oplus W\cong
V\oplus W$ (where we recall once again that "representation" means
"finite-dimensional representation" for us!), then $U\cong V$. This can be
proven using the Krull-Remak-Schmidt theorem, or, when the characteristic of
the field is $0$, using semisimplicity of $k\left[  G\right]  $.}; hence,
abstract algebraic identities that we can prove to hold in arbitrary special
$\lambda$-rings yield actual isomorphies of representations of finite groups.
(Of course, they only yield them once we will have proven that
$\operatorname*{FRep}_{k}G\diagup I$ is a special $\lambda$-ring. At the
moment, this is not proven in this text, although it is rather easy to show
using character theory.)

\subsection{Grothendieck rings of groups}

The situation gets more complicated when the field over which we are working
is not of characteristic $0$. In this case, it turns out that
$\operatorname*{FRep}_{k}G\diagup I$ is not necessarily a special $\lambda
$-ring any more (although still a $\lambda$-ring by Exercise 1.1). If we
insist on getting a special $\lambda$-ring, we must modify our definition of
$I$ to%
\begin{align*}
I  &  =\left\langle V-U-W\ \mid\ U\text{, }V\text{ and }W\text{ are three
representations of }G\text{ such that}\right. \\
&  \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left.  \text{there
exists an exact sequence }0\rightarrow U\rightarrow V\rightarrow
W\rightarrow0\right\rangle .
\end{align*}
The resulting ring $\operatorname*{FRep}_{k}G\diagup I$ is called the
\textit{Grothendieck ring} of representations of $G$ over our field. A proof
that it is a special $\lambda$-ring is sketched in [7] (Example on page 95),
but I do not understand it. Anyway this result is not as strong as in
characteristic $0$ anymore, because the equality $\overline{U}=\overline{V}$
in the Grothendieck ring $\operatorname*{FRep}_{k}G\diagup I$ does not imply
$U\cong V$ as representations of $G$ when $\operatorname*{char}k\neq0$. So the
Grothendieck ring is, in some sense, a pale shadow of the representation
theory of $G$.

\subsection{Vector bundles}

Vector bundles over a given compact Hausdorff space are similar to
representations of a given group in several ways: They are somehow "enriched"
vector space structures (a vector bundle is, roughly speaking, a family of
vector spaces with additional topological structure; a representation of a
group is a vector space with a group action on it), so one can form direct
sums, tensor products and exterior powers of both of these. Hence, it is not
surprising that we can define a $\lambda$-ring structure on a kind of "ring of
vector bundles over a space" similarly to the $\lambda$-ring structure on the
representation ring of a group. However, just as in the case of
representations of a group over nonzero characteristic, we must be careful
with vector bundles, because this "ring of vector bundles over a space"
actually does not consist of vector bundles, but of equivalence classes, and
sometimes, different vector bundles can lie in one and the same equivalence
class (just as representations of groups are no longer uniquely determined by
their equivalence class in the representation ring when the characteristic of
the ground field is not $0$). This "ring of vector bundles" is denoted by
$K\left(  X\right)  $, where $X$ is the base space, and is the first
fundamental object of study in K-theory. We will not delve into K-theory here;
we will only provide some of its backbone, namely the abstract algebraic
theory of $\lambda$-rings (which appear not only in K-theory, but also in
representation theory and elsewhere).

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 1.1.} Let $G$ be a group, and let $V$ and $W$ be two
representations of $G$. Let $k\in\mathbb{N}$. Let $\iota_{V}:V\rightarrow
V\oplus W$ and $\iota_{W}:W\rightarrow V\oplus W$ be the canonical injections.

For every $i\in\left\{  0,1,...,k\right\}  $, we can define a vector space
homomorphism%
\[
\Phi_{i}:\wedge^{i}V\otimes\wedge^{k-i}W\rightarrow\wedge^{k}\left(  V\oplus
W\right)
\]
by requiring that it sends
\begin{align*}
&  \left(  v_{1}\wedge v_{2}\wedge...\wedge v_{i}\right)  \otimes\left(
w_{1}\wedge w_{2}\wedge...\wedge w_{k-i}\right)  \ \ \ \ \ \ \ \ \ \ \text{to}%
\\
&  \iota_{V}\left(  v_{1}\right)  \wedge\iota_{V}\left(  v_{2}\right)
\wedge...\wedge\iota_{V}\left(  v_{i}\right)  \wedge\iota_{W}\left(
w_{1}\right)  \wedge\iota_{W}\left(  w_{2}\right)  \wedge...\wedge\iota
_{W}\left(  w_{k-i}\right)
\end{align*}
for all $v_{1},v_{2},...,v_{i}\in V$ and $w_{1},w_{2},...,w_{k-i}\in W$.

\textbf{(a)} Prove that this vector space homomorphism $\Phi_{i}$ is a
homomorphism of representations.

\textbf{(b)} Prove that the vector space homomorphism%
\[
\bigoplus_{i=0}^{k}\wedge^{i}V\otimes\wedge^{k-i}W\rightarrow\wedge^{k}\left(
V\oplus W\right)
\]
composed of the homomorphisms $\Phi_{i}$ for all $i\in\left\{
0,1,...,k\right\}  $ is a canonical isomorphism of representations.
\end{quotation}

\section{$\lambda$-rings}

\subsection{The definition}

The following definition introduces our most important notions: that of a
$\lambda$-ring, that of a $\lambda$-ring homomorphism, and that of a
sub-$\lambda$-ring. While these notions are rather elementary (and much easier
to define than the ones in Sections 5 and later), they are the basis of our theory.

\begin{quote}
\textbf{Definition.} \textbf{1)} Let $K$ be a ring. Let $\lambda
^{i}:K\rightarrow K$ be a mapping\footnote{Here, "mapping" actually means
"mapping" and not "group homomorphism" of "ring homomorphism".} for every
$i\in\mathbb{N}$ such that $\lambda^{0}\left(  x\right)  =1$ and $\lambda
^{1}\left(  x\right)  =x$ for every $x\in K$. Assume that%
\begin{equation}
\lambda^{k}\left(  x+y\right)  =\sum_{i=0}^{k}\lambda^{i}\left(  x\right)
\lambda^{k-i}\left(  y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }%
k\in\mathbb{N},\text{ }x\in K\text{ and }y\in K. \label{lambda1}%
\end{equation}
Then, we call $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
$ a $\lambda$\textit{-ring}. We will also call $K$ itself a $\lambda$-ring if
there is an obvious (from the context) choice of the sequence of mappings
$\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}$ which makes $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ a $\lambda$-ring.

\textbf{2)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ and $\left(  L,\left(  \mu^{i}\right)  _{i\in\mathbb{N}}\right)  $
be two $\lambda$-rings. Let $f:K\rightarrow L$ be a map. Then, $f$ is called a
$\lambda$\textit{-ring homomorphism} (or \textit{homomorphism of }$\lambda
$\textit{-rings}) if and only if $f$ is a ring homomorphism and satisfies
$\mu^{i}\circ f=f\circ\lambda^{i}$ for every $i\in\mathbb{N}$.

\textbf{3)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a $\lambda$-ring. Let $L$ be a subring of $K$. Then, $L$ is
said to be a \textit{sub-}$\lambda$\textit{-ring} of $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ if and only if $\lambda
^{i}\left(  L\right)  \subseteq L$ for every $i\in\mathbb{N}$. Obviously, if
$L$ is a sub-$\lambda$-ring of $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  ,$ then $\left(  L,\left(  \lambda^{i}\mid
_{L}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring, and the
canonical inclusion $L\rightarrow K$ is a $\lambda$-ring homomorphism.
\end{quote}

\subsection{An alternative characterization}

We will now give an alternative characterization of $\lambda$-rings:

\begin{quote}
\textbf{Theorem 2.1.} Let $K$ be a ring. Let $\lambda^{i}:K\rightarrow K$ be a
mapping\footnote{Here, "mapping" actually means "mapping" and not "group
homomorphism" of "ring homomorphism".} for every $i\in\mathbb{N}$ such that
$\lambda^{0}\left(  x\right)  =1$ and $\lambda^{1}\left(  x\right)  =x$ for
every $x\in K$. Consider the ring $K\left[  \left[  T\right]  \right]  $ of
formal series in the indeterminate $T$ over the ring $K.$ Define a map
$\lambda_{T}:K\rightarrow K\left[  \left[  T\right]  \right]  $ by
\[
\lambda_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  T^{i}\ \ \ \ \ \ \ \ \ \ \text{for every }x\in K.
\]
Note that the power series $\lambda_{T}\left(  x\right)  =\sum\limits_{i\in
\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}$ has the coefficient
$\lambda^{0}\left(  x\right)  =1$ before $T^{0};$ thus, it is invertible in
$K\left[  \left[  T\right]  \right]  $.

\textbf{(a)} Then, $\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(
y\right)  =\lambda_{T}\left(  x+y\right)  $ for every $x\in K$ and every $y\in
K$ if and only if $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ is a $\lambda$-ring.

\textbf{(b)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a $\lambda$-ring. Then,%
\begin{align*}
\lambda_{T}\left(  0\right)   &  =1;\\
\lambda_{T}\left(  -x\right)   &  =\left(  \lambda_{T}\left(  x\right)
\right)  ^{-1}\ \ \ \ \ \ \ \ \ \ \text{for every }x\in K;\\
\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)   &
=\lambda_{T}\left(  x+y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }x\in
K\text{ and every }y\in K.
\end{align*}


\textbf{(c)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ and $\left(  L,\left(  \mu^{i}\right)  _{i\in\mathbb{N}}\right)  $
be two $\lambda$-rings. Consider the map $\lambda_{T}:K\rightarrow K\left[
\left[  T\right]  \right]  $ defined above, and a similarly defined map
$\mu_{T}:L\rightarrow L\left[  \left[  T\right]  \right]  $ for the $\lambda
$-ring $L$. Let $f:K\rightarrow L$ be a ring homomorphism. Consider the rings
$K\left[  \left[  T\right]  \right]  $ and $L\left[  \left[  T\right]
\right]  $. Obviously, the homomorphism $f$ induces a homomorphism $f\left[
\left[  T\right]  \right]  :K\left[  \left[  T\right]  \right]  \rightarrow
L\left[  \left[  T\right]  \right]  $ (defined by $\left(  f\left[  \left[
T\right]  \right]  \right)  \left(  \sum\limits_{i\in\mathbb{N}}a_{i}%
T^{i}\right)  =\sum\limits_{i\in\mathbb{N}}f\left(  a_{i}\right)  T^{i}$ for
every $\sum\limits_{i\in\mathbb{N}}a_{i}T^{i}\in K\left[  \left[  T\right]
\right]  $ with $a_{i}\in K$).

Then, $f$ is a $\lambda$-ring homomorphism if and only if $\mu_{T}\circ
f=f\left[  \left[  T\right]  \right]  \circ\lambda_{T}$.

\textbf{(d)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a $\lambda$-ring. Then, $\lambda^{i}\left(  0\right)  =0$ for
every positive integer $i$.
\end{quote}

\textit{Proof of Theorem 2.1.} \textbf{(a)} Every $x\in K$ and every $y\in K$
satisfy%
\begin{align*}
\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)   &  =\left(
\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}\right)
\cdot\left(  \sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  y\right)
T^{i}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\lambda_{T}\left(  x\right)
=\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}\text{ and
}\lambda_{T}\left(  y\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
y\right)  T^{i}\right) \\
&  =\sum_{k\in\mathbb{N}}\sum_{i=0}^{k}\lambda^{i}\left(  x\right)
\lambda^{k-i}\left(  y\right)  \cdot T^{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the product of two
formal power series}\right)
\end{align*}
and%
\[
\lambda_{T}\left(  x+y\right)  =\sum_{i\in\mathbb{N}}\lambda^{i}\left(
x+y\right)  T^{i}=\sum_{k\in\mathbb{N}}\lambda^{k}\left(  x+y\right)  T^{k}.
\]
Hence, the equation $\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(
y\right)  =\lambda_{T}\left(  x+y\right)  $ is equivalent to $\sum
\limits_{k\in\mathbb{N}}\sum\limits_{i=0}^{k}\lambda^{i}\left(  x\right)
\lambda^{k-i}\left(  y\right)  \cdot T^{k}=\sum\limits_{k\in\mathbb{N}}%
\lambda^{k}\left(  x+y\right)  T^{k}$, which, in turn, means that every
$k\in\mathbb{N}$ satisfies $\sum\limits_{i=0}^{k}\lambda^{i}\left(  x\right)
\lambda^{k-i}\left(  y\right)  =\lambda^{k}\left(  x+y\right)  $, and this is
exactly the property (\ref{lambda1}) from the definition of a $\lambda$-ring.
Thus, we have $\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)
=\lambda_{T}\left(  x+y\right)  $ for every $x\in K$ and every $y\in K$ if and
only if $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is
a $\lambda$-ring. This proves Theorem 2.1 \textbf{(a)}.

\textbf{(b)} Theorem 2.1 \textbf{(a)} tells us that $\lambda_{T}\left(
x\right)  \cdot\lambda_{T}\left(  y\right)  =\lambda_{T}\left(  x+y\right)  $
for every $x\in K$ and every $y\in K$ if and only if $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring. Since we
know that $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $
is a $\lambda$-ring, we thus conclude that
\begin{equation}
\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)  =\lambda
_{T}\left(  x+y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }x\in K\text{ and
every }y\in K. \label{2.1.pf.1}%
\end{equation}
Applied to $x=y=0$, this rewrites as $\lambda_{T}\left(  0\right)
\cdot\lambda_{T}\left(  0\right)  =\lambda_{T}\left(  0+0\right)  =\lambda
_{T}\left(  0\right)  $, what yields $\lambda_{T}\left(  0\right)  =1$ (since
$\lambda_{T}\left(  0\right)  $ is invertible in $K\left[  \left[  T\right]
\right]  $).

On the other hand, every $x\in K$ satisfies
\begin{align*}
\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  -x\right)   &
=\lambda_{T}\left(  0\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{2.1.pf.1}), applied to }y=-x\right) \\
&  =1,
\end{align*}
hence $\lambda_{T}\left(  -x\right)  =\left(  \lambda_{T}\left(  x\right)
\right)  ^{-1}$. Theorem 2.1 \textbf{(b)} is thus proven.

\textbf{(c)} We have $\left(  \mu_{T}\circ f\right)  \left(  x\right)
=\mu_{T}\left(  f\left(  x\right)  \right)  =\sum\limits_{i\in\mathbb{N}}%
\mu^{i}\left(  f\left(  x\right)  \right)  T^{i}$ (by the definition of
$\mu_{T}$) and $\left(  f\left[  \left[  T\right]  \right]  \circ\lambda
_{T}\right)  \left(  x\right)  =\left(  f\left[  \left[  T\right]  \right]
\right)  \left(  \lambda_{T}\left(  x\right)  \right)  =\left(  f\left[
\left[  T\right]  \right]  \right)  \left(  \sum\limits_{i\in\mathbb{N}%
}\lambda^{i}\left(  x\right)  T^{i}\right)  =\sum\limits_{i\in\mathbb{N}%
}f\left(  \lambda^{i}\left(  x\right)  \right)  T^{i}$ for every $x\in K$.
Hence, $\mu_{T}\circ f=f\left[  \left[  T\right]  \right]  \circ\lambda_{T}$
is equivalent to $\sum\limits_{i\in\mathbb{N}}\mu^{i}\left(  f\left(
x\right)  \right)  T^{i}=\sum\limits_{i\in\mathbb{N}}f\left(  \lambda
^{i}\left(  x\right)  \right)  T^{i}$ for every $x\in K,$ which in turn is
equivalent to $\mu^{i}\left(  f\left(  x\right)  \right)  =f\left(
\lambda^{i}\left(  x\right)  \right)  $ for every $x\in K$ and every
$i\in\mathbb{N}$, which in turn means that $\mu^{i}\circ f=f\circ\lambda^{i}$
for every $i\in\mathbb{N}$, which in turn means that $f$ is a $\lambda$-ring
homomorphism. This proves Theorem 2.1 \textbf{(c)}.

\textbf{(d)} Applying the equality $\lambda_{T}\left(  x\right)
=\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}$ to $x=0$, we
obtain $\lambda_{T}\left(  0\right)  =\sum\limits_{i\in\mathbb{N}}\lambda
^{i}\left(  0\right)  T^{i}$. But since $\lambda_{T}\left(  0\right)  =1$,
this rewrites as $1=\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  0\right)
T^{i}$. For every positive integer $i$, the coefficient of $T^{i}$ on the left
hand side of this equality is $0$, while the coefficient of $T^{i}$ on the
right hand side of this equality is $\lambda^{i}\left(  0\right)  $. Since the
coefficients of $T^{i}$ on the two sides of an equality must be equal, this
yields $0=\lambda^{i}\left(  0\right)  $ for every positive integer $i$. This
proves Theorem 2.1 \textbf{(d)}.

The map $\lambda_{T}$ defined in Theorem 2.1 will follow us through the whole
theory of $\lambda$-rings. It is often easier to deal with than the maps
$\lambda^{i}$, since (as Theorem 2.1 \textbf{(a)} and \textbf{(b)} show)
$\lambda_{T}$ is a monoid homomorphism from $\left(  K,+\right)  $ to $\left(
K\left[  \left[  T\right]  \right]  ,\cdot\right)  $ when $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring. Many
properties of $\lambda$-rings are easier to write in terms of $\lambda_{T}$
than in terms of the separate $\lambda^{i}$. We will later become acquainted
with the notion of "special $\lambda$-rings", for which $\lambda_{T}$ is not
only a monoid homomorphism but actually a $\lambda$-ring homomorphism (but not
to $K\left[  \left[  T\right]  \right]  $ but to a different $\lambda$-ring
with a new ring structure).

\subsection{$\lambda$-ideals}

Just as rings have ideals and Lie algebras have Lie ideals, there is a notion
of $\lambda$-ideals defined for $\lambda$-rings. Here is one way to define them:

\begin{quote}
\textbf{Definition.} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in
\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $I$ be an ideal of the ring
$K$. Then, $I$ is said to be a $\lambda$\textit{-ideal} of $K$ if and only if
every $t\in I$ and every positive integer $i$ satisfy $\lambda^{i}\left(
t\right)  \in I$.
\end{quote}

Just as rings can be factored by ideals to obtain new rings, and Lie algebras
can be factored by Lie ideals to obtain new Lie algebras, we can factor
$\lambda$-rings by $\lambda$-ideals and obtain new $\lambda$-rings:

\begin{quote}
\textbf{Theorem 2.2.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $I$ be a $\lambda$-ideal
of the ring $K$. For every $z\in K$, let $\overline{z}$ denote the residue
class of $z$ modulo $I$. (This $\overline{z}$ lies in $K\diagup I$.)

\textbf{(a)} If $x\in K\diagup I$ is arbitrary, and $y\in K$ and $z\in K$ are
two elements of $K$ satisfying $\overline{y}=x$ and $\overline{z}=x$, then
$\overline{\lambda^{i}\left(  y\right)  }=\overline{\lambda^{i}\left(
z\right)  }$ for every $i\in\mathbb{N}$.

\textbf{(b)} For every $i\in\mathbb{N}$, define a map $\widetilde{\lambda}%
^{i}:K\diagup I\rightarrow K\diagup I$ as follows: For every $x\in K\diagup
I$, let $\widetilde{\lambda}^{i}\left(  x\right)  $ be defined as
$\overline{\lambda^{i}\left(  w\right)  }$, where $w$ is an element of $K$
satisfying $\overline{w}=x$. (This is well-defined because the value of
$\overline{\lambda^{i}\left(  w\right)  }$ does not depend on the choice of
$w$\ \ \ \ \footnote{In fact, any two choices of $w$ lead to the same value of
$\overline{\lambda^{i}\left(  w\right)  }$ (this follows from Theorem 2.2
\textbf{(a)}).}.)

Then, $\left(  K\diagup I,\left(  \widetilde{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring.

\textbf{(c)} The canonical projection $K\rightarrow K\diagup I$ is a $\lambda
$-ring homomorphism.
\end{quote}

The proof of Theorem 2.2 is given in the solution of Exercise 2.3.

Along with Theorem 2.2 comes the following result:

\begin{quote}
\textbf{Theorem 2.3.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and $\left(  L,\left(  \mu^{i}\right)
_{i\in\mathbb{N}}\right)  $ be two $\lambda$-rings. Let $f:K\rightarrow L$ be
a $\lambda$-ring homomorphism. Then, $\operatorname*{Ker}f$ is a $\lambda$-ideal.
\end{quote}

The proof of Theorem 2.3 is given in the solution of Exercise 2.4.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 2.1.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and $\left(  L,\left(  \mu^{i}\right)
_{i\in\mathbb{N}}\right)  $ be two $\lambda$-rings. Let $f:K\rightarrow L$ be
a ring homomorphism. Let $E$ be a generating set of the $\mathbb{Z}$-module
$K$.

\textbf{(a)} Prove that $f$ is a $\lambda$-ring homomorphism if and only if
every $e\in E$ satisfies $\left(  \mu_{T}\circ f\right)  \left(  e\right)
=\left(  f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(
e\right)  $.

\textbf{(b)} Prove that $f$ is a $\lambda$-ring homomorphism if and only if
every $e\in E$ satisfies $\left(  \mu^{i}\circ f\right)  \left(  e\right)
=\left(  f\circ\lambda^{i}\right)  \left(  e\right)  $ for every
$i\in\mathbb{N}$.

\textit{Exercise 2.2.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $L$ be a subset of $K$
which is closed under addition, multiplication and the maps $\lambda^{i}$.
Assume that $0\in L$ and $1\in L$. Then, the subset $L-L$ of $K$ (this subset
$L-L$ is defined by $L-L=\left\{  \ell-\ell^{\prime}\mid\ell\in L,\ \ell
^{\prime}\in L\right\}  $) is a sub-$\lambda$-ring of $K$.

\textit{Exercise 2.3.} Prove Theorem 2.2.

\textit{Exercise 2.4.} Prove Theorem 2.3.
\end{quotation}

\section{Examples of $\lambda$-rings}

\subsection{Binomial $\lambda$-rings}

Before we go deeper into the theory, it is time for some examples.

Obviously, the trivial ring $0$ (the ring satisfying $0=1$) along with the
trivial maps $\lambda^{i}:0\rightarrow0$ is a $\lambda$-ring. Let us move on
to more surprising examples:

\begin{quote}
\textbf{Theorem 3.1.} For every $i\in\mathbb{N}$, define a map $\lambda
^{i}:\mathbb{Z}\rightarrow\mathbb{Z}$ by $\lambda^{i}\left(  x\right)
=\dbinom{x}{i}$ for every $x\in\mathbb{Z}$.\ \ \ \ \footnote{Note that
$\dbinom{x}{i}$ is defined to be $\dfrac{x\cdot\left(  x-1\right)
\cdot...\cdot\left(  x-i+1\right)  }{i!}$ for every $x\in\mathbb{R}$ and
$i\in\mathbb{N}$.} Then, $\left(  \mathbb{Z},\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring.
\end{quote}

\textit{Proof of Theorem 3.1.} Trivially, $\lambda^{0}\left(  x\right)  =1$
and $\lambda^{1}\left(  x\right)  =x$ for every $x\in\mathbb{Z}$. The only
challenge, if there is a challenge in this proof, is to verify the identity
(\ref{lambda1}) for $K=\mathbb{Z}$. In other words, we have to prove that%
\begin{equation}
\dbinom{x+y}{k}=\sum_{i=0}^{k}\dbinom{x}{i}\dbinom{y}{k-i} \label{vandermonde}%
\end{equation}
for every $k\in\mathbb{N},$ $x\in\mathbb{Z}$ and $y\in\mathbb{Z}.$ This is the
so-called \textit{Vandermonde convolution identity}, and probably its shortest
proof is to fix $k\in\mathbb{N}$, then notice that it is a polynomial identity
in both $x$ and $y$, so it is enough to prove it for all natural $x$ and $y$
(because a polynomial identity holding for all natural variables must hold
everywhere). But for $x$ and $y$ natural, we have%
\begin{align*}
\sum_{k=0}^{x+y}\sum_{i=0}^{k}\dbinom{x}{i}\dbinom{y}{k-i}T^{k}  &
=\underbrace{\sum_{i=0}^{x}\dbinom{x}{i}T^{i}}_{\substack{=\left(  1+T\right)
^{x}\text{ by the}\\\text{binomial formula}}}\cdot\underbrace{\sum_{j=0}%
^{y}\dbinom{y}{j}T^{j}}_{\substack{=\left(  1+T\right)  ^{y}\text{ by
the}\\\text{binomial formula}}}\\
&  =\left(  1+T\right)  ^{x}\cdot\left(  1+T\right)  ^{y}=\left(  1+T\right)
^{x+y}=\sum_{k=0}^{x+y}\dbinom{x+y}{k}T^{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the binomial formula}\right)
\end{align*}
in the polynomial ring $\mathbb{Z}\left[  T\right]  $, and thus
(\ref{vandermonde}) follows by comparison of
coefficients.\footnote{\textit{Remark.} It is tempting to apply this argument
to the general case (where $x$ and $y$ are not required to be natural),
because the binomial formula holds for negative exponents as well (of course,
this requires working in the formal series ring $\mathbb{Z}\left[  \left[
T\right]  \right]  $ rather than in the polynomial ring $\mathbb{Z}\left[
T\right]  $), but I am not sure whether this argument is free of circular
reasoning because it is not at all obvious that $\left(  1+T\right)
^{x}\left(  1+T\right)  ^{y}=\left(  1+T\right)  ^{x+y}$ in $\mathbb{Z}\left[
\left[  T\right]  \right]  $ for negative $x$ and $y$, and I even fear that
this is usually proven using (\ref{vandermonde}).} This proves Theorem 3.1.

Our next example is a generalization of Theorem 3.1:

\begin{quote}
\textbf{Definition.} Let $K$ be a ring. We call $K$ a \textit{binomial ring}
if and only if none of the elements $1,$ $2,$ $3,$ $...$ is a zero-divisor in
$K$, and $n!\mid x\cdot\left(  x-1\right)  \cdot...\cdot\left(  x-i+1\right)
$ for every $x\in K$ and every $n\in\mathbb{N}$.

\textbf{Theorem 3.2.} Let $K$ be a binomial ring. For every $i\in\mathbb{N}$,
define a map $\lambda^{i}:K\rightarrow K$ by $\lambda^{i}\left(  x\right)
=\dbinom{x}{i}$ for every $x\in K$ (where, again, $\dbinom{x}{i}$ is defined
to be $\dfrac{x\cdot\left(  x-1\right)  \cdot...\cdot\left(  x-i+1\right)
}{i!}$). Then, $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ is a $\lambda$-ring.
\end{quote}

Such $\lambda$-rings $K$ are called \textit{binomial }$\lambda$\textit{-rings}.

\textit{Proof of Theorem 3.2.} Obviously, $\lambda^{0}\left(  x\right)  =1$
and $\lambda^{1}\left(  x\right)  =x$ for every $x\in K$, so it only remains
to show that (\ref{lambda1}) is satisfied. This means proving
(\ref{vandermonde}) for every $k\in\mathbb{N},$ $x\in K$ and $y\in K$. But
this is easy now: Fix $k\in\mathbb{N}$. Then, (\ref{vandermonde}) is a
polynomial identity in both $x$ and $y$, and since we know that it holds for
every $x\in\mathbb{Z}$ and every $y\in\mathbb{Z}$ (as we have seen in the
proof of Theorem 3.1), it follows that it holds for every $x\in K$ and every
$y\in K$ (since a polynomial identity holding for all integer variables must
hold everywhere). This completes the proof of Theorem 3.2.

Obviously, the $\lambda$-ring $\left(  \mathbb{Z},\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ defined in Theorem 3.1 is a binomial $\lambda
$-ring. For other examples of binomial $\lambda$-rings, see Exercise 3.1. Of
course, every $\mathbb{Q}$-algebra is a binomial ring as well.

\subsection{Adjoining a polynomial variable to a $\lambda$-ring}

Binomial $\lambda$-rings are not the main examples of $\lambda$-rings. We will
see an important example of $\lambda$-rings in Theorem 5.1 and Exercise 6.1.
Another simple way to construct new examples from known ones is the following one:

\begin{quote}
\textbf{Definition.} Let $K$ be a ring. Let $L$ be a $K$-algebra. Consider the
ring $K\left[  \left[  T\right]  \right]  $ of formal power series in the
indeterminate $T$ over the ring $K$, and the ring $L\left[  \left[  T\right]
\right]  $ of formal power series in the indeterminate $T$ over the ring $L$.
For every $\mu\in L$, we can define a $K$-algebra homomorphism
$\operatorname*{ev}_{\mu T}:K\left[  \left[  T\right]  \right]  \rightarrow
L\left[  \left[  T\right]  \right]  $ by setting $\operatorname*{ev}_{\mu
T}\left(  \sum\limits_{i\in\mathbb{N}}a_{i}T^{i}\right)  =\sum\limits_{i\in
\mathbb{N}}a_{i}\mu^{i}T^{i}$ for every power series $\sum\limits_{i\in
\mathbb{N}}a_{i}T^{i}\in K\left[  \left[  T\right]  \right]  $ (which
satisfies $a_{i}\in K$ for every $i\in\mathbb{N}$). (In other words,
$\operatorname*{ev}_{\mu T}$ is the map that takes any power series in $T$ and
replaces every $T$ in this power series by $\mu T$.)

\textbf{Theorem 3.3.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Consider the polynomial ring
$K\left[  S\right]  $. For every $i\in\mathbb{N}$, define a map $\overline
{\lambda}^{i}:K\left[  S\right]  \rightarrow K\left[  S\right]  $ as follows:
For every $\sum\limits_{j\in\mathbb{N}}a_{j}S^{j}\in K\left[  S\right]  $
(with $a_{j}\in K$ for every $j\in\mathbb{N}$), let $\overline{\lambda}%
^{i}\left(  \sum\limits_{j\in\mathbb{N}}a_{j}S^{j}\right)  $ be the
coefficient of the power series $\prod\limits_{j\in\mathbb{N}}\lambda_{S^{j}%
T}\left(  a_{j}\right)  \in\left(  K\left[  S\right]  \right)  \left[  \left[
T\right]  \right]  $ before $T^{i}$, where the power series $\lambda_{S^{j}%
T}\left(  a_{j}\right)  \in\left(  K\left[  S\right]  \right)  \left[  \left[
T\right]  \right]  $ is defined as $\operatorname*{ev}_{S^{j}T}\left(
\lambda_{T}\left(  a_{j}\right)  \right)  $.

\textbf{(a)} Then, $\left(  K\left[  S\right]  ,\left(  \overline{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring. The ring $K$ is
a sub-$\lambda$-ring of $\left(  K\left[  S\right]  ,\left(  \overline
{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $.

\textbf{(b)} For every $a\in K$ and $\alpha\in\mathbb{N}$, we have
$\overline{\lambda}^{i}\left(  aS^{\alpha}\right)  =\lambda^{i}\left(
a\right)  S^{\alpha i}$ for every $i\in\mathbb{N}$.
\end{quote}

\textit{Proof of Theorem 3.3.} \textbf{(a)} Define a map $\overline{\lambda
}_{T}:K\left[  S\right]  \rightarrow\left(  K\left[  S\right]  \right)
\left[  \left[  T\right]  \right]  $ by $\overline{\lambda}_{T}\left(
u\right)  =\sum\limits_{i\in\mathbb{N}}\overline{\lambda}^{i}\left(  u\right)
T^{i}$ for every $u\in K\left[  S\right]  $. Then, according to the definition
of the maps $\overline{\lambda}^{i}$, we have $\overline{\lambda}_{T}\left(
\sum\limits_{j\in\mathbb{N}}a_{j}S^{j}\right)  =\prod\limits_{j\in\mathbb{N}%
}\lambda_{S^{j}T}\left(  a_{j}\right)  \in\left(  K\left[  S\right]  \right)
\left[  \left[  T\right]  \right]  $ for every $\sum\limits_{j\in\mathbb{N}%
}a_{j}S^{j}\in K\left[  S\right]  $ (with $a_{j}\in K$ for every
$j\in\mathbb{N}$).

But by Theorem 2.1 \textbf{(a)}, proving that $\left(  K\left[  S\right]
,\left(  \overline{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a
$\lambda$-ring boils down to verifying that%
\[
\overline{\lambda}_{T}\left(  \sum\limits_{j\in\mathbb{N}}a_{j}S^{j}%
+\sum\limits_{j\in\mathbb{N}}b_{j}S^{j}\right)  =\overline{\lambda}_{T}\left(
\sum\limits_{j\in\mathbb{N}}a_{j}S^{j}\right)  \cdot\overline{\lambda}%
_{T}\left(  \sum\limits_{j\in\mathbb{N}}b_{j}S^{j}\right)
\]
for every $\sum\limits_{j\in\mathbb{N}}a_{j}S^{j}\in K\left[  S\right]  $ and
$\sum\limits_{j\in\mathbb{N}}b_{j}S^{j}\in K\left[  S\right]  $. This is
clear, because%
\begin{align*}
\overline{\lambda}_{T}\left(  \sum\limits_{j\in\mathbb{N}}a_{j}S^{j}%
+\sum\limits_{j\in\mathbb{N}}b_{j}S^{j}\right)   &  =\overline{\lambda}%
_{T}\left(  \sum\limits_{j\in\mathbb{N}}\left(  a_{j}+b_{j}\right)
S^{j}\right)  =\prod\limits_{j\in\mathbb{N}}\underbrace{\lambda_{S^{j}%
T}\left(  a_{j}+b_{j}\right)  }_{\substack{=\lambda_{S^{j}T}\left(
a_{j}\right)  \cdot\lambda_{S^{j}T}\left(  b_{j}\right)  ,\\\text{since
}\lambda_{T}\left(  a_{j}+b_{j}\right)  =\lambda_{T}\left(  a_{j}\right)
\cdot\lambda_{T}\left(  b_{j}\right)  \\\text{by Theorem 2.1 \textbf{(a)}}}}\\
&  =\prod\limits_{j\in\mathbb{N}}\lambda_{S^{j}T}\left(  a_{j}\right)
\cdot\prod\limits_{j\in\mathbb{N}}\lambda_{S^{j}T}\left(  b_{j}\right)
=\overline{\lambda}_{T}\left(  \sum\limits_{j\in\mathbb{N}}a_{j}S^{j}\right)
\cdot\overline{\lambda}_{T}\left(  \sum\limits_{j\in\mathbb{N}}b_{j}%
S^{j}\right)  .
\end{align*}
Thus, $\left(  K\left[  S\right]  ,\left(  \overline{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring. The rest of Theorem 3.3
\textbf{(a)} is yet easier to verify.

\textbf{(b)} We have $\overline{\lambda}_{T}\left(  aS^{\alpha}\right)
=\lambda_{S^{\alpha}T}\left(  a\right)  $ as a particular case of
$\overline{\lambda}_{T}\left(  \sum\limits_{j\in\mathbb{N}}a_{j}S^{j}\right)
=\prod\limits_{j\in\mathbb{N}}\lambda_{S^{j}T}\left(  a_{j}\right)  $. The
equation $\overline{\lambda}^{i}\left(  aS^{\alpha}\right)  =\lambda
^{i}\left(  a\right)  S^{\alpha i}$ for every $i\in\mathbb{N}$ follows by
comparing coefficients in $\overline{\lambda}_{T}\left(  aS^{\alpha}\right)
=\lambda_{S^{\alpha}T}\left(  a\right)  $. Thus, Theorem 3.3 \textbf{(b)} is proven.

The exercises below give some more examples.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 3.1.} Let $p\in\mathbb{N}$ be a prime. Prove that the
localization $\left\{  1,p,p^{2},...\right\}  ^{-1}\mathbb{Z}$ of the ring
$\mathbb{Z}$ at the multiplicative subset $\left\{  1,p,p^{2},...\right\}  $
is a binomial ring.

{\small [One of the reasons I include this exercise here that I am looking for
a nice solution.]}

\textit{Exercise 3.2.} Let $K$ be a ring where none of the elements $1,$ $2,$
$3,$ $...$ is a zero-divisor. Let $E$ be a subset of $K$ that generates $K$ as
a ring. Assume that $n!\mid x\cdot\left(  x-1\right)  \cdot...\cdot\left(
x-n+1\right)  $ for every $x\in E$ and every $n\in\mathbb{N}$. Prove that $K$
is a binomial ring.

{\small [Again, I don't really like the solution that I have.]}

\textit{Exercise 3.3.} \textbf{(a)} Let $K$ be a binomial ring. Let $p\in
K\left[  \left[  T\right]  \right]  $ be a formal power series with
coefficient $1$ before $T^{0}$ (we will later denote the set of such power
series by $1+K\left[  \left[  T\right]  \right]  ^{+}$). For every
$i\in\mathbb{N}$, define a map $\lambda^{i}:K\rightarrow K$ as follows: For
every $x\in K$, let $\lambda^{i}\left(  x\right)  $ be the coefficient of the
formal power series $\left(  1+pT\right)  ^{x}$ (which is defined as
$\sum\limits_{k\in\mathbb{N}}\dbinom{x}{k}\left(  pT\right)  ^{k}%
\ \ \ \ $\footnote{If $K$ is a $\mathbb{Q}$-algebra, then this power series
also equals $\exp\left(  x\log\left(  1+pT\right)  \right)  $, where
$\log\left(  1+T\right)  $ is the power series $\log\left(  1+T\right)
=\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\dfrac{\left(
-1\right)  ^{i-1}}{i}T^{i}$.}) before $T^{i}$. Prove that $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring.

\textbf{(b)} If $p=1$, prove that this $\lambda$-ring is the one defined in
Theorem 3.2.

\textit{Exercise 3.4.} Let $M$ be a commutative monoid with neutral element,
written multiplicatively (this means, in particular, that we denote the
neutral element of $M$ as $1$). Define a $\mathbb{Z}$-algebra $\mathbb{Z}%
\left[  M\right]  $ as follows:

As a $\mathbb{Z}$-module, let $\mathbb{Z}\left[  M\right]  $ be the free
$\mathbb{Z}$-module with the basis $M$. Let the multiplication on
$\mathbb{Z}\left[  M\right]  $ be the $\mathbb{Z}$-linear extension of the
multiplication on the monoid $M$.

For every $i\in\mathbb{N}$, define a map $\lambda^{i}:\mathbb{Z}\left[
M\right]  \rightarrow\mathbb{Z}\left[  M\right]  $ as follows: For every
$\sum\limits_{m\in M}\alpha_{m}m\in\mathbb{Z}\left[  M\right]  $ (with
$\alpha_{m}\in\mathbb{Z}$ for every $m\in M$), let $\lambda^{i}\left(
\sum\limits_{m\in M}\alpha_{m}m\right)  $ be the coefficient of the power
series $\prod\limits_{m\in M}\left(  1+mT\right)  ^{\alpha_{m}}\in\left(
\mathbb{Z}\left[  M\right]  \right)  \left[  \left[  T\right]  \right]  $
before $T^{i}$.

Prove that $\left(  \mathbb{Z}\left[  M\right]  ,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring.

\textit{Exercise 3.5.} \textbf{(a)} Let $M$ be a commutative monoid with
neutral element, written multiplicatively (this means, in particular, that we
denote the neutral element of $M$ as $1$). Let $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring.

Define a $K$-algebra $K\left[  M\right]  $ as follows:

As a $K$-module, let $K\left[  M\right]  $ be the free $K$-module with the
basis $M$. Let the multiplication on $K\left[  M\right]  $ be the $K$-linear
extension of the multiplication on the monoid $M$.

For every $i\in\mathbb{N}$, define a map $\overline{\lambda}^{i}:K\left[
M\right]  \rightarrow K\left[  M\right]  $ as follows: For every
$\sum\limits_{m\in M}\alpha_{m}m\in K\left[  M\right]  $ (with $\alpha_{m}\in
K$ for every $m\in M$), let $\overline{\lambda}^{i}\left(  \sum\limits_{m\in
M}\alpha_{m}m\right)  $ be the coefficient of the power series $\prod
\limits_{m\in M}\lambda_{mT}\left(  \alpha_{m}\right)  \in\left(  K\left[
M\right]  \right)  \left[  \left[  T\right]  \right]  $ before $T^{i}$, where
the power series $\lambda_{mT}\left(  \alpha_{m}\right)  \in\left(  K\left[
M\right]  \right)  \left[  \left[  T\right]  \right]  $ is defined as
$\operatorname*{ev}_{mT}\left(  \lambda_{T}\left(  \alpha_{m}\right)  \right)
$.

Prove that $\left(  K\left[  M\right]  ,\left(  \overline{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring. The ring $K$ is a
sub-$\lambda$-ring of $\left(  K\left[  M\right]  ,\left(  \overline{\lambda
}^{i}\right)  _{i\in\mathbb{N}}\right)  $. For every $a\in K$ and $m\in M$, we
have $\overline{\lambda}^{i}\left(  am\right)  =\lambda^{i}\left(  a\right)
m^{i}$ for every $i\in\mathbb{N}$.

\textbf{(b)} Show that Exercise 3.4 is a particular case of \textbf{(a)} for
$K=\mathbb{Z}$, and that Theorem 3.3 is a particular case of \textbf{(a)} for
$M\cong\mathbb{N}$ (where $\mathbb{N}$ denotes the \textit{additive} monoid
$\mathbb{N}$).
\end{quotation}

\section{Intermezzo: Symmetric polynomials}

Our next plan is to introduce a rather general example of $\lambda$-rings that
we will use as a prototype to the notion of \textit{special }$\lambda
$\textit{-rings}. Before we do this, we need some rather clumsy theory of
symmetric polynomials. In case you can take the proofs for granted, you don't
need to read much of this paragraph - you only need to know Theorems 4.3 and
4.4 and the preceding definitions (only the goals of the definitions; not the
actual constructions of the polynomials $P_{k}$ and $P_{k,j}$).

\subsection{Symmetric polynomials are generated by the elementary symmetric
ones}

\begin{quote}
\textbf{Theorem 4.1 (characterization of symmetric polynomials).} Let $K$ be a
ring. Let $m\in\mathbb{N}$. Consider the ring $K\left[  U_{1},U_{2}%
,...,U_{m}\right]  $ (the polynomial ring in $m$ indeterminates $U_{1},$
$U_{2},$ $...,$ $U_{m}$ over the ring $K$). For every $i\in\mathbb{N}$, let
$X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ be the so-called
$i$\textit{-th elementary symmetric polynomial} in the variables $U_{1},$
$U_{2},$ $...,$ $U_{m}$. (In particular, $X_{0}=1$ and $X_{i}=0$ for every
$i>m$.)

A polynomial $P\in K\left[  U_{1},U_{2},...,U_{m}\right]  $ is called
\textit{symmetric} if it satisfies $P\left(  U_{1},U_{2},...,U_{m}\right)
=P\left(  U_{\pi\left(  1\right)  },U_{\pi\left(  2\right)  },...,U_{\pi
\left(  m\right)  }\right)  $ for every permutation $\pi$ of the set $\left\{
1,2,...,m\right\}  $.

\textbf{(a)} Let $P\in K\left[  U_{1},U_{2},...,U_{m}\right]  $ be a symmetric
polynomial. Then, there exists one and only one polynomial $Q\in
\underbrace{K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]
}_{\text{polynomial ring}}$ such that $P\left(  U_{1},U_{2},...,U_{m}\right)
=Q\left(  X_{1},X_{2},...,X_{m}\right)  $.\ \ \ \ \footnote{In other words,
the $K$-subalgebra%
\[
\left\{  P\in K\left[  U_{1},U_{2},...,U_{m}\right]  \ \mid\ P\text{ is
symmetric}\right\}
\]
of the polynomial ring $K\left[  U_{1},U_{2},...,U_{m}\right]  $ is generated
by the elements $X_{1},$ $X_{2},$ $...,$ $X_{m}$. Moreover, these elements
$X_{1},$ $X_{2},$ $...,$ $X_{m}$ are algebraically independent, so that the
map%
\[
\underbrace{K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]
}_{\text{polynomial ring}}\rightarrow\left\{  P\in K\left[  U_{1}%
,U_{2},...,U_{m}\right]  \ \mid\ P\text{ is symmetric}\right\}
\]
which maps every $\alpha_{i}$ to $X_{i}$ is a bijection.}

\textbf{(b)} Let $\ell\in\mathbb{N}$. Assume, moreover, that $P\in K\left[
U_{1},U_{2},...,U_{m}\right]  $ is a symmetric polynomial of total degree
$\leq\ell$ in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$. Then, the
variables $\alpha_{i}$ for $i>\ell$ do not appear in the polynomial $Q$.

There is a canonical homomorphism $K\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{m}\right]  \rightarrow K\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{\ell}\right]  $ (which maps every $\alpha_{i}$ to $\left\{
\begin{array}
[c]{c}%
\alpha_{i},\text{ if }i\leq\ell;\\
0,\text{ if }i>\ell
\end{array}
\right.  $)\ \ \ \ \footnote{This homomorphism is a surjection if $\ell\leq m$
and an injection if $\ell\geq m$.}. If we denote by $Q_{\ell}$ the image of
$Q\in K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $ under this
homomorphism, then, $P\left(  U_{1},U_{2},...,U_{m}\right)  =Q\left(
X_{1},X_{2},...,X_{m}\right)  =Q_{\ell}\left(  X_{1},X_{2},...,X_{\ell
}\right)  $.
\end{quote}

\subsection{UV-symmetric polynomials are generated by the elementary symmetric
ones}

We are not going to prove Theorem 4.1 here, since pretty much every good
algebra book does it.\footnote{Only one remark about Theorem 4.1 \textbf{(b)}:
We have $Q\left(  X_{1},X_{2},...,X_{m}\right)  =Q_{\ell}\left(  X_{1}%
,X_{2},...,X_{\ell}\right)  $, because the variables $\alpha_{i}$ for $i>\ell$
do not appear in the polynomial $Q$.} But we are going to extend it to two
sets of indeterminates:

\begin{quote}
\textbf{Theorem 4.2 (characterization of UV-symmetric polynomials).} Let $K$
be a ring. Let $m\in\mathbb{N}$ and $n\in\mathbb{N}$. Consider the ring
$K\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $ (the
polynomial ring in $m+n$ indeterminates $U_{1},$ $U_{2},$ $...,$ $U_{m},$
$V_{1},$ $V_{2},$ $...,$ $V_{n}$ over the ring $K$). For every $i\in
\mathbb{N}$, let $X_{i}=\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$
be the $i$-th elementary symmetric polynomial in the variables $U_{1},$
$U_{2},$ $...,$ $U_{m}$. For every $j\in\mathbb{N}$, let $Y_{j}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,n\right\}  ;\\\left\vert
S\right\vert =j}}\prod\limits_{k\in S}V_{k}$ be the $j$-th elementary
symmetric polynomial in the variables $V_{1},$ $V_{2},$ $...,$ $V_{n}$.

A polynomial $P\in K\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}%
\right]  $ is called \textit{UV-symmetric} if it satisfies%
\[
P\left(  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right)  =P\left(
U_{\pi\left(  1\right)  },U_{\pi\left(  2\right)  },...,U_{\pi\left(
m\right)  },V_{\sigma\left(  1\right)  },V_{\sigma\left(  2\right)
},...,V_{\sigma\left(  n\right)  }\right)
\]
for every permutation $\pi$ of the set $\left\{  1,2,...,m\right\}  $ and
every permutation $\sigma$ of the set $\left\{  1,2,...,n\right\}  $.

\textbf{(a)} Let $P\in K\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2}%
,...,V_{n}\right]  $ be a UV-symmetric polynomial. Then, there exists one and
only one polynomial $Q\in K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}%
,\beta_{1},\beta_{2},...,\beta_{n}\right]  $ such that $P\left(  U_{1}%
,U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right)  =Q\left(  X_{1},X_{2}%
,...,X_{m},Y_{1},Y_{2},...,Y_{n}\right)  $.\ \ \ \ \footnote{In other words,
the $K$-subalgebra%
\[
\left\{  P\in K\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]
\ \mid\ P\text{ is UV-symmetric}\right\}
\]
of the polynomial ring $K\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2}%
,...,V_{n}\right]  $ is generated by the elements $X_{1},$ $X_{2},$ $...,$
$X_{m},$ $Y_{1},$ $Y_{2},$ $...,$ $Y_{n}$. Moreover, these elements $X_{1},$
$X_{2},$ $...,$ $X_{m},$ $Y_{1},$ $Y_{2},$ $...,$ $Y_{n}$ are algebraically
independent, so that the map%
\[
\underbrace{K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m},\beta_{1},\beta
_{2},...,\beta_{n}\right]  }_{\text{polynomial ring}}\rightarrow\left\{  P\in
K\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  \ \mid\ P\text{
is UV-symmetric}\right\}
\]
which maps every $\alpha_{i}$ to $X_{i}$ and every $\beta_{j}$ to $Y_{j}$ is a
bijection.}

\textbf{(b)} Let $\ell\in\mathbb{N}$ and $k\in\mathbb{N}$. Assume, moreover,
that $P\in K\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $ is a
UV-symmetric polynomial of total degree $\leq\ell$ in the variables $U_{1},$
$U_{2},$ $...,$ $U_{m}$ and of total degree $\leq k$ in the variables $V_{1},$
$V_{2},$ $...,$ $V_{n}.$ Then, neither the variables $\alpha_{i}$ for $i>\ell$
nor the variables $\beta_{j}$ for $j>k$ ever appear in the polynomial $Q$.

There is a canonical homomorphism%
\[
K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m},\beta_{1},\beta_{2}%
,...,\beta_{n}\right]  \rightarrow K\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{\ell},\beta_{1},\beta_{2},...,\beta_{k}\right]
\]
(which maps every $\alpha_{i}$ to $\left\{
\begin{array}
[c]{c}%
\alpha_{i},\text{ if }i\leq\ell;\\
0,\text{ if }i>\ell
\end{array}
\right.  $ and every $\beta_{j}$ to $\left\{
\begin{array}
[c]{c}%
\beta_{j},\text{ if }j\leq k;\\
0,\text{ if }j>k
\end{array}
\right.  $). If we denote by $Q_{\ell,k}$ the image of $Q\in K\left[
\alpha_{1},\alpha_{2},...,\alpha_{m},\beta_{1},\beta_{2},...,\beta_{n}\right]
$ under this homomorphism, then%
\[
P\left(  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right)  =Q_{\ell
,k}\left(  X_{1},X_{2},...,X_{\ell},Y_{1},Y_{2},...,Y_{k}\right)  .
\]



\end{quote}

\textit{Proof of Theorem 4.2 (\textbf{very} roughly sketched).} \textbf{(a)}
Consider $P$ as a polynomial in the indeterminates $V_{1},$ $V_{2},$ $...,$
$V_{n}$ over the ring $K\left[  U_{1},U_{2},...,U_{m}\right]  $. Then, $P$ is
a symmetric polynomial in these indeterminates $V_{1},$ $V_{2},$ $...,$
$V_{n}$, so Theorem 4.1 \textbf{(a)} yields the existence of one and only one
polynomial $\widehat{Q}\in\underbrace{\left(  K\left[  U_{1},U_{2}%
,...,U_{m}\right]  \right)  \left[  \beta_{1},\beta_{2},...,\beta_{n}\right]
}_{\text{polynomial ring}}$ such that $P\left(  U_{1},U_{2},...,U_{m}%
,V_{1},V_{2},...,V_{n}\right)  =\widehat{Q}\left(  Y_{1},Y_{2},...,Y_{n}%
\right)  $. Now, for every $n$-tuple $\left(  \lambda_{1},\lambda
_{2},...,\lambda_{n}\right)  \in\mathbb{N}^{n}$, the coefficient of this
polynomial $\widehat{Q}$ before $\beta_{1}^{\lambda_{1}}\beta_{2}^{\lambda
_{2}}...\beta_{n}^{\lambda_{n}}$ is a symmetric polynomial in the variables
$U_{1},$ $U_{2},$ $...,$ $U_{m}\ \ \ \ $\footnote{Okay, the "symmetric" part
may need an explanation.
\par
{}In fact, let $\sigma$ be a permutation of the set $\left\{
1,2,...,m\right\}  .$
\par
Let $\rho$ be the canonical $K$-algebra isomorphism $\left(  K\left[
U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \beta_{1},\beta_{2}%
,...,\beta_{n}\right]  \rightarrow\left(  K\left[  \beta_{1},\beta
_{2},...,\beta_{n}\right]  \right)  \left[  U_{1},U_{2},...,U_{m}\right]  $.
\par
Let $\widehat{Q}_{\sigma}\in\left(  K\left[  U_{1},U_{2},...,U_{m}\right]
\right)  \left[  \beta_{1},\beta_{2},...,\beta_{n}\right]  $ be the polynomial
defined by $\widehat{Q}_{\sigma}=\rho^{-1}\left(  \left(  \rho\left(
\widehat{Q}\right)  \right)  \left(  U_{\sigma\left(  1\right)  }%
,U_{\sigma\left(  2\right)  },...,U_{\sigma\left(  m\right)  }\right)
\right)  .$ Then, $P\left(  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}%
\right)  =\widehat{Q}\left(  Y_{1},Y_{2},...,Y_{n}\right)  $ yields $P\left(
U_{\sigma\left(  1\right)  },U_{\sigma\left(  2\right)  },...,U_{\sigma\left(
m\right)  },V_{1},V_{2},...,V_{n}\right)  =\widehat{Q}_{\sigma}\left(
Y_{1},Y_{2},...,Y_{n}\right)  $. But $P\left(  U_{1},U_{2},...,U_{m}%
,V_{1},V_{2},...,V_{n}\right)  =P\left(  U_{\sigma\left(  1\right)
},U_{\sigma\left(  2\right)  },...,U_{\sigma\left(  m\right)  },V_{1}%
,V_{2},...,V_{n}\right)  $ (since $P$ is UV-symmetric). Thus, $\widehat{Q}%
\left(  Y_{1},Y_{2},...,Y_{n}\right)  =\widehat{Q}_{\sigma}\left(  Y_{1}%
,Y_{2},...,Y_{n}\right)  $ for every permutation $\sigma$ of $\left\{
1,2,...,m\right\}  $. This yields $\widehat{Q}=\widehat{Q}_{\sigma}$ for every
permutation $\sigma$ of $\left\{  1,2,...,m\right\}  $ (since $Y_{1},$
$Y_{2},$ $...,$ $Y_{n}$ are algebraically independent over $K\left[
U_{1},U_{2},...,U_{m}\right]  $, as we can see by applying Theorem 4.1 to
$K\left[  U_{1},U_{2},...,U_{m}\right]  $ instead of $K$ and to $V_{1},$
$V_{2},$ $...,$ $V_{n}$ instead of $U_{1},$ $U_{2},$ $...,$ $U_{m}$). This
means that the coefficient of this polynomial $\widehat{Q}$ before $\beta
_{1}^{\lambda_{1}}\beta_{2}^{\lambda_{2}}...\beta_{n}^{\lambda_{n}}$ is a
symmetric polynomial in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$ for
every $n$-tuple $\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)
\in\mathbb{N}^{n}$.}. Hence, by Theorem 4.1 \textbf{(a)}, there exists a
polynomial $R_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)  }%
\in\underbrace{K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]
}_{\text{polynomial ring}}$ such that the coefficient of the polynomial
$\widehat{Q}$ before $\beta_{1}^{\lambda_{1}}\beta_{2}^{\lambda_{2}}%
...\beta_{n}^{\lambda_{n}}$ is $R_{\left(  \lambda_{1},\lambda_{2}%
,...,\lambda_{n}\right)  }\left(  X_{1},X_{2},...,X_{m}\right)  $. Thus,%
\begin{align*}
&  P\left(  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right)  =\widehat{Q}%
\left(  Y_{1},Y_{2},...,Y_{n}\right) \\
&  =\sum_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)
\in\mathbb{N}^{n}}\underbrace{\left(  \text{the coefficient of the polynomial
}\widehat{Q}\text{ before }\beta_{1}^{\lambda_{1}}\beta_{2}^{\lambda_{2}%
}...\beta_{n}^{\lambda_{n}}\right)  }_{=R_{\left(  \lambda_{1},\lambda
_{2},...,\lambda_{n}\right)  }\left(  X_{1},X_{2},...,X_{m}\right)  }%
Y_{1}^{\lambda_{1}}Y_{2}^{\lambda_{2}}...Y_{n}^{\lambda_{n}}\\
&  =\sum_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)
\in\mathbb{N}^{n}}R_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)
}\left(  X_{1},X_{2},...,X_{m}\right)  Y_{1}^{\lambda_{1}}Y_{2}^{\lambda_{2}%
}...Y_{n}^{\lambda_{n}}.
\end{align*}
Thus, the polynomial $Q\in K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}%
,\beta_{1},\beta_{2},...,\beta_{n}\right]  $ defined by%
\[
Q=\sum_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)  \in
\mathbb{N}^{n}}R_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)
}\left(  \alpha_{1},\alpha_{2},...,\alpha_{m}\right)  \beta_{1}^{\lambda_{1}%
}\beta_{2}^{\lambda_{2}}...\beta_{n}^{\lambda_{n}}%
\]
satisfies $P\left(  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right)
=Q\left(  X_{1},X_{2},...,X_{m},Y_{1},Y_{2},...,Y_{n}\right)  $. It only
remains to prove that this is the only such polynomial. This amounts to
showing that $X_{1},$ $X_{2},$ $...,$ $X_{m},$ $Y_{1},$ $Y_{2},$ $...,$
$Y_{n}$ are algebraically independent over $K$. But this is clear (from
Exercise 4.3, applied to $S=K\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]  $, $T=K\left[  U_{1},U_{2},...,U_{m}\right]  $,
$p_{i}=X_{i}$ and $q_{j}=Y_{j}$), since $X_{1},$ $X_{2},$ $...,$ $X_{m}$ are
algebraically independent over $K$ (by Theorem 4.1 \textbf{(a)}) and the
variables $Y_{1},$ $Y_{2},$ $...,$ $Y_{n}$ are algebraically independent over
$K\left[  U_{1},U_{2},...,U_{m}\right]  $ (by Theorem 4.1 \textbf{(a)},
applied to $K\left[  U_{1},U_{2},...,U_{m}\right]  $ instead of $K$ and to
$V_{1},$ $V_{2},$ $...,$ $V_{n}$ instead of $U_{1},$ $U_{2},$ $...,$ $U_{m}$).

For part \textbf{(b)}, we argue the same way as in \textbf{(a)}, but applying
Theorem 4.1 \textbf{(b)} along with Theorem 4.1 \textbf{(a)}.

Note that in the following, we are going to use Theorems 4.1 and 4.2 for
$K=\mathbb{Z}$ only, until Section 10 where we actually get to use them for
general $K$.

\subsection{Grothendieck's polynomials $P_{k}$}

Theorem 4.2 allows us to make the following definition:

\begin{quote}
\textbf{Definition.} Let $k\in\mathbb{N}$. Our goal now is to define a
polynomial $P_{k}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{k},\beta_{1},\beta_{2},...,\beta_{k}\right]  $ such that%
\begin{equation}
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=P_{k}\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2},...,Y_{k}%
\right)  \label{Pk1}%
\end{equation}
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]  $ for every $n\in\mathbb{N}$ and $m\in\mathbb{N}$,
where $X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ is the $i$-th
elementary symmetric polynomial in the variables $U_{1},$ $U_{2},$ $...,$
$U_{m}$ for every $i\in\mathbb{N}$, and $Y_{j}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,n\right\}  ;\\\left\vert
S\right\vert =j}}\prod\limits_{k\in S}V_{k}$ is the $j$-th elementary
symmetric polynomial in the variables $V_{1},$ $V_{2},$ $...,$ $V_{n}$ for
every $j\in\mathbb{N}$.

In order to do this, we first fix some $n\in\mathbb{N}$ and $m\in\mathbb{N}$.
The polynomial%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}\in\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]
\]
is UV-symmetric. Thus, Theorem 4.2 \textbf{(a)} yields that there exists one
and only one polynomial $Q\in\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{m},\beta_{1},\beta_{2},...,\beta_{n}\right]  $ such that%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=Q\left(  X_{1},X_{2},...,X_{m},Y_{1},Y_{2},...,Y_{n}\right)
\]
in $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $.
Since the polynomial $\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  ;\\\left\vert
S\right\vert =k}}\prod\limits_{\left(  i,j\right)  \in S}U_{i}V_{j}$ has total
degree $\leq k$ in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$ and of total
degree $\leq k$ in the variables $V_{1},$ $V_{2},$ $...,$ $V_{n}$, Theorem 4.2
\textbf{(b)} yields that%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=Q_{k,k}\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2}%
,...,Y_{k}\right)  ,
\]
where $Q_{k,k}$ is the image of the polynomial $Q$ under the canonical
homomorphism $\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{m},\beta
_{1},\beta_{2},...,\beta_{n}\right]  \rightarrow\mathbb{Z}\left[  \alpha
_{1},\alpha_{2},...,\alpha_{k},\beta_{1},\beta_{2},...,\beta_{k}\right]  $.
However, this polynomial $Q_{k,k}$ is not independent of $n$ and $m$ yet (as
the polynomial $P_{k}$ that we intend to construct should be), so we call it
$Q_{k,k,\left[  n,m\right]  }$ rather than just $Q_{k,k}$.

Now we forget that we fixed $n\in\mathbb{N}$ and $m\in\mathbb{N}$. We have
learnt that%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=Q_{k,k,\left[  n,m\right]  }\left(  X_{1},X_{2}%
,...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]  $ for every $n\in\mathbb{N}$ and $m\in\mathbb{N}$.
Now, define a polynomial $P_{k}\in\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{k},\beta_{1},\beta_{2},...,\beta_{k}\right]  $ by
$P_{k}=Q_{k,k,\left[  k,k\right]  }.$

\textbf{Theorem 4.3.} \textbf{(a)} The polynomial $P_{k}$ just defined
satisfies the equation (\ref{Pk1}) in the polynomial ring $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $ for every $n\in
\mathbb{N}$ and $m\in\mathbb{N}$. (Hence, the goal mentioned above in the
definition is actually achieved.)

\textbf{(b)} For every $n\in\mathbb{N}$ and $m\in\mathbb{N}$, we have%
\begin{equation}
\prod_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }\left(  1+U_{i}V_{j}T\right)  =\sum_{k\in\mathbb{N}}%
P_{k}\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)  T^{k}
\label{Pk2}%
\end{equation}
in the ring $\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]  \right)  \left[  \left[  T\right]  \right]  $. (Note
that the right hand side of this equation is a power series with coefficient
$1$ before $T^{0}$, since $P_{0}=1$.)
\end{quote}

\textit{Proof of Theorem 4.3.} \textbf{(a)} \textit{1st Step:} Fix
$n\in\mathbb{N}$ and $m\in\mathbb{N}$ such that $n\geq k$ and $m\geq k$. Then,
we claim that $Q_{k,k,\left[  n,m\right]  }=P_{k}$.

\textit{Proof.} The definition of $Q_{k,k,\left[  n,m\right]  }$ yields
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=Q_{k,k,\left[  n,m\right]  }\left(  X_{1},X_{2}%
,...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]  $. Applying the canonical ring epimorphism
$\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]
\rightarrow\mathbb{Z}\left[  U_{1},U_{2},...,U_{k},V_{1},V_{2},...,V_{k}%
\right]  $ (which maps every $U_{i}$ to $\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq k;\\
0,\text{ if }i>k
\end{array}
\right.  $ and every $V_{j}$ to $\left\{
\begin{array}
[c]{c}%
V_{j},\text{ if }j\leq k;\\
0,\text{ if }j>k
\end{array}
\right.  $) to this equation (and noticing that this epimorphism maps every
$X_{i}$ with $i\geq1$ to the corresponding $X_{i}$ of the image ring and every
$Y_{j}$ with $j\geq1$ to the corresponding $Y_{j}$ of the image ring!), we
obtain%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,k\right\}  \times\left\{
1,2,...,k\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=Q_{k,k,\left[  n,m\right]  }\left(  X_{1},X_{2}%
,...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{k},V_{1}%
,V_{2},...,V_{k}\right]  $. On the other hand, the definition of
$Q_{k,k,\left[  k,k\right]  }$ yields%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,k\right\}  \times\left\{
1,2,...,k\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=Q_{k,k,\left[  k,k\right]  }\left(  X_{1},X_{2}%
,...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)
\]
in the same ring. These two equations yield%
\[
Q_{k,k,\left[  n,m\right]  }\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2}%
,...,Y_{k}\right)  =Q_{k,k,\left[  k,k\right]  }\left(  X_{1},X_{2}%
,...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)  .
\]
Since the elements $X_{1},$ $X_{2},$ $...,$ $X_{k},$ $Y_{1},$ $Y_{2},$ $...,$
$Y_{k}$ of $\mathbb{Z}\left[  U_{1},U_{2},...,U_{k},V_{1},V_{2},...,V_{k}%
\right]  $ are algebraically independent (by Theorem 4.2 \textbf{(a)}), this
yields $Q_{k,k,\left[  n,m\right]  }=Q_{k,k,\left[  k,k\right]  }.$ In other
words, $Q_{k,k,\left[  n,m\right]  }=P_{k},$ and the 1st Step is proven.

\textit{2nd Step:} For every $n\in\mathbb{N}$ and $m\in\mathbb{N}$, the
equation (\ref{Pk1}) is satisfied in the polynomial ring $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $.

\textit{Proof.} Let $n^{\prime}\in\mathbb{N}$ be such that $n^{\prime}\geq n$
and $n^{\prime}\geq k$ (such an $n^{\prime}$ clearly exists). Let $m^{\prime
}\in\mathbb{N}$ be such that $m^{\prime}\geq m$ and $m^{\prime}\geq k$ (such
an $m^{\prime}$ clearly exists). Then, the 1st Step (applied to $n^{\prime}$
and $m^{\prime}$ instead of $n$ and $m$) yields that $Q_{k,k,\left[
n^{\prime},m^{\prime}\right]  }=P_{k}.$

The definition of $Q_{k,k,\left[  n^{\prime},m^{\prime}\right]  }$ yields
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m^{\prime}\right\}  \times\left\{
1,2,...,n^{\prime}\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(
i,j\right)  \in S}U_{i}V_{j}=Q_{k,k,\left[  n^{\prime},m^{\prime}\right]
}\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m^{\prime}}%
,V_{1},V_{2},...,V_{n^{\prime}}\right]  $. Applying the canonical ring
epimorphism $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m^{\prime}},V_{1}%
,V_{2},...,V_{n^{\prime}}\right]  \rightarrow\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $ (which maps every $U_{i}$ to
$\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq m;\\
0,\text{ if }i>m
\end{array}
\right.  $ and every $V_{j}$ to $\left\{
\begin{array}
[c]{c}%
V_{j},\text{ if }j\leq n;\\
0,\text{ if }j>n
\end{array}
\right.  $) to this equation (and noticing that this epimorphism maps every
$X_{i}$ with $i\geq1$ to the corresponding $X_{i}$ of the image ring and every
$Y_{j}$ with $j\geq1$ to the corresponding $Y_{j}$ of the image ring!), we
obtain%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}=\underbrace{Q_{k,k,\left[  n^{\prime},m^{\prime}\right]  }%
}_{=P_{k}}\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]  $. Hence, the equation (\ref{Pk1}) is satisfied in
the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1}%
,V_{2},...,V_{n}\right]  .$ This completes the 2nd Step and proves Theorem 4.3
\textbf{(a)}.

\textbf{(b)} We have%
\begin{align*}
\prod_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }\left(  1+U_{i}V_{j}T\right)   &  =\sum_{k\in\mathbb{N}%
}\underbrace{\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}%
}\prod_{\left(  i,j\right)  \in S}U_{i}V_{j}}_{\substack{=P_{k}\left(
X_{1},X_{2},...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)  \\\text{(according to
(\ref{Pk1}))}}}T^{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Exercise 4.2 \textbf{(d)}, applied to}\\
Q=\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \text{,}\\
A=\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}%
\right]  \right)  \left[  \left[  T\right]  \right]  \text{,}\\
\text{ }t=T\text{ and }\alpha_{\left(  i,j\right)  }=U_{i}V_{j}%
\end{array}
\right) \\
&  =\sum_{k\in\mathbb{N}}P_{k}\left(  X_{1},X_{2},...,X_{k},Y_{1}%
,Y_{2},...,Y_{k}\right)  T^{k}.
\end{align*}
This proves Theorem 4.3 \textbf{(b)}.

\textbf{Example.} The above definition of the polynomials $P_{k}$ was rather
abstract. Let us sketch an example of how these polynomials are computed -
namely, let us compute $P_{2}$.

While our definition of $P_{k}$ was somewhat indirect (we constructed $P_{k}$
in multiple steps; while each of these steps is constructive, this still is a
rather long way to $P_{k}$), the important thing about $P_{k}$ is that it
satisfies (\ref{Pk1}). In fact, for every $m\geq k$ and $n\geq k$, the
polynomial $P_{k}$ is uniquely determined by the equation (\ref{Pk1}%
)\footnote{\textit{Proof.} Theorem 4.2 \textbf{(a)} yields that the elements
$X_{1}$, $X_{2}$, $...$, $X_{m}$, $Y_{1}$, $Y_{2}$, $...$, $Y_{n}$ of the
polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2}%
,...,V_{n}\right]  $ are algebraically independent. Since $m\geq k$ and $n\geq
k$, this yields that the elements $X_{1}$, $X_{2}$, $...$, $X_{k}$, $Y_{1}$,
$Y_{2}$, $...$, $Y_{k}$ of the polynomial ring $\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $ are algebraically
independent. Hence, a polynomial $\mathfrak{p}\in\mathbb{Z}\left[  \alpha
_{1},\alpha_{2},...,\alpha_{k},\beta_{1},\beta_{2},...,\beta_{k}\right]  $ is
uniquely determined by the value $\mathfrak{p}\left(  X_{1},X_{2}%
,...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)  $. Thus, the polynomial $P_{k}$ is
uniquely determined by the equation (\ref{Pk1}) (because the equation
(\ref{Pk1}) determines the value $P_{k}\left(  X_{1},X_{2},...,X_{k}%
,Y_{1},Y_{2},...,Y_{k}\right)  $).}, so that we only need (\ref{Pk1}) to find
$P_{k}$.

Since we want to compute $P_{2}$, let us pick $k=2$. Now we need to pick some
$m\geq k$ and $n\geq k$; the best choice is $m=n=2$ (choosing greater $m$ or
$n$ would lead to the same polynomial $P_{k}$ in the end, but the computations
required to obtain it would involve some longer terms). So let $m=n=2$. Then,
the left hand side of (\ref{Pk1}) is%
\begin{align*}
&  \sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}U_{i}V_{j}\\
&  =\sum_{\substack{S\subseteq\left\{  1,2\right\}  \times\left\{
1,2\right\}  ;\\\left\vert S\right\vert =2}}\prod_{\left(  i,j\right)  \in
S}U_{i}V_{j}\\
&  =\prod_{\left(  i,j\right)  \in\left\{  \left(  1,1\right)  ,\left(
1,2\right)  \right\}  }U_{i}V_{j}+\prod_{\left(  i,j\right)  \in\left\{
\left(  1,1\right)  ,\left(  2,1\right)  \right\}  }U_{i}V_{j}+\prod_{\left(
i,j\right)  \in\left\{  \left(  1,1\right)  ,\left(  2,2\right)  \right\}
}U_{i}V_{j}\\
&  \ \ \ \ \ \ \ \ \ \ +\prod_{\left(  i,j\right)  \in\left\{  \left(
1,2\right)  ,\left(  2,1\right)  \right\}  }U_{i}V_{j}+\prod_{\left(
i,j\right)  \in\left\{  \left(  1,2\right)  ,\left(  2,2\right)  \right\}
}U_{i}V_{j}+\prod_{\left(  i,j\right)  \in\left\{  \left(  2,1\right)
,\left(  2,2\right)  \right\}  }U_{i}V_{j}\\
&  =U_{1}^{2}V_{1}V_{2}+2U_{1}U_{2}V_{1}^{2}+2U_{1}U_{2}V_{1}V_{2}+U_{1}%
U_{2}V_{2}^{2}+U_{2}^{2}V_{1}V_{2},
\end{align*}
while the right hand side is%
\[
P_{k}\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)  =P_{2}\left(
X_{1},X_{2},Y_{1},Y_{2}\right)  .
\]
Thus our polynomial $P_{2}$ must satisfy
\[
U_{1}^{2}V_{1}V_{2}+U_{1}U_{2}V_{1}^{2}+2U_{1}U_{2}V_{1}V_{2}+U_{1}U_{2}%
V_{2}^{2}+U_{2}^{2}V_{1}V_{2}=P_{2}\left(  X_{1},X_{2},Y_{1},Y_{2}\right)
\]
in $\mathbb{Z}\left[  U_{1},U_{2},V_{1},V_{2}\right]  $. According to Theorem
4.2 \textbf{(a)}, the polynomial $P_{2}$ is uniquely determined by this
condition, but in order to actually compute it, we need to recall how Theorem
4.2 \textbf{(a)} was proven. In other words, we need to recall how to write a
UV-symmetric polynomial as a polynomial in the elementary symmetric
polynomials $X_{1}$, $X_{2}$, $...$ and $Y_{1}$, $Y_{2}$, $...$.

Let us look what we did in our proof of Theorem 4.2 \textbf{(a)} above, in the
particular case of the UV-symmetric polynomial
\[
U_{1}^{2}V_{1}V_{2}+U_{1}U_{2}V_{1}^{2}+2U_{1}U_{2}V_{1}V_{2}+U_{1}U_{2}%
V_{2}^{2}+U_{2}^{2}V_{1}V_{2}.
\]
In this case, the proof begins by considering $U_{1}^{2}V_{1}V_{2}+2U_{1}%
U_{2}V_{1}^{2}+U_{1}U_{2}V_{1}V_{2}+U_{1}U_{2}V_{2}^{2}+U_{2}^{2}V_{1}V_{2}$
as a polynomial in the indeterminates $V_{1},$ $V_{2}$ over the ring
$\mathbb{Z}\left[  U_{1},U_{2}\right]  $. Then, $P$ is a symmetric polynomial
in these indeterminates $V_{1},$ $V_{2}$. Thus, Theorem 4.1 \textbf{(a)}
yields the existence of one and only one polynomial $\widehat{Q}\in\left(
K\left[  U_{1},U_{2}\right]  \right)  \left[  \beta_{1},\beta_{2}\right]  $
such that%
\[
U_{1}^{2}V_{1}V_{2}+U_{1}U_{2}V_{1}^{2}+2U_{1}U_{2}V_{1}V_{2}+U_{1}U_{2}%
V_{2}^{2}+U_{2}^{2}V_{1}V_{2}=\widehat{Q}\left(  Y_{1},Y_{2}\right)  .
\]
This polynomial $\widehat{Q}$ can be obtained by any algorithm which writes a
symmetric polynomial as a polynomial in the elementary symmetric polynomials;
I assume that you know such an algorithm (if not, read it up; most proofs of
Theorem 4.1 \textbf{(a)} give such an algorithm). Applying this algorithm, we
get
\[
U_{1}^{2}V_{1}V_{2}+U_{1}U_{2}V_{1}^{2}+2U_{1}U_{2}V_{1}V_{2}+U_{1}U_{2}%
V_{2}^{2}+U_{2}^{2}V_{1}V_{2}=\left(  U_{1}^{2}+U_{2}^{2}\right)  Y_{2}%
+U_{1}U_{2}Y_{1}^{2},
\]
so that $\widehat{Q}=\left(  U_{1}^{2}+U_{2}^{2}\right)  \beta_{2}+U_{1}%
U_{2}\beta_{1}^{2}$.

Now, for every $2$-tuple $\left(  \lambda_{1},\lambda_{2}\right)
\in\mathbb{N}^{2}$, the coefficient of this polynomial $\widehat{Q}$ before
$\beta_{1}^{\lambda_{1}}\beta_{2}^{\lambda_{2}}$ is a symmetric polynomial in
the variables $U_{1},$ $U_{2}$. Hence, by Theorem 4.1 \textbf{(a)}, there
exists a polynomial $R_{\left(  \lambda_{1},\lambda_{2}\right)  }\in
\mathbb{Z}\left[  \alpha_{1},\alpha_{2}\right]  $ such that this coefficient
is $R_{\left(  \lambda_{1},\lambda_{2}\right)  }\left(  X_{1},X_{2}\right)  $.
This $R_{\left(  \lambda_{1},\lambda_{2}\right)  }$ can generally be computed
by any algorithm which writes a symmetric polynomial as a polynomial in the
elementary symmetric polynomials. In our case, the polynomial $\widehat{Q}$
has only two nonzero coefficients: the coefficient $U_{1}^{2}+U_{2}^{2}$
before $\beta_{2}$ and the coefficient $U_{1}U_{2}$ before $\beta_{1}^{2}$. So
we get two polynomials $R_{\left(  0,1\right)  }$ and $R_{\left(  2,0\right)
}$, whereas all the other $R_{\left(  \lambda_{1},\lambda_{2}\right)  }$ are
zero. More concretely, in order to obtain $R_{\left(  0,1\right)  }$, we write
the symmetric polynomial $U_{1}^{2}+U_{2}^{2}$ (which is the coefficient of
$\widehat{Q}$ before $\beta_{1}^{0}\beta_{2}^{1}=\beta_{2}$) as a polynomial
in the elementary symmetric polynomials; this gives us $U_{1}^{2}+U_{2}%
^{2}=X_{1}^{2}-2X_{2}$, so that $R_{\left(  0,1\right)  }=\alpha_{1}%
^{2}-2\alpha_{2}$. Similarly, $R_{\left(  2,0\right)  }=\alpha_{2}$.

Now, according to the proof of Theorem 4.2 \textbf{(a)}, a polynomial $P_{2}$
satisfying $U_{1}V_{1}+U_{1}V_{2}+U_{2}V_{1}+U_{2}V_{2}=P_{2}\left(
X_{1},X_{2},Y_{1},Y_{2}\right)  $ can be defined by the equation%
\[
P_{2}=\sum_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)
\in\mathbb{N}^{n}}R_{\left(  \lambda_{1},\lambda_{2},...,\lambda_{n}\right)
}\left(  \alpha_{1},\alpha_{2},...,\alpha_{m}\right)  \beta_{1}^{\lambda_{1}%
}\beta_{2}^{\lambda_{2}}...\beta_{n}^{\lambda_{n}}.
\]
In our case, this simplifies to%
\[
P_{2}=\underbrace{R_{\left(  0,1\right)  }\left(  \alpha_{1},\alpha
_{2}\right)  }_{=\alpha_{1}^{2}-2\alpha_{2}}\beta_{1}^{0}\beta_{2}%
^{1}+\underbrace{R_{\left(  2,0\right)  }\left(  \alpha_{1},\alpha_{2}\right)
}_{=\alpha_{2}}\beta_{1}^{2}\beta_{2}^{0}=\left(  \alpha_{1}^{2}-2\alpha
_{2}\right)  \beta_{2}+\alpha_{2}\beta_{1}^{2}=\alpha_{1}^{2}\beta_{2}%
+\alpha_{2}\beta_{1}^{2}-2\alpha_{2}\beta_{2}.
\]


So we have found $P_{2}$. Similarly we can compute $P_{k}$ for all
$k\in\mathbb{N}$, even though the computations get longer with increasing $k$
very rapidly. Here are the values for small $k$:%
\begin{align*}
P_{0}  &  =1;\\
P_{1}  &  =\alpha_{1}\beta_{1};\\
P_{2}  &  =\alpha_{1}^{2}\beta_{2}+\alpha_{2}\beta_{1}^{2}-2\alpha_{2}%
\beta_{2};\\
P_{3}  &  =\alpha_{1}^{3}\beta_{3}+\alpha_{3}\beta_{1}^{3}+\alpha_{1}%
\alpha_{2}\beta_{1}\beta_{2}-3\alpha_{1}\alpha_{2}\beta_{3}-3\alpha_{3}%
\beta_{1}\beta_{2}+3\alpha_{3}\beta_{3};\\
P_{4}  &  =\alpha_{4}\beta_{1}^{4}+\alpha_{1}\alpha_{3}\beta_{1}^{2}\beta
_{2}+\alpha_{1}^{2}\alpha_{2}\beta_{1}\beta_{3}+\alpha_{1}^{4}\beta
_{4}-4\alpha_{4}\beta_{1}^{2}\beta_{2}+\alpha_{2}^{2}\beta_{2}^{2}-2\alpha
_{1}\alpha_{3}\beta_{2}^{2}-2\alpha_{2}^{2}\beta_{1}\beta_{3}\\
&  \ \ \ \ \ \ \ \ \ \ -\alpha_{1}\alpha_{3}\beta_{1}\beta_{3}-4\alpha_{1}%
^{2}\alpha_{2}\beta_{4}+2\alpha_{4}\beta_{2}^{2}+4\alpha_{4}\beta_{1}\beta
_{3}+2\alpha_{2}^{2}\beta_{4}+4\alpha_{1}\alpha_{3}\beta_{4}-4\alpha_{4}%
\beta_{4};\\
P_{5}  &  =\alpha_{5}\beta_{1}^{5}+\alpha_{1}\alpha_{4}\beta_{1}^{3}\beta
_{2}+\alpha_{1}^{2}\alpha_{3}\beta_{1}^{2}\beta_{3}+\alpha_{1}^{3}\alpha
_{2}\beta_{1}\beta_{4}+\alpha_{1}^{5}\beta_{5}-5\alpha_{5}\beta_{1}^{3}%
\beta_{2}+\alpha_{2}\alpha_{3}\beta_{1}\beta_{2}^{2}\\
&  \ \ \ \ \ \ \ \ \ \ -3\alpha_{1}\alpha_{4}\beta_{1}\beta_{2}^{2}%
-2\alpha_{2}\alpha_{3}\beta_{1}^{2}\beta_{3}-\alpha_{1}\alpha_{4}\beta_{1}%
^{2}\beta_{3}+\alpha_{1}\alpha_{2}^{2}\beta_{2}\beta_{3}-2\alpha_{1}^{2}%
\alpha_{3}\beta_{2}\beta_{3}\\
&  \ \ \ \ \ \ \ \ \ \ -3\alpha_{1}\alpha_{2}^{2}\beta_{1}\beta_{4}-\alpha
_{1}^{2}\alpha_{3}\beta_{1}\beta_{4}-5\alpha_{1}^{3}\alpha_{2}\beta
_{5}+5\alpha_{5}\beta_{1}\beta_{2}^{2}+5\alpha_{5}\beta_{1}^{2}\beta
_{3}-\alpha_{2}\alpha_{3}\beta_{2}\beta_{3}\\
&  \ \ \ \ \ \ \ \ \ \ +5\alpha_{1}\alpha_{4}\beta_{2}\beta_{3}+5\alpha
_{2}\alpha_{3}\beta_{1}\beta_{4}+\alpha_{1}\alpha_{4}\beta_{1}\beta
_{4}+5\alpha_{1}\alpha_{2}^{2}\beta_{5}+5\alpha_{1}^{2}\alpha_{3}\beta_{5}\\
&  \ \ \ \ \ \ \ \ \ \ -5\alpha_{5}\beta_{2}\beta_{3}-5\alpha_{5}\beta
_{1}\beta_{4}-5\alpha_{2}\alpha_{3}\beta_{5}-5\alpha_{1}\alpha_{4}\beta
_{5}+5\alpha_{5}\beta_{5}.
\end{align*}
Now back to the general case.

\subsection{Grothendieck's polynomials $P_{k,j}$}

Just as our above definition of the polynomials $P_{k}$ and Theorem 4.3 based
upon Theorem 4.2, we can make another definition basing upon Theorem 4.1:

\begin{quote}
\textbf{Definition.} For every set $H$ and every $j\in\mathbb{N}$, let us
denote by $\mathcal{P}_{j}\left(  H\right)  $ the set of all $j$-element
subsets of $H.$ (This is also often denoted as $\dbinom{H}{j}$.)

Let $j\in\mathbb{N}$. Let $k\in\mathbb{N}$. Our goal now is to define a
polynomial $P_{k,j}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{kj}\right]  $ such that%
\begin{equation}
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=P_{k,j}\left(  X_{1},X_{2},...,X_{kj}\right)  \label{Pkj1}%
\end{equation}
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ for
every $m\in\mathbb{N}$, where $X_{i}=\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$
is the $i$-th elementary symmetric polynomial in the variables $U_{1},$
$U_{2},$ $...,$ $U_{m}$ for every $i\in\mathbb{N}$.

In order to do this, we first fix some $m\in\mathbb{N}$. The polynomial%
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}U_{i}%
\in\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]
\]
is symmetric. Thus, Theorem 4.1 \textbf{(a)} yields that there exists one and
only one polynomial $Q\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{m}\right]  $ such that%
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=Q\left(  X_{1},X_{2},...,X_{m}\right)  .
\]
Since the polynomial $\sum\limits_{\substack{S\subseteq\mathcal{P}_{j}\left(
\left\{  1,2,...,m\right\}  \right)  ;\\\left\vert S\right\vert =k}%
}\prod\limits_{I\in S}\prod\limits_{i\in I}U_{i}$ has total degree $\leq kj$
in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$, Theorem 4.1 \textbf{(b)}
yields that%
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=Q_{k,j}\left(  X_{1},X_{2},...,X_{kj}\right)  ,
\]
where $Q_{k,j}$ is the image of the polynomial $Q$ under the canonical
homomorphism $\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]
\rightarrow\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{kj}\right]  $.
However, this polynomial $Q_{k,j}$ is not independent of $m$ yet (as the
polynomial $P_{k,j}$ that we intend to construct should be), so we call it
$Q_{k,j,\left[  m\right]  }$ rather than just $Q_{k,j}$.

Now we forget that we fixed $m\in\mathbb{N}$. We have learnt that%
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=Q_{k,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{kj}\right)  ,
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ for
every $m\in\mathbb{N}$. Now, define a polynomial $P_{k,j}\in\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{kj}\right]  $ by $P_{k,j}=Q_{k,j,\left[
kj\right]  }.$

\textbf{Theorem 4.4.} \textbf{(a)} The polynomial $P_{k,j}$ just defined
satisfies the equation (\ref{Pkj1}) in the polynomial ring $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $ for every $m\in\mathbb{N}$. (Hence, the goal
mentioned above in the definition is actually achieved.)

\textbf{(b)} For every $m\in\mathbb{N}$ and $j\in\mathbb{N}$, we have%
\begin{equation}
\prod_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\left(  1+\prod_{i\in I}U_{i}\cdot T\right)  =\sum_{k\in\mathbb{N}}%
P_{k,j}\left(  X_{1},X_{2},...,X_{kj}\right)  T^{k} \label{Pkj2}%
\end{equation}
in the ring $\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)
\left[  \left[  T\right]  \right]  $. (Note that the right hand side of this
equation is a power series with coefficient $1$ before $T^{0}$, since
$P_{0,j}=1$.)
\end{quote}

\textit{Proof of Theorem 4.4.} \textbf{(a)} \textit{1st Step:} Fix
$m\in\mathbb{N}$ such that $m\geq kj$. Then, we claim that $Q_{k,j,\left[
m\right]  }=P_{k,j}$.

\textit{Proof.} The definition of $Q_{k,j,\left[  m\right]  }$ yields
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=Q_{k,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{kj}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $.
Applying the canonical ring epimorphism $\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  \rightarrow\mathbb{Z}\left[  U_{1},U_{2}%
,...,U_{kj}\right]  $ (which maps every $U_{i}$ to $\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq kj;\\
0,\text{ if }i>kj
\end{array}
\right.  $) to this equation (and noticing that this epimorphism maps every
$X_{i}$ with $i\geq1$ to the corresponding $X_{i}$ of the image ring!), we
obtain%
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,kj\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=Q_{k,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{kj}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{kj}\right]  $. On
the other hand, the definition of $Q_{k,j,\left[  kj\right]  }$ yields%
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,kj\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=Q_{k,j,\left[  kj\right]  }\left(  X_{1},X_{2},...,X_{kj}\right)
\]
in the same ring. These two equations yield%
\[
Q_{k,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{kj}\right)
=Q_{k,j,\left[  kj\right]  }\left(  X_{1},X_{2},...,X_{kj}\right)  .
\]
Since the elements $X_{1},$ $X_{2},$ $...,$ $X_{kj}$ of $\mathbb{Z}\left[
U_{1},U_{2},...,U_{kj}\right]  $ are algebraically independent (by Theorem 4.1
\textbf{(a)}), this yields $Q_{k,j,\left[  m\right]  }=Q_{k,j,\left[
kj\right]  }.$ In other words, $Q_{k,j,\left[  m\right]  }=P_{k,j},$ and the
1st Step is proven.

\textit{2nd Step:} For every $m\in\mathbb{N}$, the equation (\ref{Pkj1}) is
satisfied in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  $.

\textit{Proof.} Let $m^{\prime}\in\mathbb{N}$ be such that $m^{\prime}\geq m$
and $m^{\prime}\geq kj$. Then, the 1st Step (applied to $m^{\prime}$ instead
of $m$) yields that $Q_{k,j,\left[  m^{\prime}\right]  }=P_{k,j}.$

The definition of $Q_{k,j,\left[  m^{\prime}\right]  }$ yields
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m^{\prime
}\right\}  \right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in
I}U_{i}=Q_{k,j,\left[  m^{\prime}\right]  }\left(  X_{1},X_{2},...,X_{kj}%
\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m^{\prime}%
}\right]  $. Applying the canonical ring epimorphism $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m^{\prime}}\right]  \rightarrow\mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $ (which maps every $U_{i}$ to $\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq m;\\
0,\text{ if }i>m
\end{array}
\right.  $) to this equation (and noticing that this epimorphism maps every
$X_{i}$ with $i\geq1$ to the corresponding $X_{i}$ of the image ring!), we
obtain%
\[
\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}\prod_{i\in I}%
U_{i}=\underbrace{Q_{k,j,\left[  m^{\prime}\right]  }}_{=P_{k,j}}\left(
X_{1},X_{2},...,X_{kj}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  .$
This means that the equation (\ref{Pkj1}) is satisfied in the polynomial ring
$\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  .$ This completes the 2nd
Step and proves Theorem 4.4 \textbf{(a)}.

\textbf{(b)} We have%
\begin{align*}
\prod_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\left(  1+\prod_{i\in I}U_{i}\cdot T\right)   &  =\sum_{k\in\mathbb{N}%
}\underbrace{\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  ;\\\left\vert S\right\vert =k}}\prod_{I\in S}%
\prod\limits_{i\in I}U_{i}}_{\substack{=P_{k,j}\left(  X_{1},X_{2}%
,...,X_{kj}\right)  \\\text{(according to (\ref{Pkj1}))}}}T^{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Exercise 4.2 \textbf{(d)}, applied to}\\
Q=\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)  \text{,
}A=\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[
\left[  T\right]  \right]  \text{,}\\
\text{ }t=T\text{ and }\alpha_{I}=\prod\limits_{i\in I}U_{i}%
\end{array}
\right) \\
&  =\sum_{k\in\mathbb{N}}P_{k,j}\left(  X_{1},X_{2},...,X_{kj}\right)  T^{k}.
\end{align*}
This proves Theorem 4.4 \textbf{(b)}.

\textbf{Example.} Computing the polynomials $P_{k,j}$ can be done by
retracking their definition, just as in the case of $P_{k}$. It is even easier
than computing $P_{k}$, because the definition of $P_{k}$ made use of Theorem
4.2 \textbf{(a)}, while that of $P_{k,j}$ did not. Thus all we need is
(\ref{Pkj1}) and an algorithm to write a symmetric polynomial as a polynomial
in the elementary symmetric ones. I am not doing any example computations for
this here, but here are some results:%
\begin{align*}
P_{0,j}  &  =1\ \ \ \ \ \ \ \ \ \ \text{for all }j\in\mathbb{N}\text{;}\\
P_{1,0}  &  =1;\\
P_{1,j}  &  =\alpha_{j}\ \ \ \ \ \ \ \ \ \ \text{for all positive }%
j\in\mathbb{N}\text{;}\\
P_{k,0}  &  =0\ \ \ \ \ \ \ \ \ \ \text{for all integers }k\geq2\text{;}\\
P_{k,1}  &  =\alpha_{k}\ \ \ \ \ \ \ \ \ \ \text{for all positive }%
k\in\mathbb{N}\text{;}\\
P_{2,2}  &  =\alpha_{1}\alpha_{3}-\alpha_{4};\\
P_{2,3}  &  =\alpha_{6}-\alpha_{1}\alpha_{5}+\alpha_{2}\alpha_{4};\\
P_{3,2}  &  =\alpha_{6}+\alpha_{1}^{2}\alpha_{4}-2\alpha_{2}\alpha_{4}%
-\alpha_{1}\alpha_{5}+\alpha_{3}^{2};\\
P_{3,3}  &  =\alpha_{1}\alpha_{4}^{2}+\alpha_{2}^{2}\alpha_{5}-2\alpha
_{1}\alpha_{3}\alpha_{5}-\alpha_{1}\alpha_{2}\alpha_{6}+\alpha_{1}^{2}%
\alpha_{7}-\alpha_{4}\alpha_{5}+3\alpha_{3}\alpha_{6}-\alpha_{2}\alpha
_{7}-\alpha_{1}\alpha_{8}+\alpha_{9};\\
P_{4,2}  &  =\alpha_{1}^{3}\alpha_{5}+\alpha_{1}\alpha_{3}\alpha_{4}%
-3\alpha_{1}\alpha_{2}\alpha_{5}-\alpha_{1}^{2}\alpha_{6}-\alpha_{4}%
^{2}+\alpha_{3}\alpha_{5}+2\alpha_{2}\alpha_{6}+\alpha_{1}\alpha_{7}%
-\alpha_{8}.
\end{align*}
Do you see the pattern in the $P_{2,j}$? See Exercise 4.4 for the answer.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 4.1. (Computing }$P_{k}$ \textit{and }$P_{k,j}$ \textit{as
coefficients of determinants.)} The definitions of the polynomials $P_{k}$ and
$P_{k,j}$ provide a possibility to recursively compute them for given values
of $k$ and $j$ (at least if one knows the constructive proof of Theorem 4.1,
which is fortunately the one given in most books). In this exercise, we will
show another way to compute explicit formulas for $P_{k}$ and $P_{k,j}$:

\textbf{(a)} Let $m\in\mathbb{N}$. In the polynomial ring $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $, let $X_{i}=\sum\limits_{\substack{S\subseteq
\left\{  1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in
S}U_{k}$ be the $i$-th elementary symmetric polynomial in the variables
$U_{1},$ $U_{2},$ $...,$ $U_{m}$ for every $i\in\mathbb{N}$.

Define a matrix $F_{U}\in\left(  \mathbb{Z}\left[  X_{1},X_{2},...,X_{m}%
\right]  \right)  ^{m\times m}$ by%
\[
F_{U}=\left(
\begin{array}
[c]{cccccc}%
0 & 1 & 0 & 0 & \cdots & 0\\
0 & 0 & 1 & 0 & \cdots & 0\\
0 & 0 & 0 & 1 & \cdots & 0\\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
0 & 0 & 0 & 0 & \cdots & 1\\
\left(  -1\right)  ^{m-1}X_{m} & \left(  -1\right)  ^{m-2}X_{m-1} & \left(
-1\right)  ^{m-3}X_{m-2} & \left(  -1\right)  ^{m-4}X_{m-3} & \cdots & \left(
-1\right)  ^{0}X_{1}%
\end{array}
\right)  .
\]
Prove that the polynomial $\det\left(  TF_{U}+I_{m}\right)  \in\left(
\mathbb{Z}\left[  X_{1},X_{2},...,X_{m}\right]  \right)  \left[  T\right]  $
equals $\prod\limits_{i=1}^{m}\left(  1+U_{i}T\right)  $.

\textbf{(b)} Let $m\in\mathbb{N}$ and $n\in\mathbb{N}$. In the polynomial ring
$\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]  $, let
$X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ be the $i$-th
elementary symmetric polynomial in the variables $U_{1},$ $U_{2},$ $...,$
$U_{m}$ for every $i\in\mathbb{N}$, and $Y_{j}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,n\right\}  ;\\\left\vert
S\right\vert =j}}\prod\limits_{k\in S}V_{k}$ be the $j$-th elementary
symmetric polynomial in the variables $V_{1},$ $V_{2},$ $...,$ $V_{n}$ for
every $j\in\mathbb{N}$.

Similarly to the matrix $F_{U}$ defined in part \textbf{(a)}, we can define a
matrix $F_{V}\in\left(  \mathbb{Z}\left[  Y_{1},Y_{2},...,Y_{n}\right]
\right)  ^{n\times n}$ by%
\[
F_{V}=\left(
\begin{array}
[c]{cccccc}%
0 & 1 & 0 & 0 & \cdots & 0\\
0 & 0 & 1 & 0 & \cdots & 0\\
0 & 0 & 0 & 1 & \cdots & 0\\
\vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
0 & 0 & 0 & 0 & \cdots & 1\\
\left(  -1\right)  ^{n-1}Y_{n} & \left(  -1\right)  ^{n-2}Y_{n-1} & \left(
-1\right)  ^{n-3}Y_{n-2} & \left(  -1\right)  ^{n-4}Y_{n-3} & \cdots & \left(
-1\right)  ^{0}Y_{1}%
\end{array}
\right)  .
\]
Prove that the polynomial $\det\left(  -T\left(  F_{U}\otimes F_{V}\right)
+I_{mn}\right)  \in\left(  \mathbb{Z}\left[  X_{1},X_{2},...,X_{m},Y_{1}%
,Y_{2},...,Y_{n}\right]  \right)  \left[  T\right]  $ equals $\prod
\limits_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }\left(  1+U_{i}V_{j}T\right)  .$ Conclude that the
coefficient of this polynomial before $T^{k}$ equals to $Q_{k,k,\left[
n,m\right]  }\left(  X_{1},X_{2},...,X_{k},Y_{1},Y_{2},...,Y_{k}\right)  $
defined in the definition of $P_{k}$. How to compute $P_{k}$ now? (Don't
forget to choose $n$ and $m$ such that $n\geq k$ and $m\geq k$.)

\textbf{(c)} Let $m\in\mathbb{N}$ and $j\in\mathbb{N}$. In part \textbf{(a)},
prove that the polynomial $\det\left(  \left(  -1\right)  ^{j}T\left(
\wedge^{j}F_{U}\right)  +I_{m}\right)  \in\left(  \mathbb{Z}\left[
X_{1},X_{2},...,X_{m}\right]  \right)  \left[  T\right]  $ equals
$\prod\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\left(  1+\prod\limits_{i\in I}U_{i}\cdot T\right)  $. Conclude that the
coefficient of this polynomial before $T^{k}$ equals to $Q_{k,j,\left[
m\right]  }\left(  X_{1},X_{2},...,X_{kj}\right)  $ defined in the definition
of $P_{k,j}$. How to compute $P_{k,j}$ now? (Don't forget to choose $m$ such
that $m\geq kj$.)

\textit{Exercise 4.2.}

\textbf{(a)} Let $\alpha_{1}$, $\alpha_{2}$, $...$, $\alpha_{m}$ be any
elements of a commutative ring $A$. Prove that%
\[
\prod\limits_{i=1}^{m}\left(  1+\alpha_{i}\right)  =\sum\limits_{S\subseteq
\left\{  1,2,...,m\right\}  }\prod\limits_{k\in S}\alpha_{k}.
\]


\textbf{(b)} Let $\alpha_{1}$, $\alpha_{2}$, $...$, $\alpha_{m}$ and $t$ be
any elements of a commutative ring $A$. Then, prove that%
\[
\prod\limits_{i=1}^{m}\left(  1+\alpha_{i}t\right)  =\sum\limits_{i\in
\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}\alpha_{k}t^{i}.
\]
\footnote{Note that a product of the form $\prod\limits_{k\in S}\alpha
_{k}t^{i}$ has to be read as $\left(  \prod\limits_{k\in S}\alpha_{k}\right)
t^{i}$, rather than as $\prod\limits_{k\in S}\left(  \alpha_{k}t^{i}\right)
$. This is a particular case of the general convention about parsing product
expressions that we made in Section 0.}

\textbf{(c)} Let $\alpha_{1}$, $\alpha_{2}$, $...$, $\alpha_{m}$ and $t$ be
any elements of a commutative ring $A$. Then, prove that%
\[
\prod\limits_{i=1}^{m}\left(  1-\alpha_{i}t\right)  =\sum\limits_{i\in
\mathbb{N}}\left(  -1\right)  ^{i}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
\alpha_{k}t^{i}.
\]


\textbf{(d)} Let $Q$ be a finite set, and let $A$ be a commutative ring. Let
$\alpha_{q}$ be an element of $A$ for every $q\in Q$. Let $t\in A$. Then,
prove that%
\[
\prod\limits_{q\in Q}\left(  1+\alpha_{q}t\right)  =\sum\limits_{k\in
\mathbb{N}}\sum\limits_{\substack{S\subseteq Q;\\\left\vert S\right\vert
=k}}\prod\limits_{q\in S}\alpha_{q}t^{k}.
\]


(These are four variants of one and the same identity, which is very easy but
basic and used in much of the theory of symmetric polynomials.)

\textit{Exercise 4.3.} Let $K$ be a ring. Let $S$ be a $K$-algebra. Let $T$ be
a $K$-subalgebra of $S$. Let $p_{1}$, $p_{2}$, $...$, $p_{m}$ be $m$ elements
of $T$, and let $q_{1}$, $q_{2}$, $...$, $q_{n}$ be $n$ elements of $S$.
Assume that the elements $p_{1}$, $p_{2}$, $...$, $p_{m}$ are algebraically
independent over $K$, and that the elements $q_{1}$, $q_{2}$, $...$, $q_{n}$
are algebraically independent over $T$. Prove that the $m+n$ elements $p_{1}$,
$p_{2}$, $...$, $p_{m}$, $q_{1}$, $q_{2}$, $...$, $q_{n}$ are algebraically
independent over $K$.

\textit{Exercise 4.4.} Prove that $P_{2,j}=\sum\limits_{i=0}^{j-1}\left(
-1\right)  ^{i+j-1}\alpha_{i}\alpha_{2j-i}$ for every $j\in\mathbb{N}$, where
$\alpha_{0}$ has to be interpreted as $1$.

[The result of Exercise 4.4 is a result by John Hopkinson\ (Proposition 2.1 in
[9]). His proof is different from the one I give in the solutions. He also
gives a similar, even if more complicated formula for $P_{3,j}$: see
Proposition 2.2 in [9].]
\end{quotation}

\section{A $\lambda$-ring structure on $\Lambda\left(  K\right)  =1+K\left[
\left[  T\right]  \right]  ^{+}$}

\subsection{Definition of the $\lambda$-ring $\Lambda\left(  K\right)  $}

Now we are going to introduce a $\lambda$-ring structure on a particular set
defined for any given ring $K.$

\begin{quote}
\textbf{Definition.} Let $K$ be a ring. Consider the ring $K\left[  \left[
T\right]  \right]  $ of formal power series in the variable $T$ over $K$. Let
$K\left[  \left[  T\right]  \right]  ^{+}$ denote the subset%
\begin{align*}
TK\left[  \left[  T\right]  \right]   &  =\left\{  \sum_{i\in\mathbb{N}}%
a_{i}T^{i}\in K\left[  \left[  T\right]  \right]  \ \mid\ a_{i}\in K\text{ for
all }i,\text{ and }a_{0}=0\right\} \\
&  =\left\{  p\in K\left[  \left[  T\right]  \right]  \ \mid\ p\text{ is a
power series with constant term }0\right\}
\end{align*}
of the ring $K\left[  \left[  T\right]  \right]  $. We are going to define a
ring structure on the set
\begin{align*}
1+K\left[  \left[  T\right]  \right]  ^{+}  &  =\left\{  1+u\mid u\in K\left[
\left[  T\right]  \right]  ^{+}\right\} \\
&  =\left\{  p\in K\left[  \left[  T\right]  \right]  \ \mid\ p\text{ is a
power series with constant term }1\right\}  .
\end{align*}
First, we define an Abelian group structure on this set:

Define an addition $\widehat{+}$ on the set $1+K\left[  \left[  T\right]
\right]  ^{+}$ by $u\widehat{+}v=uv$ for every $u\in1+K\left[  \left[
T\right]  \right]  ^{+}$ and $v\in1+K\left[  \left[  T\right]  \right]  ^{+}$.
In other words, addition on $1+K\left[  \left[  T\right]  \right]  ^{+}$ is
defined as multiplication of power series. The zero of $1+K\left[  \left[
T\right]  \right]  ^{+}$ will be $1$. The subtraction $\widehat{-}$ on the set
$1+K\left[  \left[  T\right]  \right]  ^{+}$ is given by $u\widehat{-}%
v=\dfrac{u}{v}$ for every $u\in1+K\left[  \left[  T\right]  \right]  ^{+}$ and
$v\in1+K\left[  \left[  T\right]  \right]  ^{+}$ (since every $v\in1+K\left[
\left[  T\right]  \right]  ^{+}$ is an invertible power series).

Then, clearly, $\left(  1+K\left[  \left[  T\right]  \right]  ^{+}%
,\widehat{+}\right)  $ is an Abelian group with zero $1$.

Now, define a multiplication $\widehat{\cdot}$ on the set $1+K\left[  \left[
T\right]  \right]  ^{+}$ by%
\[
\left(  \sum_{i\in\mathbb{N}}a_{i}T^{i}\right)  \widehat{\cdot}\left(
\sum_{i\in\mathbb{N}}b_{i}T^{i}\right)  =\sum_{k\in\mathbb{N}}P_{k}\left(
a_{1},a_{2},...,a_{k},b_{1},b_{2},...,b_{k}\right)  T^{k}%
\]
\footnote{Here, the $\sum\limits_{k\in\mathbb{N}}$ sign means addition in
$K\left[  \left[  T\right]  \right]  $, not in $1+K\left[  \left[  T\right]
\right]  ^{+}$. The same holds for the $\sum\limits_{i\in\mathbb{N}}$ sign.}
for any two power series $\sum\limits_{i\in\mathbb{N}}a_{i}T^{i}\in1+K\left[
\left[  T\right]  \right]  ^{+}$ and $\sum\limits_{i\in\mathbb{N}}b_{i}%
T^{i}\in1+K\left[  \left[  T\right]  \right]  ^{+}$ (where $a_{i}$ and $b_{i}$
lie in $K$ for every $i\in\mathbb{N}$).

The multiplicative unity of the ring $1+K\left[  \left[  T\right]  \right]
^{+}$ will be $1+T$.

Also, for every $j\in\mathbb{N}$, define a mapping $\widehat{\lambda}%
^{j}:1+K\left[  \left[  T\right]  \right]  ^{+}\rightarrow1+K\left[  \left[
T\right]  \right]  ^{+}$ by%
\[
\widehat{\lambda}^{j}\left(  \sum_{i\in\mathbb{N}}a_{i}T^{i}\right)
=\sum_{k\in\mathbb{N}}P_{k,j}\left(  a_{1},a_{2},...,a_{kj}\right)  T^{k}%
\]
for every power series $\sum\limits_{i\in\mathbb{N}}a_{i}T^{i}\in1+K\left[
\left[  T\right]  \right]  ^{+}$ (where $a_{i}\in K$ for every $i\in
\mathbb{N}$).
\end{quote}

Note that we have denoted the newly-defined addition, subtraction and
multiplication on the set $1+K\left[  \left[  T\right]  \right]  ^{+}$ by
$\widehat{+},$ $\widehat{-}$ and $\widehat{\cdot}$ in order to distinguish
them from the addition $+,$ subtraction $-$ and multiplication $\cdot$
inherited from $K\left[  \left[  T\right]  \right]  $. We will later continue
in this spirit (for instance, we will denote a finite sum with respect to the
addition $\widehat{+}$ by the sign $\widehat{\sum}$, while a finite sum with
respect to the addition $+$ will be written using the normal $\sum$
sign).\footnote{In [2], Knutson writes $"+"$, $"-"$ and $"\cdot"$ (with
quotation marks) instead of $\widehat{+},$ $\widehat{-}$ and $\widehat{\cdot}$
for the newly-defined operations. In [1], Fulton and Lang simply write $+,$
$-$ and $\cdot$ for $\widehat{+},$ $\widehat{-}$ and $\widehat{\cdot}$,
approving the danger of confusion with the "old" operations $+,$ $-$ and
$\cdot$ inherited from $K\left[  \left[  T\right]  \right]  $.}

\begin{quote}
\textbf{Theorem 5.1.} \textbf{(a)} The multiplication $\widehat{\cdot}$ just
defined makes $\left(  1+K\left[  \left[  T\right]  \right]  ^{+}%
,\widehat{+},\widehat{\cdot}\right)  $ a ring with multiplicative unity $1+T$.
We will call this ring $\Lambda\left(  K\right)  $.

\textbf{(b)} The above defined maps $\widehat{\lambda}^{j}$ make $\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  $ a $\lambda$-ring.
\end{quote}

Before we prove this Theorem 5.1, we will have to do some preparatory work: We
will introduce a subset $1+K\left[  T\right]  ^{+}$ of $1+K\left[  \left[
T\right]  \right]  ^{+}$ which consists of polynomials with constant term $1$.
We will show (Theorem 5.2) how we can factorize such polynomials into linear
factors in an extension of our ring $K$ (similarly to Galois theory, but
easier, because we don't have to worry about the extension not being a field).
Then, we will see how the operations $\widehat{+}$, $\widehat{\cdot}$ and
$\widehat{\lambda}^{j}$ act on factorized linear polynomials (Theorem 5.3).
Then, with the help of some very basic point-set topology, we will see that
the subset $1+K\left[  T\right]  ^{+}$ is dense in an appropriate topology on
$1+K\left[  \left[  T\right]  \right]  ^{+}$ (Theorem 5.5 \textbf{(a)}), that
this topology is Hausdorff (Theorem 5.5 \textbf{(e)}), and that the operations
$\widehat{+}$, $\widehat{\cdot}$ and $\widehat{\lambda}^{j}$ are continuous
with respect to it (Theorem 5.5 \textbf{(d)}), so that in order to prove the
ring and $\lambda$-ring axioms for $\Lambda\left(  K\right)  $, we only need
to prove them on elements of this dense subset $1+K\left[  T\right]  ^{+}$.
This will then be done using Theorems 5.2 and 5.3.

Even if you are willing to believe me that Theorem 5.1 holds, you are advised
to read this proof, since the ideas and notions it uses will be reused several
times (e. g., in Sections 9 and 10).

\subsection{Preparing for the proof of Theorem 5.1: introducing $1+K\left[
T\right]  ^{+}$}

Before we prove this Theorem 5.1, we try to motivate the above definition of
$\Lambda\left(  K\right)  $:

\begin{quote}
\textbf{Definition.} Let $K\left[  T\right]  ^{+}$ be the subset of $K\left[
T\right]  $ defined by%
\begin{align*}
K\left[  T\right]  ^{+}  &  =TK\left[  T\right]  =\left\{  \sum_{i\in
\mathbb{N}}a_{i}T^{i}\in K\left[  T\right]  \ \mid\ a_{i}\in K\text{ for all
}i,\text{ and }a_{0}=0\right\} \\
&  =\left\{  p\in K\left[  T\right]  \ \mid\ p\text{ is a polynomial with
constant term }0\right\}  .
\end{align*}
Then, the set $1+K\left[  T\right]  ^{+}$ is a subset of $1+K\left[  \left[
T\right]  \right]  ^{+}.$ The elements of $1+K\left[  T\right]  ^{+}$ are polynomials.
\end{quote}

So $1+K\left[  T\right]  ^{+}$ is the set of all polynomials $p\in K\left[
T\right]  $ with constant term $1$. Loosely speaking, this means that the
elements of $1+K\left[  T\right]  ^{+}$ are monic polynomials "turned upside
down" (in the sense that if $\sum\limits_{i=0}^{n}a_{i}T^{i}$ is a polynomial
in $1+K\left[  T\right]  ^{+}$ degree $n$ (with $a_{i}\in K$ for every $i$),
then $\sum\limits_{i=0}^{n}a_{n-i}T^{i}$ is a monic polynomial of degree $n$,
and conversely). This allows us to take some properties of monic polynomials
and use them to derive similar properties for polynomials in $1+K\left[
T\right]  ^{+}$. For example, we can take Exercise 5.1 (which says that
whenever $P$ is a monic polynomial of degree $n$ over a ring $K$, we can find
a finite-free extension ring of $K$ over which the polynomial $P$ factors into
a product of monic linear polynomials), and "turn it upside down", obtaining
the following fact about polynomials in $1+K\left[  T\right]  ^{+}$:

\begin{quote}
\textbf{Theorem 5.2.} Let $K$ be a ring. For every element $p\in1+K\left[
T\right]  ^{+}$, there exists an integer $n$ (the degree of the polynomial
$p$), a finite-free extension ring $K_{p}$ of the ring $K$ and $n$ elements
$p_{1},$ $p_{2},$ $...,$ $p_{n}$ of this extension ring $K_{p}$ such that
$p=\prod\limits_{i=1}^{n}\left(  1+p_{i}T\right)  $ in $K_{p}\left[  T\right]
$.
\end{quote}

\textit{Proof of Theorem 5.2.} Write the polynomial $p$ in the form
$p=\sum\limits_{i=0}^{n}a_{i}T^{i}$, where $n=\deg p$. Then, $a_{0}=1$ (since
$p\in1+K\left[  T\right]  ^{+}$).

Define a new polynomial $\widetilde{p}=\sum\limits_{i=0}^{n}a_{n-i}T^{i}\in
K\left[  T\right]  $. Then, the polynomial $\widetilde{p}$ is monic (since
$a_{0}=1$) and satisfies $n=\deg\widetilde{p}$. Hence, by Exercise 5.1
(applied to $P=\widetilde{p}$), there exists a finite-free extension ring
$K_{\widetilde{p}}$ of the ring $K$ and $n$ elements $\widetilde{p}_{1}$,
$\widetilde{p}_{2}$, $...$, $\widetilde{p}_{n}$ of this extension ring
$K_{\widetilde{p}}$ such that $\widetilde{p}=\prod\limits_{i=1}^{n}\left(
T-\widetilde{p}_{i}\right)  $ in $K_{\widetilde{p}}\left[  T\right]  $.

Consider this ring $K_{\widetilde{p}}$ and these $n$ elements $\widetilde{p}%
_{1}$, $\widetilde{p}_{2}$, $...$, $\widetilde{p}_{n}$. Let $K_{p}$ be the
extension ring $K_{\widetilde{p}}$, and let $p_{i}$ be the element
$-\widetilde{p}_{i}\in K_{p}$ for every $i\in\left\{  1,2,...,n\right\}  $.
Then,
\[
\sum\limits_{i=0}^{n}a_{n-i}T^{i}=\widetilde{p}=\prod\limits_{i=1}^{n}\left(
T-\widetilde{p}_{i}\right)  =\prod\limits_{i=1}^{n}\left(
T+\underbrace{\left(  -\widetilde{p}_{i}\right)  }_{=p_{i}}\right)
=\prod\limits_{i=1}^{n}\left(  T+p_{i}\right)  =\prod\limits_{i=1}^{n}\left(
p_{i}+T\right)  .
\]
Therefore, Exercise 5.2 \textbf{(a)} (applied to $L=K_{p}$) yields that
$\sum\limits_{i=0}^{n}a_{i}T^{i}=\prod\limits_{i=1}^{n}\left(  1+p_{i}%
T\right)  $. Since $p=\sum\limits_{i=0}^{n}a_{i}T^{i}$, this rewrites as
$p=\prod\limits_{i=1}^{n}\left(  1+p_{i}T\right)  $. Thus, Theorem 5.2 is proven.

\subsection{Preparing for the proof of Theorem 5.1: extending the ring to make
polynomials split}

Theorem 5.2 shows us that we can split every polynomial $p\in1+K\left[
T\right]  ^{+}$ into linear factors in a suitably large (but finite-free)
extension ring of $K$. This is a rather useful fact: Whenever we have to prove
some facts about polynomials in $1+K\left[  T\right]  ^{+}$, it allows us to
"adjoin roots of these polynomials" to $K$. In this sense it is a partial
replacement of the fundamental theorem of algebra for arbitrary commutative
rings. Of course, its use is limited by the fact that we don't know much about
the extension ring of $K$ in which $p$ factors, but the fact that it is
finite-free is enough for many things!

To make systematic use of Theorem 5.2, let us introduce some notation again:

\begin{quote}
\textbf{Definition.} For every set $H$, let $\mathcal{P}_{\operatorname*{fin}%
}^{\ast}\left(  H\right)  $ denote the set of all finite multisets which
consist of elements of $H$. Also, we recall that we denote the multiset formed
by the elements $u_{1},$ $u_{2},$ $...,$ $u_{n}$ (with multiplicity) by
$\left[  u_{1},u_{2},...,u_{n}\right]  $.

For our ring $K$, let $\operatorname*{Exten}K$ be the set of all finite-free
extension rings of $K$. (Again, this is not a set. Again, we don't care.
Basically it is enough to consider all finite-free extension rings of the form
$K\left[  X_{1},X_{2},...,X_{n}\right]  \diagup I$ with $I$ being an ideal of
$K\left[  X_{1},X_{2},...,X_{n}\right]  $, and \textit{these} extension rings
do form a set.)

Let $K^{\operatorname*{int}}$ be the subset%
\[
\left\{  \left(  \widetilde{K},\left[  u_{1},u_{2},...,u_{n}\right]  \right)
\in\bigcup\limits_{K^{\prime}\subseteq\operatorname*{Exten}K}^{\cdot
}\mathcal{P}_{\operatorname*{fin}}^{\ast}\left(  K^{\prime}\right)
\ \ \mid\ \ \prod\limits_{i=1}^{n}\left(  1+u_{i}T\right)  \in K\left[
T\right]  \right\}
\]
of $\bigcup\limits_{K^{\prime}\subseteq\operatorname*{Exten}K}^{\cdot
}\mathcal{P}_{\operatorname*{fin}}^{\ast}\left(  K^{\prime}\right)  $ (where
$\bigcup\limits_{K^{\prime}\subseteq\operatorname*{Exten}K}^{\cdot}%
\mathcal{P}_{\operatorname*{fin}}^{\ast}\left(  K^{\prime}\right)  $ denotes
the disjoint union of the sets $\mathcal{P}_{\operatorname*{fin}}^{\ast
}\left(  K^{\prime}\right)  $ over all $K^{\prime}\subseteq
\operatorname*{Exten}K$, defined by $\bigcup\limits_{K^{\prime}\subseteq
\operatorname*{Exten}K}^{\cdot}\mathcal{P}_{\operatorname*{fin}}^{\ast}\left(
K^{\prime}\right)  =\bigcup\limits_{K^{\prime}\subseteq\operatorname*{Exten}%
K}\left\{  K^{\prime}\right\}  \times\mathcal{P}_{\operatorname*{fin}}^{\ast
}\left(  K^{\prime}\right)  $). We can then define a map%
\[
\Pi:K^{\operatorname*{int}}\rightarrow1+K\left[  T\right]  ^{+}%
\]
through%
\begin{align*}
\Pi\left(  \widetilde{K},\left[  u_{1},u_{2},...,u_{n}\right]  \right)   &
=\prod\limits_{i=1}^{n}\left(  1+u_{i}T\right)  \in1+K\left[  T\right]  ^{+}\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }\left(  \widetilde{K},\left[
u_{1},u_{2},...,u_{n}\right]  \right)  \in K^{\operatorname*{int}}.
\end{align*}


We also define a map%
\[
r:1+K\left[  T\right]  ^{+}\rightarrow K^{\operatorname*{int}}%
\]
(the $r$ stands for "roots" here) through
\[
r\left(  p\right)  =\left(  K_{p},\left[  p_{1},p_{2},...,p_{n}\right]
\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }p\in1+K\left[  T\right]  ^{+},
\]
where $K_{p}$ and $\left[  p_{1},p_{2},...,p_{n}\right]  $ are defined as in
Theorem 5.2.

Clearly, $\Pi\circ r=\operatorname*{id}$, so that every polynomial
$p\in1+K\left[  T\right]  ^{+}$ can be written as $p=\Pi\left(  \widetilde{K}%
,\left[  u_{1},u_{2},...,u_{n}\right]  \right)  $ for some $\left(
\widetilde{K},\left[  u_{1},u_{2},...,u_{n}\right]  \right)  \in
K^{\operatorname*{int}}$.
\end{quote}

This way, we have a correspondence between elements of $1+K\left[  T\right]
^{+}$ and multisets of elements of an extension ring of $K$. This
correspondence is neither injective nor surjective, but it reminds us of the
correspondence between polynomials over a field and their roots over
extensions of that field (and the proof of Theorem 5.2 explains why), and it
will help us to understand $\widehat{+},$ $\widehat{\cdot}$ and
$\widehat{\lambda}^{j}$ better.

\subsection{Preparing for the proof of Theorem 5.1: the ring structure on
$\Lambda\left(  K\right)  $ explained}

In fact, the following fact explains the ring operations $\widehat{+}$ and
$\widehat{\cdot}$ and the $\lambda$-operations $\widehat{\lambda}^{j}$ on
$1+K\left[  T\right]  ^{+}$ in terms of this correspondence:

\begin{quote}
\textbf{Theorem 5.3.} Let $K$ be a ring.

Let $u\in1+K\left[  T\right]  ^{+}$ and $v\in1+K\left[  T\right]  ^{+}$.
Assume that $u=\Pi\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}%
\right]  \right)  $ for some $\left(  \widetilde{K}_{u},\left[  u_{1}%
,u_{2},...,u_{m}\right]  \right)  \in K^{\operatorname*{int}}$ and that
$v=\Pi\left(  \widetilde{K}_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)
$ for some $\left(  \widetilde{K}_{v},\left[  v_{1},v_{2},...,v_{n}\right]
\right)  \in K^{\operatorname*{int}}$. This, in particular, implies that
$\widetilde{K}_{u}$ and $\widetilde{K}_{v}$ are finite-free extension rings of
$K$. Let $\widetilde{K}_{u,v}$ be a finite-free extension ring of $K$ which
contains both $\widetilde{K}_{u}$ and $\widetilde{K}_{v}$ as subrings.

\textbf{(a)} Such a ring $\widetilde{K}_{u,v}$ always exists. For
instance,\footnote{In the following, the $\otimes$ sign always means
$\otimes_{K}$ until stated otherwise.} $\widetilde{K}_{u}\otimes
\widetilde{K}_{v}$ is a finite-free extension ring of $K$, and we can
canonically identify $\widetilde{K}_{u}$ with the subring $\widetilde{K}%
_{u}\otimes1$ of $\widetilde{K}_{u}\otimes\widetilde{K}_{v}$, and
$\widetilde{K}_{v}$ with the subring $1\otimes\widetilde{K}_{v}$ of
$\widetilde{K}_{u}\otimes\widetilde{K}_{v}$; hence, we can set $\widetilde{K}%
_{u,v}=\widetilde{K}_{u}\otimes\widetilde{K}_{v}$.

\textbf{(b)} We have $u\widehat{+}v=\Pi\left(  \widetilde{K}_{u,v},\left[
u_{1},u_{2},...,u_{m},v_{1},v_{2},...,v_{n}\right]  \right)  $.

\textbf{(c)} Also, $u\widehat{\cdot}v=\Pi\left(  \widetilde{K}_{u,v},\left[
u_{i}v_{j}\mid\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  \right]  \right)  $.

\textbf{(d)} Let $j\in\mathbb{N}$. Then, $\widehat{\lambda}^{j}\left(
u\right)  =\Pi\left(  \widetilde{K}_{u},\left[  \prod\limits_{i\in I}%
u_{i}\ \mid\ I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
\right]  \right)  $.
\end{quote}

\textit{Proof of Theorem 5.3.} The assumption that $u=\Pi\left(
\widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  $ is just a
different way to say that $u=\prod\limits_{i=1}^{m}\left(  1+u_{i}T\right)  $.
Similarly, $v=\prod\limits_{j=1}^{n}\left(  1+v_{j}T\right)  $. Let
$u=\sum\limits_{i\in\mathbb{N}}a_{i}T^{i}$ and $v=\sum\limits_{i\in\mathbb{N}%
}b_{i}T^{i}$.

\textbf{(a)} The $K$-module $\widetilde{K}_{u}\otimes\widetilde{K}_{v}$ is
finite-free (being the tensor product of two finite-free $K$-modules). The
embedding $K\rightarrow\widetilde{K}_{v}$ is injective; hence, the map
$\widetilde{K}_{u}\otimes K\rightarrow\widetilde{K}_{u}\otimes\widetilde{K}%
_{v}$ it induces must also be injective (since $\widetilde{K}_{u}$ is
finite-free, and hence tensoring with $\widetilde{K}_{u}$ is an exact
functor). Thus, we can canonically identify $\widetilde{K}_{u}$ with the
subring $\widetilde{K}_{u}\otimes K=\widetilde{K}_{u}\otimes1$ of
$\widetilde{K}_{u}\otimes\widetilde{K}_{v}$. Similarly, we can canonically
identify $\widetilde{K}_{v}$ with the subring $1\otimes\widetilde{K}_{v}$ of
$\widetilde{K}_{u}\otimes\widetilde{K}_{v}$. As a consequence, $\widetilde{K}%
_{u}\otimes\widetilde{K}_{v}$ is an extension ring of $K$. This proves Theorem
5.3 \textbf{(a)}.

\textbf{(b)} The equations $u=\prod\limits_{i=1}^{m}\left(  1+u_{i}T\right)  $
and $v=\prod\limits_{j=1}^{n}\left(  1+v_{j}T\right)  $ yield $u\widehat{+}%
v=uv=\prod\limits_{i=1}^{m}\left(  1+u_{i}T\right)  \prod\limits_{j=1}%
^{n}\left(  1+v_{j}T\right)  $, what rewrites as $u\widehat{+}v=\Pi\left(
\widetilde{K}_{u,v},\left[  u_{1},u_{2},...,u_{m},v_{1},v_{2},...,v_{n}%
\right]  \right)  .$

\textbf{(c)} Consider the ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
,V_{1},V_{2},...,V_{n}\right]  $ (the polynomial ring in $m+n$ indeterminates
$U_{1},$ $U_{2},$ $...,$ $U_{m},$ $V_{1},$ $V_{2},$ $...,$ $V_{n}$ over the
ring $\mathbb{Z}$). For every $i\in\mathbb{N}$, let $X_{i}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ be the $i$-th elementary
symmetric polynomial in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$. For
every $j\in\mathbb{N}$, let $Y_{j}=\sum\limits_{\substack{S\subseteq\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =j}}\prod\limits_{k\in S}V_{k}$
be the $j$-th elementary symmetric polynomial in the variables $V_{1},$
$V_{2},$ $...,$ $V_{n}$.

There exists a ring homomorphism%
\[
\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]
\rightarrow\widetilde{K}_{u,v}%
\]
which maps $U_{i}$ to $u_{i}$ for every $i$ and $V_{j}$ to $v_{j}$ for every
$j$. This homomorphism maps $X_{i}$ to $a_{i}$ for every $i\in\mathbb{N}$
(because $a_{i}$ is the $i$-th elementary symmetric polynomial applied to
$u_{1},$ $u_{2},$ $...,$ $u_{m}$, since $\sum\limits_{i\in\mathbb{N}}%
a_{i}T^{i}=u=\prod\limits_{i=1}^{m}\left(  1+u_{i}T\right)  $) and $Y_{j}$ to
$b_{j}$ for every $j\in\mathbb{N}$ (for a similar reason). Hence, applying
this homomorphism to (\ref{Pk2}), we obtain%
\[
\prod_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }\left(  1+u_{i}v_{j}T\right)  =\sum_{k\in\mathbb{N}}%
P_{k}\left(  a_{1},a_{2},...,a_{k},b_{1},b_{2},...,b_{k}\right)  T^{k}.
\]
But%
\[
\sum_{k\in\mathbb{N}}P_{k}\left(  a_{1},a_{2},...,a_{k},b_{1},b_{2}%
,...,b_{k}\right)  T^{k}=\left(  \sum_{i\in\mathbb{N}}a_{i}T^{i}\right)
\widehat{\cdot}\left(  \sum_{i\in\mathbb{N}}b_{i}T^{i}\right)
=u\widehat{\cdot}v,
\]
so this becomes%
\[
\prod_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }\left(  1+u_{i}v_{j}T\right)  =u\widehat{\cdot}v,
\]
and thus%
\[
u\widehat{\cdot}v=\prod_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  }\left(  1+u_{i}v_{j}T\right)  =\Pi\left(
\widetilde{K}_{u,v},\left[  u_{i}v_{j}\mid\left(  i,j\right)  \in\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right]  \right)  ,
\]
proving Theorem 5.3 \textbf{(c)}.

\textbf{(d)} Consider the polynomial ring $\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  $. For every $i\in\mathbb{N}$, let $X_{i}%
=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ be the $i$-th elementary
symmetric polynomial in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$.

There exists a ring homomorphism $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  \rightarrow\widetilde{K}_{u}$ which maps $U_{i}$ to $u_{i}$ for every
$i$. This homomorphism maps $X_{i}$ to $a_{i}$ for every $i\in\mathbb{N}$
(because $a_{i}$ is the $i$-th elementary symmetric polynomial applied to
$u_{1},$ $u_{2},$ $...,$ $u_{m}$, since $\sum\limits_{i\in\mathbb{N}}%
a_{i}T^{i}=u=\prod\limits_{i=1}^{m}\left(  1+u_{i}T\right)  $). Hence,
applying this homomorphism to (\ref{Pkj2}), we obtain%
\[
\prod_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\left(  1+\prod_{i\in I}u_{i}\cdot T\right)  =\sum_{k\in\mathbb{N}}%
P_{k,j}\left(  a_{1},a_{2},...,a_{kj}\right)  T^{k}.
\]
But%
\[
\sum_{k\in\mathbb{N}}P_{k,j}\left(  a_{1},a_{2},...,a_{kj}\right)
T^{k}=\widehat{\lambda}^{j}\left(  \sum_{i\in\mathbb{N}}a_{i}T^{i}\right)
=\widehat{\lambda}^{j}\left(  u\right)  ,
\]
so this becomes%
\[
\prod_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\left(  1+\prod_{i\in I}u_{i}\cdot T\right)  =\widehat{\lambda}^{j}\left(
u\right)  ,
\]
and thus%
\[
\widehat{\lambda}^{j}\left(  u\right)  =\prod_{I\in\mathcal{P}_{j}\left(
\left\{  1,2,...,m\right\}  \right)  }\left(  1+\prod_{i\in I}u_{i}\cdot
T\right)  =\Pi\left(  \widetilde{K}_{u},\left[  \prod\limits_{i\in I}%
u_{i}\ \mid\ I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
\right]  \right)  ,
\]
proving Theorem 5.3 \textbf{(d)}.

\begin{quote}
\textbf{Corollary 5.4.} Let $K$ be a ring. Let $\widetilde{K}$ be a
finite-free extension ring of $K$. Let $I$ be some finite set, and let $T_{i}$
be a finite set for every $i\in I$. Let $u_{i,j}$ be an element of
$\widetilde{K}$ for every $i\in I$ and every $j\in T_{i}$. We will write
$\left[  u_{i,j}\mid i\in I\text{ and }j\in T_{i}\right]  $ for the multiset
formed by all these $u_{i,j}$ (where each element occurs as often as it occurs
among these $u_{i,j}$).

\textbf{(a)} Then,%
\[
\widehat{\sum_{i\in I}}\Pi\left(  \widetilde{K},\left[  u_{i,j}\mid j\in
T_{i}\right]  \right)  =\Pi\left(  \widetilde{K},\left[  u_{i,j}\mid i\in
I\text{ and }j\in T_{i}\right]  \right)  .
\]
Here, the sign $\widehat{\sum\limits_{i\in I}}$ means a finite sum based on
the addition $\widehat{+}$ of the ring $\Lambda\left(  K\right)  $ (for
instance, $\widehat{\sum\limits_{i\in\left\{  1,2,3\right\}  }}a_{i}$ means
$a_{1}\widehat{+}a_{2}\widehat{+}a_{3}$ and not $a_{1}+a_{2}+a_{3}$).

\textbf{(b)} Also,%
\[
\widehat{\prod_{i\in I}}\Pi\left(  \widetilde{K},\left[  u_{i,j}\mid j\in
T_{i}\right]  \right)  =\Pi\left(  \widetilde{K},\left[  \prod_{i\in
I}u_{i,j_{i}}\mid\left(  j_{i}\right)  _{i\in I}\in\prod_{i\in I}T_{i}\right]
\right)  .
\]
Here, the sign $\widehat{\prod\limits_{i\in I}}$ means a finite product based
on the multiplication $\widehat{\cdot}$ of the ring $\Lambda\left(  K\right)
$ (for instance, $\widehat{\prod\limits_{i\in\left\{  1,2,3\right\}  }}a_{i}$
means $a_{1}\widehat{\cdot}a_{2}\widehat{\cdot}a_{3}$ and not $a_{1}\cdot
a_{2}\cdot a_{3}$).
\end{quote}

\textit{Proof of Corollary 5.4.} Part \textbf{(a)} follows by induction from
Theorem 5.3 \textbf{(b)}, and part \textbf{(b)} follows by induction from
Theorem 5.3 \textbf{(c)}.

For later use, we restate part \textbf{(d)} of Theorem 5.3 in somewhat more
flexible notations:

\begin{quote}
\textbf{Theorem 5.3' (d)}. Let $K$ be a ring. Let $w\in1+K\left[  T\right]
^{+}$. Assume that $w=\Pi\left(  \widetilde{K},\left[  w_{\ell}\mid\ell\in
L\right]  \right)  $ for some $\left(  \widetilde{K},\left[  w_{\ell}\mid
\ell\in L\right]  \right)  \in K^{\operatorname*{int}}$. Let $k\in\mathbb{N}$.
Then,%
\[
\widehat{\lambda}^{k}\left(  w\right)  =\Pi\left(  \widetilde{K},\left[
\prod_{\ell\in S}w_{\ell}\mid S\in\mathcal{P}_{k}\left(  L\right)  \right]
\right)  .
\]



\end{quote}

\textit{Proof of Theorem 5.3' \textbf{(d)}.} Since $L$ is a finite set used
only for labelling, we can WLOG assume that $L=\left\{  1,2,...,m\right\}  $
for some $m\in\mathbb{N}$. Thus, $w=\Pi\left(  \widetilde{K},\left[  w_{\ell
}\mid\ell\in L\right]  \right)  $ rewrites as $w=\Pi\left(  \widetilde{K}%
,\left[  w_{\ell}\mid\ell\in\left\{  1,2,...,m\right\}  \right]  \right)
=\Pi\left(  \widetilde{K},\left[  w_{1},w_{2},...,w_{m}\right]  \right)  $.
Hence, we can apply Theorem 5.3 \textbf{(d)} to $u=w$, $j=k$, $\widetilde{K}%
_{u}=\widetilde{K}$, and $u_{\ell}=w_{\ell}$ and obtain%
\begin{align*}
\widehat{\lambda}^{k}\left(  w\right)   &  =\Pi\left(  \widetilde{K},\left[
\prod_{i\in I}w_{i}\mid I\in\mathcal{P}_{k}\left(  \underbrace{\left\{
1,2,...,m\right\}  }_{=L}\right)  \right]  \right)  =\Pi\left(  \widetilde{K}%
,\left[  \prod_{i\in I}w_{i}\mid I\in\mathcal{P}_{k}\left(  L\right)  \right]
\right) \\
&  =\Pi\left(  \widetilde{K},\left[  \prod_{\ell\in S}w_{\ell}\mid
S\in\mathcal{P}_{k}\left(  L\right)  \right]  \right)
\end{align*}
(here, we renamed $i$ and $I$ as $\ell$ and $S$). This proves Theorem 5.3'
\textbf{(d)}.

\subsection{Preparing for the proof of Theorem 5.1: the $\left(  T\right)
$-topology}

We are approaching the proof of Theorem 5.1. The idea of the proof is: We have
to show some identities for elements of $1+K\left[  \left[  T\right]  \right]
^{+}$ (such as associativity of multiplication). Computing with elements of
$1+K\left[  \left[  T\right]  \right]  ^{+}$ is very difficult, but computing
with elements of $1+K\left[  T\right]  ^{+}$ is rather easy thanks to Theorem
5.3. Hence, we are going to reduce Theorem 5.1 to the case when our elements
are in $1+K\left[  T\right]  ^{+}$. The reader is encouraged to try doing this
on his own. In practice, it is a matter of noticing that for every
$k\in\mathbb{N}$, only the first so and so many coefficients of the power
series $u$ and $v$ matter when computing the $k$-th coefficient of
$u\widehat{\cdot}v$ (for instance), and thus we can truncate the power series
at these coefficients, thus turning it into a polynomial. The abstract
algebraical way to formulate this argument is by introducing the so-called
$\left(  T\right)  $\textit{-topology} (also called the $\left(  T\right)
$\textit{-adic topology}) on $K\left[  \left[  T\right]  \right]  $:

\begin{quote}
\textbf{Definition.} Let $K$ be a ring. As a $K$-module, $K\left[  \left[
T\right]  \right]  =\bigoplus\limits_{k\in\mathbb{N}}KT^{k}$. Now, we define
the so-called $\left(  T\right)  $\textit{-topology} on the ring $K\left[
\left[  T\right]  \right]  $ as the topology generated by%
\[
\left\{  u+\sum_{k\geq N}KT^{k}\ \mid\ u\in K\left[  \left[  T\right]
\right]  \text{ and }N\in\mathbb{N}\right\}  .
\]
In other words, the open sets of this topology should be all translates of the
submodules $\sum\limits_{k\geq N}KT^{k}$ for $N\in\mathbb{N}$, as well as the
unions of these sets\footnote{This includes the empty union, which is
$\varnothing$.}. (Note that the sum $\sum\limits_{k\geq N}KT^{k}$ is actually
a direct sum. Also note that every translate of the submodule $\sum
\limits_{k\geq N}KT^{k}$ for $N\in\mathbb{N}$ actually has the form
$p+\sum\limits_{k\geq N}KT^{k}$ for a polynomial $p\in K\left[  T\right]  $ of
degree $<N$, and this polynomial is uniquely determined.)
\end{quote}

This $\left(  T\right)  $-topology is a particular case of several known
constructions; for example, a similar way exists to define a topology on any
graded ring, or on a ring with a given ideal, or on the ring with a given
sequence of ideal satisfying certain properties. We will need only the
$\left(  T\right)  $-topology, however.

Now, an easy fact:

\begin{quote}
\textbf{Theorem 5.5.} Let $K$ be a ring. The $\left(  T\right)  $-topology on
the ring $K\left[  \left[  T\right]  \right]  $ restricts to a topology on its
subset $1+K\left[  \left[  T\right]  \right]  ^{+}$; we call this topology the
$\left(  T\right)  $\textit{-topology} again. Whenever we say "open",
"continuous", "dense", etc., we are referring to this topology.

\textbf{(a)} The subset $1+K\left[  T\right]  ^{+}$ is dense in $1+K\left[
\left[  T\right]  \right]  ^{+}$.

\textbf{(b)} Let $f:1+K\left[  \left[  T\right]  \right]  ^{+}\rightarrow
1+K\left[  \left[  T\right]  \right]  ^{+}$ be a map such that for every
$n\in\mathbb{N}$ there exists some $N\in\mathbb{N}$ such that the first $n$
coefficients of the image of a formal power series under $f$ depend only on
the first $N$ coefficients of the series itself (and not on the remaining
ones). Then, $f$ is continuous.

\textbf{(c)} Let $g:\left(  1+K\left[  \left[  T\right]  \right]  ^{+}\right)
\times\left(  1+K\left[  \left[  T\right]  \right]  ^{+}\right)
\rightarrow1+K\left[  \left[  T\right]  \right]  ^{+}$ be a map such that for
every $n\in\mathbb{N}$ there exists some $N\in\mathbb{N}$ such that the first
$n$ coefficients of the image of a pair of formal power series under $f$
depend only on the first $N$ coefficients of the two series itself (and not on
the remaining ones). Then, $g$ is continuous.

\textbf{(d)} The map%
\begin{align*}
\left(  1+K\left[  \left[  T\right]  \right]  ^{+}\right)  \times\left(
1+K\left[  \left[  T\right]  \right]  ^{+}\right)   &  \rightarrow1+K\left[
\left[  T\right]  \right]  ^{+},\\
\left(  u,v\right)   &  \mapsto u\widehat{+}v,
\end{align*}
the map%
\begin{align*}
\left(  1+K\left[  \left[  T\right]  \right]  ^{+}\right)  \times\left(
1+K\left[  \left[  T\right]  \right]  ^{+}\right)   &  \rightarrow1+K\left[
\left[  T\right]  \right]  ^{+},\\
\left(  u,v\right)   &  \mapsto u\widehat{-}v,
\end{align*}
the map%
\begin{align*}
\left(  1+K\left[  \left[  T\right]  \right]  ^{+}\right)  \times\left(
1+K\left[  \left[  T\right]  \right]  ^{+}\right)   &  \rightarrow1+K\left[
\left[  T\right]  \right]  ^{+},\\
\left(  u,v\right)   &  \mapsto u\widehat{\cdot}v,
\end{align*}
and the map $\widehat{\lambda}^{j}:1+K\left[  \left[  T\right]  \right]
^{+}\rightarrow1+K\left[  \left[  T\right]  \right]  ^{+}$ for every
$j\in\mathbb{N}$ are continuous.

\textbf{(e)} The topological spaces $K\left[  \left[  T\right]  \right]  $ and
$1+K\left[  \left[  T\right]  \right]  ^{+}$ are Hausdorff spaces.
\end{quote}

Note that Theorem 5.5 \textbf{(d)} yields that any finite compositions of the
maps $\widehat{+},$ $\widehat{-},$ $\widehat{\cdot}$ and $\widehat{\lambda
}^{j}$ are continuous (since finite compositions of continuous functions are
continuous). In particular, any polynomial with integral coefficients acts on
$1+K\left[  \left[  T\right]  \right]  ^{+}$ as a continuous map.

\textit{Proof of Theorem 5.5.} \textbf{(a)} and \textbf{(e)} are done in any
commutative algebra book such as [3], Chapter 10.

\textbf{(b)} and \textbf{(c)} are basic exercises in topology.

\textbf{(d)} follows from \textbf{(b)} and \textbf{(c)} together with the
definitions of $\widehat{+},$ $\widehat{\cdot}$ and $\widehat{\lambda}^{j}$.

\subsection{Proof of Theorem 5.1}

Now it comes:

\textit{Proof of Theorem 5.1.} \textbf{(a)} We have to prove the ring axioms
for $\left(  1+K\left[  \left[  T\right]  \right]  ^{+},\widehat{+}%
,\widehat{\cdot}\right)  $ (including the unity axiom for $1+T$). There are
several axioms to be checked, but the idea is always the same, so we will only
check the associativity of $\widehat{\cdot}$ and leave the rest to the reader.

In order to prove that the operation $\widehat{\cdot}$ is associative, we must
show that $u\widehat{\cdot}\left(  v\widehat{\cdot}w\right)  =\left(
u\widehat{\cdot}v\right)  \widehat{\cdot}w$ for all $u,v,w\in1+K\left[
\left[  T\right]  \right]  ^{+}$. Since the operation $\widehat{\cdot}$ is
continuous (by Theorem 5.5 \textbf{(d)}), and $1+K\left[  T\right]  ^{+}$ is a
dense subset of $1+K\left[  \left[  T\right]  \right]  ^{+}$ (by Theorem 5.5
\textbf{(a)}), this needs only to be shown for all $u,v,w\in1+K\left[
T\right]  ^{+}$.\ \ \ \ \footnote{At this point, we are actually also using
Theorem 5.5 \textbf{(e)}. In fact, what we are using is the fact that if two
continuous maps from a topological space $\mathfrak{P}$ to a Hausdorff
topological space $\mathfrak{Q}$ are equal to each other on a dense subset of
$\mathfrak{P}$, then they are equal to each other on the whole $\mathfrak{P}%
$.} So let us assume that $u,v,w\in1+K\left[  T\right]  ^{+}$. Then, there exist

\begin{itemize}
\item some $\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]
\right)  \in K^{\operatorname*{int}}$ such that $u=\Pi\left(  \widetilde{K}%
_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  ,$

\item some $\left(  \widetilde{K}_{v},\left[  v_{1},v_{2},...,v_{n}\right]
\right)  \in K^{\operatorname*{int}}$ such that $v=\Pi\left(  \widetilde{K}%
_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)  ,$

\item some $\left(  \widetilde{K}_{w},\left[  w_{1},w_{2},...,w_{\ell}\right]
\right)  \in K^{\operatorname*{int}}$ such that $w=\Pi\left(  \widetilde{K}%
_{w},\left[  w_{1},w_{2},...,w_{\ell}\right]  \right)  $.
\end{itemize}

Let $L=\widetilde{K}_{u}\otimes\widetilde{K}_{v}\otimes\widetilde{K}_{w}$. We
identify the rings $\widetilde{K}_{u},$ $\widetilde{K}_{v},$ $\widetilde{K}%
_{w}$ with the subrings $\widetilde{K}_{u}\otimes1\otimes1,$ $1\otimes
\widetilde{K}_{v}\otimes1,$ $1\otimes1\otimes\widetilde{K}_{w}$ of the ring
$L=\widetilde{K}_{u}\otimes\widetilde{K}_{v}\otimes\widetilde{K}_{w},$
respectively. This way, $L$ becomes an extension ring of $K$ which contains
all three rings $\widetilde{K}_{u},$ $\widetilde{K}_{v},$ $\widetilde{K}_{w}.$
Now, Theorem 5.3 \textbf{(c)} yields%
\begin{align*}
u\widehat{\cdot}v  &  =\Pi\left(  L,\left[  u_{i}v_{j}\mid\left(  i,j\right)
\in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right]
\right)  ;\\
\left(  u\widehat{\cdot}v\right)  \widehat{\cdot}w  &  =\Pi\left(  L,\left[
\left(  u_{i}v_{j}\right)  w_{k}\mid\left(  \left(  i,j\right)  ,k\right)
\in\left(  \left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}
\right)  \times\left\{  1,2,...,\ell\right\}  \right]  \right)  ,
\end{align*}
as well as%
\begin{align*}
v\widehat{\cdot}w  &  =\Pi\left(  L,\left[  v_{j}w_{k}\mid\left(  j,k\right)
\in\left\{  1,2,...,n\right\}  \times\left\{  1,2,...,\ell\right\}  \right]
\right)  ;\\
u\widehat{\cdot}\left(  v\widehat{\cdot}w\right)   &  =\Pi\left(  L,\left[
u_{i}\left(  v_{j}w_{k}\right)  \mid\left(  i,\left(  j,k\right)  \right)
\in\left\{  1,2,...,m\right\}  \times\left(  \left\{  1,2,...,n\right\}
\times\left\{  1,2,...,\ell\right\}  \right)  \right]  \right)  .
\end{align*}
But there is a canonical isomorphism of sets%
\[
\left(  \left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right)
\times\left\{  1,2,...,\ell\right\}  \rightarrow\left\{  1,2,...,m\right\}
\times\left(  \left\{  1,2,...,n\right\}  \times\left\{  1,2,...,\ell\right\}
\right)  ,
\]
mapping every $\left(  \left(  i,j\right)  ,k\right)  $ to $\left(  i,\left(
j,k\right)  \right)  $. Hence,%
\begin{align*}
&  \Pi\left(  L,\left[  \left(  u_{i}v_{j}\right)  w_{k}\mid\left(  \left(
i,j\right)  ,k\right)  \in\left(  \left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  \right)  \times\left\{  1,2,...,\ell\right\}  \right]
\right) \\
&  =\Pi\left(  L,\left[  \underbrace{\left(  u_{i}v_{j}\right)  w_{k}}%
_{=u_{i}\left(  v_{j}w_{k}\right)  }\mid\left(  i,\left(  j,k\right)  \right)
\in\left\{  1,2,...,m\right\}  \times\left(  \left\{  1,2,...,n\right\}
\times\left\{  1,2,...,\ell\right\}  \right)  \right]  \right) \\
&  =\Pi\left(  L,\left[  u_{i}\left(  v_{j}w_{k}\right)  \mid\left(  i,\left(
j,k\right)  \right)  \in\left\{  1,2,...,m\right\}  \times\left(  \left\{
1,2,...,n\right\}  \times\left\{  1,2,...,\ell\right\}  \right)  \right]
\right)  .
\end{align*}
Thus,%
\begin{align*}
\left(  u\widehat{\cdot}v\right)  \widehat{\cdot}w  &  =\Pi\left(  L,\left[
\left(  u_{i}v_{j}\right)  w_{k}\mid\left(  \left(  i,j\right)  ,k\right)
\in\left(  \left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}
\right)  \times\left\{  1,2,...,\ell\right\}  \right]  \right) \\
&  =\Pi\left(  L,\left[  u_{i}\left(  v_{j}w_{k}\right)  \mid\left(  i,\left(
j,k\right)  \right)  \in\left\{  1,2,...,m\right\}  \times\left(  \left\{
1,2,...,n\right\}  \times\left\{  1,2,...,\ell\right\}  \right)  \right]
\right) \\
&  =u\widehat{\cdot}\left(  v\widehat{\cdot}w\right)  .
\end{align*}
This proves the associativity of the operation $\widehat{\cdot}$. As I said
above, the other ring axioms can be proven similarly, so we can consider
Theorem 5.1 \textbf{(a)} as proven.

\textbf{(b)} It is easy to see that $\widehat{\lambda}^{0}\left(  x\right)
=1+T=\left(  \text{the multiplicative unity of the ring }\left(  1+K\left[
\left[  T\right]  \right]  ^{+},\widehat{+},\widehat{\cdot}\right)  \right)  $
and $\widehat{\lambda}^{1}\left(  x\right)  =x$ for every $x\in\Lambda\left(
K\right)  $. It now remains to prove that%
\begin{equation}
\widehat{\lambda}^{j}\left(  u+v\right)  =\widehat{\sum_{i=0}^{j}%
}\widehat{\lambda}^{i}\left(  u\right)  \widehat{\cdot}\widehat{\lambda}%
^{j-i}\left(  v\right)  \label{SpezLemma1}%
\end{equation}
for every $j\in\mathbb{N},$ $u\in\Lambda\left(  K\right)  $ and $v\in
\Lambda\left(  K\right)  .$ Here, the sign $\widehat{\sum\limits_{i=0}^{j}}$
means that the summation is based on the addition $\widehat{+}$ of the ring
$\Lambda\left(  K\right)  $.

Let us fix some $j\in\mathbb{N}$. Since the addition $\widehat{+},$ the
multiplication $\widehat{\cdot}$ and the map $\widehat{\lambda}^{i}$ for every
$i\in\mathbb{N}$ are continuous (by Theorem 5.5 \textbf{(d)}), and $1+K\left[
T\right]  ^{+}$ is a dense subset of $1+K\left[  \left[  T\right]  \right]
^{+}$ (by Theorem 5.5 \textbf{(a)}), we only need to check (\ref{SpezLemma1})
for all $u,v\in1+K\left[  T\right]  ^{+}$. So let us assume that
$u,v\in1+K\left[  T\right]  ^{+}$. Then, there exist some $\left(
\widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  \in
K^{\operatorname*{int}}$ such that $u=\Pi\left(  \widetilde{K}_{u},\left[
u_{1},u_{2},...,u_{m}\right]  \right)  ,$ and some $\left(  \widetilde{K}%
_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)  \in K^{\operatorname*{int}%
}$ such that $v=\Pi\left(  \widetilde{K}_{v},\left[  v_{1},v_{2}%
,...,v_{n}\right]  \right)  $. Let $\widetilde{K}_{u,v}$ be a finite-free
extension ring of $K$ which contains both $\widetilde{K}_{u}$ and
$\widetilde{K}_{v}$ as subrings. (Such an extension ring exists, as was proven
in Theorem 5.3 \textbf{(a)}.) Theorem 5.3 \textbf{(b)} yields%
\[
u\widehat{+}v=\Pi\left(  \widetilde{K}_{u,v},\left[  u_{1},u_{2}%
,...,u_{m},v_{1},v_{2},...,v_{n}\right]  \right)  .
\]
In other words, if we define $m+n$ elements $w_{1},$ $w_{2},$ $...,$ $w_{m+n}$
by $w_{i}=\left\{
\begin{array}
[c]{c}%
u_{i},\text{ if }i\leq m;\\
v_{i-m},\text{ if }i>m
\end{array}
\right.  $ for every $i\in\left\{  1,2,...,m+n\right\}  $, then%
\[
u\widehat{+}v=\Pi\left(  \widetilde{K}_{u,v},\left[  w_{1},w_{2}%
,...,w_{m+n}\right]  \right)  .
\]
Thus, Theorem 5.3 \textbf{(d)} yields%
\[
\widehat{\lambda}^{j}\left(  u\widehat{+}v\right)  =\Pi\left(  \widetilde{K}%
_{u,v},\left[  \prod\limits_{i\in I}w_{i}\ \mid\ I\in\mathcal{P}_{j}\left(
\left\{  1,2,...,m+n\right\}  \right)  \right]  \right)  .
\]
But since%
\begin{align*}
&  \left[  \prod\limits_{i\in I}w_{i}\ \mid\ I\in\mathcal{P}_{j}\left(
\left\{  1,2,...,m+n\right\}  \right)  \right] \\
&  =\left[  \prod\limits_{i\in J\cup K^{\prime}}w_{i}\ \mid\ i\in\left\{
0,1,...,j\right\}  \text{, }J\in\mathcal{P}_{i}\left(  \left\{
1,2,...,m\right\}  \right)  \text{, }K^{\prime}\in\mathcal{P}_{j-i}\left(
\left\{  m+1,m+2,...,m+n\right\}  \right)  \right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because every set }I\in\mathcal{P}_{j}\left(  \left\{
1,2,...,m+n\right\}  \right)  \text{ can be uniquely}\\
\text{written as a union of two sets }J\in\mathcal{P}_{i}\left(  \left\{
1,2,...,m\right\}  \right)  \text{ and}\\
K^{\prime}\in\mathcal{P}_{j-i}\left(  \left\{  m+1,m+2,...,m+n\right\}
\right)  \text{ for some }i\in\left\{  0,1,...,j\right\} \\
\text{(namely, these two sets are }J=I\cap\left\{  1,2,...,m\right\}  \text{
and}\\
K^{\prime}=I\cap\left\{  m+1,m+2,...,m+n\right\}  \text{, and }i\text{ is the
cardinality of }J\text{)}%
\end{array}
\right) \\
&  =\left[  \prod\limits_{\alpha\in J}w_{\alpha}\prod\limits_{\beta\in
K^{\prime}}w_{\beta}\ \mid\ i\in\left\{  0,1,...,j\right\}  \text{, }%
J\in\mathcal{P}_{i}\left(  \left\{  1,2,...,m\right\}  \right)  \text{,
}K^{\prime}\in\mathcal{P}_{j-i}\left(  \left\{  m+1,m+2,...,m+n\right\}
\right)  \right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\prod\limits_{i\in J\cup
K^{\prime}}w_{i}=\prod\limits_{\alpha\in J}w_{\alpha}\prod\limits_{\beta\in
K^{\prime}}w_{\beta}\text{ (because }J\cap K^{\prime}=\varnothing
\text{)}\right) \\
&  =\left[  \prod\limits_{\alpha\in J}w_{\alpha}\prod\limits_{\beta\in
M}w_{m+\beta}\ \mid\ i\in\left\{  0,1,...,j\right\}  \text{, }J\in
\mathcal{P}_{i}\left(  \left\{  1,2,...,m\right\}  \right)  \text{, }%
M\in\mathcal{P}_{j-i}\left(  \left\{  1,2,...,n\right\}  \right)  \right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we have substituted }M=\left\{
u-m\mid u\in K^{\prime}\right\}  \text{ for }K^{\prime}\right) \\
&  =\left[  \prod\limits_{\alpha\in J}u_{\alpha}\prod\limits_{\beta\in
M}v_{\beta}\ \mid\ i\in\left\{  0,1,...,j\right\}  \text{, }J\in
\mathcal{P}_{i}\left(  \left\{  1,2,...,m\right\}  \right)  \text{, }%
M\in\mathcal{P}_{j-i}\left(  \left\{  1,2,...,n\right\}  \right)  \right] \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }w_{i}=\left\{
\begin{array}
[c]{c}%
u_{i},\text{ if }i\leq m;\\
v_{i-m},\text{ if }i>m
\end{array}
\right.  \right)  ,
\end{align*}
this becomes%
\begin{align*}
&  \widehat{\lambda}^{j}\left(  u\widehat{+}v\right) \\
&  =\Pi\left(  \widetilde{K}_{u,v},\left[  \prod\limits_{\alpha\in J}%
u_{\alpha}\prod\limits_{\beta\in M}v_{\beta}\ \mid\ i\in\left\{
0,1,...,j\right\}  \text{, }J\in\mathcal{P}_{i}\left(  \left\{
1,2,...,m\right\}  \right)  \text{, }M\in\mathcal{P}_{j-i}\left(  \left\{
1,2,...,n\right\}  \right)  \right]  \right) \\
&  =\widehat{\sum_{i=0}^{j}}\Pi\left(  \widetilde{K}_{u,v},\left[
\prod\limits_{\alpha\in J}u_{\alpha}\prod\limits_{\beta\in M}v_{\beta}%
\ \mid\ J\in\mathcal{P}_{i}\left(  \left\{  1,2,...,m\right\}  \right)
\text{, }M\in\mathcal{P}_{j-i}\left(  \left\{  1,2,...,n\right\}  \right)
\right]  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Corollary 5.4 \textbf{(a)}}\right) \\
&  =\widehat{\sum_{i=0}^{j}}\underbrace{\Pi\left(  \widetilde{K}_{u},\left[
\prod\limits_{\alpha\in J}u_{\alpha}\ \mid\ J\in\mathcal{P}_{i}\left(
\left\{  1,2,...,m\right\}  \right)  \right]  \right)  }_{=\widehat{\lambda
}^{i}\left(  u\right)  \text{ by Theorem 5.3 \textbf{(d)}}}\widehat{\cdot
}\underbrace{\Pi\left(  \widetilde{K}_{v},\left[  \prod\limits_{\beta\in
M}v_{\beta}\ \mid\ \text{ }M\in\mathcal{P}_{j-i}\left(  \left\{
1,2,...,n\right\}  \right)  \right]  \right)  }_{=\widehat{\lambda}%
^{j-i}\left(  v\right)  \text{ by Theorem 5.3 \textbf{(d)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 5.3 \textbf{(c)}}\right) \\
&  =\widehat{\sum_{i=0}^{j}}\widehat{\lambda}^{i}\left(  u\right)
\widehat{\cdot}\widehat{\lambda}^{j-i}\left(  v\right)  ,
\end{align*}
proving (\ref{SpezLemma1}). Theorem 5.1 \textbf{(b)} is proven.

\subsection{$\lambda_{T}:K\rightarrow\Lambda\left(  K\right)  $ is an additive
group homomorphism}

The following trivial fact is a foreshadowing of the notion of "special
$\lambda$-rings":

\begin{quote}
\textbf{Theorem 5.6.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Consider the map $\lambda
_{T}:K\rightarrow\Lambda\left(  K\right)  $ defined by
\[
\lambda_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  T^{i}\ \ \ \ \ \ \ \ \ \ \text{for every }x\in K.
\]
Then, $\lambda_{T}$ is an additive group homomorphism (where the additive
group structure on $\Lambda\left(  K\right)  $ is given by $\widehat{+}$).
\end{quote}

\textit{Proof of Theorem 5.6.} The map $\lambda_{T}$ is well-defined (i. e.
every $x\in K$ satisfies $\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  T^{i}\in\Lambda\left(  K\right)  $) because $\lambda^{0}\left(
x\right)  =1$ for every $x\in K$. The assertion that $\lambda_{T}$ is an
additive group homomorphism follows from Theorem 2.1 \textbf{(b)} (because as
an additive group, $\Lambda\left(  K\right)  =\left(  \Lambda\left(  K\right)
,\widehat{+}\right)  =\left(  \Lambda\left(  K\right)  ,\cdot\right)  $).
Theorem 5.6 is thus proven.

While Theorem 5.6 says that $\lambda_{T}$ is an additive group homomorphism,
it is not in general a ring homomorphism. But for many $\lambda$-rings $K$, it
is one - and even a $\lambda$-ring homomorphism. These $\lambda$-rings will be
studied in the next Section.

\subsection{On the evaluation (substitution) map}

The following properties of the map $\operatorname*{ev}$ defined in Section 3
will turn out useful to us later:

\begin{quote}
\textbf{Theorem 5.7.} Let $K$ be a ring.

\textbf{(a)} For every $\mu\in K$, the map $\operatorname*{ev}_{\mu
T}:K\left[  \left[  T\right]  \right]  \rightarrow K\left[  \left[  T\right]
\right]  $ is continuous (with respect to the $\left(  T\right)  $-topology).

\textbf{(b)} Let $u\in1+K\left[  T\right]  ^{+}$. Assume that $u=\Pi\left(
\widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  $ for some
$\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  \in
K^{\operatorname*{int}}$. Let $\mu\in K$. Then, $\operatorname*{ev}_{\mu
T}\left(  u\right)  =\Pi\left(  \widetilde{K}_{u},\left[  \mu u_{1},\mu
u_{2},...,\mu u_{m}\right]  \right)  =\Pi\left(  \widetilde{K}_{u},\left[  \mu
u_{i}\mid i\in\left\{  1,2,...,m\right\}  \right]  \right)  $.

\textbf{(c)} Let $u\in\Lambda\left(  K\right)  $ and $v\in\Lambda\left(
K\right)  $. Let $\mu\in K$. Then, $\operatorname*{ev}_{\mu T}\left(
u\right)  \widehat{+}\operatorname*{ev}_{\mu T}\left(  v\right)
=\operatorname*{ev}_{\mu T}\left(  u\widehat{+}v\right)  $.

\textbf{(d)} Let $u\in\Lambda\left(  K\right)  $ and $v\in\Lambda\left(
K\right)  $. Let $\mu\in K$ and $\nu\in K$. Then, $\operatorname*{ev}_{\mu
T}\left(  u\right)  \widehat{\cdot}\operatorname*{ev}_{\nu T}\left(  v\right)
=\operatorname*{ev}_{\mu\nu T}\left(  u\widehat{\cdot}v\right)  $.

\textbf{(e)} Let $u\in\Lambda\left(  K\right)  $. Let $\mu\in K$. Let
$k\in\mathbb{N}$. Then, $\widehat{\lambda}^{k}\left(  \operatorname*{ev}_{\mu
T}\left(  u\right)  \right)  =\operatorname*{ev}_{\mu^{k}T}\left(
\widehat{\lambda}^{k}\left(  u\right)  \right)  $.
\end{quote}

\textit{Proof of Theorem 5.7.} \textbf{(a)} Obvious from Theorem 5.5
\textbf{(b)} (or, more precisely, from the assertion you get if you replace
$1+K\left[  \left[  T\right]  \right]  ^{+}$ by $K\left[  \left[  T\right]
\right]  $ in Theorem 5.5 \textbf{(b)}; but this assertion is proven in the
same way as Theorem 5.5 \textbf{(b)}).

\textbf{(b)} By assumption, $u=\Pi\left(  \widetilde{K}_{u},\left[
u_{1},u_{2},...,u_{m}\right]  \right)  =\prod\limits_{i=1}^{m}\left(
1+u_{i}T\right)  ,$ so that%
\[
\operatorname{ev}_{\mu T}\left(  u\right)  =\prod\limits_{i=1}^{m}\left(
1+u_{i}\mu T\right)  =\prod\limits_{i=1}^{m}\left(  1+\mu u_{i}T\right)
=\Pi\left(  \widetilde{K}_{u},\left[  \mu u_{1},\mu u_{2},...,\mu
u_{m}\right]  \right)  ,
\]
and Theorem 5.7 \textbf{(b)} is proven.

\textbf{(d)} Since the operation $\widehat{\cdot}$ and the maps
$\operatorname*{ev}_{\mu T}$, $\operatorname*{ev}_{\nu T}$ and
$\operatorname*{ev}_{\mu\nu T}$ are continuous (by Theorem 5.5 \textbf{(d)
}and Theorem 5.7 \textbf{(a)}), and $1+K\left[  T\right]  ^{+}$ is a dense
subset of $1+K\left[  \left[  T\right]  \right]  ^{+}$ (by Theorem 5.5
\textbf{(a)}), this needs only to be shown for all $u,v\in1+K\left[  T\right]
^{+}$. So let us assume that $u,v\in1+K\left[  T\right]  ^{+}$. Then, there
exist some $\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]
\right)  \in K^{\operatorname*{int}}$ such that $u=\Pi\left(  \widetilde{K}%
_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  ,$ and some $\left(
\widetilde{K}_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)  \in
K^{\operatorname*{int}}$ such that $v=\Pi\left(  \widetilde{K}_{v},\left[
v_{1},v_{2},...,v_{n}\right]  \right)  $. Theorem 5.3 \textbf{(a)} says that
there exists an extension ring $\widetilde{K}_{u,v}$ containing both
$\widetilde{K}_{u}$ and $\widetilde{K}_{v}$ as subrings. Now, Theorem 5.3
\textbf{(c)} yields $u\widehat{\cdot}v=\Pi\left(  \widetilde{K}_{u,v},\left[
u_{i}v_{j}\mid\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  \right]  \right)  $, so that Theorem 5.7
\textbf{(b)} gives us%
\begin{align*}
\operatorname*{ev}\nolimits_{\mu\nu T}\left(  u\widehat{\cdot}v\right)   &
=\Pi\left(  \widetilde{K}_{u,v},\left[  \mu\nu u_{i}v_{j}\mid\left(
i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}
\right]  \right) \\
&  =\Pi\left(  \widetilde{K}_{u,v},\left[  \mu u_{i}\cdot\nu v_{j}\mid\left(
i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}
\right]  \right)  .
\end{align*}


On the other hand, Theorem 5.7 \textbf{(b)} yields $\operatorname*{ev}_{\mu
T}\left(  u\right)  =\Pi\left(  \widetilde{K}_{u},\left[  \mu u_{1},\mu
u_{2},...,\mu u_{m}\right]  \right)  $ and (similarly) $\operatorname*{ev}%
_{\nu T}\left(  v\right)  =\Pi\left(  \widetilde{K}_{v},\left[  \nu v_{1},\nu
v_{2},...,\nu v_{n}\right]  \right)  $. Thus, Theorem 5.3 \textbf{(c)} yields%
\[
\operatorname*{ev}\nolimits_{\mu T}\left(  u\right)  \widehat{\cdot
}\operatorname*{ev}\nolimits_{\nu T}\left(  v\right)  =\Pi\left(
\widetilde{K}_{u,v},\left[  \mu u_{i}\cdot\nu v_{j}\mid\left(  i,j\right)
\in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right]
\right)  .
\]
Hence, $\operatorname*{ev}_{\mu T}\left(  u\right)  \widehat{\cdot
}\operatorname*{ev}_{\nu T}\left(  v\right)  =\operatorname*{ev}_{\mu\nu
T}\left(  u\widehat{\cdot}v\right)  $. This proves Theorem 5.7 \textbf{(d)}.

\textbf{(c)} We can prove Theorem 5.7 \textbf{(c)} similarly to our above
proof of Theorem 5.7 \textbf{(d)}. However, there is also a much simpler proof
of Theorem 5.7 \textbf{(c)}: Since $\operatorname*{ev}\nolimits_{\mu T}$ is a
ring homomorphism, we have $\operatorname*{ev}\nolimits_{\mu T}\left(
u\right)  \cdot\operatorname*{ev}\nolimits_{\nu T}\left(  v\right)
=\operatorname*{ev}\nolimits_{\mu T}\left(  u\cdot v\right)  $. Since
$\widehat{+}$ is the multiplication on $1+K\left[  \left[  T\right]  \right]
^{+}$, this rewrites as $\operatorname*{ev}_{\mu T}\left(  u\right)
\widehat{+}\operatorname*{ev}_{\mu T}\left(  v\right)  =\operatorname*{ev}%
_{\mu T}\left(  u\widehat{+}v\right)  $. This proves Theorem 5.7 \textbf{(c)}.

\textbf{(e)} Since the maps $\widehat{\lambda}^{k}$ and $\operatorname*{ev}%
_{\mu T}$ and $\operatorname*{ev}\nolimits_{\mu^{k}T}$ are continuous (by
Theorem 5.5 \textbf{(d) }and Theorem 5.7 \textbf{(a)}), and $1+K\left[
T\right]  ^{+}$ is a dense subset of $1+K\left[  \left[  T\right]  \right]
^{+}$ (by Theorem 5.5 \textbf{(a)}), this needs only to be shown for all
$u\in1+K\left[  T\right]  ^{+}$. So, from now on we assume that $u\in
1+K\left[  T\right]  ^{+}$. Then, there exists some $\left(  \widetilde{K}%
_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  \in K^{\operatorname*{int}%
}$ such that $u=\Pi\left(  \widetilde{K}_{u},\left[  u_{1},u_{2}%
,...,u_{m}\right]  \right)  $. Theorem 5.3 \textbf{(d)} then yields%
\[
\widehat{\lambda}^{k}\left(  u\right)  =\Pi\left(  \widetilde{K}_{u},\left[
\prod\limits_{i\in I}u_{i}\ \mid\ I\in\mathcal{P}_{k}\left(  \left\{
1,2,...,m\right\}  \right)  \right]  \right)  =\prod\limits_{I\in
\mathcal{P}_{k}\left(  \left\{  1,2,...,m\right\}  \right)  }\left(
1+\prod\limits_{i\in I}u_{i}\cdot T\right)  ,
\]
so that%
\begin{align*}
\operatorname*{ev}\nolimits_{\mu^{k}T}\left(  \widehat{\lambda}^{k}\left(
u\right)  \right)   &  =\prod\limits_{I\in\mathcal{P}_{k}\left(  \left\{
1,2,...,m\right\}  \right)  }\left(  1+\prod\limits_{i\in I}u_{i}\cdot\mu
^{k}T\right)  =\prod\limits_{I\in\mathcal{P}_{k}\left(  \left\{
1,2,...,m\right\}  \right)  }\left(  1+\prod\limits_{i\in I}\left(  \mu
u_{i}\right)  \cdot T\right) \\
&  =\Pi\left(  \widetilde{K}_{u},\left[  \prod\limits_{i\in I}\left(  \mu
u_{i}\right)  \ \mid\ I\in\mathcal{P}_{k}\left(  \left\{  1,2,...,m\right\}
\right)  \right]  \right)  .
\end{align*}
On the other hand, Theorem 5.7 \textbf{(b)} yields $\operatorname*{ev}_{\mu
T}\left(  u\right)  =\Pi\left(  \widetilde{K}_{u},\left[  \mu u_{1},\mu
u_{2},...,\mu u_{m}\right]  \right)  $ and thus, by Theorem 5.3 \textbf{(d)}
again,%
\[
\widehat{\lambda}^{k}\left(  \operatorname*{ev}\nolimits_{\mu T}\left(
u\right)  \right)  =\Pi\left(  \widetilde{K}_{u},\left[  \prod\limits_{i\in
I}\left(  \mu u_{i}\right)  \ \mid\ I\in\mathcal{P}_{k}\left(  \left\{
1,2,...,m\right\}  \right)  \right]  \right)  ,
\]
so that we conclude $\widehat{\lambda}^{k}\left(  \operatorname*{ev}_{\mu
T}\left(  u\right)  \right)  =\operatorname*{ev}_{\mu^{k}T}\left(
\widehat{\lambda}^{k}\left(  u\right)  \right)  $, and Theorem 5.7
\textbf{(e)} is proven.

\subsection{The functor $\Lambda$}

Finally, a small definition that turns $\Lambda$ into a functor:

\begin{quote}
\textbf{Definition.} Every homomorphism $\varphi:K\rightarrow L$ of rings
canonically induces a $\lambda$-ring homomorphism $\Lambda\left(  K\right)
\rightarrow\Lambda\left(  L\right)  $ (which sends every $\sum\limits_{i\in
\mathbb{N}}a_{i}T^{i}\in\Lambda\left(  K\right)  $ to $\sum\limits_{i\in
\mathbb{N}}\varphi\left(  a_{i}\right)  T^{i}\in\Lambda\left(  L\right)  $).
This homomorphism $\Lambda\left(  K\right)  \rightarrow\Lambda\left(
L\right)  $ will be denoted by $\Lambda\left(  \varphi\right)  $.
\end{quote}

It is easy to see that this $\Lambda\left(  \varphi\right)  $ indeed is a
$\lambda$-ring homomorphism.\footnote{Basically, this is because the $P_{k}$
and $P_{k,j}$ are polynomials, and polynomials commute with ring
homomorphisms.} Besides, it has some obvious properties: If $\varphi$ is
surjective, then so is $\Lambda\left(  \varphi\right)  $. If $\varphi$ is
injective, then $\Lambda\left(  \varphi\right)  $ is injective as well; thus,
if $L$ is an extension ring of $K$, then $\Lambda\left(  L\right)  $ can be
canonically considered an extension ring of $\Lambda\left(  K\right)  $.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 5.1.} Let $K$ be a ring. For every monic polynomial $P\in
K\left[  T\right]  $, there exists a finite-free extension ring $K_{P}$ of the
ring $K$ and $n$ elements $p_{1},$ $p_{2},$ $...,$ $p_{n}$ of this extension
ring $K_{P}$ such that $P=\prod\limits_{i=1}^{n}\left(  T-p_{i}\right)  $ in
$K_{P}\left[  T\right]  $, where $n=\deg P$.

\textit{Exercise 5.2.} Let $L$ be a ring. Let $n\in\mathbb{N}$, let $a_{0}$,
$a_{1}$, $...$, $a_{n}$ be some elements of $L$, and let $p_{1}$, $p_{2}$,
$...$, $p_{n}$ be some elements of $L$.

\textbf{(a)} If $\sum\limits_{i=0}^{n}a_{n-i}T^{i}=\prod\limits_{i=1}%
^{n}\left(  p_{i}+T\right)  $ in the polynomial ring $L\left[  T\right]  $,
then prove that $\sum\limits_{i=0}^{n}a_{i}T^{i}=\prod\limits_{i=1}^{n}\left(
1+p_{i}T\right)  $.

\textbf{(b)} If $\sum\limits_{i=0}^{n}a_{i}T^{i}=\prod\limits_{i=1}^{n}\left(
1+p_{i}T\right)  $ in the polynomial ring $L\left[  T\right]  $, then prove
that $\sum\limits_{i=0}^{n}a_{n-i}T^{i}=\prod\limits_{i=1}^{n}\left(
p_{i}+T\right)  $.

\textit{Exercise 5.3.} Let $K$ be a ring. Let $p$ be an element of $K$. Let
$P\in K\left[  T\right]  $ be a monic polynomial such that $P\left(  p\right)
=0$. Let $n=\deg P$. Then, there exists a finite-free extension ring
$K_{P}^{\prime}$ of the ring $K$ and $n$ elements $p_{1},$ $p_{2},$ $...,$
$p_{n}$ of this extension ring $K_{P}^{\prime}$ such that $P=\prod
\limits_{i=1}^{n}\left(  T-p_{i}\right)  $ in $K_{P}^{\prime}\left[  T\right]
$ and such that $p=p_{n}$.

\textit{Exercise 5.4.} Let $K$ be a ring, and $L$ an extension ring of $K$.
For some $n\in\mathbb{N}$, an element $u$ of $L$ is said to be $n$%
\textit{-integral} over $K$ if there exists a monic polynomial $P\in K\left[
T\right]  $ such that $\deg P=n$ and $P\left(  u\right)  =0$.

Let $n\in\mathbb{N}$ and $m\in\mathbb{N}$. Let $\alpha$ and $\beta$ be two
elements of $L$ such that $\alpha$ is $n$-integral over $K$ and $\beta$ is
$m$-integral over $K$. Prove that $\alpha\beta$ is $nm$-integral over $K$.

[This is a known fact, but it turns out to also be a corollary of our
construction of the polynomials $P_{k}$ further above.]

\textit{Exercise 5.5.} Let $K$ be a ring, and $I$ be an ideal of $K$. Let
$I\left[  \left[  T\right]  \right]  $ denote the subring%
\begin{align*}
&  \left\{  \sum_{i\in\mathbb{N}}a_{i}T^{i}\in K\left[  \left[  T\right]
\right]  \ \mid\ a_{i}\in I\text{ for all }i\right\} \\
&  =\left\{  p\in K\left[  \left[  T\right]  \right]  \ \mid\ p\text{ is a
power series with all its coefficients lying in }I\right\}
\end{align*}
of $K\left[  \left[  T\right]  \right]  $. Let $I\left[  \left[  T\right]
\right]  ^{+}$ denote the subset%
\begin{align*}
TI\left[  \left[  T\right]  \right]   &  =\left\{  \sum_{i\in\mathbb{N}}%
a_{i}T^{i}\in I\left[  \left[  T\right]  \right]  \ \mid\ a_{i}\in I\text{ for
all }i,\text{ and }a_{0}=0\right\} \\
&  =\left\{  p\in I\left[  \left[  T\right]  \right]  \ \mid\ p\text{ is a
power series with constant term }0\right\}
\end{align*}
of $I\left[  \left[  T\right]  \right]  $. Consider the subset $1+I\left[
\left[  T\right]  \right]  ^{+}$ of $1+K\left[  \left[  T\right]  \right]
^{+}=\Lambda\left(  K\right)  $.\ \ \ \ \footnote{Notice that $I\left[
\left[  T\right]  \right]  ^{+}\neq I\cdot\left(  K\left[  \left[  T\right]
\right]  ^{+}\right)  $ in general!} Prove the following:

\textbf{(a)} We have $1+I\left[  \left[  T\right]  \right]  ^{+}%
=\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)  $, where $\pi$
is the canonical projection $K\rightarrow K\diagup I$.

\textbf{(b)} The set $1+I\left[  \left[  T\right]  \right]  ^{+}$ is a
$\lambda$-ideal of the $\lambda$-ring $\Lambda\left(  K\right)  $.
\end{quotation}

\section{Special $\lambda$-rings}

\subsection{Definition}

Now we will define a particular subclass of $\lambda$-rings that we will be
interested in from now on:

\begin{quote}
\textbf{Definition.} \textbf{1)} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. The map $\lambda_{T}$ defined
in Theorem 5.6 is an additive group homomorphism (by Theorem 5.6). We call
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ a
\textit{special }$\lambda$\textit{-ring} if this map $\lambda_{T}:\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  \rightarrow\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  $ is a $\lambda$-ring homomorphism.

\textbf{2)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a $\lambda$-ring. Let $L$ be a sub-$\lambda$-ring of $K$. If
$\left(  L,\left(  \lambda^{i}\mid_{L}\right)  _{i\in\mathbb{N}}\right)  $ is
a special $\lambda$-ring, then we call $L$ a \textit{special sub-}$\lambda
$\textit{-ring} of $K$.
\end{quote}

A different, more down-to-earth characterization of special $\lambda$-rings:

\begin{quote}
\textbf{Theorem 6.1.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring.

Then, $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a
special $\lambda$-ring if and only if%
\begin{align}
&  \lambda^{k}\left(  xy\right)  =P_{k}\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{k}\left(  x\right)  ,\lambda
^{1}\left(  y\right)  ,\lambda^{2}\left(  y\right)  ,...,\lambda^{k}\left(
y\right)  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N}\text{, }x\in K\text{
and }y\in K \label{Lkxy}%
\end{align}
and%
\begin{align}
&  \lambda^{k}\left(  \lambda^{j}\left(  x\right)  \right)  =P_{k,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{kj}\left(  x\right)  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N}\text{, }j\in
\mathbb{N}\text{ and }x\in K. \label{LkLjx}%
\end{align}



\end{quote}

\textit{Proof of Theorem 6.1.} According to the preceding definition, $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a special
$\lambda$-ring if and only if the map $\lambda_{T}$ is a $\lambda$-ring
homomorphism. This map is always an additive group homomorphism (by Theorem
5.6); hence, it is a $\lambda$-ring homomorphism if and only if it satisfies
the three conditions%
\begin{align*}
\lambda_{T}\left(  xy\right)   &  =\lambda_{T}\left(  x\right)  \widehat{\cdot
}\lambda_{T}\left(  y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }x\in
K\text{ and }y\in K,\\
\lambda_{T}\left(  1\right)   &  =1+T,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\lambda_{T}\left(  \lambda^{j}\left(  x\right)  \right)   &  =\widehat{\lambda
}^{j}\left(  \lambda_{T}\left(  x\right)  \right)
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\mathbb{N}\text{ and }x\in K
\end{align*}
(note that $1+T$ is the multiplicative unity of $\Lambda\left(  K\right)  $).
The second of these three conditions actually follows from the third one
(since $\lambda_{T}\left(  \lambda^{j}\left(  x\right)  \right)
=\widehat{\lambda}^{j}\left(  \lambda_{T}\left(  x\right)  \right)  $, applied
to $j=0$, yields $\lambda_{T}\left(  1\right)  =1+T$), so we see that the map
$\lambda_{T}$ is a $\lambda$-ring homomorphism if and only if it satisfies the
two conditions%
\begin{align*}
\lambda_{T}\left(  xy\right)   &  =\lambda_{T}\left(  x\right)  \widehat{\cdot
}\lambda_{T}\left(  y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }x\in
K\text{ and }y\in K,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\lambda_{T}\left(  \lambda^{j}\left(  x\right)  \right)   &  =\widehat{\lambda
}^{j}\left(  \lambda_{T}\left(  x\right)  \right)
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\mathbb{N}\text{ and }x\in K.
\end{align*}


But these two conditions are equivalent to (\ref{Lkxy}) and (\ref{LkLjx}),
respectively (because of the definitions of $\widehat{\cdot}$ and
$\widehat{\lambda}^{j}$ and because two formal power series are equal if and
only if their respective coefficients are equal). This proves Theorem 6.1.

\subsection{$\Lambda\left(  K\right)  $ is special}

\begin{quote}
\textbf{Theorem 6.2 (Grothendieck).} Let $K$ be a ring. Then, $\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  $ is a special $\lambda$-ring.
\end{quote}

\textit{Proof of Theorem 6.2.} According to Theorem 6.1, we only have to prove
that%
\begin{align}
&  \widehat{\lambda}^{k}\left(  u\widehat{\cdot}v\right)  =\widehat{P_{k}%
}\left(  \widehat{\lambda}^{1}\left(  u\right)  ,\widehat{\lambda}^{2}\left(
u\right)  ,...,\widehat{\lambda}^{k}\left(  u\right)  ,\widehat{\lambda}%
^{1}\left(  v\right)  ,\widehat{\lambda}^{2}\left(  v\right)
,...,\widehat{\lambda}^{k}\left(  v\right)  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N}\text{, }u\in
\Lambda\left(  K\right)  \text{ and }v\in\Lambda\left(  K\right)  ,
\label{6.2.P.Lkxy}%
\end{align}
and%
\begin{align}
&  \widehat{\lambda}^{k}\left(  \widehat{\lambda}^{j}\left(  u\right)
\right)  =\widehat{P_{k,j}}\left(  \widehat{\lambda}^{1}\left(  u\right)
,\widehat{\lambda}^{2}\left(  u\right)  ,...,\widehat{\lambda}^{kj}\left(
u\right)  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N}\text{, }j\in
\mathbb{N}\text{ and }u\in\Lambda\left(  K\right)  . \label{6.2.P.LkLjx}%
\end{align}
Here, we are using the following \textit{notation:} If $S\in\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{kj}\right]  $ is a polynomial, then
$\widehat{S}\left(  \widehat{\lambda}^{1}\left(  u\right)  ,\widehat{\lambda
}^{2}\left(  u\right)  ,...,\widehat{\lambda}^{kj}\left(  u\right)  \right)  $
denotes the polynomial $S$ applied to $\widehat{\lambda}^{1}\left(  u\right)
,$ $\widehat{\lambda}^{2}\left(  u\right)  ,$ $...,$ $\widehat{\lambda}%
^{kj}\left(  u\right)  $ \textit{as elements of the ring }$\Lambda\left(
K\right)  $ (and not as elements of the ring $K\left[  \left[  T\right]
\right]  $). For instance, if $S=\alpha_{1}+\alpha_{2}+...+\alpha_{kj},$ then
$\widehat{S}\left(  \widehat{\lambda}^{1}\left(  u\right)  ,\widehat{\lambda
}^{2}\left(  u\right)  ,...,\widehat{\lambda}^{kj}\left(  u\right)  \right)  $
means $\widehat{\lambda}^{1}\left(  u\right)  \widehat{+}\widehat{\lambda}%
^{2}\left(  u\right)  \widehat{+}...\widehat{+}\widehat{\lambda}^{kj}\left(
u\right)  $ (and not $\widehat{\lambda}^{1}\left(  u\right)  +\widehat{\lambda
}^{2}\left(  u\right)  +...+\widehat{\lambda}^{kj}\left(  u\right)  $, where
$+$ denotes the addition in the ring $K\left[  \left[  T\right]  \right]  $).
This explains how the right hand sides of the equations (\ref{6.2.P.Lkxy}) and
(\ref{6.2.P.LkLjx}) should be understood.

Let us first prove (\ref{6.2.P.Lkxy}): Since the subset $1+K\left[  T\right]
^{+}$ is dense in $1+K\left[  \left[  T\right]  \right]  ^{+}=\Lambda\left(
K\right)  $ (by Theorem 5.5 \textbf{(a)}), and since $\widehat{\cdot}$ and
$\widehat{\lambda}^{i}$ are continuous (by Theorem 5.5 \textbf{(d)}), it will
be enough to verify (\ref{6.2.P.Lkxy}) for $u\in1+K\left[  T\right]  ^{+}$ and
$v\in1+K\left[  T\right]  ^{+}$. Then, there exist some $\left(
\widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  \in
K^{\operatorname*{int}}$ such that $u=\Pi\left(  \widetilde{K},\left[
u_{1},u_{2},...,u_{m}\right]  \right)  ,$ and some $\left(  \widetilde{K}%
_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)  \in K^{\operatorname*{int}%
}$ such that $v=\Pi\left(  \widetilde{K},\left[  v_{1},v_{2},...,v_{n}\right]
\right)  .$ By Theorem 5.3 \textbf{(a)}, there exists a finite-free extension
ring $\widetilde{K}_{u,v}$ of $K$ which contains both $\widetilde{K}_{u}$ and
$\widetilde{K}_{v}$ as subrings. We replace $K$ by $\widetilde{K}_{u,v}$ now
(silently using the obvious fact that the injection $K\rightarrow
\widetilde{K}_{u,v}$ canonically yields an injection $\Lambda\left(  K\right)
\rightarrow\Lambda\left(  \widetilde{K}_{u,v}\right)  $). Hence, we can now
assume that $u_{1},$ $u_{2},$ $...,$ $u_{m},$ $v_{1},$ $v_{2},$ $...,$ $v_{n}$
all lie in $K$. Theorem 5.3 \textbf{(c)} yields $u\widehat{\cdot}v=\Pi\left(
\widetilde{K}_{u,v},\left[  u_{i}v_{j}\mid\left(  i,j\right)  \in\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right]  \right)  $.
Since we identified $\widetilde{K}_{u,v}$ with $K$, this becomes%
\[
u\widehat{\cdot}v=\Pi\left(  K,\left[  u_{i}v_{j}\mid\left(  i,j\right)
\in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right]
\right)  .
\]
Thus, Theorem 5.3' \textbf{(d)} (applied to $w=u\widehat{\cdot}v$,
$\widetilde{K}=K$, $L=\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  $ and $w_{\left(  i,j\right)  }=u_{i}v_{j}$) yields%
\[
\widehat{\lambda}^{k}\left(  u\widehat{\cdot}v\right)  =\Pi\left(  K,\left[
\prod_{\left(  i,j\right)  \in S}u_{i}v_{j}\mid S\in\mathcal{P}_{k}\left(
\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right)
\right]  \right)  .
\]


There exists a ring homomorphism%
\[
\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]
\rightarrow\Lambda\left(  K\right)
\]
which maps $U_{i}$ to $1+u_{i}T$ for every $i$ and $V_{j}$ to $1+v_{j}T$ for
every $j$. This homomorphism maps $X_{i}=\sum\limits_{\substack{S\subseteq
\left\{  1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in
S}U_{k}$ to%
\begin{align*}
\widehat{\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}}\widehat{\prod\limits_{k\in S}}%
\underbrace{\left(  1+u_{k}T\right)  }_{=\Pi\left(  K,\left[  u_{k}\right]
\right)  }  &  =\widehat{\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}}\underbrace{\widehat{\prod
\limits_{k\in S}}\Pi\left(  K,\left[  u_{k}\right]  \right)  }_{\substack{=\Pi
\left(  K,\left[  \prod\limits_{k\in S}u_{k}\right]  \right)
\\\text{according to Corollary 5.4 \textbf{(b)}}}}=\widehat{\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}}\Pi\left(  K,\left[  \prod\limits_{k\in S}u_{k}\right]
\right) \\
&  =\Pi\left(  K,\left[  \prod\limits_{k\in S}u_{k}\mid S\subseteq\left\{
1,2,...,m\right\}  ;\ \left\vert S\right\vert =i\right]  \right) \\
&  =\Pi\left(  K,\left[  \prod\limits_{k\in S}u_{k}\mid S\in\mathcal{P}%
_{i}\left(  \left\{  1,2,...,m\right\}  \right)  \right]  \right) \\
&  =\widehat{\lambda}^{i}\left(  u\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{after Theorem 5.3 \textbf{(d)}}\right)
\end{align*}
and $Y_{j}$ to $\widehat{\lambda}^{j}\left(  v\right)  $ for every
$j\in\mathbb{N}$ (according to a similar argument). Hence, applying this
homomorphism to (\ref{Pk1}), we obtain%
\begin{align*}
&  \widehat{\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}%
}}\widehat{\prod_{\left(  i,j\right)  \in S}}\left(  1+u_{i}T\right)
\widehat{\cdot}\left(  1+v_{j}T\right) \\
&  =\widehat{P_{k}}\left(  \widehat{\lambda}^{1}\left(  u\right)
,\widehat{\lambda}^{2}\left(  u\right)  ,...,\widehat{\lambda}^{k}\left(
u\right)  ,\widehat{\lambda}^{1}\left(  v\right)  ,\widehat{\lambda}%
^{2}\left(  v\right)  ,...,\widehat{\lambda}^{k}\left(  v\right)  \right)  .
\end{align*}
But combined with%
\begin{align*}
&  \widehat{\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}%
}}\widehat{\prod_{\left(  i,j\right)  \in S}}\underbrace{\left(
1+u_{i}T\right)  \widehat{\cdot}\left(  1+v_{j}T\right)  }_{\substack{=\Pi
\left(  K,\left[  u_{i}\right]  \right)  \widehat{\cdot}\Pi\left(  K,\left[
v_{j}\right]  \right)  \\=\Pi\left(  K,\left[  u_{i}v_{j}\right]  \right)
\text{ after}\\\text{Theorem 5.3 \textbf{(c)}}}}=\widehat{\sum
_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}}\underbrace{\widehat{\prod
_{\left(  i,j\right)  \in S}}\Pi\left(  K,\left[  u_{i}v_{j}\right]  \right)
}_{\substack{=\Pi\left(  K,\left[  \prod\limits_{\left(  i,j\right)  \in
S}u_{i}v_{j}\right]  \right)  \\\text{after Corollary 5.4 \textbf{(b)}}}}\\
&  =\widehat{\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}}\Pi\left(
K,\left[  \prod\limits_{\left(  i,j\right)  \in S}u_{i}v_{j}\right]  \right)
\\
&  =\Pi\left(  K,\left[  \prod_{\left(  i,j\right)  \in S}u_{i}v_{j}\mid
S\subseteq\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}
;\ \left\vert S\right\vert =k\right]  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{after Corollary 5.4 \textbf{(a)}}\right)
\\
&  =\Pi\left(  K,\left[  \prod_{\left(  i,j\right)  \in S}u_{i}v_{j}\mid
S\in\mathcal{P}_{k}\left(  \left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  \right)  \right]  \right) \\
&  =\widehat{\lambda}^{k}\left(  u\widehat{\cdot}v\right)  ,
\end{align*}
this yields%
\[
\widehat{\lambda}^{k}\left(  u\widehat{\cdot}v\right)  =\widehat{P_{k}}\left(
\widehat{\lambda}^{1}\left(  u\right)  ,\widehat{\lambda}^{2}\left(  u\right)
,...,\widehat{\lambda}^{k}\left(  u\right)  ,\widehat{\lambda}^{1}\left(
v\right)  ,\widehat{\lambda}^{2}\left(  v\right)  ,...,\widehat{\lambda}%
^{k}\left(  v\right)  \right)  .
\]
Thus, (\ref{6.2.P.Lkxy}) is proven.

Next we are going to prove (\ref{6.2.P.LkLjx}) (the argument will be similar
to the above proof of (\ref{6.2.P.Lkxy})):

Since the subset $1+K\left[  T\right]  ^{+}$ is dense in $1+K\left[  \left[
T\right]  \right]  ^{+}=\Lambda\left(  K\right)  $ (by Theorem 5.5
\textbf{(a)}), and since all the $\widehat{\lambda}^{i}$ are continuous (by
Theorem 5.5 \textbf{(d)}), it will be enough to verify (\ref{6.2.P.LkLjx}) for
the case $u\in1+K\left[  T\right]  ^{+}$. But in this case, there exists some
$\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  \in
K^{\operatorname*{int}}$ such that $u=\Pi\left(  \widetilde{K},\left[
u_{1},u_{2},...,u_{m}\right]  \right)  $. By definition, $\widetilde{K}_{u}$
is a finite-free extension of $K$.

We replace $K$ by $\widetilde{K}_{u}$ now (silently using the obvious fact
that the injection $K\rightarrow\widetilde{K}_{u}$ canonically yields an
injection $\Lambda\left(  K\right)  \rightarrow\Lambda\left(  \widetilde{K}%
_{u}\right)  $). Hence, we can now assume that $u_{1},$ $u_{2},$ $...,$
$u_{m}$ all lie in $K$. Theorem 5.3 \textbf{(d)} yields $\widehat{\lambda}%
^{j}\left(  u\right)  =\Pi\left(  \widetilde{K}_{u},\left[  \prod\limits_{i\in
I}u_{i}\ \mid\ I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
\right]  \right)  $. Since we identified $\widetilde{K}_{u,v}$ with $K$, this
becomes%
\[
\widehat{\lambda}^{j}\left(  u\right)  =\Pi\left(  K,\left[  \prod
\limits_{i\in I}u_{i}\ \mid\ I\in\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  \right]  \right)  .
\]
Thus, Theorem 5.3' \textbf{(d)} (applied to $w=\widehat{\lambda}^{j}\left(
u\right)  $, $\widetilde{K}=K$, $L=\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  $ and $w_{I}=\prod\limits_{i\in I}u_{i}$) yields%
\[
\widehat{\lambda}^{k}\left(  \widehat{\lambda}^{j}\left(  u\right)  \right)
=\Pi\left(  K,\left[  \prod_{I\in S}\prod\limits_{i\in I}u_{i}\ \mid
\ S\in\mathcal{P}_{k}\left(  \mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  \right)  \right]  \right)  .
\]


There exists a ring homomorphism%
\[
\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \rightarrow\Lambda\left(
K\right)
\]
which maps $U_{i}$ to $1+u_{i}T$ for every $i$. This homomorphism maps
$X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ to
$\widehat{\lambda}^{i}\left(  u\right)  $\ \ \ \ \footnote{This can be proven
exactly in the same way as we have showed, during the proof of
(\ref{6.2.P.Lkxy}), that the ring homomorphism
\[
\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2},...,V_{n}\right]
\rightarrow\Lambda\left(  K\right)
\]
which maps $U_{i}$ to $1+u_{i}T$ for every $i$ and $V_{j}$ to $1+v_{j}T$ for
every $j$ must map $X_{i}=\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$
to $\widehat{\lambda}^{i}\left(  u\right)  $ (where the notations are the ones
we introduced in our above proof of (\ref{6.2.P.Lkxy})).}. Hence, applying
this homomorphism to (\ref{Pkj1}), we obtain%
\[
\widehat{\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  ;\\\left\vert S\right\vert =k}}}\widehat{\prod
_{I\in S}}\widehat{\prod_{i\in I}}\left(  1+u_{i}T\right)  =\widehat{P_{k,j}%
}\left(  \widehat{\lambda}^{1}\left(  u\right)  ,\widehat{\lambda}^{2}\left(
u\right)  ,...,\widehat{\lambda}^{kj}\left(  u\right)  \right)  .
\]
But combined with%
\begin{align*}
\widehat{\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  ;\\\left\vert S\right\vert =k}}}\widehat{\prod
_{I\in S}}\underbrace{\widehat{\prod_{i\in I}}\left(  1+u_{i}T\right)
}_{\substack{=\Pi\left(  K,\left[  \prod\limits_{i\in I}u_{i}\right]  \right)
\\\text{after Corollary 5.4 \textbf{(b)}}}}  &  =\widehat{\sum
_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  ;\\\left\vert S\right\vert =k}}}\underbrace{\widehat{\prod_{I\in S}%
}\Pi\left(  K,\left[  \prod\limits_{i\in I}u_{i}\right]  \right)
}_{\substack{=\Pi\left(  K,\left[  \prod\limits_{I\in S}\prod\limits_{i\in
I}u_{i}\right]  \right)  \\\text{after Corollary 5.4 \textbf{(b)}}}}\\
&  =\widehat{\sum_{\substack{S\subseteq\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  ;\\\left\vert S\right\vert =k}}}\Pi\left(
K,\left[  \prod\limits_{I\in S}\prod\limits_{i\in I}u_{i}\right]  \right) \\
&  =\Pi\left(  K,\left[  \prod\limits_{I\in S}\prod\limits_{i\in I}u_{i}%
\ \mid\ S\subseteq\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
;\ \left\vert S\right\vert =k\right]  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{after Corollary 5.4 \textbf{(a)}}\right)
\\
&  =\Pi\left(  K,\left[  \prod_{I\in S}\prod\limits_{i\in I}u_{i}\ \mid
\ S\in\mathcal{P}_{k}\left(  \mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  \right)  \right]  \right) \\
&  =\widehat{\lambda}^{k}\left(  \widehat{\lambda}^{j}\left(  u\right)
\right)  ,
\end{align*}
this becomes%
\[
\widehat{\lambda}^{k}\left(  \widehat{\lambda}^{j}\left(  u\right)  \right)
=\widehat{P_{k,j}}\left(  \widehat{\lambda}^{1}\left(  u\right)
,\widehat{\lambda}^{2}\left(  u\right)  ,...,\widehat{\lambda}^{kj}\left(
u\right)  \right)  .
\]
Thus, we have verified (\ref{6.2.P.LkLjx}). Theorem 6.2 is thus proven.

Theorem 6.1 gives us an alternative definition of special $\lambda$-rings via
the polynomials $P_{k}$ and $P_{k,j}$. Why, then, did we define the notion of
special $\lambda$-rings via the map $\lambda_{T}:\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  \rightarrow\left(  \Lambda\left(
K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $
rather than using Theorem 6.1? The reason is that while Theorem 6.1 provides
an easy-to-formulate definition of special $\lambda$-rings, it is rather hard
to work with. In order to check that some given ring is a special $\lambda
$-ring using Theorem 6.1, we would have to prove the identities (\ref{Lkxy})
and (\ref{LkLjx}), which is a difficult task since the polynomials $P_{k}$ and
$P_{k,j}$ are very hard to compute explicitly. Using the definition that we
gave, we would have to check that $\lambda_{T}:\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  \rightarrow\left(  \Lambda\left(
K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $
is a $\lambda$-ring homomorphism, what seems to be harder, but turns out not
that hard since Exercise 2.1 reduces this to checking some identity at
$\mathbb{Z}$-module generators of $K$.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 6.1.} Let $K$ be a ring. Consider the localization $\left(
1+K\left[  T\right]  ^{+}\right)  ^{-1}K\left[  T\right]  $ of the polynomial
ring $K\left[  T\right]  $ at the multiplicatively closed subset $1+K\left[
T\right]  ^{+}$. \ \ \ \ \footnote{When $K$ is a field, this localization is
simply the (local) ring of the (so-called) rational functions in one variable
over $K$ which have no pole at $0$. (Note that the term "rational function" is
being used here for an element of the quotient field $\operatorname*{Quot}%
\left(  K\left[  T\right]  \right)  $. This is the standard meaning that the
term "rational function" has in modern literature. This meaning is somewhat
confusing: In fact, rational functions are not functions in the standard
meaning of this word; they \textit{induce} functions (although no functions on
$K$, but instead only functions on an open subset of $K$), but even these
induced functions don't determine them uniquely, so the word "function" in
"rational function" really doesn't make any sense. However, lacking a better
word, everybody keeps calling the elements of $\operatorname*{Quot}\left(
K\left[  T\right]  \right)  $ "rational functions", and so do I.)} This
localization $\left(  1+K\left[  T\right]  ^{+}\right)  ^{-1}K\left[
T\right]  $ can be considered a subring of $K\left[  \left[  T\right]
\right]  $ (since $K\left[  T\right]  \subseteq K\left[  \left[  T\right]
\right]  $, and every element of $1+K\left[  T\right]  ^{+}$ is invertible in
$K\left[  \left[  T\right]  \right]  $). Prove that the set $\left(
1+K\left[  T\right]  ^{+}\right)  ^{-1}K\left[  T\right]  \cap\Lambda\left(
K\right)  $ is a special sub-$\lambda$-ring of $\Lambda\left(  K\right)  $.

\textit{Exercise 6.2.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring. Then, prove that:

\textbf{(a)} Every $n\in\mathbb{Z}$ and $i\in\mathbb{N}$ satisfy $\lambda
^{i}\left(  n\cdot1\right)  =\dbinom{n}{i}\cdot1$, where $1$ denotes the unity
of the ring $K$.

\textbf{(b)} None of the elements $1,$ $2,$ $3,$ $...$ of the ring $K$ equals
zero in $K$, unless $K$ is the trivial ring.

\textit{Exercise 6.3.} Consider the ring $\mathbb{Z}\left[  X\right]
\diagup\left(  X^{2},2X\right)  =\mathbb{Z}\left[  x\right]  $, where $x$
denotes the residue class of $X$ modulo the ideal $\left(  X^{2},2X\right)  $.

Define a map $\lambda_{T}:\mathbb{Z}\left[  x\right]  \rightarrow\left(
\mathbb{Z}\left[  x\right]  \right)  \left[  \left[  T\right]  \right]  $ by
$\lambda_{T}\left(  a+bx\right)  =\left(  1+T\right)  ^{a}\left(  1+xT\right)
^{b}$ for every $a\in\mathbb{Z}$ and $b\in\mathbb{Z}$.

Define a map $\lambda^{i}:\mathbb{Z}\left[  x\right]  \rightarrow
\mathbb{Z}\left[  x\right]  $ for every $i\in\mathbb{N}$ through the condition
$\lambda_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  T^{i}$ for every $x\in K$.

Prove that $\left(  \mathbb{Z}\left[  x\right]  ,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a special $\lambda$-ring. [This way, we see
that the additive group of a special $\lambda$-ring needs not be torsion-free.]

\textit{Exercise 6.4.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $E$ be a generating set
of the $\mathbb{Z}$-module $K$.

Prove that the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is special if and only if it satisfies%
\begin{align}
&  \lambda^{k}\left(  xy\right)  =P_{k}\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{k}\left(  x\right)  ,\lambda
^{1}\left(  y\right)  ,\lambda^{2}\left(  y\right)  ,...,\lambda^{k}\left(
y\right)  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N}\text{, }x\in E\text{
and }y\in E \label{LkxyE}%
\end{align}
and%
\begin{align}
&  \lambda^{k}\left(  \lambda^{j}\left(  x\right)  \right)  =P_{k,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{kj}\left(  x\right)  \right) \nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N}\text{, }j\in
\mathbb{N}\text{ and }x\in E. \label{LkLjxE}%
\end{align}


\textit{Exercise 6.5.} Let $K$ be a ring. Let $i\in\mathbb{N}$. Define a
mapping $\operatorname*{coeff}\nolimits_{i}:\Lambda\left(  K\right)
\rightarrow K$ by $\operatorname*{coeff}\nolimits_{i}\left(  \sum
\limits_{j\in\mathbb{N}}a_{j}T^{j}\right)  =a_{i}$ for every $\sum
\limits_{j\in\mathbb{N}}a_{j}T^{j}\in\Lambda\left(  K\right)  $ (with
$a_{j}\in K$ for every $j\in\mathbb{N}$). (In other words,
$\operatorname*{coeff}\nolimits_{i}$ is the mapping that takes a power series
and returns its coefficient before $T^{i}.$)

Prove that%
\[
\operatorname*{coeff}\nolimits_{i}\left(  u\right)  =\operatorname*{coeff}%
\nolimits_{1}\left(  \widehat{\lambda}^{i}\left(  u\right)  \right)
\ \ \ \ \ \ \ \ \ \ \text{for every }u\in\Lambda\left(  K\right)  .
\]


\textit{Exercise 6.6.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring, and $A$ be a ring.
Let $\varphi:K\rightarrow A$ be a ring homomorphism, and let
$\operatorname*{coeff}\nolimits_{1}^{A}:\Lambda\left(  A\right)  \rightarrow
A$ be the mapping defined by $\operatorname*{coeff}\nolimits_{1}^{A}\left(
\sum\limits_{j\in\mathbb{N}}a_{j}T^{j}\right)  =a_{1}$ for every
$\sum\limits_{j\in\mathbb{N}}a_{j}T^{j}\in\Lambda\left(  A\right)  $ (with
$a_{j}\in A$ for every $j\in\mathbb{N}$). (In other words,
$\operatorname*{coeff}\nolimits_{1}^{A}$ is the mapping that takes a power
series and returns its coefficient before $T^{1}.$)

As Theorem 5.1 \textbf{(b)} states, $\left(  \Lambda\left(  A\right)  ,\left(
\widehat{\lambda}_{A}^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda
$-ring, where the maps $\widehat{\lambda}_{A}^{i}:\Lambda\left(  A\right)
\rightarrow\Lambda\left(  A\right)  $ are defined in the same way as the maps
$\widehat{\lambda}^{i}:\Lambda\left(  K\right)  \rightarrow\Lambda\left(
K\right)  $ (which we have defined in Section 5) but for the ring $A$ instead
of $K$.

Prove that there exists one and only one $\lambda$-ring homomorphism
$\widetilde{\varphi}:K\rightarrow\Lambda\left(  A\right)  $ such that
$\operatorname*{coeff}\nolimits_{1}^{A}\circ\widetilde{\varphi}=\varphi$.

\textit{Exercise 6.7.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring, and $I$ be an ideal
of $K$. Let $S$ be a subset of $I$ which generates the ideal $I$. Assume that
every $s\in S$ and every positive integer $i$ satisfy $\lambda^{i}\left(
s\right)  \in I$. Then, prove that $I$ is a $\lambda$-ideal of $K$.
\end{quotation}

\section{Examples of special $\lambda$-rings}

\subsection{Binomial $\lambda$-rings}

We have learned a lot of examples for $\lambda$-rings, but which of them are
special? Of course, the trivial ring $0$ with the trivial maps $\lambda
^{i}:0\rightarrow0$ is a special $\lambda$-ring. Also, we know a vast class of
special $\lambda$-rings from Theorem 6.2. Obviously, every sub-$\lambda$-ring
of a special $\lambda$-ring is special. On the other hand, the $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ defined in
Exercise 3.3 \textbf{(a)} is not special unless $p=1$. What happens to the
other examples from Section 3?

\begin{quote}
\textbf{Theorem 7.1.} The $\lambda$-ring $\left(  \mathbb{Z},\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ defined in Theorem 3.1 is special.
\end{quote}

\textit{Proof of Theorem 7.1.} According to Theorem 6.1, we just have to
verify the identities (\ref{Lkxy}) and (\ref{LkLjx}) for $K=\mathbb{Z}$. In
other words, we have to prove that%
\begin{equation}
\dbinom{xy}{k}=P_{k}\left(  \dbinom{x}{1},\dbinom{x}{2},...,\dbinom{x}%
{k},\dbinom{y}{1},\dbinom{y}{2},...,\dbinom{y}{k}\right)  \label{7.1.Lkxy}%
\end{equation}
for every $k\in\mathbb{N}$, $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$ and%
\begin{equation}
\dbinom{\dbinom{x}{j}}{k}=P_{k,j}\left(  \dbinom{x}{1},\dbinom{x}%
{2},...,\dbinom{x}{kj}\right)  \label{7.1.LkLjx}%
\end{equation}
for every $k\in\mathbb{N}$, $j\in\mathbb{N}$ and $x\in\mathbb{Z}.$

Let us prove (\ref{7.1.Lkxy}): Fix $k\in\mathbb{N}$. Then, (\ref{7.1.Lkxy}) is
a polynomial identity in $x$ and in $y.$ Hence, (for the same reason as in the
proof of Theorem 3.1) it is enough to prove (\ref{7.1.Lkxy}) for all natural
$x$ and $y$. In this case, let $m=x$ and $n=y$. There exists a ring
homomorphism $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m},V_{1},V_{2}%
,...,V_{n}\right]  \rightarrow\mathbb{Z}$ mapping every $U_{i}$ to $1$ and
every $V_{j}$ to $1$. This homomorphism maps $X_{i}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ to%
\[
\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\underbrace{\prod\limits_{k\in S}1}_{=1}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}1=\sum\limits_{S\in\mathcal{P}_{i}\left(  \left\{
1,2,...,m\right\}  \right)  }1=\left\vert \mathcal{P}_{i}\left(  \left\{
1,2,...,m\right\}  \right)  \right\vert =\dbinom{m}{i}%
\]
for every $i\in\mathbb{N},$ and (for similar reasons) maps $Y_{j}$ to
$\dbinom{n}{j}$ for every $j\in\mathbb{N}$. Thus, applying this homomorphism
to the polynomial identity (\ref{Pk1}), we obtain%
\[
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\prod_{\left(  i,j\right)
\in S}1\cdot1=P_{k}\left(  \dbinom{m}{1},\dbinom{m}{2},...,\dbinom{m}%
{k},\dbinom{n}{1},\dbinom{n}{2},...,\dbinom{n}{k}\right)  .
\]
Since $m=x,$ $n=y$ and
\begin{align*}
\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  ;\\\left\vert S\right\vert =k}}\underbrace{\prod_{\left(
i,j\right)  \in S}1\cdot1}_{=1}  &  =\sum_{\substack{S\subseteq\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  ;\\\left\vert
S\right\vert =k}}1=\sum_{S\in\mathcal{P}_{k}\left(  \left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right)  }1\\
&  =\left\vert \mathcal{P}_{k}\left(  \left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  \right)  \right\vert =\dbinom{mn}{k}%
=\dbinom{xy}{k},
\end{align*}
this equality transforms into (\ref{7.1.Lkxy}). Hence, (\ref{7.1.Lkxy}) is
proven (since, as we said, once (\ref{7.1.Lkxy}) is proven for natural $x$ and
$y$, it follows that (\ref{7.1.Lkxy}) holds for all integers $x$ and $y$).
Just as we have derived (\ref{7.1.Lkxy}) from (\ref{Pk1}), we can derive
(\ref{7.1.LkLjx}) from (\ref{Pkj1}), and Theorem 7.1 is proven.

This generalizes:

\begin{quote}
\textbf{Theorem 7.2.} Let $K$ be a binomial ring. The $\lambda$-ring $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ defined in Theorem
3.2 is special.
\end{quote}

\textit{Proof of Theorem 7.2.} This follows from our proof of Theorem 7.1 in
the same way as Theorem 3.2 followed from our proof of Theorem 3.1. To be more
precise: According to Theorem 6.1, the $\lambda$-ring $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is special if it satisfies the
identities (\ref{Lkxy}) and (\ref{LkLjx}). This means (\ref{7.1.Lkxy}) for
every $k\in\mathbb{N}$, $x\in K$ and $y\in K$ and (\ref{7.1.LkLjx}) for every
$k\in\mathbb{N}$, $j\in\mathbb{N}$ and $x\in K$. In the proof of Theorem 7.1,
we have proven these identities for all $x\in\mathbb{Z}$ and $y\in\mathbb{Z}$;
but being polynomial identities (for fixed $k$ and $j$), these identities
therefore also hold for every $x\in K$ and $y\in K$, and Theorem 7.2 is proven.

\subsection{Adjoining a polynomial variable to a $\lambda$-ring}

Theorem 3.3 has a special version as well:

\begin{quote}
\textbf{Theorem 7.3.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring. Then, the $\lambda
$-ring $\left(  K\left[  S\right]  ,\left(  \overline{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  $ defined in Theorem 3.3 is special.
\end{quote}

\textit{Proof of Theorem 7.3.} As in the proof of Theorem 3.3, we can define a
map $\overline{\lambda}_{T}:K\left[  S\right]  \rightarrow\left(  K\left[
S\right]  \right)  \left[  \left[  T\right]  \right]  $ by
\[
\overline{\lambda}_{T}\left(  u\right)  =\sum\limits_{i\in\mathbb{N}}%
\overline{\lambda}^{i}\left(  u\right)  T^{i}\ \ \ \ \ \ \ \ \ \ \text{for
every }u\in K\left[  S\right]  .
\]
Noting that $\overline{\lambda}_{T}\left(  u\right)  \in\Lambda\left(
K\left[  S\right]  \right)  $ for every $u\in K\left[  S\right]  $ (since
$\left(  K\left[  S\right]  ,\left(  \overline{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a $\lambda$-ring), we see that we can actually
consider $\overline{\lambda}_{T}$ as a map $K\left[  S\right]  \rightarrow
\Lambda\left(  K\left[  S\right]  \right)  $.

Theorem 5.6 yields that the map $\overline{\lambda}_{T}$ is an additive group
homomorphism. In order to show that the $\lambda$-ring $\left(  K\left[
S\right]  ,\left(  \overline{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $
is special, we must prove that this map $\overline{\lambda}_{T}$ is a
$\lambda$-ring homomorphism.

Let $E=\left\{  aS^{\alpha}\mid a\in K,\ \alpha\in\mathbb{N}\right\}  $.
Obviously, $E$ is a generating set of the $\mathbb{Z}$-module $K\left[
S\right]  $. Notice that $\overline{\lambda}_{T}\left(  aS^{\alpha}\right)
=\lambda_{S^{\alpha}T}\left(  a\right)  $ for every $a\in K$ and $\alpha
\in\mathbb{N}$ (as shown in the proof of Theorem 3.3 \textbf{(b)}).

For every $a\in K,$ $\alpha\in\mathbb{N}$, $b\in K$ and $\beta\in\mathbb{N}$,
we have%
\begin{align*}
&  \overline{\lambda}_{T}\left(  aS^{\alpha}\right)  \widehat{\cdot}%
\overline{\lambda}_{T}\left(  bS^{\beta}\right)  =\lambda_{S^{\alpha}T}\left(
a\right)  \widehat{\cdot}\lambda_{S^{\beta}T}\left(  b\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\overline{\lambda}_{T}\left(
aS^{\alpha}\right)  =\lambda_{S^{\alpha}T}\left(  a\right)  \text{ and
similarly }\overline{\lambda}_{T}\left(  bS^{\beta}\right)  =\lambda
_{S^{\beta}T}\left(  b\right)  \right) \\
&  =\operatorname*{ev}\nolimits_{S^{\alpha}T}\left(  \lambda_{T}\left(
a\right)  \right)  \widehat{\cdot}\operatorname*{ev}\nolimits_{S^{\beta}%
T}\left(  \lambda_{T}\left(  b\right)  \right)  =\operatorname*{ev}%
\nolimits_{S^{\alpha}S^{\beta}T}\left(  \lambda_{T}\left(  a\right)
\widehat{\cdot}\lambda_{T}\left(  b\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Theorem 5.7 \textbf{(d)}, applied to }K\left[  S\right]  ,\text{
}\lambda_{T}\left(  a\right)  ,\text{ }\lambda_{T}\left(  b\right)  ,\text{
}S^{\alpha}\text{ and }S^{\beta}\\
\text{instead of }K,\text{ }u,\text{ }v,\text{ }\mu\text{ and }\nu
\end{array}
\right) \\
&  =\operatorname*{ev}\nolimits_{S^{\alpha}S^{\beta}T}\left(  \lambda
_{T}\left(  ab\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\lambda_{T}\text{ is a ring
homomorphism, as }\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  \text{ is a special }\lambda\text{-ring}\right) \\
&  =\lambda_{S^{\alpha}S^{\beta}T}\left(  ab\right)  =\lambda_{S^{\alpha
+\beta}T}\left(  ab\right)
\end{align*}
and $\overline{\lambda}_{T}\left(  aS^{\alpha}\cdot bS^{\beta}\right)
=\overline{\lambda}_{T}\left(  ab\cdot S^{\alpha+\beta}\right)  =\lambda
_{S^{\alpha+\beta}T}\left(  ab\right)  ,$ so that $\overline{\lambda}%
_{T}\left(  aS^{\alpha}\right)  \widehat{\cdot}\overline{\lambda}_{T}\left(
bS^{\beta}\right)  =\overline{\lambda}_{T}\left(  aS^{\alpha}\cdot bS^{\beta
}\right)  $. In other words, $\overline{\lambda}_{T}\left(  e\right)
\widehat{\cdot}\overline{\lambda}_{T}\left(  f\right)  =\overline{\lambda}%
_{T}\left(  ef\right)  $ for any two elements $e$ and $f$ of $E$. Since $E$ is
a generating set of the $\mathbb{Z}$-module $K\left[  S\right]  $, and since
$\overline{\lambda}_{T}$ is already known to be an additive group
homomorphism, it thus follows that $\overline{\lambda}_{T}\left(  x\right)
\widehat{\cdot}\overline{\lambda}_{T}\left(  y\right)  =\overline{\lambda}%
_{T}\left(  xy\right)  $ for any two elements $x$ and $y$ of $K\left[
S\right]  $. Since $\overline{\lambda}_{T}$ also maps the multiplicative unity
$1$ of $K\left[  S\right]  $ to the multiplicative unity $1+T$ of
$\Lambda\left(  K\left[  S\right]  \right)  $ (this follows from
$\overline{\lambda}_{T}\left(  aS^{\alpha}\right)  =\lambda_{S^{\alpha}%
T}\left(  a\right)  $, applied to $a=1$ and $\alpha=0$), it thus follows that
$\overline{\lambda}_{T}:K\left[  S\right]  \rightarrow\Lambda\left(  K\left[
S\right]  \right)  $ is a ring homomorphism.

Now, for every $i\in\mathbb{N}$, let us define a map $\widehat{\overline
{\lambda}}^{i}:\Lambda\left(  K\left[  S\right]  \right)  \rightarrow
\Lambda\left(  K\left[  S\right]  \right)  $ in the same way as the map
$\widehat{\lambda}^{i}:\Lambda\left(  K\right)  \rightarrow\Lambda\left(
K\right)  $ was defined in Section 5 (but with $K$ replaced by $K\left[
S\right]  $). Then, the diagram%
\begin{equation}
\xymatrixcolsep{4pc}\xymatrix{ \Lambda\left(K\right) \ar@{^{(}->}[d] \ar[r]^{\widehat{\lambda}^i} & \Lambda\left(K\right) \ar@{^{(}->}[d] \\ \Lambda\left(K\left[S\right]\right) \ar[r]_{\widehat{\overline{\lambda}}^i} & \Lambda\left(K\left[S\right]\right) }
\label{7.3.commdiag}%
\end{equation}
(where the vertical arrows are induced by the canonical inclusion
$K\rightarrow K\left[  S\right]  $) is commutative (since the maps
$\widehat{\lambda}^{i}:\Lambda\left(  K\right)  \rightarrow\Lambda\left(
K\right)  $ and $\widehat{\overline{\lambda}}^{i}:\Lambda\left(  K\left[
S\right]  \right)  \rightarrow\Lambda\left(  K\left[  S\right]  \right)  $
were defined in the same natural way).

For every $a\in K$ and $\alpha\in\mathbb{N}$, we have%
\begin{align*}
&  \left(  \widehat{\overline{\lambda}}^{i}\circ\overline{\lambda}_{T}\right)
\left(  aS^{\alpha}\right)  =\widehat{\overline{\lambda}}^{i}\left(
\overline{\lambda}_{T}\left(  aS^{\alpha}\right)  \right) \\
&  =\widehat{\overline{\lambda}}^{i}\left(  \operatorname*{ev}%
\nolimits_{S^{\alpha}T}\left(  \lambda_{T}\left(  a\right)  \right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\overline{\lambda}_{T}\left(
aS^{\alpha}\right)  =\lambda_{S^{\alpha}T}\left(  a\right)
=\operatorname*{ev}\nolimits_{S^{\alpha}T}\left(  \lambda_{T}\left(  a\right)
\right)  \right) \\
&  =\operatorname*{ev}\nolimits_{\left(  S^{\alpha}\right)  ^{i}T}\left(
\widehat{\overline{\lambda}}^{i}\left(  \lambda_{T}\left(  a\right)  \right)
\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 5.7 \textbf{(e)}, applied to
}K\left[  S\right]  ,\text{ }\lambda_{T}\left(  a\right)  ,\text{ }S^{\alpha
}\text{ and }i\text{ instead of }K,\text{ }u,\text{ }\mu\text{ and }k\right)
\\
&  =\operatorname*{ev}\nolimits_{\left(  S^{\alpha}\right)  ^{i}T}\left(
\widehat{\lambda}^{i}\left(  \lambda_{T}\left(  a\right)  \right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{due to the commutative diagram
(\ref{7.3.commdiag})}\right) \\
&  =\operatorname*{ev}\nolimits_{\left(  S^{\alpha}\right)  ^{i}T}\left(
\lambda_{T}\left(  \lambda^{i}\left(  a\right)  \right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\widehat{\lambda}^{i}\circ\lambda_{T}=\lambda_{T}\circ\lambda
^{i}\text{, because }\lambda_{T}\text{ is a }\lambda\text{-ring homomorphism,}%
\\
\text{since }\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
\text{ is a special }\lambda\text{-ring}%
\end{array}
\right) \\
&  =\lambda_{\left(  S^{\alpha}\right)  ^{i}T}\left(  \lambda^{i}\left(
a\right)  \right)  =\lambda_{S^{\alpha i}T}\left(  \lambda^{i}\left(
a\right)  \right)  =\overline{\lambda}_{T}\left(  \underbrace{\lambda
^{i}\left(  a\right)  S^{\alpha i}}_{\substack{=\overline{\lambda}^{i}\left(
aS^{\alpha}\right)  \text{ by}\\\text{Theorem 3.3 \textbf{(b)}}}}\right)
=\overline{\lambda}_{T}\left(  \overline{\lambda}^{i}\left(  aS^{\alpha
}\right)  \right)  =\left(  \overline{\lambda}_{T}\circ\overline{\lambda}%
^{i}\right)  \left(  aS^{\alpha}\right)  .
\end{align*}
In other words, every $e\in E$ satisfies $\left(  \widehat{\overline{\lambda}%
}^{i}\circ\overline{\lambda}_{T}\right)  \left(  e\right)  =\left(
\overline{\lambda}_{T}\circ\overline{\lambda}^{i}\right)  \left(  e\right)  $.

Altogether, we now know that $\overline{\lambda}_{T}:K\left[  S\right]
\rightarrow\Lambda\left(  K\left[  S\right]  \right)  $ is a ring
homomorphism, that $E$ is a generating set of the $\mathbb{Z}$-module
$K\left[  S\right]  $, and that every $e\in E$ satisfies $\left(
\widehat{\overline{\lambda}}^{i}\circ\overline{\lambda}_{T}\right)  \left(
e\right)  =\left(  \overline{\lambda}_{T}\circ\overline{\lambda}^{i}\right)
\left(  e\right)  $. Thus, by Exercise 2.1 \textbf{(b)}, it follows that
$\overline{\lambda}_{T}$ is a $\lambda$-ring homomorphism. This proves Theorem 7.3.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 7.1.} Let $M$ be a commutative monoid with neutral element.
Prove that the $\lambda$-ring $\left(  \mathbb{Z}\left[  M\right]  ,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ defined in Exercise 3.4 is special.

\textit{Exercise 7.2.} Let $M$ be a commutative monoid with neutral element.
Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a
special $\lambda$-ring. Prove that the $\lambda$-ring $\left(  K\left[
M\right]  ,\left(  \overline{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $
defined in Exercise 3.5 \textbf{(a)} is special.
\end{quotation}

\section{The $\lambda$-verification principle}

\subsection{$n$-operations of special $\lambda$-rings}

In Section 5, we have constructed a family of $\lambda$-rings $\Lambda\left(
K\right)  $ which are (comparatively) easy to work with due to the following
property: If you want to prove an identity involving the ring structure of
$\Lambda\left(  K\right)  $ (the addition $\widehat{+}$, the corresponding
subtraction $\widehat{-}$, the zero $1$, the multiplication $\widehat{\cdot}$,
and the multiplicative unity $1+T$) and the mappings $\widehat{\lambda}^{i}$,
then it is enough to verify it for elements of $1+K\left[  T\right]  ^{+}$
only (by continuity, according to Theorem 5.5); and this is usually much
easier since we know what $\widehat{+}$, $\widehat{\cdot}$ and
$\widehat{\lambda}^{i}$ mean for elements of $1+K\left[  T\right]  ^{+}$ (this
is what Theorem 5.3 is for).

As a consequence of this, it is no wonder that often an identity is more
easily proven in $\Lambda\left(  K\right)  $ than in arbitrary $\lambda
$-rings. However, it turns out that if an identity can be proven in
$\Lambda\left(  K\right)  $, then it automatically holds for arbitrary special
$\lambda$-rings! This is one of the so-called $\lambda$\textit{-verification
principles}\footnote{We are following [2], pp. 25-27 here, though our Theorem
8.1 is not exactly what [2] calls "verification principle".}. Before we
formulate this principle, let us first formally define what kind of identities
it will hold for:

\begin{quote}
\textbf{Definition.} Let $\operatorname*{Rng}^{\operatorname*{S}\Lambda}$
denote the so-called \textit{category of special }$\lambda$\textit{-rings},
which is defined as the category whose objects are the special $\lambda$-rings
and whose morphisms are $\lambda$-ring homomorphisms between its objects.

Let $\operatorname*{USet}:\operatorname*{Rng}^{\operatorname*{S}\Lambda
}\rightarrow\operatorname*{Set}$ be the functor which maps every special
$\lambda$-ring to its underlying set. Let $n\in\mathbb{N}$. An $n$%
-\textit{operation of special }$\lambda$\textit{-rings} will mean a natural
transformation from the functor $\operatorname*{USet}^{n}$ to
$\operatorname*{USet}$ (where the functor $\operatorname*{USet}^{n}$ is
defined as the functor from $\operatorname*{Rng}^{\operatorname*{S}\Lambda}$
to $\operatorname*{Set}^{n}$ which maps every special $\lambda$-ring $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ to the family
$\left(  \underbrace{K,K,...,K}_{n\text{ times}}\right)  $ of sets).

In other words, an $n$-operation $m$ of special $\lambda$-rings is a family of
mappings\footnote{Here, "mapping" actually means "mapping" and not "group
homomorphism" of "ring homomorphism".} $m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }:K^{n}\rightarrow K$ for every special
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ such that the diagram%
\begin{equation}
\xymatrixcolsep{5pc}\xymatrix{ K^n \ar[r]^{f^{\times n}} \ar[d]_{m_{\left(K,\left(\lambda^i\right)_{i\in\mathbb{N}}\right)}} & L^n \ar[d]^{m_{\left(L,\left(\mu^i\right)_{i\in\mathbb{N}}\right)}} \\ K \ar[r]_f & L }
\label{I-oper}%
\end{equation}
commutes for any two special $\lambda$-rings $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ and $\left(  L,\left(  \mu
^{i}\right)  _{i\in\mathbb{N}}\right)  $ and any $\lambda$-ring homomorphism
$f:\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
\rightarrow\left(  L,\left(  \mu^{i}\right)  _{i\in\mathbb{N}}\right)  $.
Here, $f^{\times n}$ means the map from $K^{n}$ to $L^{n}$ which equals $f$ on
each coordinate.
\end{quote}

In practice, what are $n$-operations of special $\lambda$-rings? The answer
is: Pretty much every map $K^{n}\rightarrow K$ which is defined for every
special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in
\mathbb{N}}\right)  $ just using addition, subtraction, multiplication, $0$
and $1$ and the maps $\lambda^{i}$ is an $n$-operation. In particular, every
polynomial map (where the polynomial has integer coefficients) is an
$n$-operation, and so are the maps $\lambda^{i}:K\rightarrow K$. To give a
different example, the family of maps $m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }:K^{3}\rightarrow K$ for every special
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ defined by%
\[
m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(
a_{1},a_{2},a_{3}\right)  =\lambda^{5}\left(  \lambda^{2}\left(  a_{1}\right)
-\lambda^{4}\left(  a_{2}\right)  \cdot a_{3}\right)
\]
is a $3$-operation of special $\lambda$-rings.

\subsection{A useful triviality}

Now, here is the theorem we came for:

\begin{quote}
\textbf{Theorem 8.1 (}$\lambda$\textbf{-verification principle).} Let $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a special
$\lambda$-ring. Let $n\in\mathbb{N}$. Let $m$ and $m^{\prime}$ be two
$n$-operations of special $\lambda$-rings.

Assume that $m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda
}^{i}\right)  _{i\in\mathbb{N}}\right)  }=m_{\left(  \Lambda\left(  K\right)
,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}$.
Then, $m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
}=m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }%
^{\prime}$.
\end{quote}

The proof of this result turns out to be surprisingly simple. First a trivial lemma:

\begin{quote}
\textbf{Theorem 8.2.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Define a mapping
$\operatorname*{coeff}\nolimits_{1}:\Lambda\left(  K\right)  \rightarrow K$ by
$\operatorname*{coeff}\nolimits_{1}\left(  \sum\limits_{j\in\mathbb{N}}%
a_{j}T^{j}\right)  =a_{1}$ for every $\sum\limits_{j\in\mathbb{N}}a_{j}%
T^{j}\in\Lambda\left(  K\right)  $ (with $a_{j}\in K$ for every $j\in
\mathbb{N}$). (In other words, $\operatorname*{coeff}\nolimits_{1}$ is the
mapping that takes a power series and returns its coefficient before $T^{1}.$)

Then, $\operatorname*{coeff}\nolimits_{1}\circ\lambda_{T}=\operatorname*{id}%
_{K}$.
\end{quote}

\textit{Proof of Theorem 8.2.} This is clear, since $\left(
\operatorname*{coeff}\nolimits_{1}\circ\lambda_{T}\right)  \left(  x\right)
=\operatorname*{coeff}\nolimits_{1}\left(  \lambda_{T}\left(  x\right)
\right)  =\operatorname*{coeff}\nolimits_{1}\left(  \sum\limits_{i\in
\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}\right)  =\lambda^{1}\left(
x\right)  =x$ for every $x\in K$. Theorem 8.2 is now proven.

\textit{Proof of Theorem 8.1.} Since $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a special $\lambda$-ring, the map $\lambda
_{T}:K\rightarrow\Lambda\left(  K\right)  $ is a $\lambda$-ring homomorphism.
According to (\ref{I-oper}), we thus have the two commutative diagrams%
\[
\xymatrixrowsep{5pc}\xymatrixcolsep{4pc}\xymatrix{
K^n \ar[r]^{\left(\lambda_T\right)^{\times n}} \ar[d]_{m_{\left(K,\left(\lambda^i\right)_{i\in\mathbb{N}}\right)}} & \left(\Lambda\left(K\right)\right)^n \ar[d]^{m_{\left(\Lambda\left(K\right),\left(\widehat{\lambda}^i\right)_{i\in\mathbb{N}}\right)}} \\
K \ar[r]_{\lambda_T} & \Lambda\left(K\right)
}
\]
and%
\[
\xymatrixrowsep{5pc}\xymatrixcolsep{4pc}\xymatrix{
K^n \ar[r]^{\left(\lambda_T\right)^{\times n}} \ar[d]_{m^{\prime}_{\left(K,\left(\lambda^i\right)_{i\in\mathbb{N}}\right)}} & \left(\Lambda\left(K\right)\right)^n \ar[d]^{m^{\prime}_{\left(\Lambda\left(K\right),\left(\widehat{\lambda}^i\right)_{i\in\mathbb{N}}\right)}} \\
K \ar[r]_{\lambda_T} & \Lambda\left(K\right)
}.
\]
Hence, $m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }=m_{\left(  \Lambda\left(  K\right)
,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}$
yields%
\[
\lambda_{T}\circ m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  }=m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }\circ\left(  \lambda_{T}\right)
^{\times n}=m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\circ\left(  \lambda
_{T}\right)  ^{\times n}=\lambda_{T}\circ m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}.
\]
Hence, $m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
}=m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }%
^{\prime}$ because $\lambda_{T}$ is injective (due to Theorem 8.2). Theorem
8.1 is thus proven!

\subsection{$1$-dimensional elements}

Before we move on to concrete properties of special $\lambda$-rings, let us
merge Theorems 8.1 and 5.5 into one simple principle for proving facts about
$\lambda$-rings -- our Theorem 8.4 below. Before we formulate it, let us
define the notion of $1$\textit{-dimensional} elements of a $\lambda$-ring.

\begin{quote}
\textbf{Definition.} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in
\mathbb{N}}\right)  $ be a $\lambda$-ring, and let $x\in K$ be an element of
$K$. Then, $x$ is said to be $1$\textit{-dimensional} if and only if
$\lambda^{i}\left(  x\right)  =0$ for every integer $i>1$.

\textbf{Theorem 8.3.}

\textbf{(a)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a $\lambda$-ring. Let $x\in K$ be an element of $K$. The
element $x$ is $1$-dimensional if and only if $\lambda_{T}\left(  x\right)
=1+xT$ (where $\lambda_{T}:K\rightarrow K\left[  \left[  T\right]  \right]  $
is the map defined in Theorem 2.1).

\textbf{(b)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a special $\lambda$-ring. Let $x$ and $y$ be two $1$%
-dimensional elements of $K$. Then, $xy$ is $1$-dimensional as well.

\textbf{(c)} Let $K$ be a ring. Let $e\in K$. Then, the element $1+eT$ of the
$\lambda$-ring $\Lambda\left(  K\right)  $ is $1$-dimensional.
\end{quote}

\textit{Proof of Theorem 8.3.} \textbf{(a)} In fact,%
\[
\lambda_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  T^{i}=\underbrace{\lambda^{0}\left(  x\right)  }_{=1}%
+\underbrace{\lambda^{1}\left(  x\right)  }_{=x}T+\sum
\limits_{\substack{i>1\\\text{integer}}}\lambda^{i}\left(  x\right)
T^{i}=1+xT+\sum\limits_{\substack{i>1\\\text{integer}}}\lambda^{i}\left(
x\right)  T^{i}.
\]
Hence, $\lambda_{T}\left(  x\right)  =1+xT$ if and only if $\lambda^{i}\left(
x\right)  =0$ for every integer $i>1$ (which means that $x$ is $1$%
-dimensional). Theorem 8.3 \textbf{(a)} is thus proven.

\textbf{(b)} Since the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is special, the map $\lambda_{T}$, seen as a map
from $K$ to $\Lambda\left(  K\right)  $, is a ring homomorphism, so that
$\lambda_{T}\left(  xy\right)  =\lambda_{T}\left(  x\right)  \widehat{\cdot
}\lambda_{T}\left(  y\right)  $. But Theorem 8.3 \textbf{(a)} yields
$\lambda_{T}\left(  x\right)  =1+xT=\Pi\left(  K,\left[  x\right]  \right)  $.
Similarly, $\lambda_{T}\left(  y\right)  =\Pi\left(  K,\left[  y\right]
\right)  $. Thus,%
\begin{align*}
\lambda_{T}\left(  xy\right)   &  =\lambda_{T}\left(  x\right)  \widehat{\cdot
}\lambda_{T}\left(  y\right)  =\Pi\left(  K,\left[  x\right]  \right)
\widehat{\cdot}\Pi\left(  K,\left[  y\right]  \right)  =\Pi\left(  K,\left[
xy\right]  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{after Theorem 5.3
\textbf{(c)}}\right) \\
&  =1+xyT.
\end{align*}
By Theorem 8.3 \textbf{(a)} (applied to $xy$ instead of $x$), this yields that
$xy$ is $1$-dimensional. Thus, Theorem 8.3 \textbf{(b)} is proven.

\textbf{(c)} For every integer $i>1$, the element%
\begin{align*}
\widehat{\lambda}^{i}\left(  1+eT\right)   &  =\Pi\left(
K,\underbrace{\left[  \prod_{i\in I}e\mid I\in\mathcal{P}_{i}\left(  \left\{
1\right\}  \right)  \right]  }_{\substack{\text{empty multiset,}\\\text{since
}i>1\text{ yields }\mathcal{P}_{i}\left(  \left\{  1\right\}  \right)
=\varnothing}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 5.3 \textbf{(d)}, since
}1+eT=\Pi\left(  K,\left[  e\right]  \right)  \right) \\
&  =\Pi\left(  K,\text{ empty multiset}\right)  =1
\end{align*}
is the zero of $\Lambda\left(  K\right)  $. Thus, $1+eT$ is $1$-dimensional.
Theorem 8.3 \textbf{(c)} is proven.

\subsection{The continuous splitting $\lambda$-verification principle}

Now, we can formulate the desired result:

\begin{quote}
\textbf{Theorem 8.4 (continuous splitting }$\lambda$\textbf{-verification
principle).} Let $n\in\mathbb{N}$. Let $m$ and $m^{\prime}$ be two
$n$-operations of special $\lambda$-rings.

Assume that the following two assumptions hold:

\textit{Continuity assumption:} The maps $m_{\left(  \Lambda\left(  K\right)
,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }:\left(
\Lambda\left(  K\right)  \right)  ^{n}\rightarrow\Lambda\left(  K\right)  $
and $m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}:\left(  \Lambda\left(
K\right)  \right)  ^{n}\rightarrow\Lambda\left(  K\right)  $ are continuous
with respect to the $\left(  T\right)  $-topology for every special $\lambda
$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $.

\textit{Split equality assumption:} For every special $\lambda$-ring $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and every $\left(
u_{1},u_{2},...,u_{n}\right)  \in K^{n}$ such that $u_{i}$ is the sum of
finitely many $1$-dimensional elements of $K$ for every $i\in\left\{
1,2,...,n\right\}  $, we have $m_{\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  }\left(  u_{1},u_{2},...,u_{n}\right)  =m_{\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(
u_{1},u_{2},...,u_{n}\right)  $.

Then, $m=m^{\prime}$.
\end{quote}

\textit{Proof of Theorem 8.4.} We have to prove that $m=m^{\prime}$. In other
words, we must show that $m_{\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  }=m_{\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  }^{\prime}$ for every special $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $. According
to Theorem 8.1, this will immediately follow once we have shown that
$m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }=m_{\left(  \Lambda\left(  K\right)  ,\left(
\widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}$ for every
special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in
\mathbb{N}}\right)  $. So it remains to prove this.

Consider a special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $. We must prove that $m_{\left(  \Lambda\left(
K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)
}=m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }^{\prime}$.

Consider the $\left(  T\right)  $-topology on $\Lambda\left(  K\right)  $. The
maps $m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }$ and $m_{\left(  \Lambda\left(
K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)
}^{\prime}$ are continuous, while the subset $1+K\left[  T\right]  ^{+}$ of
$1+K\left[  \left[  T\right]  \right]  ^{+}=\Lambda\left(  K\right)  $ is
dense (by Theorem 5.5 \textbf{(a)}). Hence, in order to prove that $m_{\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  }=m_{\left(  \Lambda\left(  K\right)  ,\left(
\widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}$, it will
be enough to show that
\begin{equation}
m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }\left(  u_{1},u_{2},...,u_{n}\right)  =m_{\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  }^{\prime}\left(  u_{1},u_{2},...,u_{n}\right)
\label{8.4.goal}%
\end{equation}
for every $\left(  u_{1},u_{2},...,u_{n}\right)  \in\left(  1+K\left[
T\right]  ^{+}\right)  ^{n}.$

Fix some $\left(  u_{1},u_{2},...,u_{n}\right)  \in\left(  1+K\left[
T\right]  ^{+}\right)  ^{n}$. For every $i\in\left\{  1,2,...,n\right\}  $,
there exists some $\left(  \widetilde{K}_{u_{i}},\left[  \left(  u_{i}\right)
_{1},\left(  u_{i}\right)  _{2},...,\left(  u_{i}\right)  _{n_{i}}\right]
\right)  \in K^{\operatorname*{int}}$ such that $u_{i}=\Pi\left(
\widetilde{K}_{u_{i}},\left[  \left(  u_{i}\right)  _{1},\left(  u_{i}\right)
_{2},...,\left(  u_{i}\right)  _{n_{i}}\right]  \right)  $. According to
Theorem 5.3 \textbf{(a)} (applied several times), there exists a finite-free
extension ring $K^{\prime}$ of $K$ which contains the $\widetilde{K}_{u_{i}}$
for all $i\in\left\{  1,2,...,n\right\}  $ as subrings. Hence, $u_{i}%
=\Pi\left(  K^{\prime},\left[  \left(  u_{i}\right)  _{1},\left(
u_{i}\right)  _{2},...,\left(  u_{i}\right)  _{n_{i}}\right]  \right)  $ for
every $i\in\left\{  1,2,...,n\right\}  $.

In the ring $\Lambda\left(  K^{\prime}\right)  $ (which is an extension ring
of $\Lambda\left(  K\right)  $, since $K\subseteq K^{\prime}$ and since
$\Lambda$ is a functor), this yields%
\begin{align}
u_{i}  &  =\Pi\left(  K^{\prime},\left[  \left(  u_{i}\right)  _{1},\left(
u_{i}\right)  _{2},...,\left(  u_{i}\right)  _{n_{i}}\right]  \right)
=\prod_{j=1}^{n_{i}}\left(  1+\left(  u_{i}\right)  _{j}T\right)
=\widehat{\sum_{j=1}^{n_{i}}}\left(  1+\left(  u_{i}\right)  _{j}T\right)
\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since addition in }\Lambda\left(
K^{\prime}\right)  \text{ is multiplication in }K^{\prime}\left[  \left[
T\right]  \right]  \right)  . \label{8.4.hilf}%
\end{align}
On the other hand, for every $j\in\left\{  1,2,...,n_{i}\right\}  $, the
element $1+\left(  u_{i}\right)  _{j}T$ of $\Lambda\left(  K^{\prime}\right)
$ is $1$-dimensional (by Theorem 8.3 \textbf{(c)}, applied to $e=\left(
u_{i}\right)  _{j}$). Thus, (\ref{8.4.hilf}) shows that $u_{i}$ is a sum of
$1$-dimensional elements of $\Lambda\left(  K^{\prime}\right)  $ for every
$i\in\left\{  1,2,...,n\right\}  $. Hence, applying the split equality
assumption to the special $\lambda$-ring $\left(  \Lambda\left(  K^{\prime
}\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $
instead of $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $,
we see that%
\begin{equation}
m_{\left(  \Lambda\left(  K^{\prime}\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(  u_{1},u_{2},...,u_{n}\right)
=m_{\left(  \Lambda\left(  K^{\prime}\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(  u_{1},u_{2}%
,...,u_{n}\right)  . \label{8.4.fast}%
\end{equation}
This is an equality in the ring $\Lambda\left(  K^{\prime}\right)  $, but
since $\Lambda\left(  K\right)  $ can be canonically seen as a subring of
$\Lambda\left(  K^{\prime}\right)  $ (because $K$ is a subring of $K^{\prime}%
$), it easily yields the equality%
\[
m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }\left(  u_{1},u_{2},...,u_{n}\right)  =m_{\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  }^{\prime}\left(  u_{1},u_{2},...,u_{n}\right)
\]
in the ring $\Lambda\left(  K\right)  $.\ \ \ \ \footnote{\textit{Proof.} Let
$\iota$ denote the canonical inclusion $\Lambda\left(  K\right)
\rightarrow\Lambda\left(  K^{\prime}\right)  $. Since $m$ was defined as a
natural transformation, and since the inclusion $\iota:\Lambda\left(
K\right)  \rightarrow\Lambda\left(  K^{\prime}\right)  $ is a $\lambda$-ring
homomorphism, we then have $\iota\circ m_{\left(  \Lambda\left(  K\right)
,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }=m_{\left(
\Lambda\left(  K^{\prime}\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }\circ\iota^{\times n}$. Now,%
\begin{align*}
&  m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }\left(  u_{1},u_{2},...,u_{n}\right) \\
&  =\iota\left(  m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda
}^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(  u_{1},u_{2},...,u_{n}\right)
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\iota\text{ is just the
inclusion map }\Lambda\left(  K\right)  \rightarrow\Lambda\left(  K^{\prime
}\right)  \right) \\
&  =\underbrace{\left(  \iota\circ m_{\left(  \Lambda\left(  K\right)
,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }\right)
}_{=m_{\left(  \Lambda\left(  K^{\prime}\right)  ,\left(  \widehat{\lambda
}^{i}\right)  _{i\in\mathbb{N}}\right)  }\circ\iota^{\times n}}\left(
u_{1},u_{2},...,u_{n}\right)  =\left(  m_{\left(  \Lambda\left(  K^{\prime
}\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)
}\circ\iota^{\times n}\right)  \left(  u_{1},u_{2},...,u_{n}\right) \\
&  =m_{\left(  \Lambda\left(  K^{\prime}\right)  ,\left(  \widehat{\lambda
}^{i}\right)  _{i\in\mathbb{N}}\right)  }\underbrace{\left(  \iota^{\times
n}\left(  u_{1},u_{2},...,u_{n}\right)  \right)  }_{\substack{=\left(
\iota\left(  u_{1}\right)  ,\iota\left(  u_{2}\right)  ,...,\iota\left(
u_{n}\right)  \right)  \\=\left(  u_{1},u_{2},...,u_{n}\right)  \\\text{(since
}\iota\text{ is just an inclusion map)}}}=m_{\left(  \Lambda\left(  K^{\prime
}\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)
}\left(  u_{1},u_{2},...,u_{n}\right)
\end{align*}
and similarly $m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda
}^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(  u_{1},u_{2}%
,...,u_{n}\right)  =m_{\left(  \Lambda\left(  K^{\prime}\right)  ,\left(
\widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(
u_{1},u_{2},...,u_{n}\right)  $. Thus, (\ref{8.4.fast}) rewrites as
\[
m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }\left(  u_{1},u_{2},...,u_{n}\right)  =m_{\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  }^{\prime}\left(  u_{1},u_{2},...,u_{n}\right)  ,
\]
qed.} Thus we have proven (\ref{8.4.goal}). This proves Theorem 8.4.

Roughly speaking, Theorem 8.4 says that whether some identity holds on every
special $\lambda$-ring or not can be checked just by looking at the sums of
$1$-dimensional elements. This is why it is worthwhile to study such sums. Let
us record a property of these:

\subsection{$\lambda^{i}$ of a sum of $1$-dimensional elements}

\begin{quote}
\textbf{Theorem 8.5.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $u_{1},$ $u_{2},$ $...,$
$u_{m}$ be $1$-dimensional elements of $K$. Let $i\in\mathbb{N}$. Then,%
\[
\lambda^{i}\left(  u_{1}+u_{2}+...+u_{m}\right)  =\sum_{\substack{S\subseteq
\left\{  1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod_{k\in S}%
u_{k}.
\]



\end{quote}

\textit{Proof of Theorem 8.5.} We have%
\begin{align*}
&  \sum_{i\in\mathbb{N}}\lambda^{i}\left(  u_{1}+u_{2}+...+u_{m}\right)
T^{i}=\lambda_{T}\left(  u_{1}+u_{2}+...+u_{m}\right) \\
&  =\prod_{j=1}^{m}\lambda_{T}\left(  u_{j}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 2.1 \textbf{(a)}, applied several
times}\right) \\
&  =\prod_{j=1}^{m}\left(  1+u_{j}T\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since the element }u_{j}\text{ is
}1\text{-dimensional and thus satisfies }\lambda_{T}\left(  u_{j}\right)
=1+u_{j}T\right) \\
&  =\sum_{i\in\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
u_{k}\cdot T^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Exercise 4.2
\textbf{(b)}, applied to }A=K\left[  T\right]  \text{, }\alpha_{j}=u_{j}\text{
and }t=T\right)
\end{align*}
Comparing coefficients yields the assertion of Theorem 8.5.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 8.1.} Let $K$ be a ring. Define the mapping
$\operatorname*{coeff}\nolimits_{1}:\Lambda\left(  K\right)  \rightarrow K$ as
in Theorem 8.2. Then, show that $\operatorname*{coeff}\nolimits_{1}%
:\Lambda\left(  K\right)  \rightarrow K$ is a ring homomorphism\footnote{but,
generally, not a $\lambda$-ring homomorphism, even when $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a special $\lambda$-ring!}.

\textit{Exercise 8.2.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring. If $x\in K$ is an
invertible $1$-dimensional element of $K$, then prove that $x^{-1}$ is
$1$-dimensional as well.

\textit{Exercise 8.3.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $E$ be a generating set
of the $\mathbb{Z}$-module $K$ such that every element $e\in E$ is $1$-dimensional.

Prove that the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is special.
\end{quotation}

\section{Adams operations}

\subsection{The Hirzebruch-Newton polynomials}

We are now ready to define Adams operations of special $\lambda$-rings. There
are two different ways to do this; we will take one of these as the definition
and the other one as a theorem.

Remember how we defined the "universal" polynomials $P_{k}$ and $P_{k,j}$ in
Section 4? Prepare for some more:

\begin{quote}
\textbf{Definition.} Let $j\in\mathbb{N}\setminus\left\{  0\right\}  $. Our
goal is to define a polynomial $N_{j}\in\mathbb{Z}\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{j}\right]  $ such that%
\begin{equation}
\sum_{i=1}^{m}U_{i}^{j}=N_{j}\left(  X_{1},X_{2},...,X_{j}\right)  \label{Nj1}%
\end{equation}
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ for
every $m\in\mathbb{N}$, where $X_{i}=\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$
is the $i$-th elementary symmetric polynomial in the variables $U_{1},$
$U_{2},$ $...,$ $U_{m}$ for every $i\in\mathbb{N}$.

In order to do this, we first fix some $m\in\mathbb{N}$. The polynomial
$\sum\limits_{i=1}^{m}U_{i}^{j}\in\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  $ is symmetric. Thus, Theorem 4.1 \textbf{(a)} yields that there
exists one and only one polynomial $Q\in\mathbb{Z}\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{m}\right]  $ such that $\sum\limits_{i=1}^{m}U_{i}%
^{j}=Q\left(  X_{1},X_{2},...,X_{m}\right)  .$ Since the polynomial
$\sum\limits_{i=1}^{m}U_{i}^{j}$ has total degree $\leq j$ in the variables
$U_{1},$ $U_{2},$ $...,$ $U_{m}$, Theorem 4.1 \textbf{(b)} yields that%
\[
\sum_{i=1}^{m}U_{i}^{j}=Q_{j}\left(  X_{1},X_{2},...,X_{j}\right)  ,
\]
where $Q_{j}$ is the image of the polynomial $Q$ under the canonical
homomorphism $\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]
\rightarrow\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $.
However, this polynomial $Q_{j}$ is not independent of $m$ yet (as the
polynomial $N_{j}$ that we intend to construct should be), so we call it
$Q_{j,\left[  m\right]  }$ rather than just $Q_{j}$.

Now we forget that we fixed $m\in\mathbb{N}$. We have learnt that%
\[
\sum_{i=1}^{m}U_{i}^{j}=Q_{j,\left[  m\right]  }\left(  X_{1},X_{2}%
,...,X_{j}\right)  ,
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ for
every $m\in\mathbb{N}$. Now, define a polynomial $N_{j}\in\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $ by $N_{j}=Q_{j,\left[
j\right]  }.$

This polynomial $N_{j}$ is called the $j$\textit{-th Hirzebruch-Newton
polynomial}.\footnote{The "Newton" in the name of this polynomial $N_{j}$
probably refers to the fact that the explicit form of $N_{j}$ can be easily
computed (recursively) from the so-called Newton identities (which relate the
power sums and the elementary symmetric polynomials). See Theorem 9.6 and
Corollary 9.7 for details.}

\textbf{Theorem 9.1.} \textbf{(a)} The polynomial $N_{j}$ just defined
satisfies the equation (\ref{Nj1}) in the polynomial ring $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $ for every $m\in\mathbb{N}$. (Hence, the goal
mentioned above in the definition is actually achieved.)

\textbf{(b)} For every $m\in\mathbb{N}$, we have%
\begin{equation}
T\sum_{i=1}^{m}\dfrac{U_{i}}{1-U_{i}T}=\sum_{j\in\mathbb{N}\setminus\left\{
0\right\}  }N_{j}\left(  X_{1},X_{2},...,X_{j}\right)  T^{j} \label{Nj2}%
\end{equation}
in the ring $\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)
\left[  \left[  T\right]  \right]  $.
\end{quote}

\textit{Proof of Theorem 9.1.} \textbf{(a)} This proof is going to be very
similar to that of Theorem 4.4 \textbf{(a)}.

\textit{1st Step:} Fix $m\in\mathbb{N}$ such that $m\geq j$. Then, we claim
that $Q_{j,\left[  m\right]  }=N_{j}$.

\textit{Proof.} By the definition of $Q_{j,\left[  m\right]  }$, we have%
\[
\sum_{i=1}^{m}U_{i}^{j}=Q_{j,\left[  m\right]  }\left(  X_{1},X_{2}%
,...,X_{j}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $.
Applying the canonical ring epimorphism $\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  \rightarrow\mathbb{Z}\left[  U_{1},U_{2}%
,...,U_{j}\right]  $ (which maps every $U_{i}$ to $\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq j;\\
0,\text{ if }i>j
\end{array}
\right.  $) to this equation (and noticing that this epimorphism maps every
$X_{i}$ with $i\geq1$ to the corresponding $X_{i}$ of the image ring), we
obtain%
\[
\sum_{i=1}^{j}U_{i}^{j}=Q_{j,\left[  m\right]  }\left(  X_{1},X_{2}%
,...,X_{j}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{j}\right]  $. On
the other hand, the definition of $Q_{j,\left[  j\right]  }$ yields%
\[
\sum_{i=1}^{j}U_{i}^{j}=Q_{j,\left[  j\right]  }\left(  X_{1},X_{2}%
,...,X_{j}\right)
\]
in the same ring. These two equations yield $Q_{j,\left[  m\right]  }\left(
X_{1},X_{2},...,X_{j}\right)  =Q_{j,\left[  j\right]  }\left(  X_{1}%
,X_{2},...,X_{j}\right)  $. Since the elements $X_{1},$ $X_{2},$ $...,$
$X_{j}$ of $\mathbb{Z}\left[  U_{1},U_{2},...,U_{j}\right]  $ are
algebraically independent (by Theorem 4.1 \textbf{(a)}), this yields
$Q_{j,\left[  m\right]  }=Q_{j,\left[  j\right]  }.$ In other words,
$Q_{j,\left[  m\right]  }=N_{j},$ and the 1st Step is proven.

\textit{2nd Step:} For every $m\in\mathbb{N}$, the equation (\ref{Nj1}) is
satisfied in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  $.

\textit{Proof.} Let $m^{\prime}\in\mathbb{N}$ be such that $m^{\prime}\geq m$
and $m^{\prime}\geq j$. Then, the 1st Step (applied to $m^{\prime}$ instead of
$m$) yields that $Q_{j,\left[  m^{\prime}\right]  }=N_{j}.$

The definition of $Q_{j,\left[  m^{\prime}\right]  }$ yields
\[
\sum_{i=1}^{m^{\prime}}U_{i}^{j}=Q_{j,\left[  m^{\prime}\right]  }\left(
X_{1},X_{2},...,X_{j}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m^{\prime}%
}\right]  $. Applying the canonical ring epimorphism $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m^{\prime}}\right]  \rightarrow\mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $ (which maps every $U_{i}$ to $\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq m;\\
0,\text{ if }i>m
\end{array}
\right.  $) to this equation (and noticing that this epimorphism maps every
$X_{i}$ with $i\geq1$ to the corresponding $X_{i}$ of the image ring), we
obtain%
\[
\sum_{i=1}^{m}U_{i}^{j}=Q_{j,\left[  m^{\prime}\right]  }\left(  X_{1}%
,X_{2},...,X_{j}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  .$
This means that the equation (\ref{Nj1}) is satisfied in the polynomial ring
$\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ (since $Q_{j,\left[
m^{\prime}\right]  }=N_{j}$). This completes the 2nd Step and proves Theorem
9.1 \textbf{(a)}.

\textbf{(b)} We have%
\begin{align*}
T\sum_{i=1}^{m}\dfrac{U_{i}}{1-U_{i}T}  &  =\sum_{i=1}^{m}U_{i}%
T\underbrace{\left(  1-U_{i}T\right)  ^{-1}}_{=\sum\limits_{j\in\mathbb{N}%
}\left(  U_{i}T\right)  ^{j}}=\sum_{i=1}^{m}\sum_{j\in\mathbb{N}}\left(
U_{i}T\right)  ^{j+1}=\sum_{i=1}^{m}\sum_{j\in\mathbb{N}\setminus\left\{
0\right\}  }\left(  U_{i}T\right)  ^{j}\\
&  =\sum_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\sum_{i=1}^{m}\left(
U_{i}T\right)  ^{j}=\sum_{j\in\mathbb{N}\setminus\left\{  0\right\}
}\underbrace{\sum_{i=1}^{m}U_{i}^{j}}_{\substack{=N_{j}\left(  X_{1}%
,X_{2},...,X_{j}\right)  \\\text{by (\ref{Nj1})}}}T^{j}=\sum_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }N_{j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  T^{j},
\end{align*}
and Theorem 9.1 \textbf{(b)} is proven.

\textit{Remark:} There is a subtle point here: We have defined, for every
$j\in\mathbb{N}\setminus\left\{  0\right\}  ,$ a polynomial $N_{j}%
\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $ which
satisfies (\ref{Nj1}) in the polynomial ring $\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  $ for every $m\in\mathbb{N}$. We \textit{cannot}
define such a polynomial $N_{j}$ for $j=0$. In fact, if we would try to do
this as we did above, then the proof of Theorem 9.1 would fail (in fact, the
canonical ring epimorphism $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]
\rightarrow\mathbb{Z}\left[  U_{1},U_{2},...,U_{j}\right]  $ would
\textit{not} send $\sum\limits_{i=1}^{m}U_{i}^{j}$ to $\sum\limits_{i=1}%
^{j}U_{i}^{j}$ anymore, because $0^{j}$ is not $0$ for $j=0$). This is why
$N_{j}$ is well-defined only for $j\in\mathbb{N}\setminus\left\{  0\right\}  $
and not for all $j\in\mathbb{N}$.

\textbf{Example.} We can compute the polynomials $N_{j}$ in the same way as we
have computed the polynomials $P_{k,j}$ in Section 4 - by unraveling the
definition. Here are the first few $N_{j}$:%
\begin{align*}
N_{1}  &  =\alpha_{1};\\
N_{2}  &  =\alpha_{1}^{2}-2\alpha_{2};\\
N_{3}  &  =\alpha_{1}^{3}-3\alpha_{1}\alpha_{2}+3\alpha_{3};\\
N_{4}  &  =\alpha_{1}^{4}-4\alpha_{1}^{2}\alpha_{2}+4\alpha_{1}\alpha
_{3}+2\alpha_{2}^{2}-4\alpha_{4}.
\end{align*}


There are easier ways to compute the $N_{j}$, however. For example, Corollary
9.7 gives a recurrent formula, and Exercise 9.6 \textbf{(c)} gives an explicit
determinantal one.

\subsection{Definition of Adams operations}

Now, let us define Adams operations:

\begin{quote}
\textbf{Definition.} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in
\mathbb{N}}\right)  $ be a $\lambda$-ring. For every $j\in\mathbb{N}%
\setminus\left\{  0\right\}  $, we define a map $\psi^{j}:K\rightarrow K$ by%
\begin{equation}
\psi^{j}\left(  x\right)  =N_{j}\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)  \right)
\ \ \ \ \ \ \ \ \ \ \text{for every }x\in K. \label{PsiDef}%
\end{equation}
We call $\psi^{j}$ the $j$\textit{-th Adams operation} (or the $j$\textit{-th
Adams character}) of the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $.
\end{quote}

\subsection{The equality $\protect\widetilde{\psi}_{T}\left(  x\right)  =
-T\cdot\frac{d}{dT}\log\lambda_{-T}\left(  x\right)  $ for special $\lambda
$-rings}

Before we prove a batch of properties of these Adams characters, let us show
another approach to these Adams characters:

\begin{quote}
\textbf{Theorem 9.2.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring.

Define a map $\widetilde{\psi}_{T}:K\rightarrow K\left[  \left[  T\right]
\right]  $ by $\widetilde{\psi}_{T}\left(  x\right)  =\sum\limits_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}$ for
every $x\in K$.\ \ \ \ \footnote{Note that we call this map $\widetilde{\psi
}_{T}$ to distinguish it from the map $\psi_{T}$ in [1] (which is more or less
the same but differs slightly).}

Let $x\in K$.

\textbf{(a)} We have%
\[
\psi^{j}\left(  x\right)  =\left(  -1\right)  ^{j+1}\sum_{i=0}^{j}i\lambda
^{i}\left(  x\right)  \lambda^{j-i}\left(  -x\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\mathbb{N}\setminus\left\{
0\right\}  \text{.}%
\]


\textbf{(b)} We have $\widetilde{\psi}_{T}\left(  x\right)  =-T\cdot\dfrac
{d}{dT}\log\lambda_{-T}\left(  x\right)  $. Here, for every power series
$u\in1+K\left[  \left[  T\right]  \right]  ^{+}$, the \textit{logarithmic
derivative} $\dfrac{d}{dT}\log u$ of $u$ is defined by $\dfrac{d}{dT}\log
u=\dfrac{\dfrac{d}{dT}u}{u}$ (this definition works even in the cases where
the logarithm doesn't exist, such as rings of positive characteristic), and
$\lambda_{-T}\left(  x\right)  $ denotes $\operatorname*{ev}_{-T}\left(
\lambda_{T}\left(  x\right)  \right)  $.
\end{quote}

Before we start proving this, let me admit that Theorem 9.2 can be
generalized: It still holds if $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is an \textit{arbitrary} (not necessarily
special!) $\lambda$-ring. However, the proof of Theorem 9.2 that we are going
to give right now cannot be generalized to this situation; it requires the
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ to be special. The generalized version of Theorem 9.2 will be
proven later (see the proof of Theorem 9.5 below), yielding another proof of
Theorem 9.2. The reader is still advised to read the following proof of
Theorem 9.2, even if it is not directly generalizable. In fact, its first two
steps will be used at later times (in particular, its 1st step will be used in
the proof of the generalized version), whereas its 4th step gives a good
example of how Theorem 8.4 can be applied to prove properties of special
$\lambda$-rings.

\textit{Proof of Theorem 9.2.} \textit{1st step:} For any fixed special
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ and any fixed $x\in K$, the assertions \textbf{(a)} and
\textbf{(b)} are equivalent.

\textit{Proof.} In $K\left[  \left[  T\right]  \right]  $, we have%
\[
\lambda_{-T}\left(  x\right)  =\sum_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  \left(  -T\right)  ^{i}=\sum_{i\in\mathbb{N}}\left(  -1\right)
^{i}\lambda^{i}\left(  x\right)  T^{i},
\]
but also%
\begin{align*}
\left(  \lambda_{-T}\left(  x\right)  \right)  ^{-1}  &  =\lambda_{-T}\left(
-x\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left(  \lambda_{T}\left(
x\right)  \right)  ^{-1}=\lambda_{T}\left(  -x\right)  \text{ by Theorem 2.1
\textbf{(b)}}\right) \\
&  =\sum_{i\in\mathbb{N}}\left(  -1\right)  ^{i}\lambda^{i}\left(  -x\right)
T^{i}\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{due to }\lambda_{-T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}%
}\left(  -1\right)  ^{i}\lambda^{i}\left(  x\right)  T^{i}\text{,}\\
\text{applied to }-x\text{ instead of }x
\end{array}
\right)
\end{align*}
and%
\begin{align*}
\dfrac{d}{dT}\lambda_{-T}\left(  x\right)   &  =\dfrac{d}{dT}\sum
_{i\in\mathbb{N}}\left(  -1\right)  ^{i}\lambda^{i}\left(  x\right)
T^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\lambda_{-T}\left(  x\right)
=\sum_{i\in\mathbb{N}}\left(  -1\right)  ^{i}\lambda^{i}\left(  x\right)
T^{i}\right) \\
&  =\sum_{i\in\mathbb{N}}\left(  -1\right)  ^{i}\lambda^{i}\left(  x\right)
iT^{i-1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the derivative of a
formal power series}\right)  .
\end{align*}
Thus,%
\begin{align*}
&  -T\cdot\dfrac{d}{dT}\log\lambda_{-T}\left(  x\right) \\
&  =-T\cdot\dfrac{\dfrac{d}{dT}\lambda_{-T}\left(  x\right)  }{\lambda
_{-T}\left(  x\right)  }=-T\cdot\underbrace{\dfrac{d}{dT}\lambda_{-T}\left(
x\right)  }_{=\sum\limits_{i\in\mathbb{N}}\left(  -1\right)  ^{i}\lambda
^{i}\left(  x\right)  iT^{i-1}}\cdot\underbrace{\left(  \lambda_{-T}\left(
x\right)  \right)  ^{-1}}_{=\sum\limits_{i\in\mathbb{N}}\left(  -1\right)
^{i}\lambda^{i}\left(  -x\right)  T^{i}}\\
&  =-T\cdot\sum\limits_{i\in\mathbb{N}}\left(  -1\right)  ^{i}\lambda
^{i}\left(  x\right)  iT^{i-1}\cdot\sum\limits_{i\in\mathbb{N}}\left(
-1\right)  ^{i}\lambda^{i}\left(  -x\right)  T^{i}\\
&  =\sum\limits_{i\in\mathbb{N}}\left(  -1\right)  ^{i+1}\lambda^{i}\left(
x\right)  iT^{i}\cdot\sum\limits_{i\in\mathbb{N}}\left(  -1\right)
^{i}\lambda^{i}\left(  -x\right)  T^{i}\\
&  =\sum_{j\in\mathbb{N}}\sum_{i=0}^{j}\left(  -1\right)  ^{i+1}\lambda
^{i}\left(  x\right)  i\cdot\left(  -1\right)  ^{j-i}\lambda^{j-i}\left(
-x\right)  T^{j}=\sum_{j\in\mathbb{N}}\left(  -1\right)  ^{j+1}\sum_{i=0}%
^{j}i\lambda^{i}\left(  x\right)  \lambda^{j-i}\left(  -x\right)  \cdot
T^{j}\\
&  =\sum_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\left(  -1\right)
^{j+1}\sum_{i=0}^{j}i\lambda^{i}\left(  x\right)  \lambda^{j-i}\left(
-x\right)  \cdot T^{j}+\underbrace{\left(  -1\right)  ^{0+1}\sum_{i=0}%
^{0}i\lambda^{i}\left(  x\right)  \lambda^{0-i}\left(  -x\right)  \cdot T^{0}%
}_{=0}\\
&  =\sum_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\left(  -1\right)
^{j+1}\sum_{i=0}^{j}i\lambda^{i}\left(  x\right)  \lambda^{j-i}\left(
-x\right)  \cdot T^{j}.
\end{align*}
On the other hand, $\widetilde{\psi}_{T}\left(  x\right)  =\sum\limits_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}$.
Hence, $\widetilde{\psi}_{T}\left(  x\right)  =-T\cdot\dfrac{d}{dT}\log
\lambda_{-T}\left(  x\right)  $ holds if and only if%
\[
\psi^{j}\left(  x\right)  =\left(  -1\right)  ^{j+1}\sum_{i=0}^{j}i\lambda
^{i}\left(  x\right)  \lambda^{j-i}\left(  -x\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\mathbb{N}\setminus\left\{
0\right\}  \text{.}%
\]
This proves that the assertions \textbf{(a)} and \textbf{(b)} are equivalent,
and thus the 1st step is complete.

\textit{2nd step:} We will now show that the assertion \textbf{(b)} holds for
every special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and every $x\in K$ such that $x$ is the sum of
finitely many $1$-dimensional elements of $K$.

\textit{Proof.} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a special $\lambda$-ring, and let $x\in K$ be a sum of finitely
many $1$-dimensional elements of $K$. In other words, $x=u_{1}+u_{2}%
+...+u_{m}$ for some $1$-dimensional elements $u_{1},$ $u_{2},$ $...,$ $u_{m}$
of $K$. Consider these elements $u_{1},$ $u_{2},$ $...,$ $u_{m}$.

Then,%
\[
\lambda_{-T}\left(  x\right)  =\lambda_{-T}\left(  u_{1}+u_{2}+...+u_{m}%
\right)  =\prod_{j=1}^{m}\left(  1-u_{j}T\right)
\]
(since $\lambda_{T}\left(  u_{1}+u_{2}+...+u_{m}\right)  =\prod\limits_{j=1}%
^{m}\left(  1+u_{j}T\right)  $, as shown in the proof of Theorem 8.5), so
that, by the Leibniz formula,%
\begin{align*}
\dfrac{d}{dT}\lambda_{-T}\left(  x\right)   &  =\sum_{k=1}^{m}\left(
\underbrace{\dfrac{d}{dT}\left(  1-u_{k}T\right)  }_{=-u_{k}}\right)
\cdot\underbrace{\prod_{j\in\left\{  1,2,...,m\right\}  \setminus\left\{
k\right\}  }\left(  1-u_{j}T\right)  }_{=\left(  1-u_{k}T\right)  ^{-1}%
\cdot\prod\limits_{j\in\left\{  1,2,...,m\right\}  }\left(  1-u_{j}T\right)
}\\
&  =-\sum_{k=1}^{m}\dfrac{u_{k}}{1-u_{k}T}\cdot\underbrace{\prod
\limits_{j\in\left\{  1,2,...,m\right\}  }\left(  1-u_{j}T\right)  }%
_{=\lambda_{-T}\left(  x\right)  }=-\sum_{k=1}^{m}\dfrac{u_{k}}{1-u_{k}T}%
\cdot\lambda_{-T}\left(  x\right)  .
\end{align*}
Hence,%
\begin{align}
-T\cdot\dfrac{d}{dT}\log\lambda_{-T}\left(  x\right)   &  =-T\cdot
\dfrac{\dfrac{d}{dT}\lambda_{-T}\left(  x\right)  }{\lambda_{-T}\left(
x\right)  }=-T\cdot\dfrac{-\sum\limits_{k=1}^{m}\dfrac{u_{k}}{1-u_{k}T}%
\cdot\lambda_{-T}\left(  x\right)  }{\lambda_{-T}\left(  x\right)
}\nonumber\\
&  =T\cdot\sum\limits_{k=1}^{m}\dfrac{u_{k}}{1-u_{k}T}=T\sum\limits_{i=1}%
^{m}\dfrac{u_{i}}{1-u_{i}T}. \label{9.2.2step}%
\end{align}
On the other hand, Theorem 8.5 yields%
\[
\lambda^{i}\left(  x\right)  =\lambda^{i}\left(  u_{1}+u_{2}+...+u_{m}\right)
=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}u_{k}\ \ \ \ \ \ \ \ \ \ \text{for every
}i\in\mathbb{N}.
\]


Consider the polynomial ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]
$. For every $i\in\mathbb{N}$, let $X_{i}=\sum\limits_{\substack{S\subseteq
\left\{  1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in
S}U_{k}$ be the $i$-th elementary symmetric polynomial in the variables
$U_{1},$ $U_{2},$ $...,$ $U_{m}$. There exists a ring homomorphism
$\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \rightarrow K$ which maps
$U_{i}$ to $u_{i}$ for every $i$. This homomorphism therefore maps $X_{i}$ to
$\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}u_{k}=\lambda^{i}\left(  x\right)  $ for
every $i\in\mathbb{N}$. Hence, applying this homomorphism to (\ref{Nj2}), we
obtain%
\[
T\sum_{i=1}^{m}\dfrac{u_{i}}{1-u_{i}T}=\sum_{j\in\mathbb{N}\setminus\left\{
0\right\}  }\underbrace{N_{j}\left(  \lambda^{1}\left(  x\right)  ,\lambda
^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)  \right)  }_{=\psi
^{j}\left(  x\right)  \text{ by (\ref{PsiDef})}}T^{j}=\sum_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)
T^{j}=\widetilde{\psi}_{T}\left(  x\right)  .
\]
Comparing this with (\ref{9.2.2step}), we obtain%
\[
-T\cdot\dfrac{d}{dT}\log\lambda_{-T}\left(  x\right)  =\widetilde{\psi}%
_{T}\left(  x\right)  .
\]
Hence, the assertion \textbf{(b)} holds for every special $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and every
$x\in K$ such that $x$ is the sum of finitely many $1$-dimensional elements of
$K$. This completes the 2nd step.

\textit{3rd step:} We will now show that the assertion \textbf{(a)} holds for
every special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and every $x\in K$ such that $x$ is the sum of
finitely many $1$-dimensional elements of $K$.

\textit{Proof.} This follows from the 2nd step, since \textbf{(a)} and
\textbf{(b)} are equivalent (by the 1st step).

\textit{4th step:} We will now show that the assertion \textbf{(a)} holds for
every special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and every $x\in K$.

\textit{Proof.} We want to derive this from the 3rd step by applying Theorem 8.4.

Fix some $j\in\mathbb{N}\setminus\left\{  0\right\}  $.

Define a $1$-operation $m$ of special $\lambda$-rings by $m_{\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }=\psi^{j}$ for every special
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $. (This is indeed a $1$-operation, since (\ref{PsiDef}) shows that
$\psi^{j}$ is a polynomial in $\lambda^{1},$ $\lambda^{2},$ $...,$
$\lambda^{j}$ with integer coefficients.)

Define a $1$-operation $m^{\prime}$ of special $\lambda$-rings by%
\[
m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime
}\left(  x\right)  =\left(  -1\right)  ^{j+1}\sum_{i=0}^{j}i\lambda^{i}\left(
x\right)  \lambda^{j-i}\left(  -x\right)  \ \ \ \ \ \ \ \ \ \ \text{for every
}x\in K
\]
for every $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in
\mathbb{N}}\right)  $. (This is, again, a $1$-operation, since it is a
polynomial in $\lambda^{1},$ $\lambda^{2},$ $...,$ $\lambda^{j}$ with integer coefficients.)

These two $1$-operations $m$ and $m^{\prime}$ satisfy both conditions of
Theorem 8.4: The continuity assumption holds (since the operations $m$ and
$m^{\prime}$ are polynomials in $\lambda^{1},$ $\lambda^{2},$ $...,$
$\lambda^{j}$ with integer coefficients, so that the maps $m_{\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  }$ and $m_{\left(  \Lambda\left(  K\right)  ,\left(
\widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}$ are
polynomials in $\widehat{\lambda}^{1},$ $\widehat{\lambda}^{2},$ $...,$
$\widehat{\lambda}^{j}$ with integer coefficients, and therefore continuous
because of Theorem 5.5 \textbf{(d)}), and the split equality assumption holds
(since it states that for every special $\lambda$-ring $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and every $x\in K$ such that
$x$ is the sum of finitely many $1$-dimensional elements of $K$, we have
$m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(
x\right)  =m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
}^{\prime}\left(  x\right)  $; but this simply means that $\psi^{j}\left(
x\right)  =\left(  -1\right)  ^{j+1}\sum\limits_{i=0}^{j}i\lambda^{i}\left(
x\right)  \lambda^{j-i}\left(  -x\right)  ,$ which was proven in the 3rd
step). Hence, by Theorem 8.4, we have $m=m^{\prime}$. Hence, for every special
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ and every $x\in K$, we have%
\[
\psi^{j}\left(  x\right)  =m_{\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  }\left(  x\right)  =m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(  x\right)  =\left(
-1\right)  ^{j+1}\sum_{i=0}^{j}i\lambda^{i}\left(  x\right)  \lambda
^{j-i}\left(  -x\right)  .
\]
Thus, the assertion \textbf{(a)} holds for every special $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and every
$x\in K$. This completes the 4th step.

\textit{5th step:} We will now prove that the assertion \textbf{(b)} holds for
every special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and every $x\in K$.

\textit{Proof.} This follows from the 4th step, since \textbf{(a)} and
\textbf{(b)} are equivalent (by the 1st step).

Thus, the proof of Theorem 9.2 is completed.

\subsection{Adams operations are ring homomorphisms when the $\lambda$-ring is
special}

The Adams operations $\psi^{j}$ have a lot of interesting properties (that
make them easier to deal with than $\lambda$-operations!):

\begin{quote}
\textbf{Theorem 9.3.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring.

\textbf{(a)} For every $a\in K$, we have $\psi^{1}\left(  a\right)  =a$.

\textbf{(b)} For every $j\in\mathbb{N}\setminus\left\{  0\right\}  $, the map
$\psi^{j}:\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
\rightarrow\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $
is a $\lambda$-ring homomorphism.

\textbf{(c)} For every $i\in\mathbb{N}\setminus\left\{  0\right\}  $ and
$j\in\mathbb{N}\setminus\left\{  0\right\}  $, we have $\psi^{i}\circ\psi
^{j}=\psi^{j}\circ\psi^{i}=\psi^{ij}$.
\end{quote}

Before we come to prove this, let us first show an analogue of Theorem 8.5 for
the $\psi^{i}$:

\begin{quote}
\textbf{Theorem 9.4.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $u_{1},$ $u_{2},$ $...,$
$u_{m}$ be $1$-dimensional elements of $K$. Let $j\in\mathbb{N}\setminus
\left\{  0\right\}  $. Then,%
\[
\psi^{j}\left(  u_{1}+u_{2}+...+u_{m}\right)  =u_{1}^{j}+u_{2}^{j}%
+...+u_{m}^{j}.
\]



\end{quote}

\textit{Proof of Theorem 9.4.} Let $x=u_{1}+u_{2}+...+u_{m}$. Just as in the
proof of Theorem 9.2 (in the 2nd step)\footnote{Here, we use the fact that the
2nd step of the proof of Theorem 9.2 works for \textit{any} $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $, not only
for special ones.}, we can show that%
\[
T\sum\limits_{i=1}^{m}\dfrac{u_{i}}{1-u_{i}T}=\sum\limits_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}.
\]


Thus,%
\begin{align*}
\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(
x\right)  T^{j}  &  =T\sum\limits_{i=1}^{m}\dfrac{u_{i}}{1-u_{i}T}%
=\sum\limits_{i=1}^{m}u_{i}T\left(  1-u_{i}T\right)  ^{-1}=\sum\limits_{i=1}%
^{m}u_{i}T\sum_{k\in\mathbb{N}}\left(  u_{i}T\right)  ^{k}=\sum\limits_{i=1}%
^{m}\sum_{k\in\mathbb{N}}\left(  u_{i}T\right)  ^{k+1}\\
&  =\sum\limits_{i=1}^{m}\sum_{j\in\mathbb{N}\setminus\left\{  0\right\}
}\left(  u_{i}T\right)  ^{j}=\sum\limits_{i=1}^{m}\sum_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }u_{i}^{j}T^{j}=\sum_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }\sum\limits_{i=1}^{m}u_{i}^{j}T^{j}.
\end{align*}
Comparing coefficients yields $\psi^{j}\left(  x\right)  =\sum\limits_{i=1}%
^{m}u_{i}^{j}$ for every $j\in\mathbb{N}\setminus\left\{  0\right\}  ,$ and
thus Theorem 9.4 is proven.

\textit{Proof of Theorem 9.3.} \textbf{(a)} is trivial (for instance, by
Theorem 9.2 \textbf{(a)}).

\textbf{(b)} Fix some $j\in\mathbb{N}\setminus\left\{  0\right\}  $. First,
let us prove that $\psi^{j}:K\rightarrow K$ is a ring homomorphism.

This means proving that%
\begin{align}
\psi^{j}\left(  0\right)   &  =0;\label{9.3.1}\\
\psi^{j}\left(  x+y\right)   &  =\psi^{j}\left(  x\right)  +\psi^{j}\left(
y\right)  \ \ \ \ \ \ \ \ \ \ \text{for any }x\in K\text{ and }y\in
K;\label{9.3.2}\\
\psi^{j}\left(  1\right)   &  =1;\label{9.3.3}\\
\psi^{j}\left(  xy\right)   &  =\psi^{j}\left(  x\right)  \cdot\psi^{j}\left(
y\right)  \ \ \ \ \ \ \ \ \ \ \text{for any }x\in K\text{ and }y\in K.
\label{9.3.4}%
\end{align}
Out of these four equations, two (namely, (\ref{9.3.1}) and (\ref{9.3.3})) are
trivial (just apply Theorem 9.4, remembering that $1$ is a $1$-dimensional
element), so it remains to prove the other two equations - namely,
(\ref{9.3.2}) and (\ref{9.3.4}).

First, let us prove (\ref{9.3.4}):

Define a $2$-operation $m$ of special $\lambda$-rings as follows: For every
special $\lambda$-ring $K$, let $m_{\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  }:K^{2}\rightarrow K$ be the map defined by
$m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(
x,y\right)  =\psi^{j}\left(  xy\right)  $ for every $x\in K$ and $y\in K$.
(This is indeed a $2$-operation of special $\lambda$-rings, since $\psi^{j}$
is a polynomial in the $\lambda^{1},$ $\lambda^{2},$ $...,$ $\lambda^{j}$ with
integer coefficients.)

Define a $2$-operation $m^{\prime}$ of special $\lambda$-rings as follows: For
every special $\lambda$-ring $K$, let $m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}:K^{2}\rightarrow K$ be the
map defined by $m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  }^{\prime}\left(  x,y\right)  =\psi^{j}\left(  x\right)  \cdot
\psi^{j}\left(  y\right)  $ for every $x\in K$ and $y\in K$. (Again, this is
really a $2$-operation of special $\lambda$-rings.)

We want to prove that $m=m^{\prime}$. According to Theorem 8.4, this will be
done once we have verified the continuity assumption and the split equality
assumption. The continuity assumption is obviously satisfied (since for every
ring $K$, the maps $m_{\left(  \Lambda\left(  K\right)  ,\left(
\widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }:\left(
\Lambda\left(  K\right)  \right)  ^{2}\rightarrow\Lambda\left(  K\right)  $
and $m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}%
^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}:\left(  \Lambda\left(
K\right)  \right)  ^{2}\rightarrow\Lambda\left(  K\right)  $ are continuous by
Theorem 5.5 \textbf{(d)}, because they are polynomials in $\widehat{\lambda
}^{1},$ $\widehat{\lambda}^{2},$ $...,$ $\widehat{\lambda}^{j}$ with integer
coefficients). Hence, it remains to verify the split equality assumption. This
assumption claims that for every special $\lambda$-ring $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and every $\left(  x,y\right)
\in K^{2}$ such that each of $x$ and $y$ is the sum of finitely many
$1$-dimensional elements of $K$, we have $m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(  x,y\right)  =m_{\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(
x,y\right)  $.

Since $m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)
}\left(  x,y\right)  =\psi^{j}\left(  xy\right)  $ and $m_{\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(  x,y\right)
=\psi^{j}\left(  x\right)  \cdot\psi^{j}\left(  y\right)  $, this is
equivalent to claiming that for every special $\lambda$-ring $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and every $\left(
x,y\right)  \in K^{2}$ such that each of $x$ and $y$ is the sum of finitely
many $1$-dimensional elements of $K$, we have $\psi^{j}\left(  xy\right)
=\psi^{j}\left(  x\right)  \cdot\psi^{j}\left(  y\right)  $.

So let us verify this assumption. Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring, and let $\left(
x,y\right)  \in K^{2}$ be such that each of $x$ and $y$ is the sum of finitely
many $1$-dimensional elements of $K$. Thus, there exist $1$-dimensional
elements $u_{1},$ $u_{2},$ $...,$ $u_{m}$ of $K$ such that $x=u_{1}%
+u_{2}+...+u_{m}$, and there exist $1$-dimensional elements $v_{1},$ $v_{2},$
$...,$ $v_{n}$ of $K$ such that $y=v_{1}+v_{2}+...+v_{n}$. Consider these
$1$-dimensional elements. Then,%
\begin{align*}
&  m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(
x,y\right) \\
&  =\psi^{j}\left(  xy\right)  =\psi^{j}\left(  \left(  u_{1}+u_{2}%
+...+u_{m}\right)  \left(  v_{1}+v_{2}+...+v_{n}\right)  \right) \\
&  =\psi^{j}\left(  \sum_{i=1}^{m}u_{i}\sum_{i^{\prime}=1}^{n}v_{i^{\prime}%
}\right)  =\psi^{j}\left(  \sum_{i=1}^{m}\sum_{i^{\prime}=1}^{n}%
u_{i}v_{i^{\prime}}\right)  =\sum_{i=1}^{m}\sum_{i^{\prime}=1}^{n}\left(
u_{i}v_{i^{\prime}}\right)  ^{j}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Theorem 9.4, applied to the }1\text{-dimensional elements }%
u_{i}v_{i^{\prime}}\text{,}\\
\text{which are }1\text{-dimensional because of Theorem 8.3 \textbf{(b)}}%
\end{array}
\right) \\
&  =\sum_{i=1}^{m}\sum_{i^{\prime}=1}^{n}u_{i}^{j}v_{i^{\prime}}^{j}%
=\sum_{i=1}^{m}u_{i}^{j}\sum_{i^{\prime}=1}^{n}v_{i^{\prime}}^{j}%
=\underbrace{\left(  u_{1}^{j}+u_{2}^{j}+...+u_{m}^{j}\right)  }%
_{\substack{=\psi^{j}\left(  u_{1}+u_{2}+...+u_{m}\right)  \\\text{by Theorem
9.4}}}\underbrace{\left(  v_{1}^{j}+v_{2}^{j}+...+v_{n}^{j}\right)
}_{\substack{=\psi^{j}\left(  v_{1}+v_{2}+...+v_{n}\right)  \\\text{by Theorem
9.4}}}\\
&  =\psi^{j}\left(  \underbrace{u_{1}+u_{2}+...+u_{m}}_{=x}\right)  \cdot
\psi^{j}\left(  \underbrace{v_{1}+v_{2}+...+v_{n}}_{=y}\right)  =\psi
^{j}\left(  x\right)  \cdot\psi^{j}\left(  y\right)  =m_{\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(  x,y\right)  ,
\end{align*}
and the proof of the split equality assumption is complete. Thus, using
Theorem 8.4, we obtain that $\psi^{j}\left(  xy\right)  =\psi^{j}\left(
x\right)  \cdot\psi^{j}\left(  y\right)  $ holds for any $x\in K$ and any
$y\in K$.

The main idea of the above proof was that, using Theorem 8.4, we can reduce
our goal - which was to show that $\psi^{j}\left(  xy\right)  =\psi^{j}\left(
x\right)  \cdot\psi^{j}\left(  y\right)  $ for any $x\in K$ and $y\in K$ - to
a simpler goal - namely, to prove that \textit{under the additional condition}
that each of $x$ and $y$ is the sum of finitely many $1$-dimensional elements
of $K$, we have $\psi^{j}\left(  xy\right)  =\psi^{j}\left(  x\right)
\cdot\psi^{j}\left(  y\right)  $. In other words, when proving the equality
$\psi^{j}\left(  xy\right)  =\psi^{j}\left(  x\right)  \cdot\psi^{j}\left(
y\right)  $, we could WLOG assume that each of $x$ and $y$ is the sum of
finitely many $1$-dimensional elements of $K$. Under this assumption, the
equality $\psi^{j}\left(  xy\right)  =\psi^{j}\left(  x\right)  \cdot\psi
^{j}\left(  y\right)  $ was an easy consequence of Theorem 9.4. This way, we
have proven (\ref{9.3.4}). Similarly, we can show (\ref{9.3.2}).

Again, for every $i\in\mathbb{N}$, we can use the same tactic to show that
$\left(  \psi^{j}\circ\lambda^{i}\right)  \left(  x\right)  =\left(
\lambda^{i}\circ\psi^{j}\right)  \left(  x\right)  $ for every $x\in K$
(namely, we use Theorem 8.4 to reduce the proof to the case when $x$ is the
sum of finitely many $1$-dimensional elements of $K$, and we apply Theorems
9.4, 8.5 and 8.3 \textbf{(b)} to verify it in this case). Hence, $\psi
^{j}\circ\lambda^{i}=\lambda^{i}\circ\psi^{j}$ for every $i\in\mathbb{N}$, and
thus $\psi^{j}$ is a $\lambda$-ring homomorphism. Theorem 9.3 \textbf{(b)} is proven.

\textbf{(c)} Fix $i\in\mathbb{N}\setminus\left\{  0\right\}  $ and
$j\in\mathbb{N}\setminus\left\{  0\right\}  $. We have to prove that $\psi
^{i}\circ\psi^{j}=\psi^{j}\circ\psi^{i}=\psi^{ij}$. In other words, we have to
prove that $\left(  \psi^{i}\circ\psi^{j}\right)  \left(  x\right)  =\left(
\psi^{j}\circ\psi^{i}\right)  \left(  x\right)  =\psi^{ij}\left(  x\right)  $
for every $x\in K$. This can be done by the same method as in the proof of
part \textbf{(b)}: First, reduce the proof to the case when $x$ is the sum of
finitely many $1$-dimensional elements of $K$ (by an application of Theorem
8.4); then, verify $\left(  \psi^{i}\circ\psi^{j}\right)  \left(  x\right)
=\left(  \psi^{j}\circ\psi^{i}\right)  \left(  x\right)  =\psi^{ij}\left(
x\right)  $ in this case by applying Theorems 9.4 and 8.3 \textbf{(b)}. Thus,
Theorem 9.3 \textbf{(c)} is proven.

\subsection{The equality $\protect\widetilde{\psi}_{T}\left(  x\right)
=-T\cdot\frac{d}{dT}\log\lambda_{-T}\left(  x\right)  $ for arbitrary
$\lambda$-rings}

Now, as promised, we are going to prove a generalization of Theorem 9.2 to
arbitrary $\lambda$-rings:

\begin{quote}
\textbf{Theorem 9.5.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring.

Define a map $\widetilde{\psi}_{T}:K\rightarrow K\left[  \left[  T\right]
\right]  $ by $\widetilde{\psi}_{T}\left(  x\right)  =\sum\limits_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}$ for
every $x\in K$.\ \ \ \ \footnote{Note that we call this map $\widetilde{\psi
}_{T}$ to distinguish it from the map $\psi_{T}$ in [1] (which is more or less
the same but differs slightly).}

Let $x\in K$.

\textbf{(a)} We have%
\[
\psi^{j}\left(  x\right)  =\left(  -1\right)  ^{j+1}\sum_{i=0}^{j}i\lambda
^{i}\left(  x\right)  \lambda^{j-i}\left(  -x\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\mathbb{N}\setminus\left\{
0\right\}  \text{.}%
\]


\textbf{(b)} We have $\widetilde{\psi}_{T}\left(  x\right)  =-T\cdot\dfrac
{d}{dT}\log\lambda_{-T}\left(  x\right)  $. Here, for every power series
$u\in1+K\left[  \left[  T\right]  \right]  ^{+}$, the \textit{logarithmic
derivative} $\dfrac{d}{dT}\log u$ of $u$ is defined by $\dfrac{d}{dT}\log
u=\dfrac{\dfrac{d}{dT}u}{u}$ (this definition works even in the cases where
the logarithm doesn't exist, such as rings of positive characteristic), and
$\lambda_{-T}\left(  x\right)  $ denotes $\operatorname*{ev}_{-T}\left(
\lambda_{T}\left(  x\right)  \right)  $.
\end{quote}

Before we prove this, let us show a lemma about symmetric polynomials first -
a kind of continuation of Theorem 9.1:

\begin{quote}
\textbf{Theorem 9.6.} Let $m\in\mathbb{N}$. Let us recall that, for every
$j\in\mathbb{N}\setminus\left\{  0\right\}  $, we denote by $N_{j}$ the $j$-th
Hirzebruch-Newton polynomial (defined at the beginning of Section 9). Let us
also recall that for every $i\in\mathbb{N}$, we denote by $X_{i}$ the $i$-th
elementary symmetric polynomial in the polynomial ring $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $.

Then, every $n\in\mathbb{N}$ satisfies%
\[
nX_{n}=\sum_{j=1}^{n}\left(  -1\right)  ^{j-1}X_{n-j}N_{j}\left(  X_{1}%
,X_{2},...,X_{j}\right)
\]
in the ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $.
\end{quote}

This theorem is more or less a rewriting of the famous \textit{Newton
identities}.

\textit{Proof of Theorem 9.6.} In the power series ring $\left(
\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \left[
T\right]  \right]  $, we have%
\begin{align}
\prod\limits_{i=1}^{m}\left(  1-U_{i}T\right)   &  =\sum_{i\in\mathbb{N}%
}\left(  -1\right)  ^{i}\underbrace{\sum_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}%
}_{=X_{i}}T^{i}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Exercise 4.2 \textbf{(c)}, applied to }A=\left(  \mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \left[  T\right]  \right]
\text{,}\\
\alpha_{i}=U_{i}\text{ and }t=T
\end{array}
\right) \nonumber\\
&  =\sum_{i\in\mathbb{N}}\left(  -1\right)  ^{i}X_{i}T^{i}. \label{9.6.pf0}%
\end{align}


But the product rule for several factors says that whenever $\alpha_{1}$,
$\alpha_{2}$, $...$, $\alpha_{m}$ are power series in $\mathbb{K}\left[
\left[  T\right]  \right]  $ (where $\mathbb{K}$ is a commutative ring), we
have%
\[
\dfrac{d}{dT}\prod\limits_{i=1}^{m}\alpha_{i}=\sum_{j=1}^{m}\left(  \dfrac
{d}{dT}\alpha_{j}\right)  \prod_{\substack{i\in\left\{  1,2,...,m\right\}
;\\i\neq j}}\alpha_{i}.
\]
Applying this to the power series $\alpha_{i}=1-U_{i}T$, we obtain%
\begin{align*}
\dfrac{d}{dT}\prod\limits_{i=1}^{m}\left(  1-U_{i}T\right)   &  =\sum
_{j=1}^{m}\underbrace{\left(  \dfrac{d}{dT}\left(  1-U_{j}T\right)  \right)
}_{=-U_{j}=-\dfrac{U_{j}}{1-U_{j}T}\left(  1-U_{j}T\right)  }\prod
_{\substack{i\in\left\{  1,2,...,m\right\}  ;\\i\neq j}}\left(  1-U_{i}%
T\right) \\
&  =\sum_{j=1}^{m}\left(  -\dfrac{U_{j}}{1-U_{j}T}\left(  1-U_{j}T\right)
\right)  \prod_{\substack{i\in\left\{  1,2,...,m\right\}  ;\\i\neq j}}\left(
1-U_{i}T\right) \\
&  =-\sum_{j=1}^{m}\dfrac{U_{j}}{1-U_{j}T}\underbrace{\left(  1-U_{j}T\right)
\prod_{\substack{i\in\left\{  1,2,...,m\right\}  ;\\i\neq j}}\left(
1-U_{i}T\right)  }_{=\prod\limits_{i\in\left\{  1,2,...,m\right\}  }\left(
1-U_{i}T\right)  }\\
&  =-\sum_{j=1}^{m}\dfrac{U_{j}}{1-U_{j}T}\prod\limits_{i\in\left\{
1,2,...,m\right\}  }\left(  1-U_{i}T\right)  =-\sum\limits_{i=1}^{m}%
\dfrac{U_{i}}{1-U_{i}T}\prod\limits_{i\in\left\{  1,2,...,m\right\}  }\left(
1-U_{i}T\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we renamed }j\text{ as }i\text{ in
the first sum}\right)  .
\end{align*}
Since%
\begin{align*}
&  \dfrac{d}{dT}\prod\limits_{i=1}^{m}\left(  1-U_{i}T\right) \\
&  =\dfrac{d}{dT}\sum_{i\in\mathbb{N}}\left(  -1\right)  ^{i}X_{i}%
T^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{9.6.pf0})}\right) \\
&  =\sum_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\left(  -1\right)
^{i}X_{i}iT^{i-1}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the
derivative of a power series}\right)  ,
\end{align*}
this rewrites as%
\begin{equation}
\sum_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\left(  -1\right)  ^{i}%
X_{i}iT^{i-1}=-\sum\limits_{i=1}^{m}\dfrac{U_{i}}{1-U_{i}T}\prod
\limits_{i\in\left\{  1,2,...,m\right\}  }\left(  1-U_{i}T\right)  .
\label{9.6.pf2}%
\end{equation}
Now,%
\begin{align*}
\sum_{n\in\mathbb{N}}\left(  -1\right)  ^{n}nX_{n}T^{n}  &  =\sum
_{n\in\mathbb{N}}\left(  -1\right)  ^{n}X_{n}nT^{n}=\sum_{n\in\mathbb{N}%
\setminus\left\{  0\right\}  }\left(  -1\right)  ^{n}X_{n}nT^{n}%
+\underbrace{\left(  -1\right)  ^{0}X_{0}0T^{0}}_{=0}\\
&  =\sum_{n\in\mathbb{N}\setminus\left\{  0\right\}  }\left(  -1\right)
^{n}X_{n}nT^{n}=\sum_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\left(
-1\right)  ^{i}X_{i}i\underbrace{T^{i}}_{=TT^{i-1}}\ \ \ \ \ \ \ \ \ \ \left(
\text{here, we renamed }n\text{ as }i\right) \\
&  =T\underbrace{\sum_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\left(
-1\right)  ^{i}X_{i}iT^{i-1}}_{\substack{=-\sum\limits_{i=1}^{m}\dfrac{U_{i}%
}{1-U_{i}T}\prod\limits_{i\in\left\{  1,2,...,m\right\}  }\left(
1-U_{i}T\right)  \\\text{(by (\ref{9.6.pf2}))}}}=-T\sum\limits_{i=1}^{m}%
\dfrac{U_{i}}{1-U_{i}T}\prod\limits_{i\in\left\{  1,2,...,m\right\}  }\left(
1-U_{i}T\right) \\
&  =-\underbrace{\left(  T\sum\limits_{i=1}^{m}\dfrac{U_{i}}{1-U_{i}T}\right)
}_{\substack{=\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }%
N_{j}\left(  X_{1},X_{2},...,X_{j}\right)  T^{j}\\\text{(by (\ref{Nj2}))}%
}}\underbrace{\left(  \prod\limits_{i\in\left\{  1,2,...,m\right\}  }\left(
1-U_{i}T\right)  \right)  }_{\substack{=\sum\limits_{i\in\mathbb{N}}\left(
-1\right)  ^{i}X_{i}T^{i}\\\text{(by (\ref{9.6.pf0}))}}}\\
&  =-\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }N_{j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}\cdot\sum\limits_{i\in\mathbb{N}}\left(
-1\right)  ^{i}X_{i}T^{i}\\
&  =\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }N_{j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}\cdot\sum\limits_{i\in\mathbb{N}}\left(
-\left(  -1\right)  ^{i}\right)  X_{i}T^{i}\\
&  =\sum_{n\in\mathbb{N}}\left(  \sum_{j=1}^{n}N_{j}\left(  X_{1}%
,X_{2},...,X_{j}\right)  \left(  -\left(  -1\right)  ^{n-j}\right)
X_{n-j}\right)  T^{n}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the product of two
formal power series}\right)  .
\end{align*}
Comparing the coefficients before $T^{n}$ on the two sides of this equation,
we obtain%
\[
\left(  -1\right)  ^{n}nX_{n}=\sum_{j=1}^{n}N_{j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \left(  -\left(  -1\right)  ^{n-j}\right)  X_{n-j}%
\]
for every $n\in\mathbb{N}$. Dividing this equation by $\left(  -1\right)
^{n}$, we arrive at%
\begin{align*}
nX_{n}  &  =\sum_{j=1}^{n}N_{j}\left(  X_{1},X_{2},...,X_{j}\right)
\underbrace{\dfrac{-\left(  -1\right)  ^{n-j}}{\left(  -1\right)  ^{n}}%
}_{\substack{=-\left(  -1\right)  ^{\left(  n-j\right)  -n}=-\left(
-1\right)  ^{-j}\\=-\left(  \dfrac{1}{-1}\right)  ^{j}=-\left(  -1\right)
^{j}=\left(  -1\right)  ^{j-1}}}X_{n-j}\\
&  =\sum_{j=1}^{n}N_{j}\left(  X_{1},X_{2},...,X_{j}\right)  \left(
-1\right)  ^{j-1}X_{n-j}=\sum_{j=1}^{n}\left(  -1\right)  ^{j-1}X_{n-j}%
N_{j}\left(  X_{1},X_{2},...,X_{j}\right)  .
\end{align*}
This proves Theorem 9.6.

As a consequence of Theorem 9.6, we get the following fact (which can be used
as a recurrence equation to easily compute the Hirzebruch-Newton polynomials
$N_{j}$):

\begin{quote}
\textbf{Corollary 9.7.} Let us recall that, for every $j\in\mathbb{N}%
\setminus\left\{  0\right\}  $, we denote by $N_{j}$ the $j$-th
Hirzebruch-Newton polynomial (defined at the beginning of Section 9). Then,
every $n\in\mathbb{N}$ satisfies%
\[
n\alpha_{n}=\sum\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}\alpha_{n-j}%
N_{j}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j}\right)
\]
in the polynomial ring $\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{n}\right]  $. Here, $\alpha_{0}$ is to be understood as $1$.
\end{quote}

\textit{Proof of Corollary 9.7.} We WLOG assume that $n>0$ (since for $n=0$,
Corollary 9.7 is trivial).

Let $\mathfrak{Q}_{1}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{n}\right]  $ be the polynomial defined by $\mathfrak{Q}_{1}=n\alpha_{n}$.
Let $\mathfrak{Q}_{2}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{n}\right]  $ be the polynomial defined by $\mathfrak{Q}_{2}=\sum
\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}\alpha_{n-j}N_{j}\left(  \alpha
_{1},\alpha_{2},...,\alpha_{j}\right)  $. We are going to prove that
$\mathfrak{Q}_{1}=\mathfrak{Q}_{2}$.

Consider the ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{n}\right]  $ (the
polynomial ring in $n$ indeterminates $U_{1},$ $U_{2},$ $...,$ $U_{n}$ over
the ring $\mathbb{Z}$). For every $i\in\mathbb{N}$, let $X_{i}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,n\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ be the so-called $i$\textit{-th
elementary symmetric polynomial} in the variables $U_{1},$ $U_{2},$ $...,$
$U_{n}$. (In particular, $X_{0}=1$ and $X_{i}=0$ for every $i>n$.) Applying
Theorem 4.1 \textbf{(a)} to $K=\mathbb{Z}$, $m=n$ and $P=nX_{n}$, we conclude
that there exists one and only one polynomial $Q\in\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{n}\right]  $ such that $nX_{n}=Q\left(
X_{1},X_{2},...,X_{n}\right)  $. In particular, there exists \textit{at most
one} such polynomial $Q\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{n}\right]  $. Hence,
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{if }\mathfrak{Q}_{1}\in\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{n}\right]  \text{ and }\mathfrak{Q}_{2}\in\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{n}\right]  \text{ are two polynomials}\\
\text{such that }nX_{n}=\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{n}\right)
\text{ and }nX_{n}=\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{n}\right)
\text{,}\\
\text{then }\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
\end{array}
\right)  . \label{9.7.pf1}%
\end{equation}


Clearly, $\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{n}\right)  =nX_{n}$
(since $\mathfrak{Q}_{1}=n\alpha_{n}$). On the other hand,
\begin{align*}
\mathfrak{Q}_{2}  &  =\sum\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}%
\alpha_{n-j}N_{j}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j}\right) \\
&  =\sum\limits_{j=1}^{n-1}\left(  -1\right)  ^{j-1}\alpha_{n-j}N_{j}\left(
\alpha_{1},\alpha_{2},...,\alpha_{j}\right)  +\left(  -1\right)
^{n-1}\underbrace{\alpha_{n-n}}_{=\alpha_{0}=1}N_{n}\left(  \alpha_{1}%
,\alpha_{2},...,\alpha_{n}\right) \\
&  =\sum\limits_{j=1}^{n-1}\left(  -1\right)  ^{j-1}\alpha_{n-j}N_{j}\left(
\alpha_{1},\alpha_{2},...,\alpha_{j}\right)  +\left(  -1\right)  ^{n-1}%
1N_{n}\left(  \alpha_{1},\alpha_{2},...,\alpha_{n}\right)  ,
\end{align*}
so that%
\begin{align*}
\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{n}\right)   &  =\sum\limits_{j=1}%
^{n-1}\left(  -1\right)  ^{j-1}X_{n-j}N_{j}\left(  X_{1},X_{2},...,X_{j}%
\right)  +\left(  -1\right)  ^{n-1}\underbrace{1}_{=X_{0}=X_{n-n}}N_{n}\left(
X_{1},X_{2},...,X_{n}\right) \\
&  =\sum\limits_{j=1}^{n-1}\left(  -1\right)  ^{j-1}X_{n-j}N_{j}\left(
X_{1},X_{2},...,X_{j}\right)  +\left(  -1\right)  ^{n-1}X_{n-n}N_{n}\left(
X_{1},X_{2},...,X_{n}\right) \\
&  =\sum\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}X_{n-j}N_{j}\left(
X_{1},X_{2},...,X_{j}\right) \\
&  =nX_{n}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 9.6, applied to
}m=n\right)  .
\end{align*}
Hence, $\mathfrak{Q}_{1}=\mathfrak{Q}_{2}$ (due to (\ref{9.7.pf1})). Since
$\mathfrak{Q}_{1}=n\alpha_{n}$ and $\mathfrak{Q}_{2}=\sum\limits_{j=1}%
^{n}\left(  -1\right)  ^{j-1}\alpha_{n-j}N_{j}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right)  $, this rewrites as $n\alpha_{n}=\sum
\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}\alpha_{n-j}N_{j}\left(  \alpha
_{1},\alpha_{2},...,\alpha_{j}\right)  $. This proves Corollary 9.7.

\textit{Proof of Theorem 9.5.} \textit{1st step:} For any fixed $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and any
fixed $x\in K$, the assertions \textbf{(a)} and \textbf{(b)} are equivalent.

\textit{Proof.} This proof is exactly the same as the proof of the 1st step of
the proof of Theorem 9.2. (In fact, during the 1st step of the proof of
Theorem 9.2, we have never used the assumption that the $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is special.)

\textit{2nd step:} For any $\lambda$-ring $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ and any $x\in K$, we have%
\[
n\lambda^{n}\left(  x\right)  =\sum_{j=1}^{n}\left(  -1\right)  ^{j-1}%
\lambda^{n-j}\left(  x\right)  \psi^{j}\left(  x\right)
\]
for every $n\in\mathbb{N}$.

\textit{Proof.} Let $n\in\mathbb{N}$. Corollary 9.7 yields%
\begin{align*}
n\alpha_{n}  &  =\sum\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}\alpha
_{n-j}N_{j}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j}\right) \\
&  =\sum\limits_{j=1}^{n-1}\left(  -1\right)  ^{j-1}\alpha_{n-j}N_{j}\left(
\alpha_{1},\alpha_{2},...,\alpha_{j}\right)  +\left(  -1\right)
^{n-1}\underbrace{\alpha_{n-n}}_{=\alpha_{0}=1}N_{n}\left(  \alpha_{1}%
,\alpha_{2},...,\alpha_{n}\right) \\
&  =\sum\limits_{j=1}^{n-1}\left(  -1\right)  ^{j-1}\alpha_{n-j}N_{j}\left(
\alpha_{1},\alpha_{2},...,\alpha_{j}\right)  +\left(  -1\right)  ^{n-1}%
1N_{n}\left(  \alpha_{1},\alpha_{2},...,\alpha_{n}\right)  .
\end{align*}
This is a polynomial identity in $\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{n}\right]  $. Hence, we can apply this identity to
$\alpha_{1}=\lambda^{1}\left(  x\right)  $, $\alpha_{2}=\lambda^{2}\left(
x\right)  $, $...$, $\alpha_{n}=\lambda^{n}\left(  x\right)  $, and obtain%
\begin{align*}
n\lambda^{n}\left(  x\right)   &  =\sum_{j=1}^{n-1}\left(  -1\right)
^{j-1}\lambda^{n-j}\left(  x\right)  N_{j}\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ +\left(  -1\right)  ^{n-1}\underbrace{1}_{=\lambda
^{0}\left(  x\right)  =\lambda^{n-n}\left(  x\right)  }N_{n}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{n}\left(  x\right)  \right) \\
&  =\sum_{j=1}^{n-1}\left(  -1\right)  ^{j-1}\lambda^{n-j}\left(  x\right)
N_{j}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{j}\left(  x\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ +\left(  -1\right)  ^{n-1}\lambda^{n-n}\left(
x\right)  N_{n}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{n}\left(  x\right)  \right) \\
&  =\sum_{j=1}^{n}\left(  -1\right)  ^{j-1}\lambda^{n-j}\left(  x\right)
\underbrace{N_{j}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{j}\left(  x\right)  \right)  }_{=\psi^{j}\left(
x\right)  }\\
&  =\sum_{j=1}^{n}\left(  -1\right)  ^{j-1}\lambda^{n-j}\left(  x\right)
\psi^{j}\left(  x\right)  .
\end{align*}
This proves the 2nd step.

\textit{3rd step:} For any $\lambda$-ring $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ and any $x\in K$, we have%
\[
-T\cdot\dfrac{d}{dT}\lambda_{T}\left(  x\right)  =\lambda_{T}\left(  x\right)
\cdot\widetilde{\psi}_{-T}\left(  x\right)  ,
\]
where we denote the power series $\operatorname*{ev}\nolimits_{-T}\left(
\widetilde{\psi}_{T}\left(  x\right)  \right)  $ by $\widetilde{\psi}%
_{-T}\left(  x\right)  $.

\textit{Proof.} We have
\begin{align*}
\widetilde{\psi}_{-T}\left(  x\right)   &  =\operatorname*{ev}\nolimits_{-T}%
\left(  \widetilde{\psi}_{T}\left(  x\right)  \right)  =\operatorname*{ev}%
\nolimits_{-T}\left(  \sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}
}\psi^{j}\left(  x\right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\widetilde{\psi}_{T}\left(  x\right)  =\sum\limits_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}\right)
\\
&  =\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(
x\right)  \underbrace{\left(  -T\right)  ^{j}}_{=\left(  -1\right)  ^{j}T^{j}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\operatorname*{ev}%
\nolimits_{-T}\right) \\
&  =\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(
x\right)  \underbrace{\left(  -1\right)  ^{j}}_{=-\left(  -1\right)  ^{j-1}%
}T^{j}=-\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\psi
^{j}\left(  x\right)  \left(  -1\right)  ^{j-1}T^{j},
\end{align*}
so that%
\[
-\widetilde{\psi}_{-T}\left(  x\right)  =\sum\limits_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  \left(  -1\right)
^{j-1}T^{j}.
\]
Multiplying this formula with the equality $\lambda_{T}\left(  x\right)
=\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}$, we obtain%
\begin{align*}
\left(  -\widetilde{\psi}_{-T}\left(  x\right)  \right)  \cdot\lambda
_{T}\left(  x\right)   &  =\left(  \sum\limits_{j\in\mathbb{N}\setminus
\left\{  0\right\}  }\psi^{j}\left(  x\right)  \left(  -1\right)  ^{j-1}%
T^{j}\right)  \cdot\left(  \sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  T^{i}\right) \\
&  =\sum_{n\in\mathbb{N}}\left(  \sum_{j=1}^{n}\psi^{j}\left(  x\right)
\left(  -1\right)  ^{j-1}\lambda^{n-j}\left(  x\right)  \right)  T^{n}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the product of two
power series}\right) \\
&  =\sum_{n\in\mathbb{N}}\underbrace{\left(  \sum_{j=1}^{n}\left(  -1\right)
^{j-1}\lambda^{n-j}\left(  x\right)  \psi^{j}\left(  x\right)  \right)
}_{\substack{=n\lambda^{n}\left(  x\right)  \\\text{(by the 2nd step)}}%
}T^{n}=\sum_{n\in\mathbb{N}}n\lambda^{n}\left(  x\right)  T^{n}\\
&  =\sum_{n\in\mathbb{N}\setminus\left\{  0\right\}  }n\lambda^{n}\left(
x\right)  T^{n}+\underbrace{0\lambda^{0}\left(  x\right)  T^{0}}_{=0}%
=\sum_{n\in\mathbb{N}\setminus\left\{  0\right\}  }n\lambda^{n}\left(
x\right)  \underbrace{T^{n}}_{=TT^{n-1}}\\
&  =T\cdot\sum_{n\in\mathbb{N}\setminus\left\{  0\right\}  }n\lambda
^{n}\left(  x\right)  T^{n-1}.
\end{align*}
Now, $\lambda_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}}\lambda
^{i}\left(  x\right)  T^{i}=\sum\limits_{n\in\mathbb{N}}\lambda^{n}\left(
x\right)  T^{n}$, so that%
\begin{align*}
\dfrac{d}{dT}\lambda_{T}\left(  x\right)   &  =\dfrac{d}{dT}\sum
\limits_{n\in\mathbb{N}}\lambda^{n}\left(  x\right)  T^{n}=\sum_{n\in
\mathbb{N}\setminus\left\{  0\right\}  }n\lambda^{n}\left(  x\right)
T^{n-1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the derivative of a
formal power series}\right)  ,
\end{align*}
and thus%
\begin{align*}
-T\cdot\dfrac{d}{dT}\lambda_{T}\left(  x\right)   &  =-\underbrace{T\cdot
\sum_{n\in\mathbb{N}\setminus\left\{  0\right\}  }n\lambda^{n}\left(
x\right)  T^{n-1}}_{=\left(  -\widetilde{\psi}_{-T}\left(  x\right)  \right)
\cdot\lambda_{T}\left(  x\right)  }=-\left(  -\widetilde{\psi}_{-T}\left(
x\right)  \right)  \cdot\lambda_{T}\left(  x\right) \\
&  =\lambda_{T}\left(  x\right)  \cdot\widetilde{\psi}_{-T}\left(  x\right)  .
\end{align*}
This proves the 3rd step.

\textit{4th step:} For any fixed $\lambda$-ring $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ and any fixed $x\in K$, the assertion
\textbf{(b)} holds.

\textit{Proof.} By the 3rd step, we have
\[
-T\cdot\dfrac{d}{dT}\lambda_{T}\left(  x\right)  =\lambda_{T}\left(  x\right)
\cdot\widetilde{\psi}_{-T}\left(  x\right)  .
\]


Now, every formal power series $\alpha\in K\left[  \left[  T\right]  \right]
$ satisfies $\operatorname*{ev}\nolimits_{-T}\left(  \dfrac{d}{dT}%
\alpha\right)  =-\dfrac{d}{dT}\left(  \operatorname*{ev}\nolimits_{-T}%
\alpha\right)  $.\ \ \ \ \footnote{\textit{Proof.} Let $\alpha\in K\left[
\left[  T\right]  \right]  $ be a formal power series. Write $\alpha$ in the
form $\sum\limits_{i\in\mathbb{N}}\alpha_{i}T^{i}$ with $\alpha_{i}\in K$ for
every $i\in\mathbb{N}$. Then, $\operatorname*{ev}\nolimits_{-T}\alpha
=\operatorname*{ev}\nolimits_{-T}\left(  \sum\limits_{i\in\mathbb{N}}%
\alpha_{i}T^{i}\right)  =\sum\limits_{i\in\mathbb{N}}\alpha_{i}\left(
-1\right)  ^{i}T^{i}$ (by the definition of $\operatorname*{ev}\nolimits_{-T}%
$), so that%
\begin{align*}
\dfrac{d}{dT}\left(  \operatorname*{ev}\nolimits_{-T}\alpha\right)   &
=\dfrac{d}{dT}\sum\limits_{i\in\mathbb{N}}\alpha_{i}\left(  -1\right)
^{i}T^{i}=\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\alpha
_{i}\left(  -1\right)  ^{i}iT^{i-1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the derivative of a
formal power series}\right)  .
\end{align*}
\par
On the other hand, $\alpha=\sum\limits_{i\in\mathbb{N}}\alpha_{i}T^{i}$, so
that%
\begin{align*}
\dfrac{d}{dT}\alpha &  =\dfrac{d}{dT}\sum\limits_{i\in\mathbb{N}}\alpha
_{i}T^{i}=\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\alpha
_{i}iT^{i-1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the derivative of a
formal power series}\right) \\
&  =\sum\limits_{i\in\mathbb{N}}\alpha_{i+1}\left(  i+1\right)  T^{i}%
\end{align*}
(here we substituted $i$ for $i-1$). Thus,%
\begin{align*}
\operatorname*{ev}\nolimits_{-T}\left(  \dfrac{d}{dT}\alpha\right)   &
=\operatorname*{ev}\nolimits_{-T}\left(  \sum\limits_{i\in\mathbb{N}}%
\alpha_{i+1}\left(  i+1\right)  T^{i}\right)  =\sum\limits_{i\in\mathbb{N}%
}\alpha_{i+1}\left(  i+1\right)  \left(  -1\right)  ^{i}T^{i}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\operatorname*{ev}%
\nolimits_{-T}\right) \\
&  =\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\alpha
_{i}i\underbrace{\left(  -1\right)  ^{i-1}}_{=-\left(  -1\right)  ^{i}}%
T^{i-1}\ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }i\text{ for
}i+1\right) \\
&  =-\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\alpha
_{i}\underbrace{i\left(  -1\right)  ^{i}}_{=\left(  -1\right)  ^{i}i}%
T^{i-1}=-\underbrace{\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}
}\alpha_{i}\left(  -1\right)  ^{i}iT^{i-1}}_{=\dfrac{d}{dT}\left(
\operatorname*{ev}\nolimits_{-T}\alpha\right)  }=-\dfrac{d}{dT}\left(
\operatorname*{ev}\nolimits_{-T}\alpha\right)  ,
\end{align*}
qed.} Applied to $\alpha=\lambda_{T}\left(  x\right)  $, this yields
$\operatorname*{ev}\nolimits_{-T}\left(  \dfrac{d}{dT}\lambda_{T}\left(
x\right)  \right)  =-\dfrac{d}{dT}\left(  \operatorname*{ev}\nolimits_{-T}%
\left(  \lambda_{T}\left(  x\right)  \right)  \right)  $. Since
$\operatorname*{ev}\nolimits_{-T}\left(  \lambda_{T}\left(  x\right)  \right)
=\lambda_{-T}\left(  x\right)  $, this rewrites as $\operatorname*{ev}%
\nolimits_{-T}\left(  \dfrac{d}{dT}\lambda_{T}\left(  x\right)  \right)
=-\dfrac{d}{dT}\lambda_{-T}\left(  x\right)  $. On the other hand, every
formal power series $\alpha\in K\left[  \left[  T\right]  \right]  $ satisfies
$\operatorname*{ev}\nolimits_{-T}\left(  \operatorname*{ev}\nolimits_{-T}%
\alpha\right)  =\alpha$.\ \ \ \ \footnote{\textit{Proof.} Let $\alpha\in
K\left[  \left[  T\right]  \right]  $ be a formal power series. Write $\alpha$
in the form $\sum\limits_{i\in\mathbb{N}}\alpha_{i}T^{i}$ with $\alpha_{i}\in
K$ for every $i\in\mathbb{N}$. Then, $\operatorname*{ev}\nolimits_{-T}%
\alpha=\operatorname*{ev}\nolimits_{-T}\left(  \sum\limits_{i\in\mathbb{N}%
}\alpha_{i}T^{i}\right)  =\sum\limits_{i\in\mathbb{N}}\alpha_{i}\left(
-1\right)  ^{i}T^{i}$ (by the definition of $\operatorname*{ev}\nolimits_{-T}%
$), so that%
\begin{align*}
\operatorname*{ev}\nolimits_{-T}\left(  \operatorname*{ev}\nolimits_{-T}%
\alpha\right)   &  =\operatorname*{ev}\nolimits_{-T}\left(  \sum
\limits_{i\in\mathbb{N}}\alpha_{i}\left(  -1\right)  ^{i}T^{i}\right)
=\sum\limits_{i\in\mathbb{N}}\alpha_{i}\underbrace{\left(  -1\right)
^{i}\left(  -1\right)  ^{i}}_{=1}T^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the
definition of }\operatorname*{ev}\nolimits_{-T}\right) \\
&  =\sum\limits_{i\in\mathbb{N}}\alpha_{i}T^{i}=\alpha,
\end{align*}
qed.} Applied to $\alpha=\widetilde{\psi}_{T}\left(  x\right)  $, this yields
$\operatorname*{ev}\nolimits_{-T}\left(  \operatorname*{ev}\nolimits_{-T}%
\left(  \widetilde{\psi}_{T}\left(  x\right)  \right)  \right)
=\widetilde{\psi}_{T}\left(  x\right)  $. Since $\operatorname*{ev}%
\nolimits_{-T}\left(  \widetilde{\psi}_{T}\left(  x\right)  \right)
=\widetilde{\psi}_{-T}\left(  x\right)  $, this becomes $\operatorname*{ev}%
\nolimits_{-T}\left(  \widetilde{\psi}_{-T}\left(  x\right)  \right)
=\widetilde{\psi}_{T}\left(  x\right)  $.

Now,%
\begin{align*}
\operatorname*{ev}\nolimits_{-T}\left(  -T\cdot\dfrac{d}{dT}\lambda_{T}\left(
x\right)  \right)   &  =-\underbrace{\operatorname*{ev}\nolimits_{-T}\left(
T\right)  }_{=-T}\cdot\underbrace{\operatorname*{ev}\nolimits_{-T}\left(
\dfrac{d}{dT}\lambda_{T}\left(  x\right)  \right)  }_{=-\dfrac{d}{dT}%
\lambda_{-T}\left(  x\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\operatorname*{ev}\nolimits_{-T}%
\text{ is a }K\text{-algebra homomorphism}\right) \\
&  =-T\cdot\dfrac{d}{dT}\lambda_{-T}\left(  x\right)
\end{align*}
and%
\begin{align*}
\operatorname*{ev}\nolimits_{-T}\left(  \lambda_{T}\left(  x\right)
\cdot\widetilde{\psi}_{-T}\left(  x\right)  \right)   &
=\underbrace{\operatorname*{ev}\nolimits_{-T}\left(  \lambda_{T}\left(
x\right)  \right)  }_{=\lambda_{-T}\left(  x\right)  }\cdot
\underbrace{\operatorname*{ev}\nolimits_{-T}\left(  \widetilde{\psi}%
_{-T}\left(  x\right)  \right)  }_{=\widetilde{\psi}_{T}\left(  x\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\operatorname*{ev}\nolimits_{-T}%
\text{ is a }K\text{-algebra homomorphism}\right) \\
&  =\lambda_{-T}\left(  x\right)  \cdot\widetilde{\psi}_{T}\left(  x\right)  .
\end{align*}
Hence,%
\[
-T\cdot\dfrac{d}{dT}\lambda_{-T}\left(  x\right)  =\operatorname*{ev}%
\nolimits_{-T}\left(  \underbrace{-T\cdot\dfrac{d}{dT}\lambda_{T}\left(
x\right)  }_{=\lambda_{T}\left(  x\right)  \cdot\widetilde{\psi}_{-T}\left(
x\right)  }\right)  =\operatorname*{ev}\nolimits_{-T}\left(  \lambda
_{T}\left(  x\right)  \cdot\widetilde{\psi}_{-T}\left(  x\right)  \right)
=\lambda_{-T}\left(  x\right)  \cdot\widetilde{\psi}_{T}\left(  x\right)  ,
\]
so that%
\[
\widetilde{\psi}_{T}\left(  x\right)  =\dfrac{-T\cdot\dfrac{d}{dT}\lambda
_{-T}\left(  x\right)  }{\lambda_{-T}\left(  x\right)  }=-T\cdot
\underbrace{\dfrac{\dfrac{d}{dT}\lambda_{-T}\left(  x\right)  }{\lambda
_{-T}\left(  x\right)  }}_{=\dfrac{d}{dT}\log\lambda_{-T}\left(  x\right)
}=-T\cdot\dfrac{d}{dT}\log\lambda_{-T}\left(  x\right)  .
\]
Hence, assertion \textbf{(b)} holds. This completes the proof of the 4th step.

\textit{5th step:} For any fixed $\lambda$-ring $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ and any fixed $x\in K$, the assertion
\textbf{(a)} holds.

\textit{Proof.} This follows from the 4th step, since \textbf{(a)} and
\textbf{(b)} are equivalent (by the 1st step).

Thus, the proof of Theorem 9.5 is complete.

Theorem 9.5 is clearly a generalization of Theorem 9.2, and thus our above
proof of Theorem 9.5 is, at the same time, a new proof of Theorem 9.2.

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 9.1.} Let $K$ be a ring. Let $u\in1+K\left[  T\right]  ^{+}$.
For every $j\in\mathbb{N}\setminus\left\{  0\right\}  $, let us denote by
$\widehat{\psi}^{j}$ the $j$-th Adams operation of the $\lambda$-ring $\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  $.

Assume that $u=\Pi\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}%
\right]  \right)  $ for some $\left(  \widetilde{K}_{u},\left[  u_{1}%
,u_{2},...,u_{m}\right]  \right)  \in K^{\operatorname*{int}}$. Let
$j\in\mathbb{N}\setminus\left\{  0\right\}  $. Then, $\widehat{\psi}%
^{j}\left(  u\right)  =\Pi\left(  \widetilde{K}_{u},\left[  u_{1}^{j}%
,u_{2}^{j},...,u_{m}^{j}\right]  \right)  $.

[This gives a formula for $\widehat{\psi}^{j}$ similar to the formula for
$\widehat{\lambda}^{j}$ given in Theorem 5.3 \textbf{(d)}.]

\textit{Exercise 9.2.} Let $K$ be a ring. Let $i\in\mathbb{N}\setminus\left\{
0\right\}  $. Define a mapping $\operatorname*{Coeff}\nolimits_{i}:K\left[
\left[  T\right]  \right]  \rightarrow K$ by setting $\operatorname*{Coeff}%
\nolimits_{i}\left(  \sum\limits_{j\in\mathbb{N}}a_{j}T^{j}\right)  =a_{i}$
for every $\sum\limits_{j\in\mathbb{N}}a_{j}T^{j}\in K\left[  \left[
T\right]  \right]  $ (with $a_{j}\in K$ for every $j\in\mathbb{N}$). (In other
words, $\operatorname*{Coeff}\nolimits_{i}$ is the mapping that takes a power
series and returns its coefficient before $T^{i}$.)\ \ \ \ \ \footnote{Note
that we are denoting this mapping by $\operatorname*{Coeff}\nolimits_{i}$ with
a capital "C" to distinguish it from the mapping $\operatorname*{coeff}%
\nolimits_{i}$ defined in Exercise 6.5. This distinction is necessary because
these two mappings have different domains (namely, the map
$\operatorname*{Coeff}\nolimits_{i}$ is defined on all of $K\left[  \left[
T\right]  \right]  $, whereas the map $\operatorname*{coeff}\nolimits_{i}$ is
defined only on $\Lambda\left(  K\right)  $).}

\textbf{(a)} Prove that the map%
\begin{align*}
\Lambda\left(  K\right)   &  \rightarrow K,\\
u  &  \mapsto\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(
-T\dfrac{d}{dT}\log u\right)
\end{align*}
is a ring homomorphism.

\textbf{(b)} This fact, combined with Theorem 9.2 \textbf{(b)}, can be used to
give a new proof of a part of Theorem 9.3 \textbf{(b)}. Which part, and how?

\textit{Exercise 9.3.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring.

\textbf{(a)} Prove that%
\[
n\lambda^{n}\left(  x\right)  =\sum_{i=1}^{n}\left(  -1\right)  ^{i-1}%
\lambda^{n-i}\left(  x\right)  \psi^{i}\left(  x\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }x\in K\text{ and }n\in\mathbb{N}\text{.}%
\]


\textbf{(b)} Let $x\in K$ and $n\in\mathbb{N}$. Let $A_{n}=\left(
a_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq n}\in K^{n\times n}$ be the
matrix defined by%
\[
a_{i,j}=\left\{
\begin{array}
[c]{c}%
\psi^{i-j+1}\left(  x\right)  ,\text{ if }i\geq j;\\
i,\text{ if }i=j-1;\\
0,\text{ if }i<j-1
\end{array}
\right.  .
\]
Prove that $n!\lambda^{n}\left(  x\right)  =\det A_{n}$.

[The matrix $A_{n}$ has the following form:%
\[
A_{n}=\left(
\begin{array}
[c]{cccccc}%
\psi^{1}\left(  x\right)  & 1 & 0 & \cdots & 0 & 0\\
\psi^{2}\left(  x\right)  & \psi^{1}\left(  x\right)  & 2 & \cdots & 0 & 0\\
\psi^{3}\left(  x\right)  & \psi^{2}\left(  x\right)  & \psi^{1}\left(
x\right)  & \cdots & 0 & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
\psi^{n-1}\left(  x\right)  & \psi^{n-2}\left(  x\right)  & \psi^{n-3}\left(
x\right)  & \cdots & \psi^{1}\left(  x\right)  & n-1\\
\psi^{n}\left(  x\right)  & \psi^{n-1}\left(  x\right)  & \psi^{n-2}\left(
x\right)  & \cdots & \psi^{2}\left(  x\right)  & \psi^{1}\left(  x\right)
\end{array}
\right)  .
\]
]

\textbf{(c)} Let $x\in K$ and $n\in\mathbb{N}$. Let $B_{n}=\left(
b_{i,j}\right)  _{1\leq i\leq n,\ 1\leq j\leq n}\in K^{n\times n}$ be the
matrix defined by%
\[
b_{i,j}=\left\{
\begin{array}
[c]{c}%
i\lambda^{i}\left(  x\right)  ,\text{ if }j=1;\\
\lambda^{i-j+1}\left(  x\right)  ,\text{ if }i\geq j>1;\\
1,\text{ if }i=j-1;\\
0,\text{ if }i<j-1
\end{array}
\right.  .
\]
Prove that $\psi^{n}\left(  x\right)  =\det B_{n}$, where we define $\psi
^{0}\left(  x\right)  $ to mean $1$.

[The matrix $B_{n}$ has the following form:%
\[
B_{n}=\left(
\begin{array}
[c]{cccccc}%
\lambda^{1}\left(  x\right)  & 1 & 0 & \cdots & 0 & 0\\
2\lambda^{2}\left(  x\right)  & \lambda^{1}\left(  x\right)  & 1 & \cdots &
0 & 0\\
3\lambda^{3}\left(  x\right)  & \lambda^{2}\left(  x\right)  & \lambda
^{1}\left(  x\right)  & \cdots & 0 & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
\left(  n-1\right)  \lambda^{n-1}\left(  x\right)  & \lambda^{n-2}\left(
x\right)  & \lambda^{n-3}\left(  x\right)  & \cdots & \lambda^{1}\left(
x\right)  & 1\\
n\lambda^{n}\left(  x\right)  & \lambda^{n-1}\left(  x\right)  & \lambda
^{n-2}\left(  x\right)  & \cdots & \lambda^{2}\left(  x\right)  & \lambda
^{1}\left(  x\right)
\end{array}
\right)  .
\]
]

\textit{Exercise 9.4.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a binomial $\lambda$-ring. Prove that $\psi
^{n}=\operatorname*{id}$ for every $n\in\mathbb{N}\setminus\left\{  0\right\}
$.

[Note that, if we recall the definition of a binomial $\lambda$-ring and
Exercise 9.3 \textbf{(c)}, then we could reformulate this result without
reference to $\lambda$-rings.]

\textit{Exercise 9.5.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a (not necessarily special) $\lambda$-ring.
Prove that $\psi^{j}:K\rightarrow K$ is a homomorphism of additive groups for
every $j\in\mathbb{N}\setminus\left\{  0\right\}  $.

[This shows that at least part of Theorem 9.3 \textbf{(b)} does not require
the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ to be special.]

\textit{Exercise 9.6.} In this exercise, we are going to view $\mathbb{Z}%
\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $ as a subring of
$\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{n}\right]  $ for any two
$m\in\mathbb{N}$ and $n\in\mathbb{N}$ satisfying $m\leq n$. Thus, the
polynomial $N_{m}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{m}\right]  $ automatically becomes an element of $\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{n}\right]  $ whenever $1\leq m\leq n$.

\textbf{(a)} Prove that
\[
n\alpha_{n}=\sum_{i=1}^{n}\left(  -1\right)  ^{i-1}\alpha_{n-i}N_{i}\text{ in
}\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{n}\right]
\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{N}\text{.}%
\]
Here, $\alpha_{0}$ is to be understood as $1$.

\textbf{(b)} Let $n\in\mathbb{N}$. Let $A_{n}=\left(  a_{i,j}\right)  _{1\leq
i\leq n,\ 1\leq j\leq n}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{n}\right]  ^{n\times n}$ be the matrix defined by%
\[
a_{i,j}=\left\{
\begin{array}
[c]{c}%
N_{i-j+1},\text{ if }i\geq j;\\
i,\text{ if }i=j-1;\\
0,\text{ if }i<j-1
\end{array}
\right.  .
\]
Prove that $n!\alpha_{n}=\det A_{n}$.

[The matrix $A_{n}$ has the following form:%
\[
A_{n}=\left(
\begin{array}
[c]{cccccc}%
N_{1} & 1 & 0 & \cdots & 0 & 0\\
N_{2} & N_{1} & 2 & \cdots & 0 & 0\\
N_{3} & N_{2} & N_{1} & \cdots & 0 & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
N_{n-1} & N_{n-2} & N_{n-3} & \cdots & N_{1} & n-1\\
N_{n} & N_{n-1} & N_{n-2} & \cdots & N_{2} & N_{1}%
\end{array}
\right)  .
\]
]

\textbf{(c)} Let $n\in\mathbb{N}$. Let $B_{n}=\left(  b_{i,j}\right)  _{1\leq
i\leq n,\ 1\leq j\leq n}\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{n}\right]  ^{n\times n}$ be the matrix defined by%
\[
b_{i,j}=\left\{
\begin{array}
[c]{c}%
i\alpha_{i},\text{ if }j=1;\\
\alpha_{i-j+1},\text{ if }i\geq j>1;\\
1,\text{ if }i=j-1;\\
0,\text{ if }i<j-1
\end{array}
\right.  .
\]
Prove that $N_{n}=\det B_{n}$, where we define $N_{0}$ to mean $1$.

[The matrix $B_{n}$ has the following form:%
\[
B_{n}=\left(
\begin{array}
[c]{cccccc}%
\alpha_{1} & 1 & 0 & \cdots & 0 & 0\\
2\alpha_{2} & \alpha_{1} & 1 & \cdots & 0 & 0\\
3\alpha_{3} & \alpha_{2} & \alpha_{1} & \cdots & 0 & 0\\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots\\
\left(  n-1\right)  \alpha_{n-1} & \alpha_{n-2} & \alpha_{n-3} & \cdots &
\alpha_{1} & 1\\
n\alpha_{n} & \alpha_{n-1} & \alpha_{n-2} & \cdots & \alpha_{2} & \alpha_{1}%
\end{array}
\right)  .
\]
]

\textbf{(d)} Derive the results of Exercise 9.3 from Exercise 9.6
\textbf{(a)}, \textbf{(b)}, \textbf{(c)}.

\textit{Exercise 9.7.} Let $p$ be a prime number. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a (not necessarily special)
$\lambda$-ring. Prove that $\psi^{p}\left(  x\right)  \equiv x^{p}%
\operatorname{mod}pK$ for every $x\in K$.

\bigskip
\end{quotation}

\section{Todd homomorphisms of power series}

We now devote a section to the notion of Todd homomorphisms. First, two warnings:

\begin{itemize}
\item \textbf{Warning:} The following may be wrong or differ from the standard
notations. I am trying to generalize [1], I \S 6 (mostly because it is
slightly flawed\footnote{[1], I \S 6, p. 24 states that $\operatorname*{td}%
_{\varphi}\left(  e\right)  $ is a universal polynomial in $\lambda^{1}\left(
e\right)  ,$ $...,$ $\lambda^{r}\left(  e\right)  $, determined by $\varphi$
alone. I think it isn't; instead, it is just a power series. On the other
hand, my generalization $\operatorname*{td}\nolimits_{\varphi,T}$ is a
universal polynomial.} and the generalization looks more natural to me), but I
cannot guarantee that this is the "right" generalization.

\item \textbf{Another warning:} In the following, we will often formulate
results over a ring which we will call $\mathbf{Z}$. The letter $\mathbf{Z}$
will denote any ring (commutative with unity, of course). Please don't confuse
it with the similarly-looking letter $\mathbb{Z}$, which always denote the
ring of integers. The reason why I chose the letter $\mathbf{Z}$ for the ring
is that in most applications the ring $\mathbf{Z}$ will indeed be the ring
$\mathbb{Z}$ of integers.
\end{itemize}

\subsection{The universal polynomials $\operatorname*{Td}\nolimits_{\varphi
,j}$}

We begin this section with a construction similar to the construction of the
Adams operations in Section 9. The goal of this construction is to find, for
every ring $\mathbf{Z}$ (in most cases, this ring will be the ring
$\mathbb{Z}$ of integers) and every power series $\varphi\in1+\mathbf{Z}%
\left[  \left[  t\right]  \right]  ^{+}$ with constant term equal to $1$, a
polynomial $\operatorname*{Td}_{\varphi,j}\in\mathbf{Z}\left[  \alpha
_{1},\alpha_{2},...,\alpha_{j}\right]  $ for every $j\in\mathbb{N}$ such that
\[
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  =\sum_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)
T^{j}%
\]
in the ring $\left(  \mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)
\left[  \left[  T\right]  \right]  $ for every $m\in\mathbb{N}$, where
$X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ as usual. To
achieve this goal, we must again work with symmetric polynomials. First a definition:

\begin{quote}
\textbf{Definition.} Let $R$ be any ring. Let $i\in\mathbb{N}$. Then, we
define a map $\operatorname*{Coeff}\nolimits_{i}:R\left[  \left[  T\right]
\right]  \rightarrow R$ (where $R\left[  \left[  T\right]  \right]  $ is, as
always, the $R$-algebra of all formal power series in the variable $T$ over
the ring $R$) by%
\[
\left(  \operatorname*{Coeff}\nolimits_{i}\left(  P\right)  =\left(  \text{the
coefficient of }P\text{ before }T^{i}\right)  \ \ \ \ \ \ \ \ \ \ \text{for
every power series }P\in R\left[  \left[  T\right]  \right]  \right)  .
\]


In other words, we define a map $\operatorname*{Coeff}\nolimits_{i}:R\left[
\left[  T\right]  \right]  \rightarrow R$ by%
\[
\left(  \operatorname*{Coeff}\nolimits_{i}\left(  \sum\limits_{j\in\mathbb{N}%
}a_{j}T^{j}\right)  =a_{i}\ \ \ \ \ \ \ \ \ \ \text{for every }\sum
\limits_{j\in\mathbb{N}}a_{j}T^{j}\in R\left[  \left[  T\right]  \right]
\text{ (with }a_{j}\in R\text{ for every }j\in\mathbb{N}\text{)}\right)  .
\]



\end{quote}

Two remarks about this definition:

\begin{itemize}
\item The definition of $\operatorname*{Coeff}\nolimits_{i}$ that we just gave
clearly extends the definition of $\operatorname*{Coeff}\nolimits_{i}$ given
in Exercise 9.2.

\item The only difference between the map $\operatorname*{Coeff}\nolimits_{i}$
just defined and the map $\operatorname*{coeff}\nolimits_{i}$ defined in
Exercise 6.5 is that they have different domains (namely, the map
$\operatorname*{Coeff}\nolimits_{i}$ is defined on all of $R\left[  \left[
T\right]  \right]  $, whereas the map $\operatorname*{coeff}\nolimits_{i}$ is
defined only on $\Lambda\left(  R\right)  $). This looks like a minor
difference, but is substantial enough to cause confusion if we neglect it! For
example, when we say that $\operatorname*{coeff}\nolimits_{i}$ is a
homomorphism of additive groups, we mean that it maps sums in $\Lambda\left(
R\right)  $ to sums in $R$; however, when we say that $\operatorname*{Coeff}%
\nolimits_{i}$ is a homomorphism of additive groups, we mean that it maps sums
in $R\left[  \left[  T\right]  \right]  $ to sums in $R$. These are two
completely different assertions, even though $\Lambda\left(  R\right)  $ is a
subset of $R\left[  \left[  T\right]  \right]  $ and the maps
$\operatorname*{coeff}\nolimits_{i}$ and $\operatorname*{Coeff}\nolimits_{i}$
are pointwise equal on this subset! (Actually, it is very easy to see that the
assertion that $\operatorname*{coeff}\nolimits_{i}$ is a homomorphism of
additive groups is completely different from the assertion that
$\operatorname*{Coeff}\nolimits_{i}$ is a homomorphism of additive groups. The
latter assertion holds for all $i\in\mathbb{N}$, whereas the former assertion
holds only for $i=1$ (in general).)

\item It is clear that for every ring $R$ and for every $i\in\mathbb{N}$, the
map $\operatorname*{Coeff}\nolimits_{i}:R\left[  \left[  T\right]  \right]
\rightarrow R$ is an additive group homomorphism. It is also clear that if two
power series $P\in R\left[  \left[  T\right]  \right]  $ and $Q\in R\left[
\left[  T\right]  \right]  $ satisfy $\left(  \operatorname*{Coeff}%
\nolimits_{i}\left(  P\right)  =\operatorname*{Coeff}\nolimits_{i}\left(
Q\right)  \text{ for all }i\in\mathbb{N}\right)  $, then $P=Q$.
\end{itemize}

Now let us define what we mean by $1+\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$:

\begin{quote}
\textbf{Definition.} Let $\mathbf{Z}$ be a ring. Consider the ring
$\mathbf{Z}\left[  \left[  t\right]  \right]  $ of formal power series in the
variable $t$ over $\mathbf{Z}$. Let $\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$ denote the subset%
\begin{align*}
t\mathbf{Z}\left[  \left[  t\right]  \right]   &  =\left\{  \sum
_{i\in\mathbb{N}}a_{i}t^{i}\in\mathbf{Z}\left[  \left[  t\right]  \right]
\ \mid\ a_{i}\in\mathbf{Z}\text{ for all }i,\text{ and }a_{0}=0\right\} \\
&  =\left\{  p\in\mathbf{Z}\left[  \left[  t\right]  \right]  \ \mid\ p\text{
is a power series with constant term }0\right\}
\end{align*}
of the ring $\mathbf{Z}\left[  \left[  t\right]  \right]  $. Note that
\begin{align*}
1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}  &  =\left\{  1+u\mid
u\in\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}\right\} \\
&  =\left\{  p\in\mathbf{Z}\left[  \left[  t\right]  \right]  \ \mid\ p\text{
is a power series with constant term }1\right\}  .
\end{align*}



\end{quote}

We notice that this is an exact copy of a definition we made in Section 5
(namely, of the definition of $K\left[  \left[  T\right]  \right]  ^{+}$),
with the only difference that the ring that used to be called $K$ in Section 5
is called $\mathbf{Z}$ here, and that the variable that used to be $T$ in
Section 5 is $t$ here.

Now to our universal polynomials:

\begin{quote}
\textbf{Definition.} Let $\mathbf{Z}$ be a ring. Let $\varphi\in
1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power series with
constant term equal to $1$. Our goal is to define a polynomial
$\operatorname*{Td}_{\varphi,j}\in\mathbf{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right]  $ for every $j\in\mathbb{N}$ such that%
\begin{equation}
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  =\sum_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)
T^{j} \label{Td1}%
\end{equation}
in the ring $\left(  \mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)
\left[  \left[  T\right]  \right]  $ for every $m\in\mathbb{N}$, where
$X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ is the $i$-th
elementary symmetric polynomial in the variables $U_{1},$ $U_{2},$ $...,$
$U_{m}$ for every $i\in\mathbb{N}$.

In order to do this, we first fix some $m\in\mathbb{N}$ and $j\in\mathbb{N}$.
Consider the polynomial $\operatorname*{Coeff}\nolimits_{j}\left(
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)  \in
\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ (this is the coefficient of
the power series $\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)
\in\left(  \mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[
\left[  T\right]  \right]  $ before $T^{j}$). This polynomial
$\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)  $ is symmetric. Thus, Theorem 4.1
\textbf{(a)} yields that there exists one and only one polynomial
$\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  }\in\mathbf{Z}%
\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $ such that
$\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)  =\operatorname*{Todd}\nolimits_{\left(
\varphi,j\right)  }\left(  X_{1},X_{2},...,X_{m}\right)  $. Since
$\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)  $ is a polynomial of total degree $\leq
j$ in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}\ \ \ \ $%
\footnote{\textit{Proof.} There are several ways to prove this; here is the
simplest one: We use the notion of an "equigraded" power series over a graded
ring; this notion was defined in [8]. Now let $A$ be the graded ring
$\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $, where the grading is given
by the total degree (thus $U_{1}$, $U_{2}$, $...$, $U_{m}$ all lie in the
$1$-st graded component $A_{1}$). According to Theorem 1 \textbf{(a)} of [8],
the set%
\[
\left\{  \alpha\in A\left[  \left[  T\right]  \right]  \ \mid\ \text{the power
series }\alpha\text{ is equigraded}\right\}
\]
is a sub-$A_{0}$-algebra of $A\left[  \left[  T\right]  \right]  $. Since the
power series $\varphi\left(  U_{1}T\right)  $, $\varphi\left(  U_{2}T\right)
$, $...$, $\varphi\left(  U_{m}T\right)  $ all lie in this set (because they
are equigraded - just look at them), it therefore follows that $\prod
\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  $ also lies in this set. In
other words, the power series $\prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  $ is equigraded. Hence, the coefficient of the power series
$\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  $ before $T^{j}$ lies in
the $j$-th graded component of $A$ (by the definition of "equigraded"). In
other words, the coefficient of the power series $\prod\limits_{i=1}%
^{m}\varphi\left(  U_{i}T\right)  $ before $T^{j}$ is a homogeneous polynomial
of degree $j$ in the variables $U_{1}$, $U_{2}$, $...$, $U_{m}$. Since this
coefficient is $\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}%
^{m}\varphi\left(  U_{i}T\right)  \right)  $, this yields that
$\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)  $ is a homogeneous polynomial of degree
$j$ in the variables $U_{1}$, $U_{2}$, $...$, $U_{m}$. Hence,
$\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)  $ is a polynomial of total degree $\leq
j$ in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$.}, Theorem 4.1
\textbf{(b)} yields that%
\[
\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right)  =\operatorname*{Todd}\nolimits_{\left(  \varphi
,j\right)  ,j}\left(  X_{1},X_{2},...,X_{j}\right)  ,
\]
where $\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j}$ is the
image of the polynomial $\operatorname*{Todd}\nolimits_{\left(  \varphi
,j\right)  }$ under the canonical homomorphism $\mathbf{Z}\left[  \alpha
_{1},\alpha_{2},...,\alpha_{m}\right]  \rightarrow\mathbf{Z}\left[  \alpha
_{1},\alpha_{2},...,\alpha_{j}\right]  $. However, this polynomial
$\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j}$ is not
independent of $m$ yet (as the polynomial $\operatorname*{Td}%
\nolimits_{\varphi,j}$ that we intend to construct should be), so we call it
$\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]
}$ rather than just $\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)
,j}$.

Now we forget that we fixed $m\in\mathbb{N}$ (but still fix $j\in\mathbb{N}$).
We have learnt that%
\[
\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right)  =\operatorname*{Todd}\nolimits_{\left(  \varphi
,j\right)  ,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
\]
in the polynomial ring $\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ for
every $m\in\mathbb{N}$. Now, define a polynomial $\operatorname*{Td}%
\nolimits_{\varphi,j}\in\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{j}\right]  $ by $\operatorname*{Td}\nolimits_{\varphi,j}%
=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  j\right]
}.$

This polynomial $\operatorname*{Td}\nolimits_{\varphi,j}$ is called the
$j$\textit{-th Todd polynomial of }$\varphi$.

\textbf{Theorem 10.1.} The polynomials $\operatorname*{Td}\nolimits_{\varphi
,j}$ just defined satisfy the equation (\ref{Td1}) in the ring $\left(
\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \left[
T\right]  \right]  $ for every $m\in\mathbb{N}$. (Hence, the goal mentioned
above in the definition is actually achieved.)
\end{quote}

Before we prove this, we need a lemma; it is not really a fact of independent
importance, but if we don't formulate it as a lemma we will have to run
through its proof several times:

\begin{quote}
\textbf{Lemma 10.2.} Let $\mathbf{Z}$ be a ring. Let $\varphi\in
1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power series with
constant term equal to $1$. Let $m\in\mathbb{N}$ and $n\in\mathbb{N}$ be such
that $m\geq n$. Then, in the polynomial ring $\mathbf{Z}\left[  U_{1}%
,U_{2},...,U_{n}\right]  $, we have $\operatorname*{Todd}\nolimits_{\left(
\varphi,j\right)  ,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  n\right]
}\left(  X_{1},X_{2},...,X_{j}\right)  $.
\end{quote}

\textit{Proof of Lemma 10.2.} By the definition of $\operatorname*{Todd}%
\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]  }$, we have%
\begin{equation}
\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right)  =\operatorname*{Todd}\nolimits_{\left(  \varphi
,j\right)  ,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
\label{10.1.pf.1}%
\end{equation}
in the polynomial ring $\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $.

Let $\operatorname*{proj}\nolimits_{m,n}$ be the canonical $\mathbf{Z}%
$-algebra epimorphism $\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]
\rightarrow\mathbf{Z}\left[  U_{1},U_{2},...,U_{n}\right]  $ which maps every
$U_{i}$ to $\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq n;\\
0,\text{ if }i>n
\end{array}
\right.  $. This $\mathbf{Z}$-algebra homomorphism $\operatorname*{proj}%
\nolimits_{m,n}$ induces a $\mathbf{Z}$-algebra homomorphism
$\operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]  \right]
:\left(  \mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[
\left[  T\right]  \right]  \rightarrow\left(  \mathbf{Z}\left[  U_{1}%
,U_{2},...,U_{n}\right]  \right)  \left[  \left[  T\right]  \right]  $ which
maps every power series $\sum\limits_{k\in\mathbb{N}}a_{k}T^{k}$ (with
$a_{k}\in\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ for every
$k\in\mathbb{N}$) to $\sum\limits_{k\in\mathbb{N}}\operatorname*{proj}%
\nolimits_{m,n}\left(  a_{k}\right)  T^{k}$. For every $i\in\left\{
1,2,...,m\right\}  $, this homomorphism $\operatorname*{proj}\nolimits_{m,n}%
\left[  \left[  T\right]  \right]  $ satisfies $\left(  \operatorname*{proj}%
\nolimits_{m,n}\left[  \left[  T\right]  \right]  \right)  \left(
\varphi\left(  U_{i}T\right)  \right)  =\left\{
\begin{array}
[c]{c}%
\varphi\left(  U_{i}T\right)  ,\ \text{if }i\leq n;\\
1,\text{\ if }i>n
\end{array}
\right.  \ \ \ \ $\footnote{\textit{Proof.} Write the power series $\varphi
\in\mathbf{Z}\left[  \left[  t\right]  \right]  $ in the form $\varphi
=\sum\limits_{k\in\mathbb{N}}\varphi_{k}t^{k}$ with $\varphi_{k}\in\mathbf{Z}$
for every $k\in\mathbb{N}$. Notice that $\varphi_{0}=1$ since $\varphi$ has
constant term $1$.
\par
Let $i\in\left\{  1,2,...,m\right\}  $. Since $\varphi=\sum\limits_{k\in
\mathbb{N}}\varphi_{k}t^{k}$, we have $\varphi\left(  U_{i}T\right)
=\sum\limits_{k\in\mathbb{N}}\varphi_{k}\underbrace{\left(  U_{i}T\right)
^{k}}_{=U_{i}^{k}T^{k}}=\sum\limits_{k\in\mathbb{N}}\varphi_{k}U_{i}^{k}T^{k}%
$. Thus,
\begin{align*}
&  \left(  \operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]
\right]  \right)  \left(  \varphi\left(  U_{i}T\right)  \right) \\
&  =\left(  \operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]
\right]  \right)  \left(  \sum\limits_{k\in\mathbb{N}}\varphi_{k}U_{i}%
^{k}T^{k}\right)  =\sum\limits_{k\in\mathbb{N}}%
\underbrace{\operatorname*{proj}\nolimits_{m,n}\left(  \varphi_{k}U_{i}%
^{k}\right)  }_{\substack{=\varphi_{k}\left(  \operatorname*{proj}%
\nolimits_{m,n}U_{i}\right)  ^{k}\\\text{(since }\operatorname*{proj}%
\nolimits_{m,n}\text{ is a }\mathbf{Z}\text{-algebra}\\\text{homomorphism)}%
}}T^{k}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }%
\operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]  \right]  \right)
\\
&  =\sum\limits_{k\in\mathbb{N}}\varphi_{k}\left(  \operatorname*{proj}%
\nolimits_{m,n}U_{i}\right)  ^{k}T^{k}=\sum\limits_{k\in\mathbb{N}}\varphi
_{k}\left(  \left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq n;\\
0,\text{ if }i>n
\end{array}
\right.  \right)  ^{k}T^{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\operatorname*{proj}%
\nolimits_{m,n}U_{i}=\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq n;\\
0,\text{ if }i>n
\end{array}
\right.  \text{ by the definition of }\operatorname*{proj}\nolimits_{m,n}%
\right) \\
&  =\left\{
\begin{array}
[c]{c}%
\sum\limits_{k\in\mathbb{N}}\varphi_{k}U_{i}^{k}T^{k},\text{ if }i\leq n;\\
\sum\limits_{k\in\mathbb{N}}\varphi_{k}0^{k}T^{k},\text{ if }i>n
\end{array}
\right.  =\left\{
\begin{array}
[c]{c}%
\varphi\left(  U_{i}T\right)  ,\text{ if }i\leq n;\\
1,\text{ if }i>n
\end{array}
\right. \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\sum\limits_{k\in\mathbb{N}}\varphi_{k}U_{i}^{k}T^{k}%
=\varphi\left(  U_{i}T\right)  \text{ for }i\leq n\text{, but on the other
hand}\\
\sum\limits_{k\in\mathbb{N}}\varphi_{k}0^{k}T^{k}=\underbrace{\varphi_{0}%
}_{=1}\underbrace{0^{0}}_{=1}\underbrace{T^{0}}_{=1}+\sum
\limits_{\substack{k\in\mathbb{N};\\k\neq0}}\varphi_{k}\underbrace{0^{k}%
}_{\substack{=0\\\text{(since }k\neq0\text{)}}}T^{k}=1+\underbrace{\sum
\limits_{\substack{k\in\mathbb{N};\\k\neq0}}\varphi_{k}0T^{k}}_{=0}=1\text{
for }i>n
\end{array}
\right)  ,
\end{align*}
qed.}. Now, since $\operatorname*{proj}\nolimits_{m,n}\left[  \left[
T\right]  \right]  $ is a $\mathbf{Z}$-algebra homomorphism, we have%
\begin{align*}
\left(  \operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]  \right]
\right)  \left(  \prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)
&  =\prod\limits_{i=1}^{m}\underbrace{\left(  \operatorname*{proj}%
\nolimits_{m,n}\left[  \left[  T\right]  \right]  \right)  \left(
\varphi\left(  U_{i}T\right)  \right)  }_{=\left\{
\begin{array}
[c]{c}%
\varphi\left(  U_{i}T\right)  ,\ \text{if }i\leq n;\\
1,\text{\ if }i>n
\end{array}
\right.  }=\prod\limits_{i=1}^{m}\left\{
\begin{array}
[c]{c}%
\varphi\left(  U_{i}T\right)  ,\ \text{if }i\leq n;\\
1,\text{\ if }i>n
\end{array}
\right. \\
&  =\prod\limits_{i=1}^{n}\underbrace{\left\{
\begin{array}
[c]{c}%
\varphi\left(  U_{i}T\right)  ,\ \text{if }i\leq n;\\
1,\text{\ if }i>n
\end{array}
\right.  }_{=\varphi\left(  U_{i}T\right)  \text{ (since }i\leq n\text{)}%
}\cdot\prod\limits_{i=n+1}^{m}\underbrace{\left\{
\begin{array}
[c]{c}%
\varphi\left(  U_{i}T\right)  ,\ \text{if }i\leq n;\\
1,\text{\ if }i>n
\end{array}
\right.  }_{=1\text{ (since }i>n\text{)}}\\
&  =\prod\limits_{i=1}^{n}\varphi\left(  U_{i}T\right)  \cdot\underbrace{\prod
\limits_{i=n+1}^{m}1}_{=1}=\prod\limits_{i=1}^{n}\varphi\left(  U_{i}T\right)
.
\end{align*}
But the diagram%
\[
\xymatrixcolsep{5pc}\xymatrix{
\left(\mathbf Z\left[U_1,U_2,...,U_m\right]\right)\left[\left[T\right]\right] \ar[r]^{\operatorname*{proj}_{m,n}\left[\left[T\right]\right]} \ar[d]_{\operatorname*{Coeff}_j} & \left(\mathbf Z\left[U_1,U_2,...,U_m\right]\right)\left[\left[T\right]\right]  \ar[d]_{\operatorname*{Coeff}_j} \\
\mathbf Z\left[U_1,U_2,...,U_m\right] \ar[r]^{\operatorname*{proj}_{m,n}} & \mathbf Z\left[U_1,U_2,...,U_n\right]
}
\]
is commutative (this is clear from the definitions of $\operatorname*{Coeff}%
\nolimits_{j}$ and $\operatorname*{proj}\nolimits_{m,n}\left[  \left[
T\right]  \right]  $), so that $\operatorname*{proj}\nolimits_{m,n}%
\circ\operatorname*{Coeff}\nolimits_{j}=\operatorname*{Coeff}\nolimits_{j}%
\circ\left(  \operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]
\right]  \right)  $ and thus%
\begin{align*}
\left(  \operatorname*{proj}\nolimits_{m,n}\circ\operatorname*{Coeff}%
\nolimits_{j}\right)  \left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right)   &  =\left(  \operatorname*{Coeff}\nolimits_{j}%
\circ\left(  \operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]
\right]  \right)  \right)  \left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right) \\
&  =\operatorname*{Coeff}\nolimits_{j}\left(  \underbrace{\left(
\operatorname*{proj}\nolimits_{m,n}\left[  \left[  T\right]  \right]  \right)
\left(  \prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)  }%
_{=\prod\limits_{i=1}^{n}\varphi\left(  U_{i}T\right)  }\right)
=\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{n}%
\varphi\left(  U_{i}T\right)  \right) \\
&  =\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[
n\right]  }\left(  X_{1},X_{2},...,X_{j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{10.1.pf.1}), applied to }n\text{
instead of }m\right)  .
\end{align*}
Comparing this with%
\begin{align*}
&  \left(  \operatorname*{proj}\nolimits_{m,n}\circ\operatorname*{Coeff}%
\nolimits_{j}\right)  \left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right) \\
&  =\operatorname*{proj}\nolimits_{m,n}\left(
\underbrace{\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}%
^{m}\varphi\left(  U_{i}T\right)  \right)  }_{\substack{=\operatorname*{Todd}%
\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]  }\left(  X_{1}%
,X_{2},...,X_{j}\right)  \\\text{(by (\ref{10.1.pf.1}))}}}\right)
=\operatorname*{proj}\nolimits_{m,n}\left(  \operatorname*{Todd}%
\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]  }\left(  X_{1}%
,X_{2},...,X_{j}\right)  \right) \\
&  =\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[
m\right]  }\left(  \operatorname*{proj}\nolimits_{m,n}X_{1}%
,\operatorname*{proj}\nolimits_{m,n}X_{2},...,\operatorname*{proj}%
\nolimits_{m,n}X_{j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)
,j,\left[  m\right]  }\text{ is a polynomial over }\mathbf{Z}\text{ and
}\operatorname*{proj}\nolimits_{m,n}\text{ is a }\mathbf{Z}\text{-algebra
homomorphism,}\\
\text{and since polynomials over }\mathbf{Z}\text{ commute with }%
\mathbf{Z}\text{-algebra homomorphisms}%
\end{array}
\right) \\
&  =\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[
m\right]  }\left(  X_{1},X_{2},...,X_{j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\operatorname*{proj}\nolimits_{m,n}\text{ is the }\mathbf{Z}%
\text{-algebra homomorphism which maps every }U_{i}\text{ to }\left\{
\begin{array}
[c]{c}%
U_{i},\text{ if }i\leq n;\\
0,\text{ if }i>n
\end{array}
\right.  \text{,}\\
\text{and thus we know that it maps every }X_{i}\text{ with }i\geq1\text{ to
the corresponding }X_{i}\text{ of the}\\
\text{image ring, so that }\operatorname*{proj}\nolimits_{m,n}X_{1}%
=X_{1}\text{, }\operatorname*{proj}\nolimits_{m,n}X_{2}=X_{2}\text{,
}...\text{, }\operatorname*{proj}\nolimits_{m,n}X_{j}=X_{j}%
\end{array}
\right)  ,
\end{align*}
we obtain%
\[
\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  n\right]
}\left(  X_{1},X_{2},...,X_{j}\right)  =\operatorname*{Todd}\nolimits_{\left(
\varphi,j\right)  ,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
\]
in the polynomial ring $\mathbf{Z}\left[  U_{1},U_{2},...,U_{n}\right]  $.
This proves Lemma 10.2.

\textit{Proof of Theorem 10.1.} This proof is going to be very similar to the
proofs of Theorem 4.4 \textbf{(a)} and Theorem 9.1 \textbf{(a)} - except that
this time, we already have done most of our work when proving Lemma 10.2.

\textit{1st Step:} Fix $m\in\mathbb{N}$ and $j\in\mathbb{N}$ such that $m\geq
j$. Then, we claim that $\operatorname*{Todd}\nolimits_{\left(  \varphi
,j\right)  ,j,\left[  m\right]  }=\operatorname*{Td}\nolimits_{\varphi,j}$.

\textit{Proof.} Lemma 10.2 (applied to $n=j$) yields that
$\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]
}\left(  X_{1},X_{2},...,X_{j}\right)  =\operatorname*{Todd}\nolimits_{\left(
\varphi,j\right)  ,j,\left[  j\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
$ in the polynomial ring $\mathbf{Z}\left[  U_{1},U_{2},...,U_{j}\right]  $.
Since the elements $X_{1},$ $X_{2},$ $...,$ $X_{j}$ of $\mathbf{Z}\left[
U_{1},U_{2},...,U_{j}\right]  $ are algebraically independent (by Theorem 4.1
\textbf{(a)}), this yields $\operatorname*{Todd}\nolimits_{\left(
\varphi,j\right)  ,j,\left[  m\right]  }=\operatorname*{Todd}%
\nolimits_{\left(  \varphi,j\right)  ,j,\left[  j\right]  }$. Thus,
$\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]
}=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[
j\right]  }=\operatorname*{Td}\nolimits_{\varphi,j}$, and the 1st Step is proven.

\textit{2nd Step:} For every $m\in\mathbb{N}$ and $j\in\mathbb{N}$, we have
$\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)
=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]
}\left(  X_{1},X_{2},...,X_{j}\right)  $ in the ring $\mathbf{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $.

\textit{Proof.} Let $m^{\prime}\in\mathbb{N}$ be such that $m^{\prime}\geq m$
and $m^{\prime}\geq j$. Then, the 1st Step (applied to $m^{\prime}$ instead of
$m$) yields that $\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)
,j,\left[  m^{\prime}\right]  }=\operatorname*{Td}\nolimits_{\varphi,j}$. On
the other hand, Lemma 10.2 (applied to $m^{\prime}$ and $m$ instead of $m$ and
$n$) yields that $\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)
,j,\left[  m^{\prime}\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]
}\left(  X_{1},X_{2},...,X_{j}\right)  $ in the polynomial ring $\mathbf{Z}%
\left[  U_{1},U_{2},...,U_{m}\right]  $. Since $\operatorname*{Todd}%
\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m^{\prime}\right]
}=\operatorname*{Td}\nolimits_{\varphi,j}$, this rewrites as
$\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)
=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)  ,j,\left[  m\right]
}\left(  X_{1},X_{2},...,X_{j}\right)  $. This proves the 2nd Step.

\textit{3rd Step:} For every $m\in\mathbb{N}$, the equation (\ref{Td1}) is
satisfied in the ring $\left(  \mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]
\right)  \left[  \left[  T\right]  \right]  $.

\textit{Proof.} Every power series $P\in\left(  \mathbf{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  \right)  \left[  \left[  T\right]  \right]  $
satisfies $P=\sum\limits_{j\in\mathbb{N}}\left(  \operatorname*{Coeff}%
\nolimits_{j}P\right)  T^{j}$ (by the definition of $\operatorname*{Coeff}%
\nolimits_{j}$). Applied to $P=\prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  $, this yields%
\begin{align*}
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)   &  =\sum\limits_{j\in
\mathbb{N}}\underbrace{\operatorname*{Coeff}\nolimits_{j}\left(
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)  }%
_{\substack{=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)
,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)  \\\text{(by
(\ref{10.1.pf.1}))}}}T^{j}=\sum\limits_{j\in\mathbb{N}}%
\underbrace{\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)
,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)  }%
_{\substack{=\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1}%
,X_{2},...,X_{j}\right)  \\\text{(by the 2nd step)}}}T^{j}\\
&  =\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}%
\end{align*}
in the ring $\left(  \mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)
\left[  \left[  T\right]  \right]  $. This proves the 3rd Step, and thus
Theorem 10.1 is proven.

\subsection{Defining the Todd homomorphism}

Now, let us define the Todd homomorphism:

\begin{quote}
\textbf{Definition.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ be a power series with constant term equal to $1$. We
define a map $\operatorname*{td}_{\varphi,T}:K\rightarrow K\left[  \left[
T\right]  \right]  $ by%
\begin{equation}
\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  =\sum\limits_{j\in
\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)
\right)  T^{j}\ \ \ \ \ \ \ \ \ \ \text{for every }x\in K. \label{ToddDef}%
\end{equation}
We call $\operatorname*{td}\nolimits_{\varphi,T}$ the $\varphi$-\textit{Todd
homomorphism} of the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $.
\end{quote}

As already mentioned above, this notation $\operatorname*{td}%
\nolimits_{\varphi,T}$ and the name "$\varphi$-Todd homomorphism" by which I
denote it might not be standard terminology.\footnote{For instance, what [1]
calls "\textit{Todd homomorphism}" is the map $\operatorname*{td}_{\varphi
}:=\operatorname*{td}\nolimits_{\varphi,1}$ (where $\operatorname*{td}%
\nolimits_{\varphi,1}$ means "take the formal power series $\operatorname*{td}%
\nolimits_{\varphi,T}$ and replace every $T$ by $1$"), which is only defined
on $x$ if $x$ is finite-dimensional, i. e. if $x$ satisfies $\lambda
^{i}\left(  x\right)  =0$ for all sufficiently large $i.$ But I prefer the
power series $\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  $ since
it is defined on \textit{every }$x$.
\par
I am not even sure whether there exists standard terminology for Todd
homomorphisms - there does not seem to be much literature about them.}

\subsection{The case when the power series is $1+ut$}

As complicated as this definition was, we might wonder whether there is a more
explicit approach to $\varphi$-Todd homomorphisms. It turns out that there is,
if $\varphi$ is a polynomial factoring into linear polynomials of the form
$1+ut$ with $u\in\mathbf{Z}$. Let us begin with computing the $\varphi$-Todd
homomorphism for $\varphi$ itself being of this form:

\begin{quote}
\textbf{Proposition 10.3.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $u\in\mathbf{Z}$. For every $x\in K$, we
have $\operatorname*{td}\nolimits_{1+ut,T}\left(  x\right)  =\lambda
_{uT}\left(  x\right)  $, where $\lambda_{uT}\left(  x\right)  $ means
$\operatorname*{ev}\nolimits_{uT}\left(  \lambda_{T}\left(  x\right)  \right)
$.
\end{quote}

To prove this, we need to compute the $j$-th Todd polynomials of $1+ut$. This
can be done explicitly:

\begin{quote}
\textbf{Proposition 10.4.} Let $\mathbf{Z}$ be a ring. Let $u\in\mathbf{Z}$.
Then, $\operatorname*{Td}\nolimits_{1+ut,j}=u^{j}\alpha_{j}$ (in the
polynomial ring $\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{j}\right]  $) for every positive $j\in\mathbb{N}$.
\end{quote}

Note that Proposition 10.4 makes no sense for $j=0$; this will cause us some
minor trouble in the proof of Proposition 10.3.

\textit{Proof of Proposition 10.4.} Let $m\in\mathbb{N}$. Consider the ring
$\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ (the polynomial ring in $m$
indeterminates $U_{1},$ $U_{2},$ $...,$ $U_{m}$ over the ring $\mathbf{Z}$).
For every $i\in\mathbb{N}$, let $X_{i}=\sum\limits_{\substack{S\subseteq
\left\{  1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in
S}U_{k}$ be the so-called $i$\textit{-th elementary symmetric polynomial} in
the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$.

We know from Theorem 10.1 that (\ref{Td1}) holds in the ring $\left(
\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \left[
T\right]  \right]  $ whenever $\varphi\in1+\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$ is a power series with constant term equal to $1$. Applying
this to $\varphi=1+ut$, we obtain%
\[
\prod\limits_{i=1}^{m}\left(  1+ut\right)  \left(  U_{i}T\right)  =\sum
_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{1+ut,j}\left(  X_{1}%
,X_{2},...,X_{j}\right)  T^{j},
\]
where $\left(  1+ut\right)  \left(  U_{i}T\right)  $ means "the power series
$1+ut$, applied to $U_{i}T$" (and not a product of $1+ut$ and $U_{i}T$,
whatever such a product could mean). Since%
\begin{align*}
&  \prod\limits_{i=1}^{m}\underbrace{\left(  1+ut\right)  \left(
U_{i}T\right)  }_{=1+uU_{i}T=1+U_{i}\cdot uT}\\
&  =\prod\limits_{i=1}^{m}\left(  1+U_{i}\cdot uT\right)  =\sum_{i\in
\mathbb{N}}\underbrace{\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod_{k\in S}U_{k}}_{=X_{i}}%
\underbrace{\left(  uT\right)  ^{i}}_{=u^{i}T^{i}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Exercise 4.2 \textbf{(b)}, applied to
}U_{i}\text{, }\left(  \mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]
\right)  \left[  \left[  T\right]  \right]  \text{, and }uT\text{ instead of
}\alpha_{i}\text{, }A\text{, and }t\right) \\
&  =\sum_{i\in\mathbb{N}}X_{i}u^{i}T^{i}=\sum_{j\in\mathbb{N}}X_{j}u^{j}%
T^{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{here, we renamed the index }i\text{ as
}j\right)  ,
\end{align*}
this rewrites as%
\[
\sum_{j\in\mathbb{N}}X_{j}u^{j}T^{j}=\sum_{j\in\mathbb{N}}\operatorname*{Td}%
\nolimits_{1+ut,j}\left(  X_{1},X_{2},...,X_{j}\right)  T^{j}.
\]
By comparing coefficients in this equation, we conclude that%
\[
X_{j}u^{j}=\operatorname*{Td}\nolimits_{1+ut,j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \text{ in }\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]
\ \ \ \ \ \ \ \ \ \ \text{for all }j\in\mathbb{N}\text{.}%
\]


Now we forget that we fixed $m$. Instead, fix some positive $j\in\mathbb{N}$,
and take $m=j$. Then, we have just proved that
\[
X_{j}u^{j}=\operatorname*{Td}\nolimits_{1+ut,j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \text{ in }\mathbf{Z}\left[  U_{1},U_{2},...,U_{j}\right]
.
\]


Let $\mathfrak{Q}_{1}\in\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{j}\right]  $ be the polynomial defined by $\mathfrak{Q}_{1}=u^{j}\alpha_{j}%
$. Let $\mathfrak{Q}_{2}\in\mathbf{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{j}\right]  $ be the polynomial defined by $\mathfrak{Q}%
_{2}=\operatorname*{Td}\nolimits_{1+ut,j}$. We are now going to prove that
$\mathfrak{Q}_{1}=\mathfrak{Q}_{2}$.

Applying Theorem 4.1 \textbf{(a)} to $K=\mathbf{Z}$, $m=j$ and $P=X_{j}u^{j}$,
we conclude that there exists one and only one polynomial $Q\in\mathbf{Z}%
\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $ such that $X_{j}%
u^{j}=Q\left(  X_{1},X_{2},...,X_{j}\right)  $. In particular, there exists
\textit{at most one} such polynomial $Q\in\mathbf{Z}\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{j}\right]  $. Hence,
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{if }\mathfrak{Q}_{1}\in\mathbf{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right]  \text{ and }\mathfrak{Q}_{2}\in\mathbf{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \text{ are two polynomials}\\
\text{such that }X_{j}u^{j}=\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{j}%
\right)  \text{ and }X_{j}u^{j}=\mathfrak{Q}_{2}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \text{,}\\
\text{then }\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
\end{array}
\right)  . \label{10.4.pf.1}%
\end{equation}


Since our two polynomials $\mathfrak{Q}_{1}$ and $\mathfrak{Q}_{2}$ satisfy%
\begin{align*}
\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{j}\right)   &  =u^{j}%
X_{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{1}=u^{j}\alpha
_{j}\right) \\
&  =X_{j}u^{j}%
\end{align*}
and%
\begin{align*}
\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{j}\right)   &  =\operatorname*{Td}%
\nolimits_{1+ut,j}\left(  X_{1},X_{2},...,X_{j}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{2}=\operatorname*{Td}%
\nolimits_{1+ut,j}\right) \\
&  =X_{j}u^{j},
\end{align*}
we can conclude from (\ref{10.4.pf.1}) that $\mathfrak{Q}_{1}=\mathfrak{Q}%
_{2}$. Hence, $u^{j}\alpha_{j}=\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
=\operatorname*{Td}\nolimits_{1+ut,j}$. This proves Proposition 10.4.

\subsection{The $0$-th and $1$-st coefficients of $\operatorname*{td}%
\nolimits_{\varphi,T}\left(  x\right)  $}

We keep back the proof of Proposition 10.3 for a moment - instead, we first
show a proposition which gives the first two coefficients of the power series
$\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  $ in the general
case (with $\varphi$ arbitrary):

\begin{quote}
\textbf{Proposition 10.5.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ be a power series with constant term equal to $1$.

\textbf{(a)} Then, $\operatorname*{Coeff}\nolimits_{0}\left(
\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  \right)  =1$ for
every $x\in K$.

\textbf{(b)} Let $\varphi_{1}$ be the coefficient of the power series
$\varphi\in\mathbf{Z}\left[  \left[  t\right]  \right]  $ before $t^{1}$.
Then, $\operatorname*{Coeff}\nolimits_{1}\left(  \operatorname*{td}%
\nolimits_{\varphi,T}\left(  x\right)  \right)  =\varphi_{1}x$ for every $x\in
K$.
\end{quote}

To prove this, we need to compute the $0$-th and the $1$-st Todd polynomials
of $\varphi$:

\begin{quote}
\textbf{Proposition 10.6.} Let $\mathbf{Z}$ be a ring. Let $\varphi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power series with
constant term equal to $1$.

\textbf{(a)} Then, $\operatorname*{Td}\nolimits_{\varphi,0}=1$.

\textbf{(b)} Let $\varphi_{1}$ be the coefficient of the power series
$\varphi\in\mathbf{Z}\left[  \left[  t\right]  \right]  $ before $t^{1}$.
Then, $\operatorname*{Td}\nolimits_{\varphi,1}=\varphi_{1}\alpha_{1}$.
\end{quote}

\textit{Proof of Proposition 10.6.} Let $m\in\mathbb{N}$. Consider the ring
$\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ and its elements
$X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ as in the
definition of $\operatorname*{Td}\nolimits_{\varphi,j}$.

We know from Theorem 10.1 that (\ref{Td1}) holds in the ring $\left(
\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \left[
T\right]  \right]  $. In other words,%
\[
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  =\sum_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)
T^{j}.
\]


Thus,
\begin{equation}
\operatorname*{Coeff}\nolimits_{0}\left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right)  =\operatorname*{Coeff}\nolimits_{0}\left(
\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}\right)  =\operatorname*{Td}%
\nolimits_{\varphi,0}\left(  X_{1},X_{2},...,X_{0}\right)  \label{10.6.pf.1}%
\end{equation}
\footnote{The notation $\operatorname*{Td}\nolimits_{\varphi,0}\left(
X_{1},X_{2},...,X_{0}\right)  $ is somewhat unusual, but it should not be
surprising: The polynomial $\operatorname*{Td}\nolimits_{\varphi,0}$ is an
element of $\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{0}\right]  $,
that is, a polynomial in zero variables. (Of course, polynomials in zero
variables are just elements of the base ring - in this case, elements of
$\mathbf{Z}$.)} (by the definition of $\operatorname*{Coeff}\nolimits_{0}$)
and%
\begin{equation}
\operatorname*{Coeff}\nolimits_{1}\left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right)  =\operatorname*{Coeff}\nolimits_{1}\left(
\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}\right)  =\operatorname*{Td}%
\nolimits_{\varphi,1}\left(  X_{1},X_{2},...,X_{1}\right)  \label{10.6.pf.2}%
\end{equation}
(by the definition of $\operatorname*{Coeff}\nolimits_{1}$). Both of these
equations (\ref{10.6.pf.1}) and (\ref{10.6.pf.2}) hold in the ring
$\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $.

\textbf{(a)} Let $m=0$. Then, the polynomial rings $\mathbf{Z}\left[
U_{1},U_{2},...,U_{m}\right]  =\mathbf{Z}\left[  U_{1},U_{2},...,U_{0}\right]
$ and $\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{0}\right]  $ can be
canonically identified with the ring $\mathbf{Z}$ (because they are polynomial
rings in zero variables, and a polynomial ring in zero variables over a ring
$K$ is the same as the ring $K$ itself). Under this identification, the
"value" $\operatorname*{Td}\nolimits_{\varphi,0}\left(  X_{1},X_{2}%
,...,X_{0}\right)  $ corresponds to the polynomial $\operatorname*{Td}%
\nolimits_{\varphi,0}$, so that we can write $\operatorname*{Td}%
\nolimits_{\varphi,0}\left(  X_{1},X_{2},...,X_{0}\right)  =\operatorname*{Td}%
\nolimits_{\varphi,0}$.

But the equation (\ref{10.6.pf.1}) holds in the ring $\mathbf{Z}\left[
U_{1},U_{2},...,U_{m}\right]  =\mathbf{Z}\left[  U_{1},U_{2},...,U_{0}\right]
\cong\mathbf{Z}$. Hence, we have%
\[
\operatorname*{Td}\nolimits_{\varphi,0}\left(  X_{1},X_{2},...,X_{0}\right)
=\operatorname*{Coeff}\nolimits_{0}\left(  \underbrace{\prod\limits_{i=1}%
^{m}\varphi\left(  U_{i}T\right)  }_{\substack{=\left(  \text{empty
product}\right)  \\\text{(since }m=0\text{)}}}\right)  =\operatorname*{Coeff}%
\nolimits_{0}\underbrace{\left(  \text{empty product}\right)  }_{=1}=1
\]
in the ring $\mathbf{Z}$. Hence, $\operatorname*{Td}\nolimits_{\varphi
,0}=\operatorname*{Td}\nolimits_{\varphi,0}\left(  X_{1},X_{2},...,X_{0}%
\right)  =1$. This proves Proposition 10.6 \textbf{(a)}.

\textbf{(b)} Let $m=1$. Then, $\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]
=\mathbf{Z}\left[  U_{1}\right]  $, and in this ring $\mathbf{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $ we have $X_{1}=U_{1}$ (because $X_{1}$ is the
$1$-st elementary symmetric polynomial of the one variable $U_{1}$). Thus, in
this ring, we have%
\begin{align*}
\operatorname*{Td}\nolimits_{\varphi,1}\left(  U_{1}\right)   &
=\operatorname*{Td}\nolimits_{\varphi,1}\left(  X_{1}\right)
=\operatorname*{Td}\nolimits_{\varphi,1}\left(  X_{1},X_{2},...,X_{1}\right)
=\operatorname*{Coeff}\nolimits_{1}\left(  \underbrace{\prod\limits_{i=1}%
^{m}\varphi\left(  U_{i}T\right)  }_{=\varphi\left(  U_{1}T\right)  \text{
(since }m=1\text{)}}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{10.6.pf.2})}\right) \\
&  =\operatorname*{Coeff}\nolimits_{1}\left(  \varphi\left(  U_{1}T\right)
\right)  =\left(  \text{the coefficient of the power series }\varphi\left(
U_{1}T\right)  \text{ before }T^{1}\right) \\
&  =U_{1}\underbrace{\left(  \text{the coefficient of the power series
}\varphi\text{ before }t^{1}\right)  }_{=\varphi_{1}}=U_{1}\varphi_{1}.
\end{align*}


Now, let $\kappa$ be the $\mathbf{Z}$-algebra homomorphism $\mathbf{Z}\left[
\alpha_{1}\right]  \rightarrow\mathbf{Z}\left[  U_{1}\right]  $ which maps
$\alpha_{1}$ to $U_{1}$. This homomorphism $\kappa$ must be an isomorphism
(since $U_{1}$ is obviously algebraically independent). Since $\kappa$ is a
$\mathbf{Z}$-algebra homomorphism and $\operatorname*{Td}\nolimits_{\varphi
,1}$ is a polynomial, we have $\kappa\left(  \operatorname*{Td}%
\nolimits_{\varphi,1}\left(  \alpha_{1}\right)  \right)  =\operatorname*{Td}%
\nolimits_{\varphi,1}\left(  \kappa\left(  \alpha_{1}\right)  \right)  $
(because $\mathbf{Z}$-algebra homomorphisms commute with polynomials). Now,%
\begin{align*}
\kappa\left(  \underbrace{\operatorname*{Td}\nolimits_{\varphi,1}%
}_{=\operatorname*{Td}\nolimits_{\varphi,1}\left(  \alpha_{1}\right)
}\right)   &  =\kappa\left(  \operatorname*{Td}\nolimits_{\varphi,1}\left(
\alpha_{1}\right)  \right)  =\operatorname*{Td}\nolimits_{\varphi,1}\left(
\underbrace{\kappa\left(  \alpha_{1}\right)  }_{=U_{1}}\right)
=\operatorname*{Td}\nolimits_{\varphi,1}\left(  U_{1}\right) \\
&  =\underbrace{U_{1}}_{=\kappa\left(  \alpha_{1}\right)  }\varphi_{1}%
=\kappa\left(  \alpha_{1}\right)  \varphi_{1}=\varphi_{1}\kappa\left(
\alpha_{1}\right)  =\kappa\left(  \varphi_{1}\alpha_{1}\right)
\end{align*}
(since $\kappa$ is a $\mathbf{Z}$-algebra homomorphism). Thus,
$\operatorname*{Td}\nolimits_{\varphi,1}=\varphi_{1}\alpha_{1}$ (since
$\kappa$ is an isomorphism). This proves Proposition 10.6 \textbf{(b)}.

\textit{Proof of Proposition 10.5.} Let $x\in K$.

\textbf{(a)} We have%
\begin{align*}
\operatorname*{Coeff}\nolimits_{0}\left(  \operatorname*{td}\nolimits_{\varphi
,T}\left(  x\right)  \right)   &  =\operatorname*{Coeff}\nolimits_{0}\left(
\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{j}\left(  x\right)  \right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{ToddDef})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,0}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{0}\left(  x\right)
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }%
\operatorname*{Coeff}\nolimits_{0}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,0}=1\ \ \ \ \ \ \ \ \ \ \left(
\text{by Proposition 10.6 \textbf{(a)}}\right)  .
\end{align*}


\textbf{(b)} We have%
\begin{align*}
\operatorname*{Coeff}\nolimits_{1}\left(  \operatorname*{td}\nolimits_{\varphi
,T}\left(  x\right)  \right)   &  =\operatorname*{Coeff}\nolimits_{1}\left(
\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{j}\left(  x\right)  \right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{ToddDef})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,1}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{1}\left(  x\right)
\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }%
\operatorname*{Coeff}\nolimits_{1}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,1}\left(  \underbrace{\lambda
^{1}\left(  x\right)  }_{=x}\right)  =\operatorname*{Td}\nolimits_{\varphi
,1}\left(  x\right)  =\varphi_{1}x\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since Proposition 10.6 \textbf{(b)}
yields }\operatorname*{Td}\nolimits_{\varphi,1}=\varphi_{1}\alpha_{1}\right)
.
\end{align*}


Proposition 10.5 is now proven.

\subsection{Proof of Proposition 10.3}

\textit{Proof of Proposition 10.3.} Let $x\in K$. Applying (\ref{ToddDef}) to
$\varphi=1+ut$, we obtain%
\begin{align*}
&  \operatorname*{td}\nolimits_{1+ut,T}\left(  x\right) \\
&  =\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{1+ut,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{j}\left(  x\right)  \right)  T^{j}\\
&  =\underbrace{\operatorname*{Td}\nolimits_{1+ut,0}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{0}\left(  x\right)
\right)  }_{\substack{=\operatorname*{Td}\nolimits_{1+ut,0}=1\\\text{(by
Proposition 10.6 \textbf{(a)},}\\\text{applied to }\varphi=1+ut\text{)}}%
}T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}\underbrace{\operatorname*{Td}%
\nolimits_{1+ut,j}}_{\substack{=u^{j}\alpha_{j}\\\text{(by Proposition 10.4)}%
}}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{j}\left(  x\right)  \right)  T^{j}\\
&  =1T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}\underbrace{\left(
u^{j}\alpha_{j}\right)  \left(  \lambda^{1}\left(  x\right)  ,\lambda
^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)  \right)  }%
_{=u^{j}\lambda^{j}\left(  x\right)  =\lambda^{j}\left(  x\right)  u^{j}}%
T^{j}=1T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}\lambda^{j}\left(
x\right)  u^{j}T^{j}.
\end{align*}
Compared with%
\begin{align*}
\lambda_{uT}\left(  x\right)   &  =\operatorname*{ev}\nolimits_{uT}\left(
\underbrace{\lambda_{T}\left(  x\right)  }_{=\sum\limits_{j\in\mathbb{N}%
}\lambda^{j}\left(  x\right)  T^{j}}\right)  =\operatorname*{ev}%
\nolimits_{uT}\left(  \sum\limits_{j\in\mathbb{N}}\lambda^{j}\left(  x\right)
T^{j}\right) \\
&  =\sum\limits_{j\in\mathbb{N}}\lambda^{j}\left(  x\right)  u^{j}%
T^{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }%
\operatorname*{ev}\nolimits_{uT}\right) \\
&  =\underbrace{\lambda^{0}\left(  x\right)  }_{=1}\underbrace{u^{0}}%
_{=1}T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}\lambda^{j}\left(  x\right)
u^{j}T^{j}=1T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}\lambda^{j}\left(
x\right)  u^{j}T^{j},
\end{align*}
this yields that $\operatorname*{td}\nolimits_{1+ut,T}\left(  x\right)
=\lambda_{uT}\left(  x\right)  $. This proves Proposition 10.3.

\subsection{The Todd homomorphism is multiplicative in $\varphi$}

Our next proposition is another step to making the $\varphi$-Todd homomorphism manageable:

\begin{quote}
\textbf{Proposition 10.7.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ and $\psi\in1+\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$ be two power series with constant terms equal to $1$. For every
$x\in K$, we have $\operatorname*{td}\nolimits_{\varphi\psi,T}\left(
x\right)  =\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)
\operatorname*{td}\nolimits_{\psi,T}\left(  x\right)  $.
\end{quote}

Again, this boils down to an identity for Todd polynomials:

\begin{quote}
\textbf{Proposition 10.8.} Let $\mathbf{Z}$ be a ring. Let $\varphi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ and $\psi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be two power series
with constant terms equal to $1$. Then,%
\[
\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right)  =\sum\limits_{i=0}^{j}\operatorname*{Td}%
\nolimits_{\varphi,i}\left(  \alpha_{1},\alpha_{2},...,\alpha_{i}\right)
\cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j-i}\right)
\]
(in the polynomial ring $\mathbf{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{j}\right]  $) for every $j\in\mathbb{N}$.
\end{quote}

\textit{Proof of Proposition 10.8.} \textit{1st Step:} We have $\varphi\psi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$.

\textit{Proof.} The constant term of the product of two power series always
equals the product of the constant terms of these power series. Applying this
to the power series $\varphi$ and $\psi$, we obtain%
\begin{align*}
&  \left(  \text{constant term of the power series }\varphi\psi\right) \\
&  =\underbrace{\left(  \text{constant term of the power series }%
\varphi\right)  }_{=1\text{ (since }\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}\text{)}}\cdot\underbrace{\left(  \text{constant term
of the power series }\psi\right)  }_{=1\text{ (since }\psi\in1+\mathbf{Z}%
\left[  \left[  t\right]  \right]  ^{+}\text{)}}\\
&  =1\cdot1=1,
\end{align*}
so that $\varphi\psi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$.
The 1st Step is thus proven.

\textit{2nd Step:} We are going to show that for every $m\in\mathbb{N}$, we
have%
\[
\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  X_{1},X_{2},...,X_{j}%
\right)  =\sum_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(
X_{1},X_{2},...,X_{i}\right)  \cdot\operatorname*{Td}\nolimits_{\psi
,j-i}\left(  X_{1},X_{2},...,X_{j-i}\right)
\]
in the polynomial ring $\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ for
every $j\in\mathbb{N}$ (where, as usual, $X_{i}$ denotes the polynomial
$\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ (the $i$-th elementary symmetric
polynomial in the variables $U_{1},$ $U_{2},$ $...,$ $U_{m}$) for every
$i\in\mathbb{N}$).

\textit{Proof.} Let $m\in\mathbb{N}$. By Theorem 10.1, the equality
(\ref{Td1}) holds in the ring $\left(  \mathbf{Z}\left[  U_{1},U_{2}%
,...,U_{m}\right]  \right)  \left[  \left[  T\right]  \right]  $. In other
words,%
\[
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  =\sum\limits_{j\in
\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  T^{j}.
\]
Applying this equality to $\psi$ instead of $\varphi$, we get%
\[
\prod\limits_{i=1}^{m}\psi\left(  U_{i}T\right)  =\sum\limits_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\psi,j}\left(  X_{1},X_{2},...,X_{j}\right)
T^{j}.
\]
On the other hand, applying it to $\varphi\psi$ instead of $\varphi$, we get%
\[
\prod\limits_{i=1}^{m}\left(  \varphi\psi\right)  \left(  U_{i}T\right)
=\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi\psi
,j}\left(  X_{1},X_{2},...,X_{j}\right)  T^{j}.
\]
Hence,%
\begin{align*}
\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}  &  =\prod\limits_{i=1}^{m}%
\underbrace{\left(  \varphi\psi\right)  \left(  U_{i}T\right)  }%
_{=\varphi\left(  U_{i}T\right)  \psi\left(  U_{i}T\right)  }=\prod
\limits_{i=1}^{m}\left(  \varphi\left(  U_{i}T\right)  \psi\left(
U_{i}T\right)  \right) \\
&  =\underbrace{\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  }%
_{=\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}}\cdot\underbrace{\prod\limits_{i=1}%
^{m}\psi\left(  U_{i}T\right)  }_{=\sum\limits_{j\in\mathbb{N}}%
\operatorname*{Td}\nolimits_{\psi,j}\left(  X_{1},X_{2},...,X_{j}\right)
T^{j}}\\
&  =\left(  \sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi
,j}\left(  X_{1},X_{2},...,X_{j}\right)  T^{j}\right)  \cdot\left(
\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\psi,j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}\right) \\
&  =\sum\limits_{j\in\mathbb{N}}\left(  \sum_{i=0}^{j}\operatorname*{Td}%
\nolimits_{\varphi,i}\left(  X_{1},X_{2},...,X_{i}\right)  \cdot
\operatorname*{Td}\nolimits_{\psi,j-i}\left(  X_{1},X_{2},...,X_{j-i}\right)
\right)  T^{j}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the product of two
formal power series}\right)  .
\end{align*}
Comparing coefficients in this equation, we conclude that%
\[
\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  X_{1},X_{2},...,X_{j}%
\right)  =\sum_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(
X_{1},X_{2},...,X_{i}\right)  \cdot\operatorname*{Td}\nolimits_{\psi
,j-i}\left(  X_{1},X_{2},...,X_{j-i}\right)
\]
for every $j\in\mathbb{N}$. This proves the 2nd Step.

\textit{3rd Step:} Let us now prove Proposition 10.8.

Fix some $j\in\mathbb{N}$. Let $m=j$. We are going to work in the ring
$\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  =\mathbf{Z}\left[
U_{1},U_{2},...,U_{j}\right]  $.

Let $\mathfrak{Q}_{1}\in\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{j}\right]  $ be the polynomial defined by $\mathfrak{Q}_{1}%
=\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right)  $. Let $\mathfrak{Q}_{2}\in\mathbf{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $ be the polynomial defined by
$\mathfrak{Q}_{2}=\sum\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi
,i}\left(  \alpha_{1},\alpha_{2},...,\alpha_{i}\right)  \cdot
\operatorname*{Td}\nolimits_{\psi,j-i}\left(  \alpha_{1},\alpha_{2}%
,...,\alpha_{j-i}\right)  $. We are now going to prove that $\mathfrak{Q}%
_{1}=\mathfrak{Q}_{2}$.

Applying Theorem 4.1 \textbf{(a)} to $K=\mathbf{Z}$, $m=j$ and
$P=\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  $, we conclude that there exists one and only one
polynomial $Q\in\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]
$ such that $\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  X_{1}%
,X_{2},...,X_{j}\right)  =Q\left(  X_{1},X_{2},...,X_{j}\right)  $. In
particular, there exists \textit{at most one} such polynomial $Q\in
\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $. Hence,
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{if }\mathfrak{Q}_{1}\in\mathbf{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right]  \text{ and }\mathfrak{Q}_{2}\in\mathbf{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \text{ are two polynomials}\\
\text{such that }\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(
X_{1},X_{2},...,X_{j}\right)  =\mathfrak{Q}_{1}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \text{ and}\\
\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  X_{1},X_{2},...,X_{j}%
\right)  =\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{j}\right)  \text{, then
}\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
\end{array}
\right)  . \label{10.8.pf.2}%
\end{equation}


Since our two polynomials $\mathfrak{Q}_{1}$ and $\mathfrak{Q}_{2}$ satisfy%
\[
\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{j}\right)  =\operatorname*{Td}%
\nolimits_{\varphi\psi,j}\left(  X_{1},X_{2},...,X_{j}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{1}=\operatorname*{Td}%
\nolimits_{\varphi\psi,j}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j}\right)
\right)
\]
and%
\begin{align*}
\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{j}\right)   &  =\sum_{i=0}%
^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(  X_{1},X_{2},...,X_{i}%
\right)  \cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(  X_{1}%
,X_{2},...,X_{j-i}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{2}=\sum
\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(  \alpha
_{1},\alpha_{2},...,\alpha_{i}\right)  \cdot\operatorname*{Td}\nolimits_{\psi
,j-i}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j-i}\right)  \right) \\
&  =\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the 2nd Step}\right)
,
\end{align*}
we can conclude from (\ref{10.8.pf.2}) that $\mathfrak{Q}_{1}=\mathfrak{Q}%
_{2}$. Hence,%
\[
\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right)  =\mathfrak{Q}_{1}=\mathfrak{Q}_{2}=\sum
\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(  \alpha
_{1},\alpha_{2},...,\alpha_{i}\right)  \cdot\operatorname*{Td}\nolimits_{\psi
,j-i}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j-i}\right)  .
\]
This proves Proposition 10.8.

\textit{Proof of Proposition 10.7.} \textit{1st Step:} For every
$j\in\mathbb{N}$, we have%
\begin{align*}
&  \operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)
\right) \\
&  =\sum\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{i}\left(  x\right)  \right)  \cdot\operatorname*{Td}\nolimits_{\psi
,j-i}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{j-i}\left(  x\right)  \right)  .
\end{align*}


\textit{Proof.} Let $j\in\mathbb{N}$. Since the polynomials
$\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right)  $ and $\sum\limits_{i=0}^{j}\operatorname*{Td}%
\nolimits_{\varphi,i}\left(  \alpha_{1},\alpha_{2},...,\alpha_{i}\right)
\cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j-i}\right)  $ are equal (by Proposition 10.8), their
evaluations at $\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{j}\left(  x\right)  \right)  $ must also be equal. But
since the evaluation of $\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(
\alpha_{1},\alpha_{2},...,\alpha_{j}\right)  $ at $\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)
\right)  $ is $\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \lambda
^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(
x\right)  \right)  $, whereas the evaluation of $\sum\limits_{i=0}%
^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{i}\right)  \cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(
\alpha_{1},\alpha_{2},...,\alpha_{j-i}\right)  $ at $\left(  \lambda
^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(
x\right)  \right)  $ is $\sum\limits_{i=0}^{j}\operatorname*{Td}%
\nolimits_{\varphi,i}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{i}\left(  x\right)  \right)  \cdot\operatorname*{Td}%
\nolimits_{\psi,j-i}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{j-i}\left(  x\right)  \right)  $, this yields that the
values $\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)
\right)  $ and $\sum\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi
,i}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{i}\left(  x\right)  \right)  \cdot\operatorname*{Td}%
\nolimits_{\psi,j-i}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{j-i}\left(  x\right)  \right)  $ are equal. This
proves the 1st step.

\textit{2nd Step:} Now let us prove Proposition 10.7.

Let $x\in K$. By (\ref{ToddDef}) (applied to $\varphi\psi$ instead of
$\varphi$), we have%
\[
\operatorname*{td}\nolimits_{\varphi\psi,T}\left(  x\right)  =\sum
_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{j}\left(  x\right)  \right)  T^{j}.
\]
But%
\begin{align*}
&  \underbrace{\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)
}_{\substack{=\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi
,j}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{j}\left(  x\right)  \right)  T^{j}\\\text{(by (\ref{ToddDef}))}%
}}\underbrace{\operatorname*{td}\nolimits_{\psi,T}\left(  x\right)
}_{\substack{=\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\psi
,j}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{j}\left(  x\right)  \right)  T^{j}\\\text{(by (\ref{ToddDef}),
applied to }\psi\text{ instead of }\varphi\text{)}}}\\
&  =\left(  \sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi
,j}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{j}\left(  x\right)  \right)  T^{j}\right)  \cdot\left(
\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\psi,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{j}\left(  x\right)  \right)  T^{j}\right) \\
&  =\sum\limits_{j\in\mathbb{N}}\underbrace{\left(  \sum\limits_{i=0}%
^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{i}\left(  x\right)
\right)  \cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(  \lambda^{1}\left(
x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda^{j-i}\left(  x\right)
\right)  \right)  }_{\substack{=\operatorname*{Td}\nolimits_{\varphi\psi
,j}\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)
,...,\lambda^{j}\left(  x\right)  \right)  \\\text{(by the 1st Step)}}}T^{j}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the product of two
formal power series}\right) \\
&  =\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{j}\left(  x\right)  \right)  T^{j}=\operatorname*{td}\nolimits_{\varphi
\psi,T}\left(  x\right)  .
\end{align*}
This proves Proposition 10.7.

An easy consequence of Proposition 10.7:

\begin{quote}
\textbf{Proposition 10.9.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $m\in\mathbb{N}$. For every $i\in\left\{
1,2,...,m\right\}  $, let $\varphi_{i}\in1+\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$. For every
$x\in K$, we have%
\[
\operatorname*{td}\nolimits_{\prod\limits_{i=1}^{m}\varphi_{i},T}\left(
x\right)  =\prod\limits_{i=1}^{m}\operatorname*{td}\nolimits_{\varphi_{i}%
,T}\left(  x\right)  .
\]



\end{quote}

\textit{Proof of Proposition 10.9.} This can be proven by induction over $m$.
The induction base (the case $m=0$) requires showing that $\operatorname*{td}%
\nolimits_{1,T}\left(  x\right)  =1$, but this follows from Proposition
10.3\footnote{In fact, Proposition 10.3 (applied to $u=0$) yields
$\operatorname*{td}\nolimits_{1+0t,T}\left(  x\right)  =\lambda_{0T}\left(
x\right)  $. Now $\lambda_{0T}\left(  x\right)  =\operatorname*{ev}%
\nolimits_{0T}\left(  \lambda_{T}\left(  x\right)  \right)  $. Since
$\operatorname*{ev}\nolimits_{0T}$ is the map $K\left[  \left[  T\right]
\right]  \rightarrow K\left[  \left[  T\right]  \right]  $ which sends every
power series to its constant term (viewed as a constant power series), we have
$\operatorname*{ev}\nolimits_{0T}\left(  \lambda_{T}\left(  x\right)  \right)
=\left(  \text{constant term of the power series }\lambda_{T}\left(  x\right)
\right)  =1$. Thus, $\operatorname*{td}\nolimits_{1,T}\left(  x\right)
=\operatorname*{td}\nolimits_{1+0t,T}\left(  x\right)  =\lambda_{0T}\left(
x\right)  =\operatorname*{ev}\nolimits_{0T}\left(  \lambda_{T}\left(
x\right)  \right)  =1$.}. The induction step is a straightforward application
of Proposition 10.7. Thus Proposition 10.9 is proven.

\subsection{$\operatorname*{td}\nolimits_{\varphi,T}$ takes sums into
products}

Our next goal is to show the following general property of $\operatorname*{td}%
\nolimits_{\varphi,T}$:

\begin{quote}
\textbf{Theorem 10.10.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ be a power series with constant term equal to $1$.
Let $x\in K$ and $y\in K$. Then, $\operatorname*{td}\nolimits_{\varphi
,T}\left(  x\right)  \cdot\operatorname*{td}\nolimits_{\varphi,T}\left(
y\right)  =\operatorname*{td}\nolimits_{\varphi,T}\left(  x+y\right)  $.
\end{quote}

How can we prove a theorem like this? By using Proposition 10.3, we could
prove it in the case of $\varphi$ being a polynomial of the form $1+ut$ with
$u\in\mathbf{Z}$. Using Proposition 10.9, we could therefore also prove it in
the case of $\varphi$ being a product of finitely many such polynomials.
However, the case of $\varphi$ being a general power series does not directly
follow from any of our above-proven propositions. Not even the case of
$\varphi$ being a general polynomial - in fact, a general polynomial does not
always factor into polynomials of the form $1+ut$ with $u\in\mathbf{Z}$.

However, we can prove Theorem 10.10 (and similar results) using the following
two tricks: First, we need a kind of continuity (similar to the one we used in
Section 5) to reduce the case of $\varphi$ a power series to the case of
$\varphi$ a polynomial. Second, we need to split every arbitrary polynomial
$\varphi$ with constant term equal to $1$ into a product of polynomials of the
form $1+ut$; this will be done by an appropriate extension of the ring
$\mathbf{Z}$ (again, similarly to how we extended $K$ in Section 5). However,
these tricks do not yet give us a proof of Theorem 10.10 unless we change our
viewpoint to a more general one: Rather than working in a $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $, we work
with power series over an arbitrary ring. Here is what we do, precisely:

\subsection{The $\mathfrak{Todd}_{\varphi}$ map}

\begin{quote}
\textbf{Definition.} Let $\mathbf{Z}$ be a ring. Let $K$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$
be a power series with constant term equal to $1$. We define a map
$\mathfrak{Todd}_{\varphi}:K\left[  \left[  T\right]  \right]  \rightarrow
K\left[  \left[  T\right]  \right]  $ by
\begin{equation}
\mathfrak{Todd}_{\varphi}\left(  p\right)  =\sum\limits_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{j}p\right)  T^{j}\ \ \ \ \ \ \ \ \ \ \text{for every }p\in K\left[
\left[  T\right]  \right]  . \label{ToddFrak}%
\end{equation}



\end{quote}

The reason why we can consider this a generalization of the $\varphi$-Todd
homomorphism is the following:

\begin{quote}
\textbf{Proposition 10.11.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ be a power series with constant term equal to $1$.
Then, every $x\in K$ satisfies $\operatorname*{td}_{\varphi,T}\left(
x\right)  =\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  x\right)
\right)  $.
\end{quote}

\textit{Proof of Proposition 10.11.} Let $x\in K$. Then, $\lambda_{T}\left(
x\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}$, so
that every $k\in\mathbb{N}$ satisfies $\operatorname*{Coeff}\nolimits_{k}%
\left(  \lambda_{T}\left(  x\right)  \right)  =\operatorname*{Coeff}%
\nolimits_{k}\left(  \sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  x\right)
T^{i}\right)  =\lambda^{k}\left(  x\right)  $ (by the definition of
$\operatorname*{Coeff}\nolimits_{k}$). Thus, $\left(  \operatorname*{Coeff}%
\nolimits_{1}\left(  \lambda_{T}\left(  x\right)  \right)
,\operatorname*{Coeff}\nolimits_{2}\left(  \lambda_{T}\left(  x\right)
\right)  ,...,\operatorname*{Coeff}\nolimits_{j}\left(  \lambda_{T}\left(
x\right)  \right)  \right)  =\left(  \lambda^{1}\left(  x\right)  ,\lambda
^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)  \right)  $ for every
$j\in\mathbb{N}$. Now, (\ref{ToddFrak}) (applied to $p=\lambda_{T}\left(
x\right)  $) yields%
\begin{align*}
&  \mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  x\right)  \right) \\
&  =\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\operatorname*{Coeff}\nolimits_{1}\left(  \lambda_{T}\left(  x\right)
\right)  ,\operatorname*{Coeff}\nolimits_{2}\left(  \lambda_{T}\left(
x\right)  \right)  ,...,\operatorname*{Coeff}\nolimits_{j}\left(  \lambda
_{T}\left(  x\right)  \right)  \right)  T^{j}\\
&  =\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{j}\left(  x\right)  \right)  T^{j}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left(  \operatorname*{Coeff}%
\nolimits_{1}\left(  \lambda_{T}\left(  x\right)  \right)
,\operatorname*{Coeff}\nolimits_{2}\left(  \lambda_{T}\left(  x\right)
\right)  ,...,\operatorname*{Coeff}\nolimits_{j}\left(  \lambda_{T}\left(
x\right)  \right)  \right)  =\left(  \lambda^{1}\left(  x\right)  ,\lambda
^{2}\left(  x\right)  ,...,\lambda^{j}\left(  x\right)  \right)  \right) \\
&  =\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  .
\end{align*}
This proves Proposition 10.11.

Now let us generalize our above results about $\operatorname*{td}%
\nolimits_{\varphi,T}$ to results about $\mathfrak{Todd}_{\varphi}$. This will
be rather easy since our proofs generalize.

Here comes the generalization of Proposition 10.3:

\begin{quote}
\textbf{Proposition 10.12.} Let $\mathbf{Z}$ be a ring. Let $K$ be a
$\mathbf{Z}$-algebra. Let $u\in\mathbf{Z}$. Let $p\in1+K\left[  \left[
T\right]  \right]  ^{+}$. Then, $\mathfrak{Todd}_{1+ut}\left(  p\right)
=\operatorname*{ev}\nolimits_{uT}\left(  p\right)  $.\ \ \ \ \footnote{Let us
recall that $\operatorname*{ev}\nolimits_{uT}$ denotes the map $K\left[
\left[  T\right]  \right]  \rightarrow K\left[  \left[  T\right]  \right]  $
defined by%
\[
\operatorname*{ev}\nolimits_{uT}\left(  \sum\limits_{i\in\mathbb{N}}a_{i}%
T^{i}\right)  =\sum\limits_{i\in\mathbb{N}}a_{i}u^{i}T^{i}%
\ \ \ \ \ \ \ \ \ \ \text{for every power series }\sum\limits_{i\in\mathbb{N}%
}a_{i}T^{i}\in K\left[  \left[  T\right]  \right]  \text{ (with }a_{i}\in
K\text{ for every }i\text{).}%
\]
}
\end{quote}

\textit{Proof of Proposition 10.12.} The coefficient of the power series $p$
before $T^{0}$ is $1$ (since $p\in1+K\left[  \left[  T\right]  \right]  ^{+}%
$). In other words, $\operatorname*{Coeff}\nolimits_{0}p=1$ (since
$\operatorname*{Coeff}\nolimits_{0}p$ is defined as the coefficient of the
power series $p$ before $T^{0}$).

For every $j\in\mathbb{N}$, the coefficient of $p$ before $T^{j}$ is
$\operatorname*{Coeff}\nolimits_{j}p$. Hence, $p=\sum\limits_{j\in\mathbb{N}%
}\left(  \operatorname*{Coeff}\nolimits_{j}p\right)  \cdot T^{j}$. Thus,
\begin{align*}
\operatorname*{ev}\nolimits_{uT}p  &  =\operatorname*{ev}\nolimits_{uT}\left(
\sum\limits_{j\in\mathbb{N}}\left(  \operatorname*{Coeff}\nolimits_{j}%
p\right)  \cdot T^{j}\right)  =\sum\limits_{j\in\mathbb{N}}\left(
\operatorname*{Coeff}\nolimits_{j}p\right)  \cdot u^{j}T^{j}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\operatorname*{ev}%
\nolimits_{uT}\right) \\
&  =\sum_{j\in\mathbb{N}}u^{j}\left(  \operatorname*{Coeff}\nolimits_{j}%
p\right)  T^{j}=\underbrace{u^{0}}_{=1}\underbrace{\left(
\operatorname*{Coeff}\nolimits_{0}p\right)  }_{=1}T^{0}+\sum_{\substack{j\in
\mathbb{N};\\j>0}}u^{j}\left(  \operatorname*{Coeff}\nolimits_{j}p\right)
T^{j}=1T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}u^{j}\left(
\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}.
\end{align*}
Compared with%
\begin{align*}
&  \mathfrak{Todd}_{1+ut}\left(  p\right) \\
&  =\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{1+ut,j}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{ToddFrak}), applied to }%
\varphi=1+ut\right) \\
&  =\underbrace{\operatorname*{Td}\nolimits_{1+ut,0}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{0}p\right)  }%
_{\substack{=\operatorname*{Td}\nolimits_{1+ut,0}=1\\\text{(by Proposition
10.6 \textbf{(a)},}\\\text{applied to }\varphi=1+ut\text{)}}}T^{0}%
+\sum_{\substack{j\in\mathbb{N};\\j>0}}\underbrace{\operatorname*{Td}%
\nolimits_{1+ut,j}}_{\substack{=u^{j}\alpha_{j}\\\text{(by Proposition 10.4)}%
}}\left(  \operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}%
\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}\\
&  =1T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}\underbrace{\left(
u^{j}\alpha_{j}\right)  \left(  \operatorname*{Coeff}\nolimits_{1}%
p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}%
p\right)  }_{=u^{j}\left(  \operatorname*{Coeff}\nolimits_{j}p\right)  }%
T^{j}=1T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}}u^{j}\left(
\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j},
\end{align*}
this yields that $\operatorname*{ev}\nolimits_{uT}p=\mathfrak{Todd}%
_{1+ut}\left(  p\right)  $. This proves Proposition 10.12.

Next, the generalization of Proposition 10.5:

\begin{quote}
\textbf{Proposition 10.13.} Let $\mathbf{Z}$ be a ring. Let $K$ be a
$\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$. Let $p\in
K\left[  \left[  T\right]  \right]  $.

\textbf{(a)} Then, $\operatorname*{Coeff}\nolimits_{0}\left(  \mathfrak{Todd}%
_{\varphi}\left(  p\right)  \right)  =1$.

\textbf{(b)} Let $\varphi_{1}$ be the coefficient of the power series
$\varphi\in\mathbf{Z}\left[  \left[  t\right]  \right]  $ before $t^{1}$.
Then, $\operatorname*{Coeff}\nolimits_{1}\left(  \mathfrak{Todd}_{\varphi
}\left(  p\right)  \right)  =\varphi_{1}\operatorname*{Coeff}\nolimits_{1}p$.
\end{quote}

\textit{Proof of Proposition 10.13.} \textbf{(a)} We have%
\begin{align*}
&  \operatorname*{Coeff}\nolimits_{0}\left(  \mathfrak{Todd}_{\varphi}\left(
p\right)  \right) \\
&  =\operatorname*{Coeff}\nolimits_{0}\left(  \sum_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{j}p\right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{ToddFrak})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,0}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{0}p\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
}\operatorname*{Coeff}\nolimits_{0}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,0}=1\ \ \ \ \ \ \ \ \ \ \left(
\text{by Proposition 10.6 \textbf{(a)}}\right)  .
\end{align*}


\textbf{(b)} We have%
\begin{align*}
&  \operatorname*{Coeff}\nolimits_{1}\left(  \mathfrak{Todd}_{\varphi}\left(
p\right)  \right) \\
&  =\operatorname*{Coeff}\nolimits_{1}\left(  \sum_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{j}p\right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{ToddDef})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,1}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{1}p\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of
}\operatorname*{Coeff}\nolimits_{1}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,1}\left(  \operatorname*{Coeff}%
\nolimits_{1}p\right)  =\varphi_{1}\operatorname*{Coeff}\nolimits_{1}p\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since Proposition 10.6 \textbf{(b)}
yields }\operatorname*{Td}\nolimits_{\varphi,1}=\varphi_{1}\alpha_{1}\right)
.
\end{align*}


Proposition 10.13 is now proven.

Our next generalization is that of Proposition 10.7:

\begin{quote}
\textbf{Proposition 10.14.} Let $\mathbf{Z}$ be a ring. Let $K$ be a
$\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$ and $\psi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]
^{+}$ be two power series with constant terms equal to $1$. Let $p\in K\left[
\left[  T\right]  \right]  $. Then, $\mathfrak{Todd}_{\varphi\psi}\left(
p\right)  =\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}%
_{\psi}\left(  p\right)  $.
\end{quote}

\textit{Proof of Proposition 10.14.} For every $j\in\mathbb{N}$, we will
abbreviate $\operatorname*{Coeff}\nolimits_{j}p$ by $p_{j}$. Then, $\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  =\left(  p_{1}%
,p_{2},...,p_{j}\right)  $.

\textit{1st Step:} For every $j\in\mathbb{N}$, we have%
\[
\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  p_{1},p_{2},...,p_{j}%
\right)  =\sum\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(
p_{1},p_{2},...,p_{i}\right)  \cdot\operatorname*{Td}\nolimits_{\psi
,j-i}\left(  p_{1},p_{2},...,p_{j-i}\right)  .
\]


\textit{Proof.} Let $j\in\mathbb{N}$. Since the polynomials
$\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right)  $ and $\sum\limits_{i=0}^{j}\operatorname*{Td}%
\nolimits_{\varphi,i}\left(  \alpha_{1},\alpha_{2},...,\alpha_{i}\right)
\cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j-i}\right)  $ are equal (by Proposition 10.8), their
evaluations at $\left(  p_{1},p_{2},...,p_{j}\right)  $ must also be equal.
But since the evaluation of $\operatorname*{Td}\nolimits_{\varphi\psi
,j}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j}\right)  $ at $\left(
p_{1},p_{2},...,p_{j}\right)  $ is $\operatorname*{Td}\nolimits_{\varphi
\psi,j}\left(  p_{1},p_{2},...,p_{j}\right)  $, whereas the evaluation of
$\sum\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(
\alpha_{1},\alpha_{2},...,\alpha_{i}\right)  \cdot\operatorname*{Td}%
\nolimits_{\psi,j-i}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j-i}\right)  $
at $\left(  p_{1},p_{2},...,p_{j}\right)  $ is $\sum\limits_{i=0}%
^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(  p_{1},p_{2},...,p_{i}%
\right)  \cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(  p_{1}%
,p_{2},...,p_{j-i}\right)  $, this yields that the values $\operatorname*{Td}%
\nolimits_{\varphi\psi,j}\left(  p_{1},p_{2},...,p_{j}\right)  $ and
$\sum\limits_{i=0}^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(
p_{1},p_{2},...,p_{i}\right)  \cdot\operatorname*{Td}\nolimits_{\psi
,j-i}\left(  p_{1},p_{2},...,p_{j-i}\right)  $ are equal. This proves the 1st step.

\textit{2nd Step:} Now let us prove Proposition 10.14.

By (\ref{ToddFrak}) (applied to $\varphi\psi$ instead of $\varphi$), we have%
\begin{align*}
\mathfrak{Todd}_{\varphi\psi}\left(  p\right)   &  =\sum\limits_{j\in
\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi\psi,j}\underbrace{\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  }_{=\left(  p_{1}%
,p_{2},...,p_{j}\right)  }T^{j}\\
&  =\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(
p_{1},p_{2},...,p_{j}\right)  T^{j}.
\end{align*}
But%
\begin{align*}
&  \underbrace{\mathfrak{Todd}_{\varphi}\left(  p\right)  }_{\substack{=\sum
\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}\\\text{(by
(\ref{ToddFrak}))}}}\underbrace{\mathfrak{Todd}_{\psi}\left(  p\right)
}_{\substack{=\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\psi
,j}\left(  \operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}%
\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}%
\\\text{(by (\ref{ToddFrak}), applied to }\psi\text{ instead of }%
\varphi\text{)}}}\\
&  =\left(  \sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi
,j}\underbrace{\left(  \operatorname*{Coeff}\nolimits_{1}%
p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}%
p\right)  }_{=\left(  p_{1},p_{2},...,p_{j}\right)  }T^{j}\right)
\cdot\left(  \sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\psi
,j}\underbrace{\left(  \operatorname*{Coeff}\nolimits_{1}%
p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}%
p\right)  }_{=\left(  p_{1},p_{2},...,p_{j}\right)  }T^{j}\right) \\
&  =\left(  \sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi
,j}\left(  p_{1},p_{2},...,p_{j}\right)  T^{j}\right)  \cdot\left(
\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\psi,j}\left(
p_{1},p_{2},...,p_{j}\right)  T^{j}\right) \\
&  =\sum\limits_{j\in\mathbb{N}}\underbrace{\left(  \sum\limits_{i=0}%
^{j}\operatorname*{Td}\nolimits_{\varphi,i}\left(  p_{1},p_{2},...,p_{i}%
\right)  \cdot\operatorname*{Td}\nolimits_{\psi,j-i}\left(  p_{1}%
,p_{2},...,p_{j-i}\right)  \right)  }_{\substack{=\operatorname*{Td}%
\nolimits_{\varphi\psi,j}\left(  p_{1},p_{2},...,p_{j}\right)  \\\text{(by the
1st Step)}}}T^{j}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the product of two
formal power series}\right) \\
&  =\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi\psi,j}\left(
p_{1},p_{2},...,p_{j}\right)  T^{j}=\mathfrak{Todd}_{\varphi\psi}\left(
p\right)  .
\end{align*}
This proves Proposition 10.14.

Next, Proposition 10.9 generalizes to the following result:

\begin{quote}
\textbf{Proposition 10.15.} Let $\mathbf{Z}$ be a ring. Let $K$ be a
$\mathbf{Z}$-algebra. Let $m\in\mathbb{N}$. For every $i\in\left\{
1,2,...,m\right\}  $, let $\varphi_{i}\in1+\mathbf{Z}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$. Let $p\in
K\left[  \left[  T\right]  \right]  $. Then,%
\[
\mathfrak{Todd}_{\prod\limits_{i=1}^{m}\varphi_{i}}\left(  p\right)
=\prod\limits_{i=1}^{m}\mathfrak{Todd}_{\varphi_{i}}\left(  p\right)  .
\]



\end{quote}

\textit{Proof of Proposition 10.15.} This can be proven by induction over $m$.
The induction base (the case $m=0$) requires showing that $\mathfrak{Todd}%
_{1}\left(  p\right)  =1$, but this is easy\footnote{\textit{Proof.} Applying
(\ref{ToddFrak}) to $\varphi=1$, we obtain%
\begin{align*}
&  \mathfrak{Todd}_{1}\left(  p\right)  =\sum\limits_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{1,j}\left(  \operatorname*{Coeff}\nolimits_{1}%
p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}%
p\right)  T^{j}\\
&  =\underbrace{\operatorname*{Td}\nolimits_{1,0}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{0}p\right)  }_{\substack{=\operatorname*{Td}\nolimits_{1,0}%
=1\\\text{(by Proposition 10.6 \textbf{(a)},}\\\text{applied to }%
\varphi=1\text{)}}}T^{0}+\sum_{\substack{j\in\mathbb{N};\\j>0}%
}\underbrace{\operatorname*{Td}\nolimits_{1,j}}_{\substack{=\operatorname*{Td}%
\nolimits_{1+0t,j}=0^{j}\alpha_{j}\\\text{(by Proposition 10.4,}%
\\\text{applied to }u=0\text{)}}}\left(  \operatorname*{Coeff}\nolimits_{1}%
p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}%
p\right)  T^{j}\\
&  =\underbrace{1T^{0}}_{=1}+\sum_{\substack{j\in\mathbb{N};\\j>0}%
}\underbrace{0^{j}}_{\substack{=0\\\text{(since }j>0\text{)}}}\alpha
_{j}\left(  \operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}%
\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}\\
&  =1+\underbrace{\sum_{\substack{j\in\mathbb{N};\\j>0}}0\alpha_{j}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}}_{=0}=1.
\end{align*}
}. The induction step is a straightforward application of Proposition 10.14.
Thus Proposition 10.15 is proven.

We now formulate our generalization of Theorem 10.10 - it is through this
generalization that we are going to prove Theorem 10.10:

\begin{quote}
\textbf{Theorem 10.16.} Let $\mathbf{Z}$ be a ring. Let $K$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$
be a power series with constant term equal to $1$. Let $p\in1+K\left[  \left[
T\right]  \right]  ^{+}$ and $q\in1+K\left[  \left[  T\right]  \right]  ^{+}$.
Then, $\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}%
_{\varphi}\left(  q\right)  =\mathfrak{Todd}_{\varphi}\left(  pq\right)  $.
\end{quote}

To prove this theorem, we first reduce it to the case when $K=\mathbf{Z}$:

\begin{quote}
\textbf{Lemma 10.17.} Let $K$ be a ring. Let $\varphi\in1+K\left[  \left[
t\right]  \right]  ^{+}$ be a power series with constant term equal to $1$.
Let $p\in1+K\left[  \left[  T\right]  \right]  ^{+}$ and $q\in1+K\left[
\left[  T\right]  \right]  ^{+}$. Then, $\mathfrak{Todd}_{\varphi}\left(
p\right)  \cdot\mathfrak{Todd}_{\varphi}\left(  q\right)  =\mathfrak{Todd}%
_{\varphi}\left(  pq\right)  $.
\end{quote}

We will now prepare to the proof of this lemma. First, let us introduce the
version of continuity that we need.

\subsection{Preparing for the proof of Lemma 10.17}

The following two definitions are copies of two definitions which we made in
Section 5, with the only difference that the variable that used to be $T$ in
Section 5 is called $t$ here.

\begin{quote}
\textbf{Definition.} Let $K$ be a ring. Let $K\left[  t\right]  ^{+}$ be the
subset of $K\left[  t\right]  $ defined by%
\begin{align*}
K\left[  t\right]  ^{+}  &  =tK\left[  t\right]  =\left\{  \sum_{i\in
\mathbb{N}}a_{i}t^{i}\in K\left[  t\right]  \ \mid\ a_{i}\in K\text{ for all
}i,\text{ and }a_{0}=0\right\} \\
&  =\left\{  p\in K\left[  t\right]  \ \mid\ p\text{ is a polynomial with
constant term }0\right\}  .
\end{align*}
Then, the set $1+K\left[  t\right]  ^{+}$ is a subset of $1+K\left[  \left[
t\right]  \right]  ^{+}.$ The elements of $1+K\left[  t\right]  ^{+}$ are polynomials.

\textbf{Definition.} Let $K$ be a ring. As a $K$-module, $K\left[  \left[
t\right]  \right]  =\bigoplus\limits_{k\in\mathbb{N}}Kt^{k}$. Now, we define
the so-called $\left(  t\right)  $\textit{-topology} on the ring $K\left[
\left[  t\right]  \right]  $ as the topology generated by%
\[
\left\{  u+\sum_{k\geq N}Kt^{k}\ \mid\ u\in K\left[  \left[  t\right]
\right]  \text{ and }N\in\mathbb{N}\right\}  .
\]
In other words, the open sets of this topology should be all translates of the
submodules $\sum\limits_{k\geq N}Kt^{k}$ for $N\in\mathbb{N}$, as well as the
unions of these sets\footnote{This includes the empty union, which is
$\varnothing$.}. (Note that the sum $\sum\limits_{k\geq N}Kt^{k}$ is actually
a direct sum. Also note that every translate of the submodule $\sum
\limits_{k\geq N}Kt^{k}$ for $N\in\mathbb{N}$ actually has the form
$p+\sum\limits_{k\geq N}Kt^{k}$ for a polynomial $p\in K\left[  t\right]  $ of
degree $<N$, and this polynomial is uniquely determined.)
\end{quote}

Now, we have:

\begin{quote}
\textbf{Theorem 10.18.} Let $K$ be a ring. The $\left(  t\right)  $-topology
on the ring $K\left[  \left[  t\right]  \right]  $ restricts to a topology on
its subset $1+K\left[  \left[  t\right]  \right]  ^{+}$; we call this topology
the $\left(  t\right)  $\textit{-topology} again. Whenever we say "open",
"continuous", "dense", etc., we are referring to this topology.

\textbf{(a)} The subset $1+K\left[  t\right]  ^{+}$ is dense in $1+K\left[
\left[  t\right]  \right]  ^{+}$.

\textbf{(b)} Let $f:1+K\left[  \left[  t\right]  \right]  ^{+}\rightarrow
K\left[  \left[  T\right]  \right]  $ be a map such that for every
$n\in\mathbb{N}$ there exists some $N\in\mathbb{N}$ such that the first $n$
coefficients of the image of a formal power series under $f$ depend only on
the first $N$ coefficients of the series itself (and not on the remaining
ones). Then, $f$ is continuous. (Here, the topology on $K\left[  \left[
T\right]  \right]  $ is supposed to be the $\left(  T\right)  $-topology
defined in Section 5.)

\textbf{(c)} The topological spaces $K\left[  \left[  t\right]  \right]  $ and
$1+K\left[  \left[  t\right]  \right]  ^{+}$ are Hausdorff spaces.
\end{quote}

\textit{Proof of Theorem 10.18.} The parts \textbf{(a)} and \textbf{(c)} of
Theorem 10.18 are obviously obtained from the parts \textbf{(a)} and
\textbf{(e)} of Theorem 5.5 by renaming the variable $T$ as $t$. Hence, they
follow from Theorem 5.5. Part \textbf{(b)} of Theorem 10.18 is also true (it
is an exercise in topology, proven in the same way as Theorem 5.5
\textbf{(b)}). This proves Theorem 10.18.

The good thing about the topology on $1+K\left[  \left[  t\right]  \right]
^{+}$ just defined is that it makes the map $1+K\left[  \left[  t\right]
\right]  ^{+}\rightarrow K\left[  \left[  T\right]  \right]  $, $\varphi
\mapsto\mathfrak{Todd}_{\varphi}\left(  p\right)  $ continuous for every given
$p\in K\left[  \left[  T\right]  \right]  $:

\begin{quote}
\textbf{Proposition 10.19.} Let $K$ be a ring. Let $p\in K\left[  \left[
T\right]  \right]  $. Then, the map%
\[
1+K\left[  \left[  t\right]  \right]  ^{+}\rightarrow K\left[  \left[
T\right]  \right]  ,\ \ \ \ \ \ \ \ \ \ \varphi\mapsto\mathfrak{Todd}%
_{\varphi}\left(  p\right)
\]
is continuous. Here, the topology on $1+K\left[  \left[  t\right]  \right]
^{+}$ is supposed to be the $\left(  t\right)  $-topology, and the topology on
$K\left[  \left[  T\right]  \right]  $ is supposed to be the $\left(
T\right)  $-topology defined in Section 5.
\end{quote}

\textit{Proof of Proposition 10.19.} Let $f$ denote the map
\[
1+K\left[  \left[  t\right]  \right]  ^{+}\rightarrow K\left[  \left[
T\right]  \right]  ,\ \ \ \ \ \ \ \ \ \ \varphi\mapsto\mathfrak{Todd}%
_{\varphi}\left(  p\right)  .
\]
Then, in order to verify Proposition 10.19, we must prove that this map $f$ is continuous.

\textit{1st Step:} Let $n\in\mathbb{N}$. Let $\varphi\in1+K\left[  \left[
t\right]  \right]  ^{+}$ and $\psi\in1+K\left[  \left[  t\right]  \right]
^{+}$ be two power series such that the first $n$ coefficients\footnote{Note
that when we say "the first $n$ coefficients" (of some power series), we mean
the coefficients before $t^{0}$, $t^{1}$, $...$, $t^{n-1}$.} of $\varphi$ are
equal to the respective coefficients of $\psi$. Then, the first $n$
coefficients of the power series $\mathfrak{Todd}_{\varphi}\left(  p\right)  $
are equal to the respective coefficients of the power series $\mathfrak{Todd}%
_{\psi}\left(  p\right)  $.

\textit{Proof.} Let $m\in\left\{  0,1,...,n-1\right\}  $ be arbitrary.

Since the first $n$ coefficients of the power series $\varphi$ are equal to
the respective coefficients of the power series $\psi$, we have $\varphi
\equiv\psi\operatorname{mod}t^{n}$ in the ring $K\left[  \left[  t\right]
\right]  $. Thus, there exists some formal power series $\eta\in K\left[
\left[  t\right]  \right]  $ such that $\varphi-\psi=\eta t^{n}$. Consider
such an $\eta$.

Consider the polynomial ring $K\left[  U_{1},U_{2},...,U_{m}\right]  $ and its
elements $X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ as in the
definition of $\operatorname*{Td}\nolimits_{\varphi,j}$.

Every $i\in\left\{  1,2,...,m\right\}  $ satisfies%
\begin{align*}
\varphi\left(  U_{i}T\right)  -\psi\left(  U_{i}T\right)   &
=\underbrace{\left(  \varphi-\psi\right)  }_{=\eta t^{n}}\left(
U_{i}T\right)  =\left(  \eta t^{n}\right)  \left(  U_{i}T\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{where }\left(  \eta t^{n}\right)  \left(  U_{i}T\right)  \text{ means
the application of the formal}\\
\text{power series }\eta t^{n}\in K\left[  \left[  t\right]  \right]  \text{
to }U_{i}T\text{, and not a product of }\eta t^{n}\\
\text{with }U_{i}T\text{ (whatever that could mean)}%
\end{array}
\right) \\
&  =\eta\left(  U_{i}T\right)  \cdot\underbrace{\left(  U_{i}T\right)  ^{n}%
}_{=U_{i}^{n}T^{n}}=\eta\left(  U_{i}T\right)  \cdot U_{i}^{n}T^{n}%
\end{align*}
and thus $T^{n}\mid\varphi\left(  U_{i}T\right)  -\psi\left(  U_{i}T\right)
$, so that $\varphi\left(  U_{i}T\right)  \equiv\psi\left(  U_{i}T\right)
\operatorname{mod}T^{n}$ in the ring $\left(  K\left[  U_{1},U_{2}%
,...,U_{m}\right]  \right)  \left[  \left[  T\right]  \right]  $. Multiplying
the congruences $\varphi\left(  U_{i}T\right)  \equiv\psi\left(
U_{i}T\right)  \operatorname{mod}T^{n}$ for all $i\in\left\{
1,2,...,m\right\}  $, we obtain $\prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \equiv\prod\limits_{i=1}^{m}\psi\left(  U_{i}T\right)
\operatorname{mod}T^{n}$. In other words, the first $n$ coefficients of the
power series $\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  $ are equal
to the respective coefficients of the power series $\prod\limits_{i=1}^{m}%
\psi\left(  U_{i}T\right)  $. In other words, every $k\in\left\{
0,1,...,n-1\right\}  $ satisfies $\operatorname*{Coeff}\nolimits_{k}\left(
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)
=\operatorname*{Coeff}\nolimits_{k}\left(  \prod\limits_{i=1}^{m}\psi\left(
U_{i}T\right)  \right)  $. Applied to $k=m$, this yields
$\operatorname*{Coeff}\nolimits_{m}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)  =\operatorname*{Coeff}\nolimits_{m}%
\left(  \prod\limits_{i=1}^{m}\psi\left(  U_{i}T\right)  \right)  $.

According to Theorem 10.1, the equation (\ref{Td1}) holds in the ring $\left(
K\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \left[  T\right]
\right]  $. Thus,%
\begin{align*}
\operatorname*{Coeff}\nolimits_{m}\left(  \prod\limits_{i=1}^{m}\varphi\left(
U_{i}T\right)  \right)   &  =\operatorname*{Coeff}\nolimits_{m}\left(
\sum_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
X_{1},X_{2},...,X_{j}\right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by (\ref{Td1})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,m}\left(  X_{1},X_{2},...,X_{m}%
\right)  .
\end{align*}
The same argument, but applied to $\psi$ instead of $\varphi$, yields%
\[
\operatorname*{Coeff}\nolimits_{m}\left(  \prod\limits_{i=1}^{m}\psi\left(
U_{i}T\right)  \right)  =\operatorname*{Td}\nolimits_{\psi,m}\left(
X_{1},X_{2},...,X_{m}\right)  .
\]
Thus,%
\[
\operatorname*{Td}\nolimits_{\varphi,m}\left(  X_{1},X_{2},...,X_{m}\right)
=\operatorname*{Coeff}\nolimits_{m}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)  =\operatorname*{Coeff}\nolimits_{m}%
\left(  \prod\limits_{i=1}^{m}\psi\left(  U_{i}T\right)  \right)
=\operatorname*{Td}\nolimits_{\psi,m}\left(  X_{1},X_{2},...,X_{m}\right)  .
\]


We will now use this to prove $\operatorname*{Td}\nolimits_{\varphi
,m}=\operatorname*{Td}\nolimits_{\psi,m}$.

In fact, let $\mathfrak{Q}_{1}\in K\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{m}\right]  $ be the polynomial defined by $\mathfrak{Q}%
_{1}=\operatorname*{Td}\nolimits_{\varphi,m}$. Let $\mathfrak{Q}_{2}\in
K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $ be the polynomial
defined by $\mathfrak{Q}_{2}=\operatorname*{Td}\nolimits_{\psi,m}$. We are now
going to prove that $\mathfrak{Q}_{1}=\mathfrak{Q}_{2}$.

Applying Theorem 4.1 \textbf{(a)} to $\operatorname*{Td}\nolimits_{\varphi
,m}\left(  X_{1},X_{2},...,X_{m}\right)  $ instead of $P$, we conclude that
there exists one and only one polynomial $Q\in K\left[  \alpha_{1},\alpha
_{2},...,\alpha_{m}\right]  $ such that $\operatorname*{Td}\nolimits_{\varphi
,m}\left(  X_{1},X_{2},...,X_{m}\right)  =Q\left(  X_{1},X_{2},...,X_{m}%
\right)  $. In particular, there exists \textit{at most one} such polynomial
$Q\in K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $. Hence,
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{if }\mathfrak{Q}_{1}\in K\left[  \alpha_{1},\alpha_{2},...,\alpha
_{m}\right]  \text{ and }\mathfrak{Q}_{2}\in K\left[  \alpha_{1},\alpha
_{2},...,\alpha_{m}\right]  \text{ are two polynomials}\\
\text{such that }\operatorname*{Td}\nolimits_{\varphi,m}\left(  X_{1}%
,X_{2},...,X_{m}\right)  =\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{m}%
\right)  \text{ and}\\
\operatorname*{Td}\nolimits_{\varphi,m}\left(  X_{1},X_{2},...,X_{m}\right)
=\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{m}\right)  \text{, then
}\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
\end{array}
\right)  . \label{10.11.pf.1}%
\end{equation}


Since our two polynomials $\mathfrak{Q}_{1}$ and $\mathfrak{Q}_{2}$ satisfy%
\[
\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{m}\right)  =\operatorname*{Td}%
\nolimits_{\varphi,m}\left(  X_{1},X_{2},...,X_{m}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{1}=\operatorname*{Td}%
\nolimits_{\varphi,m}\right)
\]
and%
\begin{align*}
\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{m}\right)   &  =\operatorname*{Td}%
\nolimits_{\psi,m}\left(  X_{1},X_{2},...,X_{m}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{2}=\operatorname*{Td}%
\nolimits_{\psi,m}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,m}\left(  X_{1},X_{2},...,X_{m}%
\right)  ,
\end{align*}
we can conclude from (\ref{10.11.pf.1}) that $\mathfrak{Q}_{1}=\mathfrak{Q}%
_{2}$. Hence, $\operatorname*{Td}\nolimits_{\varphi,m}=\mathfrak{Q}%
_{1}=\mathfrak{Q}_{2}=\operatorname*{Td}\nolimits_{\psi,m}$.

Now,%
\begin{align*}
\operatorname*{Coeff}\nolimits_{m}\left(  \mathfrak{Todd}_{\varphi}\left(
p\right)  \right)   &  =\operatorname*{Coeff}\nolimits_{m}\left(
\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{ToddFrak})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,m}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{m}p\right)  .
\end{align*}
The same argument, applied to $\psi$ instead of $\varphi$, yields%
\[
\operatorname*{Coeff}\nolimits_{m}\left(  \mathfrak{Todd}_{\psi}\left(
p\right)  \right)  =\operatorname*{Td}\nolimits_{\psi,m}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{m}p\right)  .
\]
Thus,%
\begin{align*}
\operatorname*{Coeff}\nolimits_{m}\left(  \mathfrak{Todd}_{\varphi}\left(
p\right)  \right)   &  =\underbrace{\operatorname*{Td}\nolimits_{\varphi,m}%
}_{=\operatorname*{Td}\nolimits_{\psi,m}}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{m}p\right) \\
&  =\operatorname*{Td}\nolimits_{\psi,m}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{m}p\right)  =\operatorname*{Coeff}\nolimits_{m}\left(
\mathfrak{Todd}_{\psi}\left(  p\right)  \right)  .
\end{align*}


So we have proven that $\operatorname*{Coeff}\nolimits_{m}\left(
\mathfrak{Todd}_{\varphi}\left(  p\right)  \right)  =\operatorname*{Coeff}%
\nolimits_{m}\left(  \mathfrak{Todd}_{\psi}\left(  p\right)  \right)  $ for
every $m\in\left\{  0,1,...,n-1\right\}  $. In other words, for every
$m\in\left\{  0,1,...,n-1\right\}  $, the $m$-th coefficient of the power
series $\mathfrak{Todd}_{\varphi}\left(  p\right)  $ equals the respective
coefficient of the power series $\mathfrak{Todd}_{\psi}\left(  p\right)  $. In
other words, the first $n$ coefficients of the power series $\mathfrak{Todd}%
_{\varphi}\left(  p\right)  $ are equal to the respective coefficients of the
power series $\mathfrak{Todd}_{\psi}\left(  p\right)  $.

This proves the 1st Step.

\textit{2nd Step:} Let $n\in\mathbb{N}$. Let $\varphi\in1+K\left[  \left[
t\right]  \right]  ^{+}$ and $\psi\in1+K\left[  \left[  t\right]  \right]
^{+}$ be two power series such that the first $n$ coefficients\footnote{Note
that when we say "the first $n$ coefficients" (of some power series), we mean
the coefficients before $t^{0}$, $t^{1}$, $...$, $t^{n-1}$.} of $\varphi$ are
equal to the respective coefficients of $\psi$. Then, the first $n$
coefficients of the power series $f\left(  \varphi\right)  $ are equal to the
respective coefficients of the power series $f\left(  \psi\right)  $.

\textit{Proof.} This is just an equivalent restatement of the 1st Step, since
$f\left(  \varphi\right)  =\mathfrak{Todd}_{\varphi}\left(  p\right)  $ (by
the definition of $f$) and $f\left(  \psi\right)  =\mathfrak{Todd}_{\psi
}\left(  p\right)  $ (by the definition of $f$).

\textit{3rd Step:} We can rewrite the result of the 2nd Step as follows: If,
for some $n\in\mathbb{N}$, two power series $\varphi$ and $\psi$ in
$1+K\left[  \left[  t\right]  \right]  ^{+}$ have the same first $n$
coefficients (i. e., the first $n$ coefficients of $\varphi$ are equal to the
respective coefficients of $\psi$), then the images $f\left(  \varphi\right)
$ and $f\left(  \psi\right)  $ of these two power series under $\varphi$ also
have the same first $n$ coefficients. In other words, for every $n\in
\mathbb{N}$, the first $n$ coefficients of the image of a formal power series
under $f$ depend only on the first $n$ coefficients of the series itself (and
not on the remaining ones).

Hence, for every $n\in\mathbb{N}$, there exists some $N\in\mathbb{N}$ such
that the first $n$ coefficients of the image of a formal power series under
$f$ depend only on the first $N$ coefficients of the series itself (and not on
the remaining ones)\footnote{Namely, we can take $N=n$.}. According to Theorem
10.18 \textbf{(b)}, this yields that $f$ is continuous.

Since $f$ was defined as the map%
\[
1+K\left[  \left[  t\right]  \right]  ^{+}\rightarrow K\left[  \left[
T\right]  \right]  ,\ \ \ \ \ \ \ \ \ \ \varphi\mapsto\mathfrak{Todd}%
_{\varphi}\left(  p\right)  ,
\]
this shows that the map%
\[
1+K\left[  \left[  t\right]  \right]  ^{+}\rightarrow K\left[  \left[
T\right]  \right]  ,\ \ \ \ \ \ \ \ \ \ \varphi\mapsto\mathfrak{Todd}%
_{\varphi}\left(  p\right)
\]
is continuous. Proposition 10.19 is thus proven.

So much for the topology on $1+K\left[  \left[  t\right]  \right]  ^{+}$. We
now discuss extensions of $K$ that make polynomials factor.

By renaming the polynomial $p$ as $\varphi$ and the variable $T$ as $t$ in
Theorem 5.2, we obtain the following fact:

\begin{quote}
\textbf{Theorem 10.20.} Let $K$ be a ring. For every element $\varphi
\in1+K\left[  t\right]  ^{+}$, there exists an integer $n$ (the degree of the
polynomial $\varphi$), a finite-free extension ring $K_{\varphi}$ of the ring
$K$ and $n$ elements $p_{1},$ $p_{2},$ $...,$ $p_{n}$ of this extension ring
$K_{\varphi}$ such that $\varphi=\prod\limits_{i=1}^{n}\left(  1+p_{i}%
t\right)  $ in $K_{\varphi}\left[  t\right]  $.
\end{quote}

\subsection{Proof of Lemma 10.17}

Now, finally, to the proof of Lemma 10.17:

\textit{Proof of Lemma 10.17.} Fix $p\in1+K\left[  \left[  T\right]  \right]
^{+}$ and $q\in1+K\left[  \left[  T\right]  \right]  ^{+}$, but let
$\varphi\in1+K\left[  \left[  t\right]  \right]  ^{+}$ vary.

\textit{1st Step:} For every $\varphi\in1+K\left[  t\right]  ^{+}$, we have
$\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}_{\varphi
}\left(  q\right)  =\mathfrak{Todd}_{\varphi}\left(  pq\right)  $.

\textit{Proof.} Assume that $\varphi\in1+K\left[  t\right]  ^{+}$. According
to Theorem 10.20, there exists an integer $n$ (the degree of the polynomial
$\varphi$), a finite-free extension ring $K_{\varphi}$ of the ring $K$ and $n$
elements $p_{1},$ $p_{2},$ $...,$ $p_{n}$ of this extension ring $K_{\varphi}$
such that $\varphi=\prod\limits_{i=1}^{n}\left(  1+p_{i}t\right)  $ in
$K_{\varphi}\left[  t\right]  $. Consider this ring $K_{\varphi}$ and these
$n$ elements $p_{1},$ $p_{2},$ $...,$ $p_{n}$.

Since $K$ is a subring of $K_{\varphi}$, we can canonically view the ring
$K\left[  t\right]  $ as a subring of $K_{\varphi}\left[  t\right]  $, and
similarly we can view the ring $K\left[  \left[  t\right]  \right]  $ as a
subring of $K_{\varphi}\left[  \left[  t\right]  \right]  $, and we can view
the ring $K\left[  \left[  T\right]  \right]  $ as a subring of $K_{\varphi
}\left[  \left[  T\right]  \right]  $.

Here is a trivial observation that we will tacitly use: For every $r\in
K\left[  \left[  T\right]  \right]  $, the value of the term $\mathfrak{Todd}%
_{\varphi}\left(  r\right)  $ does not depend on whether we interpret
$\varphi$ as an element of $1+K\left[  t\right]  ^{+}$ or as an element of
$1+K_{\varphi}\left[  t\right]  ^{+}$, and also does not depend on whether we
interpret $r$ as an element of $K\left[  \left[  T\right]  \right]  $ or as an
element of $K_{\varphi}\left[  \left[  T\right]  \right]  $. This is because
the definition of $\mathfrak{Todd}_{\varphi}\left(  r\right)  $ was functorial
both in $\mathbf{Z}$ and in $K$.

Let $r\in1+K\left[  \left[  T\right]  \right]  ^{+}$ be arbitrary. Proposition
10.15 (applied to $r$, $K_{\varphi}$, $K_{\varphi}$, $n$ and $1+p_{i}t$
instead of $p$, $K$, $\mathbf{Z}$, $m$ and $\varphi_{i}$) yields that
$\mathfrak{Todd}_{\prod\limits_{i=1}^{n}\left(  1+p_{i}t\right)  }\left(
r\right)  =\prod\limits_{i=1}^{n}\mathfrak{Todd}_{1+p_{i}t}\left(  r\right)
$. Since $\prod\limits_{i=1}^{n}\left(  1+p_{i}t\right)  =\varphi$, this
rewrites as%
\begin{equation}
\mathfrak{Todd}_{\varphi}\left(  r\right)  =\prod\limits_{i=1}^{n}%
\underbrace{\mathfrak{Todd}_{1+p_{i}t}\left(  r\right)  }%
_{\substack{=\operatorname*{ev}\nolimits_{p_{i}T}\left(  r\right)  \\\text{(by
Proposition 10.12,}\\\text{applied to }K_{\varphi}\text{, }K_{\varphi}\text{,
}r\text{ and }p_{i}\\\text{instead of }\mathbf{Z}\text{, }K\text{, }p\text{
and }u\text{)}}}=\prod\limits_{i=1}^{n}\operatorname*{ev}\nolimits_{p_{i}%
T}\left(  r\right)  . \label{10.20.pf.1}%
\end{equation}
Applying (\ref{10.20.pf.1}) to $r=p$, we obtain $\mathfrak{Todd}_{\varphi
}\left(  p\right)  =\prod\limits_{i=1}^{n}\operatorname*{ev}\nolimits_{p_{i}%
T}\left(  p\right)  $. Applying (\ref{10.20.pf.1}) to $r=q$, we obtain
$\mathfrak{Todd}_{\varphi}\left(  q\right)  =\prod\limits_{i=1}^{n}%
\operatorname*{ev}\nolimits_{p_{i}T}\left(  q\right)  $. Applying
(\ref{10.20.pf.1}) to $r=pq$, we obtain
\begin{align*}
\mathfrak{Todd}_{\varphi}\left(  pq\right)   &  =\prod\limits_{i=1}%
^{n}\underbrace{\operatorname*{ev}\nolimits_{p_{i}T}\left(  pq\right)
}_{\substack{=\operatorname*{ev}\nolimits_{p_{i}T}\left(  p\right)
\cdot\operatorname*{ev}\nolimits_{p_{i}T}\left(  q\right)  \\\text{(since
}\operatorname*{ev}\nolimits_{p_{i}T}\text{ is a ring}\\\text{homomorphism)}%
}}=\prod\limits_{i=1}^{n}\left(  \operatorname*{ev}\nolimits_{p_{i}T}\left(
p\right)  \cdot\operatorname*{ev}\nolimits_{p_{i}T}\left(  q\right)  \right)
=\underbrace{\prod\limits_{i=1}^{n}\operatorname*{ev}\nolimits_{p_{i}T}\left(
p\right)  }_{=\mathfrak{Todd}_{\varphi}\left(  p\right)  }\cdot
\underbrace{\prod\limits_{i=1}^{n}\operatorname*{ev}\nolimits_{p_{i}T}\left(
q\right)  }_{=\mathfrak{Todd}_{\varphi}\left(  q\right)  }\\
&  =\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}_{\varphi
}\left(  q\right)  .
\end{align*}
This proves the 1st Step.

\textit{2nd Step:} Let $\mathfrak{f}_{1}:1+K\left[  \left[  t\right]  \right]
^{+}\rightarrow K\left[  \left[  T\right]  \right]  $ be the map which sends
every $\varphi\in1+K\left[  \left[  t\right]  \right]  ^{+}$ to
$\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}_{\varphi
}\left(  q\right)  $.

Let $\mathfrak{f}_{2}:1+K\left[  \left[  t\right]  \right]  ^{+}\rightarrow
K\left[  \left[  T\right]  \right]  $ be the map which sends every $\varphi
\in1+K\left[  \left[  t\right]  \right]  ^{+}$ to $\mathfrak{Todd}_{\varphi
}\left(  pq\right)  $.

These maps $\mathfrak{f}_{1}$ and $\mathfrak{f}_{2}$ are equal to each other
on a dense subset of $1+K\left[  \left[  t\right]  \right]  ^{+}$.

\textit{Proof.} Every $\varphi\in1+K\left[  t\right]  ^{+}$ satisfies
$\mathfrak{f}_{1}\left(  \varphi\right)  =\mathfrak{Todd}_{\varphi}\left(
p\right)  \cdot\mathfrak{Todd}_{\varphi}\left(  q\right)  $ (by the definition
of $\mathfrak{f}_{1}$) and $\mathfrak{f}_{2}\left(  \varphi\right)
=\mathfrak{Todd}_{\varphi}\left(  pq\right)  $ (by the definition of
$\mathfrak{f}_{2}$). Thus, every $\varphi\in1+K\left[  t\right]  ^{+}$
satisfies%
\begin{align*}
\mathfrak{f}_{1}\left(  \varphi\right)   &  =\mathfrak{Todd}_{\varphi}\left(
p\right)  \cdot\mathfrak{Todd}_{\varphi}\left(  q\right)  =\mathfrak{Todd}%
_{\varphi}\left(  pq\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the 1st
Step}\right) \\
&  =\mathfrak{f}_{2}\left(  \varphi\right)  .
\end{align*}
In other words, the maps $\mathfrak{f}_{1}$ and $\mathfrak{f}_{2}$ are equal
to each other on the subset $1+K\left[  t\right]  ^{+}$. Since $1+K\left[
t\right]  ^{+}$ is a dense subset of $1+K\left[  \left[  t\right]  \right]
^{+}$ (by Theorem 10.18 \textbf{(a)}), this yields that the maps
$\mathfrak{f}_{1}$ and $\mathfrak{f}_{2}$ are equal to each other on a dense
subset of $1+K\left[  \left[  t\right]  \right]  ^{+}$. This proves the 2nd Step.

\textit{3rd Step:} Consider the maps $\mathfrak{f}_{1}$ and $\mathfrak{f}_{2}$
defined in the 2nd Step.

The map $1+K\left[  \left[  t\right]  \right]  ^{+}\rightarrow K\left[
\left[  T\right]  \right]  $, $\varphi\mapsto\mathfrak{Todd}_{\varphi}\left(
p\right)  $ is continuous (by Proposition 10.19), and the map $1+K\left[
\left[  t\right]  \right]  ^{+}\rightarrow K\left[  \left[  T\right]  \right]
$, $\varphi\mapsto\mathfrak{Todd}_{\varphi}\left(  q\right)  $ is continuous
(by Proposition 10.19, applied to $q$ instead of $p$). The pointwise product
of these two maps is the map $1+K\left[  \left[  t\right]  \right]
^{+}\rightarrow K\left[  \left[  T\right]  \right]  $, $\varphi\mapsto
\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}_{\varphi
}\left(  q\right)  $; this is clearly the map $\mathfrak{f}_{1}$. Hence, we
see that the map $\mathfrak{f}_{1}$ is the pointwise product of two continuous
maps. Thus, the map $\mathfrak{f}_{1}$ itself is continuous (because the
multiplication map $K\left[  \left[  T\right]  \right]  \times K\left[
\left[  T\right]  \right]  \rightarrow K\left[  \left[  T\right]  \right]  $
is continuous, and therefore the pointwise product of two continuous maps to
$K\left[  \left[  T\right]  \right]  $ must be continuous itself).

On the other hand, the map $\mathfrak{f}_{2}$ equals the map $1+K\left[
\left[  t\right]  \right]  ^{+}\rightarrow K\left[  \left[  T\right]  \right]
$, $\varphi\mapsto\mathfrak{Todd}_{\varphi}\left(  pq\right)  $, and this map
is continuous (by Proposition 10.19, applied to $pq$ instead of $p$). We thus
see that the map $\mathfrak{f}_{2}$ is continuous.

Recall the known fact that if two continuous maps from a topological space
$\mathfrak{P}$ to a Hausdorff topological space $\mathfrak{Q}$ are equal to
each other on a dense subset of $\mathfrak{P}$, then they are equal to each
other on the whole $\mathfrak{P}$. Applying this to the two continuous maps
$\mathfrak{f}_{1}$ and $\mathfrak{f}_{2}$ from the topological space
$1+K\left[  \left[  t\right]  \right]  ^{+}$ to the Hausdorff topological
space $K\left[  \left[  T\right]  \right]  $, we conclude that the maps
$\mathfrak{f}_{1}$ and $\mathfrak{f}_{2}$ are equal to each other on the whole
$1+K\left[  \left[  t\right]  \right]  ^{+}$ (because we know from the 2nd
Step that they are equal to each other on a dense subset of $1+K\left[
\left[  t\right]  \right]  ^{+}$).

In other words, every $\varphi\in1+K\left[  \left[  t\right]  \right]  ^{+}$
satisfies $\mathfrak{f}_{1}\left(  \varphi\right)  =\mathfrak{f}_{2}\left(
\varphi\right)  $. Since every $\varphi\in1+K\left[  \left[  t\right]
\right]  ^{+}$ satisfies $\mathfrak{f}_{1}\left(  \varphi\right)
=\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}_{\varphi
}\left(  q\right)  $ (by the definition of $\mathfrak{f}_{1}$) and
$\mathfrak{f}_{2}\left(  \varphi\right)  =\mathfrak{Todd}_{\varphi}\left(
pq\right)  $ (by the definition of $\mathfrak{f}_{2}$), this rewrites as
follows: Every $\varphi\in1+K\left[  \left[  t\right]  \right]  ^{+}$
satisfies $\mathfrak{Todd}_{\varphi}\left(  p\right)  \cdot\mathfrak{Todd}%
_{\varphi}\left(  q\right)  =\mathfrak{Todd}_{\varphi}\left(  pq\right)  $.
This proves Lemma 10.17.

\subsection{Preparing for the proof of Theorem 10.16: some trivial
functoriality facts}

We next have to will derive Theorem 10.16 from Lemma 10.17. This requires a
very easy proposition and its corollary:

\begin{quote}
\textbf{Proposition 10.21.} Let $\mathbf{Z}$ and $\mathbf{Z}^{\prime}$ be two
rings, and let $\rho:\mathbf{Z}\rightarrow\mathbf{Z}^{\prime}$ be a ring
homomorphism. Let $j\in\mathbb{N}$. Clearly, the ring homomorphism
$\rho:\mathbf{Z}\rightarrow\mathbf{Z}^{\prime}$ canonically induces a ring
homomorphism $\rho\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]
:\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \rightarrow
\mathbf{Z}^{\prime}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $ and
a ring homomorphism $\rho\left[  \left[  t\right]  \right]  :\mathbf{Z}\left[
\left[  t\right]  \right]  \rightarrow\mathbf{Z}^{\prime}\left[  \left[
t\right]  \right]  $. It is also clear that the latter homomorphism
$\rho\left[  \left[  t\right]  \right]  $ maps the subset $1+\mathbf{Z}\left[
\left[  t\right]  \right]  ^{+}$ to the subset $1+\mathbf{Z}^{\prime}\left[
\left[  t\right]  \right]  ^{+}$.

Every $\varphi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$
satisfies $\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  ,j}=\rho\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{j}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\right)  $.
\end{quote}

All that this proposition tells us is that the object $\operatorname*{Td}%
\nolimits_{\varphi,j}$ is canonical with respect to the ring $\mathbf{Z}$. You
may consider this obvious (it does, indeed, become obvious if you add to
Theorem 4.1 \textbf{(a)} the additional assertion that the polynomial $Q$, for
fixed $P$, is canonical with respect to the ring $K$); if you do so, then you
can immediately continue to Corollary 10.22. Here is, however, an alternative
proof of Proposition 10.21 which does not resort to this kind of handwaving:

\textit{Proof of Proposition 10.21.} Let $\varphi\in1+\mathbf{Z}\left[
\left[  t\right]  \right]  ^{+}$.

Let $m=j$. We are going to work in the ring $\mathbf{Z}^{\prime}\left[
U_{1},U_{2},...,U_{m}\right]  =\mathbf{Z}^{\prime}\left[  U_{1},U_{2}%
,...,U_{j}\right]  $. Note that the ring homomorphism $\rho:\mathbf{Z}%
\rightarrow\mathbf{Z}^{\prime}$ canonically induces a ring homomorphism
$\rho\left[  U_{1},U_{2},...,U_{m}\right]  :\mathbf{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  \rightarrow\mathbf{Z}^{\prime}\left[  U_{1}%
,U_{2},...,U_{m}\right]  $. Also note that%
\[
\left(  \rho\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \left(
\operatorname*{Td}\nolimits_{\varphi,j}\right)  \right)  \left(  X_{1}%
,X_{2},...,X_{j}\right)  =\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(
\operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)
\right)  .
\]
\footnote{\textit{Proof.} Let $\rho^{\prime}=\rho\left[  U_{1},U_{2}%
,...,U_{m}\right]  $. Then, $\rho^{\prime}$ is the ring homomorphism
$\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \rightarrow\mathbf{Z}%
^{\prime}\left[  U_{1},U_{2},...,U_{m}\right]  $ canonically induced by the
ring homomorphism $\rho:\mathbf{Z}\rightarrow\mathbf{Z}^{\prime}$. Hence,
$\rho^{\prime}$ is a $\mathbf{Z}$-algebra homomorphism (where $\mathbf{Z}%
^{\prime}$ becomes a $\mathbf{Z}$-algebra by virtue of the ring homomorphism
$\rho:\mathbf{Z}\rightarrow\mathbf{Z}^{\prime}$) satisfying $\rho^{\prime
}\left(  U_{k}\right)  =U_{k}$ for every $k\in\left\{  1,2,...,m\right\}  $.
Thus,%
\begin{align*}
\rho^{\prime}\left(  X_{i}\right)   &  =\rho^{\prime}\left(  \sum
\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }X_{i}=\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}\right) \\
&  =\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}\underbrace{\rho^{\prime}\left(
U_{k}\right)  }_{=U_{k}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\rho^{\prime
}\text{ is a }\mathbf{Z}\text{-algebra homomorphism}\right) \\
&  =\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}U_{k}=X_{i}%
\end{align*}
for every $i\in\mathbb{N}$. Thus, $\left(  \rho^{\prime}\left(  X_{1}\right)
,\rho^{\prime}\left(  X_{2}\right)  ,...,\rho^{\prime}\left(  X_{j}\right)
\right)  =\left(  X_{1},X_{2},...,X_{j}\right)  $.
\par
Since $\rho^{\prime}$ is a $\mathbf{Z}$-algebra homomorphism and
$\operatorname*{Td}\nolimits_{\varphi,j}$ is a polynomial over $\mathbf{Z}$,
we have $\rho^{\prime}\left(  \operatorname*{Td}\nolimits_{\varphi,j}\left(
X_{1},X_{2},...,X_{j}\right)  \right)  =\operatorname*{Td}\nolimits_{\varphi
,j}\left(  \rho^{\prime}\left(  X_{1}\right)  ,\rho^{\prime}\left(
X_{2}\right)  ,...,\rho^{\prime}\left(  X_{j}\right)  \right)  $ (because
$\mathbf{Z}$-algebra homomorphisms commute with polynomials over $\mathbf{Z}%
$).
\par
On the other hand, whenever $U\in\mathbf{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right]  $ is a polynomial and $x_{1}$, $x_{2}$, $...$,
$x_{j}$ are $j$ elements of a commutative $\mathbf{Z}^{\prime}$-algebra, we
have $\left(  \rho\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \left(
U\right)  \right)  \left(  x_{1},x_{2},...,x_{j}\right)  =U\left(  x_{1}%
,x_{2},...,x_{j}\right)  $ (because this is more or less how $U\left(
x_{1},x_{2},...,x_{j}\right)  $ is defined). Applied to $U=\operatorname*{Td}%
\nolimits_{\varphi,j}$ and $x_{k}=X_{k}$, this yields%
\begin{align*}
\left(  \rho\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \left(
\operatorname*{Td}\nolimits_{\varphi,j}\right)  \right)  \left(  X_{1}%
,X_{2},...,X_{j}\right)   &  =\operatorname*{Td}\nolimits_{\varphi
,j}\underbrace{\left(  X_{1},X_{2},...,X_{j}\right)  }_{=\left(  \rho^{\prime
}\left(  X_{1}\right)  ,\rho^{\prime}\left(  X_{2}\right)  ,...,\rho^{\prime
}\left(  X_{j}\right)  \right)  }\\
&  =\operatorname*{Td}\nolimits_{\varphi,j}\left(  \rho^{\prime}\left(
X_{1}\right)  ,\rho^{\prime}\left(  X_{2}\right)  ,...,\rho^{\prime}\left(
X_{j}\right)  \right) \\
&  =\underbrace{\rho^{\prime}}_{=\rho\left[  U_{1},U_{2},...,U_{m}\right]
}\left(  \operatorname*{Td}\nolimits_{\varphi,j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \right) \\
&  =\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)  \right)  ,
\end{align*}
qed.}

The ring homomorphism $\rho\left[  U_{1},U_{2},...,U_{m}\right]
:\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \rightarrow\mathbf{Z}%
^{\prime}\left[  U_{1},U_{2},...,U_{m}\right]  $ canonically induces a ring
homomorphism $\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left[  \left[
T\right]  \right]  :\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \left[
\left[  T\right]  \right]  \rightarrow\mathbf{Z}^{\prime}\left[  U_{1}%
,U_{2},...,U_{m}\right]  \left[  \left[  T\right]  \right]  $ which is
continuous with respect to the $\left(  T\right)  $-topology. By definition of
this ring homomorphism, the diagram%
\[
\xymatrixcolsep{6pc}\xymatrix{
\mathbf Z\left[U_1,U_2,...,U_m\right]\left[\left[T\right]\right] \ar[r]^{\operatorname*{Coeff}_j} \ar[d]_{\rho\left[U_1,U_2,...,U_m\right]\left[\left[T\right]\right]} & \mathbf Z\left[U_1,U_2,...,U_m\right] \ar[d]^{\rho\left[U_1,U_2,...,U_m\right]} \\
\mathbf Z^{\prime}\left[U_1,U_2,...,U_m\right]\left[\left[T\right]\right] \ar[r]^{\operatorname*{Coeff}_j} & \mathbf Z^{\prime}\left[U_1,U_2,...,U_m\right]
}
\]
commutes. Hence,
\[
\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(  \operatorname*{Coeff}%
\nolimits_{j}\left(  \prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)
\right)  \right)  =\operatorname*{Coeff}\nolimits_{j}\left(  \rho\left[
U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]  \right]  \left(
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)  \right)  .
\]


Also,
\[
\underbrace{\operatorname*{Td}\nolimits_{\varphi,j}}%
_{\substack{=\operatorname*{Todd}\nolimits_{\left(  \varphi,j\right)
,j,\left[  j\right]  }\\=\operatorname*{Todd}\nolimits_{\left(  \varphi
,j\right)  ,j,\left[  m\right]  }\\\text{(since }j=m\text{)}}}\left(
X_{1},X_{2},...,X_{j}\right)  =\operatorname*{Todd}\nolimits_{\left(
\varphi,j\right)  ,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
=\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}%
\varphi\left(  U_{i}T\right)  \right)
\]
(by (\ref{10.1.pf.1})), so that%
\begin{align}
\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)  \right)   &
=\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(  \operatorname*{Coeff}%
\nolimits_{j}\left(  \prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)
\right)  \right) \nonumber\\
&  =\operatorname*{Coeff}\nolimits_{j}\left(  \rho\left[  U_{1},U_{2}%
,...,U_{m}\right]  \left[  \left[  T\right]  \right]  \left(  \prod
\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)  \right)  .
\label{10.21.pf.3}%
\end{align}


The map $\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]
\right]  $ is a $\mathbf{Z}$-algebra homomorphism continuous with respect to
the $\left(  T\right)  $-topology. Hence, it commutes with power series over
$\mathbf{Z}$. Thus, for every $i\in\left\{  1,2,...,m\right\}  $, we have%
\[
\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]  \right]
\left(  \varphi\left(  U_{i}T\right)  \right)  =\varphi\left(  \rho\left[
U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]  \right]  \left(
U_{i}T\right)  \right)  .
\]
Since $\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]
\right]  \left(  U_{i}T\right)  =U_{i}T$ (because the map $\rho\left[
U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]  \right]  $ is a ring
homomorphism which (by its definition) maps $U_{i}$ to $U_{i}$ and $T$ to
$T$), this simplifies to%
\[
\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]  \right]
\left(  \varphi\left(  U_{i}T\right)  \right)  =\varphi\left(  U_{i}T\right)
=\left(  \left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  \right)  \left(  U_{i}T\right)  .
\]
Now,%
\begin{align*}
\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left[  \left[  T\right]  \right]
\left(  \prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  \right)   &
=\prod\limits_{i=1}^{m}\underbrace{\rho\left[  U_{1},U_{2},...,U_{m}\right]
\left[  \left[  T\right]  \right]  \left(  \varphi\left(  U_{i}T\right)
\right)  }_{=\left(  \left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  \right)  \left(  U_{i}T\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\rho\left[  U_{1},U_{2}%
,...,U_{m}\right]  \left[  \left[  T\right]  \right]  \text{ is a ring
homomorphism}\right) \\
&  =\prod\limits_{i=1}^{m}\left(  \left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  \right)  \left(  U_{i}T\right)  ,
\end{align*}
so that (\ref{10.21.pf.3}) becomes%
\[
\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)  \right)
=\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}\left(
\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(  \varphi
\right)  \right)  \left(  U_{i}T\right)  \right)  .
\]
Compared with%
\begin{align*}
\underbrace{\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  ,j}}%
_{\substack{=\operatorname*{Todd}\nolimits_{\left(  \left(  \rho\left[
\left[  t\right]  \right]  \right)  \left(  \varphi\right)  ,j\right)
,j,\left[  j\right]  }\\=\operatorname*{Todd}\nolimits_{\left(  \left(
\rho\left[  \left[  t\right]  \right]  \right)  \left(  \varphi\right)
,j\right)  ,j,\left[  m\right]  }\\\text{(since }j=m\text{)}}}\left(
X_{1},X_{2},...,X_{j}\right)   &  =\operatorname*{Todd}\nolimits_{\left(
\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(  \varphi
\right)  ,j\right)  ,j,\left[  m\right]  }\left(  X_{1},X_{2},...,X_{j}\right)
\\
&  =\operatorname*{Coeff}\nolimits_{j}\left(  \prod\limits_{i=1}^{m}\left(
\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(  \varphi
\right)  \right)  \left(  U_{i}T\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{10.1.pf.1}), applied to }\left(
\rho\left[  \left[  t\right]  \right]  \right)  \left(  \varphi\right)  \text{
instead of }\varphi\right)  ,
\end{align*}
this yields%
\begin{equation}
\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)  \right)
=\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]
\right)  \left(  \varphi\right)  ,j}\left(  X_{1},X_{2},...,X_{j}\right)  .
\label{10.21.pf.5}%
\end{equation}


Let $\mathfrak{Q}_{1}\in\mathbf{Z}^{\prime}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right]  $ be the polynomial defined by $\mathfrak{Q}%
_{1}=\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  ,j}$. Let $\mathfrak{Q}_{2}%
\in\mathbf{Z}^{\prime}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $
be the polynomial defined by $\mathfrak{Q}_{2}=\rho\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{j}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\right)  $. We are now going to prove that $\mathfrak{Q}%
_{1}=\mathfrak{Q}_{2}$.

Applying Theorem 4.1 \textbf{(a)} to $K=\mathbf{Z}^{\prime}$, $m=j$ and
$P=\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]
\right)  \left(  \varphi\right)  ,j}\left(  X_{1},X_{2},...,X_{j}\right)  $,
we conclude that there exists one and only one polynomial $Q\in\mathbf{Z}%
^{\prime}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $ such that
$\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]
\right)  \left(  \varphi\right)  ,j}\left(  X_{1},X_{2},...,X_{j}\right)
=Q\left(  X_{1},X_{2},...,X_{j}\right)  $. In particular, there exists
\textit{at most one} such polynomial $Q\in\mathbf{Z}^{\prime}\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $. Hence,
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{if }\mathfrak{Q}_{1}\in\mathbf{Z}^{\prime}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right]  \text{ and }\mathfrak{Q}_{2}\in\mathbf{Z}^{\prime
}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \text{ are two
polynomials}\\
\text{such that }\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[
t\right]  \right]  \right)  \left(  \varphi\right)  ,j}\left(  X_{1}%
,X_{2},...,X_{j}\right)  =\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{j}%
\right)  \text{ and}\\
\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]
\right)  \left(  \varphi\right)  ,j}\left(  X_{1},X_{2},...,X_{j}\right)
=\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{j}\right)  \text{, then
}\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
\end{array}
\right)  . \label{10.21.pf.1}%
\end{equation}


Since our two polynomials $\mathfrak{Q}_{1}$ and $\mathfrak{Q}_{2}$ satisfy%
\[
\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{j}\right)  =\operatorname*{Td}%
\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  ,j}\left(  X_{1},X_{2},...,X_{j}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{1}=\operatorname*{Td}%
\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  ,j}\right)
\]
and%
\begin{align*}
\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{j}\right)   &  =\left(  \rho\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\right)  \right)  \left(  X_{1},X_{2},...,X_{j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{2}=\rho\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\right)  \right) \\
&  =\rho\left[  U_{1},U_{2},...,U_{m}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\left(  X_{1},X_{2},...,X_{j}\right)  \right) \\
&  =\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  ,j}\left(  X_{1},X_{2}%
,...,X_{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{10.21.pf.5}%
)}\right)  ,
\end{align*}
we can conclude from (\ref{10.21.pf.1}) that $\mathfrak{Q}_{1}=\mathfrak{Q}%
_{2}$. Hence,%
\[
\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]
\right)  \left(  \varphi\right)  ,j}=\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
=\rho\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \left(
\operatorname*{Td}\nolimits_{\varphi,j}\right)  .
\]
This proves Proposition 10.21.

\begin{quote}
\textbf{Corollary 10.22.} Let $\mathbf{Z}$ and $\mathbf{Z}^{\prime}$ be two
rings, and let $\rho:\mathbf{Z}\rightarrow\mathbf{Z}^{\prime}$ be a ring
homomorphism. Clearly, the ring homomorphism $\rho:\mathbf{Z}\rightarrow
\mathbf{Z}^{\prime}$ canonically induces a ring homomorphism $\rho\left[
\left[  t\right]  \right]  :\mathbf{Z}\left[  \left[  t\right]  \right]
\rightarrow\mathbf{Z}^{\prime}\left[  \left[  t\right]  \right]  $. It is also
clear that the latter homomorphism $\rho\left[  \left[  t\right]  \right]  $
maps the subset $1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ to the
subset $1+\mathbf{Z}^{\prime}\left[  \left[  t\right]  \right]  ^{+}$.

Let $K$ be a $\mathbf{Z}^{\prime}$-algebra. Then, $K$ also becomes a
$\mathbf{Z}$-algebra by virtue of the ring homomorphism $\rho$. Let
$\varphi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power
series with constant term equal to $1$.

Let $p\in K\left[  \left[  T\right]  \right]  $. Then, $\mathfrak{Todd}%
_{\varphi}\left(  p\right)  =\mathfrak{Todd}_{\left(  \rho\left[  \left[
t\right]  \right]  \right)  \left(  \varphi\right)  }\left(  p\right)  $.
\end{quote}

\textit{Proof of Corollary 10.22.} Clearly, the ring homomorphism
$\rho:\mathbf{Z}\rightarrow\mathbf{Z}^{\prime}$ canonically induces a ring
homomorphism $\rho\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]
:\mathbf{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \rightarrow
\mathbf{Z}^{\prime}\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $.

Let $j\in\mathbb{N}$. Since $K$ is a $\mathbf{Z}$-algebra by virtue of the
ring homomorphism $\rho$, the value of $\operatorname*{Td}\nolimits_{\varphi
,j}\left(  \operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}%
\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  $ is actually
defined as%
\[
\left(  \rho\left[  \alpha_{1},\alpha_{2},...,\alpha_{j}\right]  \left(
\operatorname*{Td}\nolimits_{\varphi,j}\right)  \right)  \left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)
\]
(since $\operatorname*{Td}\nolimits_{\varphi,j}$ itself is a polynomial over
$\mathbf{Z}$ rather than over $\mathbf{Z}^{\prime}$). Thus,%
\begin{align*}
\operatorname*{Td}\nolimits_{\varphi,j}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{j}p\right)   &  =\underbrace{\left(  \rho\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{j}\right]  \left(  \operatorname*{Td}%
\nolimits_{\varphi,j}\right)  \right)  }_{\substack{=\operatorname*{Td}%
\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  ,j}\\\text{(by Proposition 10.21)}}}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right) \\
&  =\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  ,j}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{j}p\right)  .
\end{align*}


Now, forget that we fixed $j$. By (\ref{ToddFrak}), we have%
\begin{align*}
\mathfrak{Todd}_{\varphi}\left(  p\right)   &  =\sum\limits_{j\in\mathbb{N}%
}\underbrace{\operatorname*{Td}\nolimits_{\varphi,j}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  }_{=\operatorname*{Td}%
\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  ,j}\left(  \operatorname*{Coeff}\nolimits_{1}%
p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}%
p\right)  }T^{j}\\
&  =\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\left(
\rho\left[  \left[  t\right]  \right]  \right)  \left(  \varphi\right)
,j}\left(  \operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}%
\nolimits_{2}p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  T^{j}.
\end{align*}


On the other hand, (\ref{ToddFrak}) (applied to $\mathbf{Z}^{\prime}$ and
$\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  $ instead of $\mathbf{Z}$ and $\varphi$) yields
\[
\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  }\left(  p\right)  =\sum\limits_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]
\right)  \left(  \varphi\right)  ,j}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{j}p\right)  T^{j}.
\]
Thus,%
\begin{align*}
\mathfrak{Todd}_{\varphi}\left(  p\right)   &  =\sum\limits_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\left(  \rho\left[  \left[  t\right]  \right]
\right)  \left(  \varphi\right)  ,j}\left(  \operatorname*{Coeff}%
\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}p,...,\operatorname*{Coeff}%
\nolimits_{j}p\right)  T^{j}\\
&  =\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  }\left(  p\right)  .
\end{align*}
This proves Corollary 10.22.

\subsection{Proof of Theorems 10.16 and 10.10}

\textit{Proof of Theorem 10.16.} Since $K$ is a $\mathbf{Z}$-algebra, there is
a canonical ring homomorphism $\rho:\mathbf{Z}\rightarrow K$. This
homomorphism induces a canonical ring homomorphism $\rho\left[  \left[
t\right]  \right]  :\mathbf{Z}\left[  \left[  t\right]  \right]  \rightarrow
K\left[  \left[  t\right]  \right]  $, which maps the subset $1+\mathbf{Z}%
\left[  \left[  t\right]  \right]  ^{+}$ to $1+K\left[  \left[  t\right]
\right]  ^{+}$. Thus, $\left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  \in1+K\left[  \left[  t\right]  \right]  ^{+}$ (since
$\varphi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$).

Corollary 10.22 yields $\mathfrak{Todd}_{\varphi}\left(  p\right)
=\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  }\left(  p\right)  $. Corollary 10.22 (applied to $q$
instead of $p$) yields $\mathfrak{Todd}_{\varphi}\left(  q\right)
=\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  }\left(  q\right)  $. Corollary 10.22 (applied to $pq$
instead of $p$) yields $\mathfrak{Todd}_{\varphi}\left(  pq\right)
=\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  }\left(  pq\right)  $. Lemma 10.17 (applied to
$\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  $ instead of $\varphi$) yields $\mathfrak{Todd}_{\left(
\rho\left[  \left[  t\right]  \right]  \right)  \left(  \varphi\right)
}\left(  p\right)  \cdot\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  }\left(  q\right)  =\mathfrak{Todd}%
_{\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  }\left(  pq\right)  $. Now,
\[
\underbrace{\mathfrak{Todd}_{\varphi}\left(  p\right)  }_{=\mathfrak{Todd}%
_{\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  }\left(  p\right)  }\cdot\underbrace{\mathfrak{Todd}_{\varphi
}\left(  q\right)  }_{=\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]
\right]  \right)  \left(  \varphi\right)  }\left(  q\right)  }=\mathfrak{Todd}%
_{\left(  \rho\left[  \left[  t\right]  \right]  \right)  \left(
\varphi\right)  }\left(  p\right)  \cdot\mathfrak{Todd}_{\left(  \rho\left[
\left[  t\right]  \right]  \right)  \left(  \varphi\right)  }\left(  q\right)
=\mathfrak{Todd}_{\left(  \rho\left[  \left[  t\right]  \right]  \right)
\left(  \varphi\right)  }\left(  pq\right)  =\mathfrak{Todd}_{\varphi}\left(
pq\right)  .
\]
Theorem 10.16 is thus proven.

\textit{Proof of Theorem 10.10.} Theorem 2.1 \textbf{(a)} yields $\lambda
_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)  =\lambda_{T}\left(
x+y\right)  $ (since $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ is a $\lambda$-ring). Proposition 10.11 yields $\operatorname*{td}%
_{\varphi,T}\left(  x\right)  =\mathfrak{Todd}_{\varphi}\left(  \lambda
_{T}\left(  x\right)  \right)  $. Proposition 10.11 (applied to $y$ instead of
$x$) yields $\operatorname*{td}_{\varphi,T}\left(  y\right)  =\mathfrak{Todd}%
_{\varphi}\left(  \lambda_{T}\left(  y\right)  \right)  $. Hence,%
\begin{align*}
&  \underbrace{\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)
}_{=\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  x\right)  \right)
}\cdot\underbrace{\operatorname*{td}\nolimits_{\varphi,T}\left(  y\right)
}_{=\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  y\right)  \right)
}=\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  x\right)  \right)
\cdot\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  y\right)  \right)
=\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  x\right)  \cdot
\lambda_{T}\left(  y\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 10.16, applied to }%
p=\lambda_{T}\left(  x\right)  \text{ and }q=\lambda_{T}\left(  y\right)
\right)  .
\end{align*}
Proposition 10.11 (applied to $x+y$ instead of $x$) yields%
\[
\operatorname*{td}\nolimits_{\varphi,T}\left(  x+y\right)  =\mathfrak{Todd}%
_{\varphi}\left(  \underbrace{\lambda_{T}\left(  x+y\right)  }%
_{\substack{=\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)
}}\right)  =\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  x\right)
\cdot\lambda_{T}\left(  y\right)  \right)  .
\]
Thus,%
\[
\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  \cdot
\operatorname*{td}\nolimits_{\varphi,T}\left(  y\right)  =\mathfrak{Todd}%
_{\varphi}\left(  \lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(
y\right)  \right)  =\operatorname*{td}\nolimits_{\varphi,T}\left(  x+y\right)
.
\]
Theorem 10.10 is thus proven.

\subsection{ $\operatorname*{td}_{\varphi,T}$ is a homomorphism of additive
groups}

A slightly improved restatement of Theorem 10.10:

\begin{quote}
\textbf{Corollary 10.23.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ be a power series with constant term equal to $1$.
Then, $\operatorname*{td}_{\varphi,T}\left(  K\right)  \subseteq\Lambda\left(
K\right)  $, and $\operatorname*{td}_{\varphi,T}:K\rightarrow\Lambda\left(
K\right)  $ is a homomorphism of additive groups.
\end{quote}

\textit{Proof of Corollary 10.23.} Every $x\in K$ satisfies
$\operatorname*{td}_{\varphi,T}\left(  x\right)  \in\Lambda\left(  K\right)  $
(since Proposition 10.5 \textbf{(a)} says that $\operatorname*{Coeff}%
\nolimits_{0}\left(  \operatorname*{td}_{\varphi,T}\left(  x\right)  \right)
=1$, so that the power series $\operatorname*{td}_{\varphi,T}\left(  x\right)
$ has the constant term $1$, and thus $\operatorname*{td}_{\varphi,T}\left(
x\right)  \in1+K\left[  \left[  T\right]  \right]  ^{+}=\Lambda\left(
K\right)  $). In other words, $\operatorname*{td}_{\varphi,T}\left(  K\right)
\subseteq\Lambda\left(  K\right)  $.

Now we are going to prove that $\operatorname*{td}_{\varphi,T}:K\rightarrow
\Lambda\left(  K\right)  $ is a homomorphism of additive groups.

Theorem 10.10 (applied to $x=0$ and $y=0$) yields $\operatorname*{td}%
\nolimits_{\varphi,T}\left(  0\right)  \cdot\operatorname*{td}%
\nolimits_{\varphi,T}\left(  0\right)  =\operatorname*{td}\nolimits_{\varphi
,T}\left(  0+0\right)  =\operatorname*{td}\nolimits_{\varphi,T}\left(
0\right)  $. Since $\operatorname*{td}\nolimits_{\varphi,T}\left(  0\right)  $
is an invertible element of $K\left[  \left[  T\right]  \right]  $ (because
$\operatorname*{td}\nolimits_{\varphi,T}\left(  0\right)  $ is a power series
with constant term $1$\ \ \ \ \footnote{since $\operatorname*{td}%
\nolimits_{\varphi,T}\left(  0\right)  \in\operatorname*{td}\nolimits_{\varphi
,T}\left(  K\right)  \subseteq\Lambda\left(  K\right)  =1+K\left[  \left[
T\right]  \right]  ^{+}$}, and every such power series is an invertible
element of $K\left[  \left[  T\right]  \right]  $), we can cancel
$\operatorname*{td}\nolimits_{\varphi,T}\left(  0\right)  $ from this
equation, and obtain $\operatorname*{td}\nolimits_{\varphi,T}\left(  0\right)
=1$. Since $0$ is the neutral element of the additive group $K$, while $1$ is
the neutral element of the additive group $\Lambda\left(  K\right)  $, this
yields that the map $\operatorname*{td}\nolimits_{\varphi,T}$ respects the
neutral elements of the additive groups $K$ and $\Lambda\left(  K\right)  $.

Any $x\in K$ and $y\in K$ satisfy%
\begin{align*}
\operatorname*{td}\nolimits_{\varphi,T}\left(  x+y\right)   &
=\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  \cdot
\operatorname*{td}\nolimits_{\varphi,T}\left(  y\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 10.10}\right) \\
&  =\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)  \widehat{+}%
\operatorname*{td}\nolimits_{\varphi,T}\left(  y\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since multiplication of power series in }1+K\left[  \left[  T\right]
\right]  ^{+}\\
\text{is addition in the ring }\Lambda\left(  K\right)
\end{array}
\right)  .
\end{align*}
Combined with the fact that the map $\operatorname*{td}\nolimits_{\varphi,T}$
respects the neutral elements of the additive groups $K$ and $\Lambda\left(
K\right)  $, this yields: The map $\operatorname*{td}_{\varphi,T}%
:K\rightarrow\Lambda\left(  K\right)  $ is a homomorphism of additive groups.
Corollary 10.23 is proven.

\subsection{ $\operatorname*{td}_{\varphi,T}$ of a $1$-dimensional element}

Next on our plan is to compute $\operatorname*{td}\nolimits_{\varphi,T}\left(
x\right)  $ for $x$ any $1$-dimensional element of $K$. We recall that we
defined the notion of a $1$-dimensional element of a $\lambda$-ring in Section 8.

Our main claim here is:

\begin{quote}
\textbf{Proposition 10.24.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $u$ be a $1$-dimensional element of $K$.
Let $\varphi\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power
series with constant term equal to $1$. Then, $\operatorname*{td}%
\nolimits_{\varphi,T}\left(  u\right)  =\varphi\left(  uT\right)  $.
\end{quote}

For the proof of this, we again have to study the universal polynomials
$\operatorname*{Td}\nolimits_{\varphi,j}$:

\begin{quote}
\textbf{Proposition 10.25.} Let $\mathbf{Z}$ be a ring. Let $\varphi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power series with
constant term equal to $1$. Let $j\in\mathbb{N}$. Let $\varphi_{j}$ denote the
coefficient of the power series $\varphi\in1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ before $t^{j}$. Then, in the polynomial ring
$\mathbf{Z}\left[  S\right]  $, we have $\operatorname*{Td}\nolimits_{\varphi
,j}\left(  S,0,0,...,0\right)  =\varphi_{j}S^{j}$. (Here, when $j=0$, the term
$\operatorname*{Td}\nolimits_{\varphi,j}\left(  S,0,0,...,0\right)  $ is
understood to denote $\operatorname*{Td}\nolimits_{\varphi,j}$.)
\end{quote}

And again, we can generalize Proposition 10.24 (and in fact, we are going to
prove Proposition 10.24 via this generalization):

\begin{quote}
\textbf{Proposition 10.26.} Let $\mathbf{Z}$ be a ring. Let $\varphi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power series with
constant term equal to $1$. Let $K$ be a $\mathbf{Z}$-algebra. Let $u\in K$.
Then, $\mathfrak{Todd}_{\varphi}\left(  1+uT\right)  =\varphi\left(
uT\right)  $.
\end{quote}

\textit{Proof of Proposition 10.25.} Let $m=1$. Consider the ring
$\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ and its elements
$X_{i}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}$ as in the
definition of $\operatorname*{Td}\nolimits_{\varphi,j}$.

Since $m=1$, we have $\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]
=\mathbf{Z}\left[  U_{1}\right]  $, and in this ring $\mathbf{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $ we have $X_{1}=U_{1}$ (because $X_{1}$ is the
$1$-st elementary symmetric polynomial of the one variable $U_{1}$).

For every integer $i>1$, we have%
\begin{align*}
X_{i}  &  =\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}=\sum
\limits_{\substack{S\subseteq\left\{  1\right\}  ;\\\left\vert S\right\vert
=i}}\prod\limits_{k\in S}U_{k}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}m=1\text{, so that }\left\{  1,2,...,m\right\}  =\left\{  1\right\}  \right)
\\
&  =\left(  \text{empty sum}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
there doesn't exist any }S\subseteq\left\{  1\right\}  \text{ with }\left\vert
S\right\vert =i\text{ (because }i>1\text{)}\right) \\
&  =0
\end{align*}
in the ring $\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $. Thus, $\left(
X_{2},X_{3},...,X_{j}\right)  =\left(  0,0,...,0\right)  $. Combining this
with $X_{1}=U_{1}$, we obtain $\left(  X_{1},X_{2},...,X_{j}\right)  =\left(
U_{1},0,0,...,0\right)  $.

We know from Theorem 10.1 that (\ref{Td1}) holds in the ring $\left(
\mathbf{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[  \left[
T\right]  \right]  $. In other words,%
\[
\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  =\sum_{i\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,i}\left(  X_{1},X_{2},...,X_{i}\right)
T^{i}%
\]
(this follows from (\ref{Td1}) upon renaming the index $j$ as $i$). Since
$\prod\limits_{i=1}^{m}\varphi\left(  U_{i}T\right)  =\varphi\left(
U_{1}T\right)  $ (because $m=1$), this rewrites as
\[
\varphi\left(  U_{1}T\right)  =\sum_{i\in\mathbb{N}}\operatorname*{Td}%
\nolimits_{\varphi,i}\left(  X_{1},X_{2},...,X_{i}\right)  T^{i}.
\]
Thus,%
\begin{align*}
\operatorname*{Coeff}\nolimits_{j}\left(  \varphi\left(  U_{1}T\right)
\right)   &  =\operatorname*{Coeff}\nolimits_{j}\left(  \sum_{i\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,i}\left(  X_{1},X_{2},...,X_{i}\right)
T^{i}\right)  =\operatorname*{Td}\nolimits_{\varphi,j}\underbrace{\left(
X_{1},X_{2},...,X_{j}\right)  }_{=\left(  U_{1},0,0,...,0\right)  }\\
&  =\operatorname*{Td}\nolimits_{\varphi,j}\left(  U_{1},0,0,...,0\right)  .
\end{align*}
Combined with%
\begin{align*}
\operatorname*{Coeff}\nolimits_{j}\left(  \varphi\left(  U_{1}T\right)
\right)   &  =\left(  \text{the coefficient of the power series }%
\varphi\left(  U_{1}T\right)  \text{ before }T^{j}\right) \\
&  =U_{1}^{j}\underbrace{\left(  \text{the coefficient of the power series
}\varphi\text{ before }t^{j}\right)  }_{=\varphi_{j}}=U_{1}^{j}\varphi
_{j}=\varphi_{j}U_{1}^{j},
\end{align*}
this yields
\[
\operatorname*{Td}\nolimits_{\varphi,j}\left(  U_{1},0,0,...,0\right)
=\varphi_{j}U_{1}^{j}.
\]


Now, let $\kappa$ be the $\mathbf{Z}$-algebra homomorphism $\mathbf{Z}\left[
S\right]  \rightarrow\mathbf{Z}\left[  U_{1}\right]  $ which maps $S$ to
$U_{1}$. This homomorphism $\kappa$ must be an isomorphism (since $U_{1}$ is
obviously algebraically independent). Since $\kappa$ is a $\mathbf{Z}$-algebra
homomorphism and $\operatorname*{Td}\nolimits_{\varphi,j}$ is a polynomial, we
have $\kappa\left(  \operatorname*{Td}\nolimits_{\varphi,j}\left(
S,0,0,...,0\right)  \right)  =\operatorname*{Td}\nolimits_{\varphi,j}\left(
\kappa\left(  S\right)  ,\kappa\left(  0\right)  ,\kappa\left(  0\right)
,...,\kappa\left(  0\right)  \right)  $ (because $\mathbf{Z}$-algebra
homomorphisms commute with polynomials). But $\left(  \kappa\left(  S\right)
,\kappa\left(  0\right)  ,\kappa\left(  0\right)  ,...,\kappa\left(  0\right)
\right)  =\left(  U_{1},0,0,...,0\right)  $ (since $\kappa\left(  S\right)
=U_{1}$ and $\kappa\left(  0\right)  =0$). Thus,%
\begin{align*}
\kappa\left(  \operatorname*{Td}\nolimits_{\varphi,j}\left(
S,0,0,...,0\right)  \right)   &  =\operatorname*{Td}\nolimits_{\varphi
,j}\underbrace{\left(  \kappa\left(  S\right)  ,\kappa\left(  0\right)
,\kappa\left(  0\right)  ,...,\kappa\left(  0\right)  \right)  }_{=\left(
U_{1},0,0,...,0\right)  }=\operatorname*{Td}\nolimits_{\varphi,j}\left(
U_{1},0,0,...,0\right)  =\varphi_{j}U_{1}^{j}\\
&  =\varphi_{j}\kappa\left(  S\right)  ^{j}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }U_{1}=\kappa\left(  S\right)  \right) \\
&  =\kappa\left(  \varphi_{j}S^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\kappa\text{ is a }\mathbf{Z}\text{-algebra homomorphism}\right)
.
\end{align*}
Thus, $\operatorname*{Td}\nolimits_{\varphi,j}\left(  S,0,0,...,0\right)
=\varphi_{j}S^{j}$ (since $\kappa$ is an isomorphism). This proves Proposition 10.25.

\textit{Proof of Proposition 10.26.} For every $j\in\mathbb{N}$, let
$\varphi_{j}$ denote the coefficient of the power series $\varphi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ before $t^{j}$. Let
$p=1+uT$. Then, $\operatorname*{Coeff}\nolimits_{1}p=u$ (by the definition of
$\operatorname*{Coeff}\nolimits_{1}$) and $\operatorname*{Coeff}%
\nolimits_{i}p=0$ for every integer $i>1$.

Let $j\in\mathbb{N}$ be arbitrary. Proposition 10.25 yields
$\operatorname*{Td}\nolimits_{\varphi,j}\left(  S,0,0,...,0\right)
=\varphi_{j}S^{j}$ in the polynomial ring $\mathbf{Z}\left[  S\right]  $.
Applying this polynomial identity to $S=u$, we obtain $\operatorname*{Td}%
\nolimits_{\varphi,j}\left(  u,0,0,...,0\right)  =\varphi_{j}u^{j}$.

On the other hand, $\left(  \operatorname*{Coeff}\nolimits_{2}%
p,\operatorname*{Coeff}\nolimits_{3}p,...,\operatorname*{Coeff}\nolimits_{j}%
p\right)  =\left(  0,0,...,0\right)  $ (since $\operatorname*{Coeff}%
\nolimits_{i}p=0$ for every integer $i>1$). Combining this with
$\operatorname*{Coeff}\nolimits_{1}p=u$, we obtain $\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  =\left(  u,0,0,...,0\right)
$. Thus,%
\[
\operatorname*{Td}\nolimits_{\varphi,j}\underbrace{\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  }_{=\left(
u,0,0,...,0\right)  }=\operatorname*{Td}\nolimits_{\varphi,j}\left(
u,0,0,...,0\right)  =\varphi_{j}u^{j}.
\]


Now forget that we fixed $j\in\mathbb{N}$. By (\ref{ToddFrak}) (applied to
$p=1+uT$), we have%
\[
\mathfrak{Todd}_{\varphi}\left(  1+uT\right)  =\sum\limits_{j\in\mathbb{N}%
}\underbrace{\operatorname*{Td}\nolimits_{\varphi,j}\left(
\operatorname*{Coeff}\nolimits_{1}p,\operatorname*{Coeff}\nolimits_{2}%
p,...,\operatorname*{Coeff}\nolimits_{j}p\right)  }_{=\varphi_{j}u^{j}}%
T^{j}=\sum\limits_{j\in\mathbb{N}}\varphi_{j}\underbrace{u^{j}T^{j}}_{=\left(
uT\right)  ^{j}}=\sum\limits_{j\in\mathbb{N}}\varphi_{j}\left(  uT\right)
^{j}.
\]
On the other hand, $\varphi=\sum\limits_{j\in\mathbb{N}}\varphi_{j}t^{j}$
(since the coefficient of the power series $\varphi$ before $t^{j}$ is
$\varphi_{j}$ for every $j\in\mathbb{N}$) and thus $\varphi\left(  uT\right)
=\sum\limits_{j\in\mathbb{N}}\varphi_{j}\left(  uT\right)  ^{j}$.

Altogether, $\mathfrak{Todd}_{\varphi}\left(  1+uT\right)  =\sum
\limits_{j\in\mathbb{N}}\varphi_{j}\left(  uT\right)  ^{j}=\varphi\left(
uT\right)  $. This proves Proposition 10.26.

\textit{Proof of Proposition 10.24.} Proposition 10.11 (applied to $x=u$)
yields $\operatorname*{td}\nolimits_{\varphi,T}\left(  u\right)
=\mathfrak{Todd}_{\varphi}\left(  \lambda_{T}\left(  u\right)  \right)  $. But
Theorem 8.3 \textbf{(a)} (applied to $x=u$) yields that $\lambda_{T}\left(
u\right)  =1+uT$ (since the element $u$ is $1$-dimensional). Thus,
$\operatorname*{td}\nolimits_{\varphi,T}\left(  u\right)  =\mathfrak{Todd}%
_{\varphi}\left(  \underbrace{\lambda_{T}\left(  u\right)  }_{=1+uT}\right)
=\mathfrak{Todd}_{\varphi}\left(  1+uT\right)  =\varphi\left(  uT\right)  $
(by Proposition 10.26). This proves Proposition 10.24.

As a consequence of Proposition 10.24, we can obtain the following formula for
$\operatorname*{td}\nolimits_{\varphi,T}$ on sums of $1$-dimensional elements:

\begin{quote}
\textbf{Theorem 10.27.} Let $\mathbf{Z}$ be a ring. Let $\varphi
\in1+\mathbf{Z}\left[  \left[  t\right]  \right]  ^{+}$ be a power series with
constant term equal to $1$. Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that $K$ is a
$\mathbf{Z}$-algebra. Let $u_{1},$ $u_{2},$ $...,$ $u_{m}$ be $1$-dimensional
elements of $K$. Then,%
\[
\operatorname*{td}\nolimits_{\varphi,T}\left(  u_{1}+u_{2}+...+u_{m}\right)
=\prod\limits_{i=1}^{m}\varphi\left(  u_{i}T\right)  .
\]



\end{quote}

\textit{Proof of Theorem 10.27.} By Corollary 10.23, we know that
$\operatorname*{td}_{\varphi,T}:K\rightarrow\Lambda\left(  K\right)  $ is a
homomorphism of additive groups. Hence,%
\begin{align*}
\operatorname*{td}\nolimits_{\varphi,T}\left(  \sum\limits_{i=1}^{m}%
u_{i}\right)   &  =\widehat{\sum\limits_{i=1}^{m}}\operatorname*{td}%
\nolimits_{\varphi,T}\left(  u_{i}\right)  =\prod\limits_{i=1}^{m}%
\operatorname*{td}\nolimits_{\varphi,T}\left(  u_{i}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the addition in the ring }\Lambda\left(  K\right)  \text{ is the
multiplication of power series,}\\
\text{so that }\widehat{\sum\limits_{i=1}^{m}}=\prod\limits_{i=1}^{m}%
\end{array}
\right) \\
&  =\prod\limits_{i=1}^{m}\varphi\left(  u_{i}T\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because every }i\in\left\{  1,2,...,m\right\}  \text{ satisfies
}\operatorname*{td}\nolimits_{\varphi,T}\left(  u_{i}\right)  =\varphi\left(
u_{i}T\right) \\
\text{(by Proposition 10.24, applied to }u=u_{i}\text{)}%
\end{array}
\right)  .
\end{align*}
Since $\sum\limits_{i=1}^{m}u_{i}=u_{1}+u_{2}+...+u_{m}$, this rewrites as
$\operatorname*{td}\nolimits_{\varphi,T}\left(  u_{1}+u_{2}+...+u_{m}\right)
=\prod\limits_{i=1}^{m}\varphi\left(  u_{i}T\right)  $. Theorem 10.27 is thus proven.

\subsection{ $\operatorname*{td}_{\varphi,T}$ for special $\lambda$-rings}

Theorem 10.27 gives us a shortcut to working with $\operatorname*{td}%
\nolimits_{\varphi,T}$ in the case when $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is a \textit{special} $\lambda$-ring: In fact, in
this case, we can often prove a property of an arbitrary element of a special
$\lambda$-ring just by proving it for sums of $1$-dimensional elements
(because of Theorem 8.4), and Theorem 10.27 gives us an explicit formula for
the value of $\operatorname*{td}\nolimits_{\varphi,T}$ at every sum of
$1$-dimensional elements. The next theorem (Theorem 10.28) will give an
example of this. First, a definition.

\begin{quote}
\textbf{Definition.} Let $j\in\mathbb{N}\setminus\left\{  0\right\}  $. Let
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a
$\lambda$-ring. Define a homomorphism $\theta_{T}^{j}:K\rightarrow
\Lambda\left(  K\right)  $ of additive groups by $\theta_{T}^{j}%
=\operatorname*{td}_{\varphi_{j},T}$, where $\varphi_{j}\in\mathbb{Z}\left[
t\right]  $ is the polynomial $1+t+t^{2}+...+t^{j-1}=\dfrac{1-t^{j}}{1-t}$.
\end{quote}

[Again, [1] considers only $\theta^{j}:=\theta_{1}^{j},$ which again is
defined on $x$ only if $x$ is finite-dimensional. These $\theta^{j}$ (or
$\theta^{j}\left(  x\right)  $ ?) are called \textit{Bott's cannibalistic
classes}, for whatever reason.]

\begin{quote}
\textbf{Theorem 10.28.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special $\lambda$-ring. Let $x\in K$. Let
$j\in\mathbb{N}\setminus\left\{  0\right\}  $. Let $\operatorname*{fr}%
\nolimits_{j}:K\left[  \left[  T\right]  \right]  \rightarrow K\left[  \left[
T\right]  \right]  $ be the map which sends every power series $\sum
\limits_{i\in\mathbb{N}}a_{i}T^{i}$ (with $a_{i}\in K$ for every
$i\in\mathbb{N}$) to the power series $\sum\limits_{i\in\mathbb{N}}a_{i}%
T^{ji}$. Then, $\operatorname*{fr}\nolimits_{j}\left(  \left(  \psi^{j}\left[
\left[  T\right]  \right]  \right)  \left(  \lambda_{-T}\left(  x\right)
\right)  \right)  =\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)
=\lambda_{-T}\left(  x\right)  \theta_{T}^{j}\left(  x\right)  $ (where
$\psi^{j}\left[  \left[  T\right]  \right]  $ means the homomorphism $K\left[
\left[  T\right]  \right]  \rightarrow K\left[  \left[  T\right]  \right]  $
defined by $\left(  \psi^{j}\left[  \left[  T\right]  \right]  \right)
\left(  \sum\limits_{i\in\mathbb{N}}a_{i}T^{i}\right)  =\sum\limits_{i\in
\mathbb{N}}\psi^{j}\left(  a_{i}\right)  T^{i}$ for every power series
$\sum\limits_{i\in\mathbb{N}}a_{i}T^{i}\in K\left[  \left[  T\right]  \right]
$).
\end{quote}

\textit{Proof of Theorem 10.28.} \textit{1st Step:} The equality
$\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)  =\lambda_{-T}\left(
x\right)  \theta_{T}^{j}\left(  x\right)  $ holds for every $x\in K$ (no
matter whether the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ is special or not).

\textit{Proof.} Let $\varphi_{j}\in\mathbb{Z}\left[  t\right]  $ be the
polynomial $1+t+t^{2}+...+t^{j-1}=\dfrac{1-t^{j}}{1-t}$. According to the
definition of $\theta_{T}^{j}$, we have $\theta_{T}^{j}=\operatorname*{td}%
_{\varphi_{j},T}$.

Let $x\in K$. Applying Proposition 10.7 to $\mathbf{Z}=\mathbb{Z}$,
$\varphi=1-t$ and $\psi=\varphi_{j}$, we obtain $\operatorname*{td}%
\nolimits_{\varphi\psi,T}\left(  x\right)  =\operatorname*{td}%
\nolimits_{\varphi,T}\left(  x\right)  \operatorname*{td}\nolimits_{\psi
,T}\left(  x\right)  $. Since%
\[
\operatorname*{td}\nolimits_{\varphi\psi,T}\left(  x\right)
=\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because }\varphi=1-t\text{ and }\psi=\varphi_{j}=\dfrac{1-t^{j}}%
{1-t}\text{,}\\
\text{so that }\varphi\psi=\left(  1-t\right)  \cdot\dfrac{1-t^{j}}%
{1-t}=1-t^{j}%
\end{array}
\right)  ,
\]%
\begin{align*}
\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)   &
=\operatorname*{td}\nolimits_{1+\left(  -1\right)  t,T}\left(  x\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\varphi=1-t=1+\left(  -1\right)
t\right) \\
&  =\lambda_{\left(  -1\right)  T}\left(  x\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Proposition 10.3, applied to }%
\mathbf{Z}=\mathbb{Z}\text{ and }u=-1\right) \\
&  =\lambda_{-T}\left(  x\right)
\end{align*}
and%
\begin{align*}
\operatorname*{td}\nolimits_{\psi,T}\left(  x\right)   &
=\underbrace{\operatorname*{td}\nolimits_{\varphi_{j},T}}_{=\theta_{T}^{j}%
}\left(  x\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\psi=\varphi
_{j}\right) \\
&  =\theta_{T}^{j}\left(  x\right)  ,
\end{align*}
this rewrites as $\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)
=\lambda_{-T}\left(  x\right)  \theta_{T}^{j}\left(  x\right)  $. This proves
the 1st Step.

\textit{2nd Step:} A remark about the map $\operatorname*{fr}\nolimits_{j}$:
This map sends every power series $P\in K\left[  \left[  T\right]  \right]  $
to the power series $P\left(  T^{j}\right)  $. It is easy to see that this map
$\operatorname*{fr}\nolimits_{j}$ is a $K$-algebra homomorphism continuous
with respect to the $\left(  T\right)  $-topology. It satisfies
$\operatorname*{fr}\nolimits_{j}\left(  T\right)  =T^{j}$ (obviously) and can
be shown to be the only continuous (with respect to the $\left(  T\right)
$-topology) ring homomorphism $K\left[  \left[  T\right]  \right]  \rightarrow
K\left[  \left[  T\right]  \right]  $ which sends $T$ to $T^{j}$.

\textit{3rd Step:} The equality $\operatorname*{fr}\nolimits_{j}\left(
\left(  \psi^{j}\left[  \left[  T\right]  \right]  \right)  \left(
\lambda_{-T}\left(  x\right)  \right)  \right)  =\operatorname*{td}%
\nolimits_{1-t^{j},T}\left(  x\right)  $ holds for every special $\lambda
$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and
every $x\in K$ such that $x$ is the sum of finitely many $1$-dimensional
elements of $K$.

\textit{Proof.} Let $\varphi=1-t^{j}$.

Let $x\in K$ be such that $x$ is the sum of finitely many $1$-dimensional
elements of $K$. In other words, $x=u_{1}+u_{2}+...+u_{m}$ for some
$1$-dimensional elements $u_{1},$ $u_{2},$ $...,$ $u_{m}$ of $K$. Consider
these elements $u_{1},$ $u_{2},$ $...,$ $u_{m}$. Then,%
\begin{align*}
\operatorname*{td}\nolimits_{\varphi,T}\left(  x\right)   &
=\operatorname*{td}\nolimits_{\varphi,T}\left(  u_{1}+u_{2}+...+u_{m}\right)
=\prod\limits_{i=1}^{m}\underbrace{\varphi\left(  u_{i}T\right)
}_{\substack{=1-\left(  u_{i}T\right)  ^{j}\\\text{(since }\varphi
=1-t^{j}\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 10.27}\right)
\\
&  =\prod\limits_{i=1}^{m}\left(  1-\underbrace{\left(  u_{i}T\right)  ^{j}%
}_{=u_{i}^{j}T^{j}}\right)  =\prod\limits_{i=1}^{m}\left(  1-u_{i}^{j}%
T^{j}\right)  .
\end{align*}
On the other hand, $x=u_{1}+u_{2}+...+u_{m}=\sum\limits_{i=1}^{m}u_{i}$, so
that%
\begin{align*}
\lambda_{T}\left(  x\right)   &  =\lambda_{T}\left(  \sum\limits_{i=1}%
^{m}u_{i}\right)  =\widehat{\sum\limits_{i=1}^{m}}\lambda_{T}\left(
u_{i}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\lambda_{T}\text{ is a
ring homomorphism}\right) \\
&  =\prod\limits_{i=1}^{m}\lambda_{T}\left(  u_{i}\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the addition in the ring }\Lambda\left(  K\right)  \text{ is
the}\\
\text{ multiplication of power series, and thus }\widehat{\sum\limits_{i=1}%
^{m}}=\prod\limits_{i=1}^{m}%
\end{array}
\right) \\
&  =\prod\limits_{i=1}^{m}\left(  1+u_{i}T\right)  \ \ \ \ \ \ \ \ \ \ \left(
%
\begin{array}
[c]{c}%
\text{because every }i\in\left\{  1,2,...,m\right\}  \text{ satisfies }%
\lambda_{T}\left(  u_{i}\right)  =1+u_{i}T\\
\text{(by Theorem 8.3 \textbf{(a)} (applied to }u_{i}\text{ instead of
}x\text{),}\\
\text{since }u_{i}\text{ is }1\text{-dimensional)}%
\end{array}
\right)  .
\end{align*}
Now,%
\begin{align*}
\lambda_{-T}\left(  x\right)   &  =\operatorname*{ev}\nolimits_{-T}\left(
\underbrace{\lambda_{T}\left(  x\right)  }_{=\prod\limits_{i=1}^{m}\left(
1+u_{i}T\right)  }\right)  =\operatorname*{ev}\nolimits_{-T}\left(
\prod\limits_{i=1}^{m}\left(  1+u_{i}T\right)  \right) \\
&  =\prod\limits_{i=1}^{m}\underbrace{\operatorname*{ev}\nolimits_{-T}\left(
1+u_{i}T\right)  }_{\substack{=1-u_{i}T\\\text{(by the definition of
}\operatorname*{ev}\nolimits_{-T}\text{)}}}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }\operatorname*{ev}\nolimits_{-T}\text{ is a ring homomorphism}%
\right) \\
&  =\prod\limits_{i=1}^{m}\left(  1-u_{i}T\right)  .
\end{align*}
Thus,%
\begin{align*}
\left(  \psi^{j}\left[  \left[  T\right]  \right]  \right)  \left(
\lambda_{-T}\left(  x\right)  \right)   &  =\left(  \psi^{j}\left[  \left[
T\right]  \right]  \right)  \left(  \prod\limits_{i=1}^{m}\left(
1-u_{i}T\right)  \right)  =\prod\limits_{i=1}^{m}\left(  1-\underbrace{\left(
\psi^{j}\left[  \left[  T\right]  \right]  \right)  \left(  u_{i}T\right)
}_{\substack{=\psi^{j}\left(  u_{i}\right)  T\\\text{(by the definition of
}\psi^{j}\left[  \left[  T\right]  \right]  \text{)}}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\psi^{j}\left[  \left[  T\right]
\right]  \text{ is a ring homomorphism}\right) \\
&  =\prod\limits_{i=1}^{m}\left(  1-\psi^{j}\left(  u_{i}\right)  T\right)  ,
\end{align*}
so that%
\begin{align*}
\operatorname*{fr}\nolimits_{j}\left(  \left(  \psi^{j}\left[  \left[
T\right]  \right]  \right)  \left(  \lambda_{-T}\left(  x\right)  \right)
\right)   &  =\operatorname*{fr}\nolimits_{j}\left(  \prod\limits_{i=1}%
^{m}\left(  1-\psi^{j}\left(  u_{i}\right)  T\right)  \right)  =\prod
\limits_{i=1}^{m}\left(  1-\psi^{j}\left(  u_{i}\right)
\underbrace{\operatorname*{fr}\nolimits_{j}\left(  T\right)  }_{=T^{j}}\right)
\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\operatorname*{fr}\nolimits_{j}%
\text{ is a }K\text{-algebra homomorphism}\right) \\
&  =\prod\limits_{i=1}^{m}\left(  1-\psi^{j}\left(  u_{i}\right)
T^{j}\right)  .
\end{align*}


Now, for every $i\in\left\{  1,2,...,m\right\}  $, we can apply Theorem 9.4 to
$1$ and $u_{i}$ instead of $m$ and $u_{i}$, and obtain $\psi^{j}\left(
u_{i}\right)  =u_{i}^{j}$. Hence,%
\[
\operatorname*{fr}\nolimits_{j}\left(  \left(  \psi^{j}\left[  \left[
T\right]  \right]  \right)  \left(  \lambda_{-T}\left(  x\right)  \right)
\right)  =\prod\limits_{i=1}^{m}\left(  1-\underbrace{\psi^{j}\left(
u_{i}\right)  }_{=u_{i}^{j}}T^{j}\right)  =\prod\limits_{i=1}^{m}\left(
1-u_{i}^{j}T^{j}\right)  =\operatorname*{td}\nolimits_{\varphi,T}\left(
x\right)  =\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)
\]
(since $\varphi=1-t^{j}$). This proves the 3rd Step.

\textit{4th Step:} The equality $\operatorname*{fr}\nolimits_{j}\left(
\left(  \psi^{j}\left[  \left[  T\right]  \right]  \right)  \left(
\lambda_{-T}\left(  x\right)  \right)  \right)  =\operatorname*{td}%
\nolimits_{1-t^{j},T}\left(  x\right)  $ holds for every special $\lambda
$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and
every $x\in K$.

\textit{Proof.} We want to derive this from the 3rd Step by applying Theorem 8.4.

Fix some $k\in\mathbb{N}$.

Define a $1$-operation $m$ of special $\lambda$-rings by $m_{\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }=\operatorname*{Coeff}%
\nolimits_{k}\circ\operatorname*{fr}\nolimits_{j}\circ\left(  \psi^{j}\left[
\left[  T\right]  \right]  \right)  \circ\lambda_{-T}$ for every special
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $. (This is indeed a $1$-operation, since (\ref{PsiDef}) shows that
$\psi^{j}$ is a polynomial in $\lambda^{1},$ $\lambda^{2},$ $...,$
$\lambda^{j}$ with integer coefficients.)

Define a $1$-operation $m^{\prime}$ of special $\lambda$-rings by $m_{\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime
}=\operatorname*{Coeff}\nolimits_{k}\circ\operatorname*{td}\nolimits_{1-t^{j}%
,T}$ for every $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $. (This is, again, a $1$-operation, since
(\ref{ToddDef}) shows that $\operatorname*{Coeff}\nolimits_{k}\circ
\operatorname*{td}\nolimits_{1-t^{j},T}=\operatorname*{Td}\nolimits_{1-t^{j}%
,k}\left(  \lambda^{1},\lambda^{2},...,\lambda^{k}\right)  $ is a polynomial
in $\lambda^{1},$ $\lambda^{2},$ $...,$ $\lambda^{k}$ with integer coefficients.)

These two $1$-operations $m$ and $m^{\prime}$ satisfy both conditions of
Theorem 8.4: The continuity assumption holds (since the operations $m$ and
$m^{\prime}$ are obtained by taking polynomials (with integer coefficients)
and compositions of finitely many of the $\lambda^{1},$ $\lambda^{2},$
$\lambda^{3},$ $...$, so that the maps $m_{\left(  \Lambda\left(  K\right)
,\left(  \widehat{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  }$ and
$m_{\left(  \Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)
_{i\in\mathbb{N}}\right)  }^{\prime}$ are obtained by taking polynomials (with
integer coefficients) and compositions of finitely many of the
$\widehat{\lambda}^{1},$ $\widehat{\lambda}^{2},$ $\widehat{\lambda}^{3},$
$...$, and therefore continuous because of Theorem 5.5 \textbf{(d)}), and the
split equality assumption holds (since it states that for every special
$\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ and every $x\in K$ such that $x$ is the sum of finitely many
$1$-dimensional elements of $K$, we have $m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(  x\right)  =m_{\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(
x\right)  $; but this simply means that $\operatorname*{Coeff}\nolimits_{k}%
\left(  \operatorname*{fr}\nolimits_{j}\left(  \left(  \psi^{j}\left[  \left[
T\right]  \right]  \right)  \left(  \lambda_{-T}\left(  x\right)  \right)
\right)  \right)  =\operatorname*{Coeff}\nolimits_{k}\left(
\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)  \right)  ,$ which was
proven in the 3rd step). Hence, by Theorem 8.4, we have $m=m^{\prime}$. Hence,
for every special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and every $x\in K$, we have $m_{\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }\left(  x\right)  =m_{\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(
x\right)  $. Since $m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  }\left(  x\right)  =\operatorname*{Coeff}\nolimits_{k}\left(
\operatorname*{fr}\nolimits_{j}\left(  \left(  \psi^{j}\left[  \left[
T\right]  \right]  \right)  \left(  \lambda_{-T}\left(  x\right)  \right)
\right)  \right)  $ (by the definition of $m_{\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  }$) and $m_{\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime}\left(  x\right)
=\operatorname*{Coeff}\nolimits_{k}\left(  \operatorname*{td}%
\nolimits_{1-t^{j},T}\left(  x\right)  \right)  $ (by the definition of
$m_{\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  }^{\prime
}$), this rewrites as follows: For every special $\lambda$-ring $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ and every $x\in K$,
we have $\operatorname*{Coeff}\nolimits_{k}\left(  \operatorname*{fr}%
\nolimits_{j}\left(  \left(  \psi^{j}\left[  \left[  T\right]  \right]
\right)  \left(  \lambda_{-T}\left(  x\right)  \right)  \right)  \right)
=\operatorname*{Coeff}\nolimits_{k}\left(  \operatorname*{td}%
\nolimits_{1-t^{j},T}\left(  x\right)  \right)  $.

Now fix some special $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ and some $x\in K$, and forget that we fixed $k$.
We have just proven that $\operatorname*{Coeff}\nolimits_{k}\left(
\operatorname*{fr}\nolimits_{j}\left(  \left(  \psi^{j}\left[  \left[
T\right]  \right]  \right)  \left(  \lambda_{-T}\left(  x\right)  \right)
\right)  \right)  =\operatorname*{Coeff}\nolimits_{k}\left(
\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)  \right)  $ for every
$k\in\mathbb{N}$. In other words, we have just proven that each coefficient of
the power series $\operatorname*{fr}\nolimits_{j}\left(  \left(  \psi
^{j}\left[  \left[  T\right]  \right]  \right)  \left(  \lambda_{-T}\left(
x\right)  \right)  \right)  $ equals to the corresponding coefficient of the
power series $\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)  $.
Thus, $\operatorname*{fr}\nolimits_{j}\left(  \left(  \psi^{j}\left[  \left[
T\right]  \right]  \right)  \left(  \lambda_{-T}\left(  x\right)  \right)
\right)  =\operatorname*{td}\nolimits_{1-t^{j},T}\left(  x\right)  $. This
proves the 4th Step.

\textit{5th Step:} Theorem 10.28 now follows by combining the 1st Step and the
4th Step.

\subsection{A somewhat more general context for Todd homomorphisms}

Having proven Theorem 10.28, we are done proving all important properties of
the $\varphi$-Todd homomorphisms. One thing that I still want to do is to give
a (not particularly unexpected, and apparently not particularly useful)
generalization of our notion of $\varphi$-Todd homomorphisms to the case when
the power series $\varphi$ does not lie in $1+\mathbf{Z}\left[  \left[
t\right]  \right]  ^{+}$ but, instead, lies in $1+\mathbf{Z}^{\prime}\left[
\left[  t\right]  \right]  ^{+}$ for $\mathbf{Z}^{\prime}$ being a
$\mathbf{Z}$-algebra. In this case, it turns out, not much will change - but,
of course, $\operatorname*{td}\nolimits_{\varphi,T}$ will no longer be a map
$K\rightarrow K\left[  \left[  T\right]  \right]  $ but instead will be a map
$K\rightarrow\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  \left[
\left[  T\right]  \right]  $. Here is the precise definition:

\begin{quote}
\textbf{Definition.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$. We define a
map $\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}%
:K\rightarrow\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  \left[
\left[  T\right]  \right]  $ by%
\begin{equation}
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)
=\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\lambda^{1}\left(  x\right)  \otimes1,\lambda^{2}\left(  x\right)
\otimes1,...,\lambda^{j}\left(  x\right)  \otimes1\right)  T^{j}%
\ \ \ \ \ \ \ \ \ \ \text{for every }x\in K. \label{ToddDefZ'}%
\end{equation}


Let me explain what I mean by $\operatorname*{Td}\nolimits_{\varphi,j}\left(
\lambda^{1}\left(  x\right)  \otimes1,\lambda^{2}\left(  x\right)
\otimes1,...,\lambda^{j}\left(  x\right)  \otimes1\right)  $ here: The tensor
product $K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}$ is both a $K$-algebra and a
$\mathbf{Z}^{\prime}$-algebra (since the tensor product of two commutative
$\mathbf{Z}$-algebras is an algebra over each of its tensorands). Since it is
a $\mathbf{Z}^{\prime}$-algebra, we can apply the polynomial
$\operatorname*{Td}\nolimits_{\varphi,j}\in\mathbf{Z}^{\prime}\left[
\alpha_{1},\alpha_{2},...,\alpha_{j}\right]  $ to the elements $\lambda
^{1}\left(  x\right)  \otimes1$, $\lambda^{2}\left(  x\right)  \otimes1$,
$...$, $\lambda^{j}\left(  x\right)  \otimes1$ of $K\otimes_{\mathbf{Z}%
}\mathbf{Z}^{\prime}$; the result of this application is what we denote by
$\operatorname*{Td}\nolimits_{\varphi,j}\left(  \lambda^{1}\left(  x\right)
\otimes1,\lambda^{2}\left(  x\right)  \otimes1,...,\lambda^{j}\left(
x\right)  \otimes1\right)  $.

We call $\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}$ the
$\left(  \varphi,\mathbf{Z}^{\prime}\right)  $-\textit{Todd homomorphism} of
the $\lambda$-ring $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $.
\end{quote}

Note that, in the particular case when $\mathbf{Z}^{\prime}=\mathbf{Z}$, the
map $\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}$ is identical
with the map $\operatorname*{td}\nolimits_{\varphi,T}$ if we make the
canonical identification of $K$ with $K\otimes_{\mathbf{Z}}\mathbf{Z}$.

All results about maps of the form $\operatorname*{td}\nolimits_{\varphi,T}$
that we have formulated possess analoga pertaining to $\operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}$. Proving these analoga is usually
as simple as repeating the proofs of the original results and replacing some
of the $\mathbf{Z}$'s by $\mathbf{Z}^{\prime}$'s, some of the $K$'s by
$\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $'s, and some of the
$\lambda^{i}\left(  x\right)  $'s by $\lambda^{i}\left(  x\right)  \otimes
1$'s. However, it is yet easier to prove these analoga by deriving them from
the corresponding properties of the maps $\mathfrak{Todd}_{\varphi}$. What
makes this possible is the following generalization of Proposition 10.11:

\begin{quote}
\textbf{Proposition 10.29.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$. Let
$\iota:K\rightarrow K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}$ be the canonical
map (mapping every $\xi\in K$ to $\xi\otimes1\in K\otimes_{\mathbf{Z}%
}\mathbf{Z}^{\prime}$). Then, every $x\in K$ satisfies $\operatorname*{td}%
_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)  =\mathfrak{Todd}_{\varphi
}\left(  \iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(
x\right)  \right)  \right)  $.
\end{quote}

The proof of this is very similar to that of Proposition 10.11, and is part of
Exercise 10.2.

Let us formulate the analoga of our above-proven results about
$\operatorname*{td}\nolimits_{\varphi,T}$. The proofs of all these analoga
will be done in Exercise 10.2.

Here is the analogue of Proposition 10.3:

\begin{quote}
\textbf{Proposition 10.30.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $u\in\mathbf{Z}^{\prime}$. For every $x\in K$, we have
$\operatorname*{td}\nolimits_{1+ut,T,\mathbf{Z}^{\prime}}\left(  x\right)
=\lambda_{\left(  1\otimes u\right)  T}\left(  x\right)  $, where
$\lambda_{\left(  1\otimes u\right)  T}\left(  x\right)  $ means
$\operatorname*{ev}\nolimits_{\left(  1\otimes u\right)  T}\left(  \lambda
_{T}\left(  x\right)  \right)  $.
\end{quote}

Similarly, here is the analogue of Proposition 10.5:

\begin{quote}
\textbf{Proposition 10.31.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$.

\textbf{(a)} Then, $\operatorname*{Coeff}\nolimits_{0}\left(
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)
\right)  =1$ for every $x\in K$.

\textbf{(b)} Let $\varphi_{1}$ be the coefficient of the power series
$\varphi\in\mathbf{Z}^{\prime}\left[  \left[  t\right]  \right]  $ before
$t^{1}$. Then, $\operatorname*{Coeff}\nolimits_{1}\left(  \operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)  \right)
=\varphi_{1}\left(  x\otimes1\right)  $ for every $x\in K$.
\end{quote}

The analogue of Proposition 10.7:

\begin{quote}
\textbf{Proposition 10.32.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]
\right]  ^{+}$ and $\psi\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]
\right]  ^{+}$ be two power series with constant terms equal to $1$. For every
$x\in K$, we have $\operatorname*{td}\nolimits_{\varphi\psi,T,\mathbf{Z}%
^{\prime}}\left(  x\right)  =\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  x\right)  \operatorname*{td}\nolimits_{\psi
,T,\mathbf{Z}^{\prime}}\left(  x\right)  $.
\end{quote}

Next, the analogue of Proposition 10.9:

\begin{quote}
\textbf{Proposition 10.33.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $m\in\mathbb{N}$. For every $i\in\left\{  1,2,...,m\right\}  $,
let $\varphi_{i}\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]  \right]
^{+}$ be a power series with constant term equal to $1$. For every $x\in K$,
we have%
\[
\operatorname*{td}\nolimits_{\prod\limits_{i=1}^{m}\varphi_{i},T,\mathbf{Z}%
^{\prime}}\left(  x\right)  =\prod\limits_{i=1}^{m}\operatorname*{td}%
\nolimits_{\varphi_{i},T,\mathbf{Z}^{\prime}}\left(  x\right)  .
\]



\end{quote}

Next, the analogue of Theorem 10.10:

\begin{quote}
\textbf{Theorem 10.34.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$. Let $x\in K$
and $y\in K$. Then, $\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}%
^{\prime}}\left(  x\right)  \cdot\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  y\right)  =\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  x+y\right)  $.
\end{quote}

The analogue of Corollary 10.23 is what one would expect it to be:

\begin{quote}
\textbf{Corollary 10.35.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}%
$-algebra. Let $\varphi\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]
\right]  ^{+}$ be a power series with constant term equal to $1$. Then,
$\operatorname*{td}_{\varphi,T,\mathbf{Z}^{\prime}}\left(  K\right)
\subseteq\Lambda\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $,
and $\operatorname*{td}_{\varphi,T,\mathbf{Z}^{\prime}}:K\rightarrow
\Lambda\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $ is a
homomorphism of additive groups.
\end{quote}

We can also generalize Proposition 10.24:

\begin{quote}
\textbf{Proposition 10.36.} Let $\mathbf{Z}$ be a ring. Let $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring such that
$K$ is a $\mathbf{Z}$-algebra. Let $u$ be a $1$-dimensional element of $K$.
Let $\mathbf{Z}^{\prime}$ be a $\mathbf{Z}$-algebra. Let $\varphi
\in1+\mathbf{Z}^{\prime}\left[  \left[  t\right]  \right]  ^{+}$ be a power
series with constant term equal to $1$. Then, $\operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  u\right)  =\varphi\left(
\left(  u\otimes1\right)  T\right)  $, where $u\otimes1$ denotes the element
$u\otimes1$ of $K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}$.
\end{quote}

Finally, the analogue to Theorem 10.27:

\begin{quote}
\textbf{Theorem 10.37.} Let $\mathbf{Z}$ be a ring. Let $\mathbf{Z}^{\prime}$
be a $\mathbf{Z}$-algebra. Let $\varphi\in1+\mathbf{Z}^{\prime}\left[  \left[
t\right]  \right]  ^{+}$ be a power series with constant term equal to $1$.
Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ be a
$\lambda$-ring such that $K$ is a $\mathbf{Z}$-algebra. Let $u_{1},$ $u_{2},$
$...,$ $u_{m}$ be $1$-dimensional elements of $K$. Then,%
\[
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  u_{1}%
+u_{2}+...+u_{m}\right)  =\prod\limits_{i=1}^{m}\varphi\left(  \left(
u_{i}\otimes1\right)  T\right)  .
\]


\bigskip
\end{quote}

\subsection{Exercises}

\begin{quotation}
\textit{Exercise 10.1.} Let $K$ be a ring. Let $m\in\mathbb{N}$. For every
$i\in\left\{  1,2,...,m\right\}  $, let $\Phi_{i}\in K\left[  \left[
T\right]  \right]  $ be a power series.

\textbf{(a)} We have $\operatorname*{Coeff}\nolimits_{0}\left(  \prod
\limits_{i=1}^{m}\Phi_{i}\right)  =\prod\limits_{i=1}^{m}\operatorname*{Coeff}%
\nolimits_{0}\left(  \Phi_{i}\right)  $.

\textbf{(b)} Assume that $\operatorname*{Coeff}\nolimits_{0}\left(  \Phi
_{i}\right)  =1$ for every $i\in\left\{  1,2,...,m\right\}  $. Then,
$\operatorname*{Coeff}\nolimits_{0}\left(  \prod\limits_{i=1}^{m}\Phi
_{i}\right)  =1$ and $\operatorname*{Coeff}\nolimits_{1}\left(  \prod
\limits_{i=1}^{m}\Phi_{i}\right)  =\sum\limits_{i=1}^{m}\operatorname*{Coeff}%
\nolimits_{1}\left(  \Phi_{i}\right)  $.

[This is a very easy exercise. It stands here because I used it to prove
Proposition 10.6 in an earlier version of this text.]

\textit{Exercise 10.2.} Prove Proposition 10.29, Proposition 10.30,
Proposition 10.31, Proposition 10.32, Proposition 10.33, Theorem 10.34,
Corollary 10.35, Proposition 10.36 and Theorem 10.37.
\end{quotation}

\bigskip

\fbox{\textbf{WARNING:} The following is incomplete and no proofs have been
added yet.}

\begin{center}
\fbox{\textbf{11. Representation and Grothendieck rings}}
\end{center}

This Section, once it is written, will contain Seiler's proof that
representation rings (Grothendieck rings of categories of representations on
projective modules) are special $\lambda$-rings.

[...]

\section*{X. Positive structure on $\lambda$-rings}

Almost all $\lambda$-rings in Fulton/Lang [1] and many $\lambda$-rings in
nature carry an additional structure called a \textit{positive structure}:

\begin{quote}
\textbf{Definition.} \textbf{1)} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring. Let $\varepsilon
:K\rightarrow\mathbb{Z}$ be a surjective\footnote{I am quoting this from [1].
Personally, I have never have met a non-surjective ring homomorphism to
$\mathbb{Z}$ in my life.} ring homomorphism. Let $\mathbf{E}$ be a subset of
$K$ such that $\mathbf{E}$ is closed under addition and multiplication and
contains the subset $\mathbb{Z}^{+}$ of $K$ (that is, the image of
$\mathbb{Z}^{+}$ under the canonical ring homomorphism $\mathbb{Z}%
^{+}\rightarrow K$). Also assume that $K=\mathbf{E}-\mathbf{E}$ (that is,
every element of $K$ can be written as difference of two elements of
$\mathbf{E}$). Furthermore, assume that every $e\in\mathbf{E}$ satisfies%
\[
\varepsilon\left(  e\right)  >0;\ \ \ \ \ \ \ \ \ \ \lambda^{i}\left(
e\right)  =0\ \ \ \ \ \ \ \ \ \ \text{for any }i>\varepsilon\left(  e\right)
,\ \ \ \ \ \ \ \ \ \ \text{and that }\lambda^{\varepsilon\left(  e\right)
}\left(  e\right)  \text{ is a unit in the ring }K.
\]
Besides, we assume that for every invertible element $u\in\mathbf{E}$, the
inverse of $u$ must lie in $\mathbf{E}$ as well.

Then, $\left(  \varepsilon,\mathbf{E}\right)  $ is called a \textit{positive
structure} on the $\lambda$-ring. The homomorphism $\varepsilon:K\rightarrow
\mathbb{Z}$ is called an \textit{augmentation} for the $\lambda$-ring $\left(
K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ with its positive
structure $\left(  \varepsilon,\mathbf{E}\right)  $. The elements of the set
$\mathbf{E}$ are called the \textit{positive elements} of the $\lambda$-ring
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ with its
positive structure $\left(  \varepsilon,\mathbf{E}\right)  $%
.\ \ \ \ \footnote{One remark about the assumption that for every invertible
element $u\in\mathbf{E}$, the inverse of $u$ must lie in $\mathbf{E}$ as well:
\par
Fulton and Lang do not make this assumption in [1], but this is a mistake on
their side. In fact, they claim that the set of all $u\in\mathbf{E}$ such that
$\varepsilon\left(  u\right)  =1$ is a subgroup of $K^{\times}$. But to make
this claim, they need the above-mentioned assumption (or another similar one).
In fact, here is an example of a $\lambda$-ring $K\ $which satisfies all of
their assumptions, but for which the set of all $u\in\mathbf{E}$ such that
$\varepsilon\left(  u\right)  =1$ is \textit{not} a subgroup of $K^{\times}$:
\par
Let $Z$ be the free group on one generator. (This group $Z$ is, of course,
none other than $\mathbb{Z}$, written multiplicatively; however we must avoid
calling it $\mathbb{Z}$, lest it is confused with the \textit{ring}
$\mathbb{Z}$.) Let $X$ be the generator of $Z$. Applying Exercise 3.4 to
$M=Z$, we get a $\lambda$-ring $\left(  \mathbb{Z}\left[  Z\right]  ,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $. Now define a map
$\varepsilon:\mathbb{Z}\left[  Z\right]  \rightarrow\mathbb{Z}$ by%
\[
\varepsilon\left(  \sum_{m\in Z}\alpha_{m}m\right)  =\sum_{m\in Z}\alpha
_{m}\ \ \ \ \ \ \ \ \ \ \text{for all }\left(  \alpha_{m}\right)  _{m\in Z}%
\in\mathbb{Z}^{\left(  Z\right)  }.
\]
Then, $\varepsilon$ is a surjective ring homomorphism. Define $\mathbf{E}$ to
be the additive and multiplicative closure of the subset%
\[
\left\{  1,X,X^{2},...\right\}  \cup\left\{  1+X^{-1},1+X^{-2},1+X^{-3}%
,...\right\}
\]
of $\mathbb{Z}\left[  Z\right]  $. It is easy to see that all of our
conditions are satisfied, except for the assumption that for every invertible
element $u\in\mathbf{E}$, the inverse of $u$ must lie in $\mathbf{E}$ as well.
Hence, if we would omit this assumption (as Fulton and Lang do in [1]), the
pair $\left(  \varepsilon,\mathbf{E}\right)  $ would be a positive structure
on our $\lambda$-ring $\left(  \mathbb{Z}\left[  Z\right]  ,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $. However, the set of all
$u\in\mathbf{E}$ such that $\varepsilon\left(  u\right)  =1$ is not a subgroup
of $K^{\times}$ in this case, since this set contains $X$ but not its inverse
$X^{-1}$ (in fact, it is easy to see that $X^{-1}\notin\mathbf{E}$; otherwise
$X^{-1}$ would be a sum of products of elements of $\left\{  1,X,X^{2}%
,...\right\}  \cup\left\{  1+X^{-1},1+X^{-2},1+X^{-3},...\right\}  $, and
applying $\varepsilon$ we would conclude that the sum has only $1$ summand,
which is easy to rule out).}

[Some assumptions may still be missing here. For example, we might want to
require that $\lambda^{i}\left(  \mathbf{E}\right)  \subseteq\mathbf{E}$.] [\#2]

\textbf{2)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a $\lambda$-ring with a positive structure $\left(
\varepsilon,\mathbf{E}\right)  .$ The subset $\left\{  u\in\mathbf{E}%
\ \mid\ \varepsilon\left(  u\right)  =1\right\}  $ of $\mathbf{E}$ is usually
denoted as $\mathbf{L}$. The elements of $\mathbf{L}$ are called the
\textit{line elements} of the $\lambda$-ring $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ with its positive structure $\left(
\varepsilon,\mathbf{E}\right)  $.

\textbf{Theorem X.1.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a $\lambda$-ring with a positive structure
$\left(  \varepsilon,\mathbf{E}\right)  .$

\textbf{(a)} Then, $\mathbf{L}=\left\{  u\in\mathbf{E}\ \mid\ \varepsilon
\left(  u\right)  =1\right\}  $ is a subgroup of the (multiplicative) unit
group $K^{\times}$ of $K$.

\textbf{(b)} We have $\mathbf{L}=\left\{  u\in\mathbf{E}\ \mid\ \lambda
_{T}\left(  u\right)  =1+uT\right\}  =\left\{  u\in\mathbf{E}\ \mid\ u\text{
is }1\text{-dimensional}\right\}  $.
\end{quote}

\textit{Proof of Theorem X.1.} \textbf{(b)} \textit{1st Step:} We have
$\mathbf{L}\subseteq\left\{  u\in\mathbf{E}\ \mid\ u\text{ is }%
1\text{-dimensional}\right\}  $.

\textit{Proof.} For every $u\in\mathbf{L}$, we have $\varepsilon\left(
u\right)  =1$ (by the definition of $\mathbf{L}$) and $\lambda^{i}\left(
u\right)  =0$ for any $i>\varepsilon\left(  u\right)  $ (by the axioms of a
positive structure, since $u\in\mathbf{L}\subseteq\mathbf{E}$). Thus, for
every $u\in\mathbf{L}$, we have $\lambda^{i}\left(  u\right)  =0$ for any
$i>1$ (because for any $i>1$, we have $i>1=\varepsilon\left(  u\right)  $ and
thus $\lambda^{i}\left(  u\right)  =0$). In other words, every $u\in
\mathbf{L}$ is $1$-dimensional. Thus, $\mathbf{L}\subseteq\left\{
u\in\mathbf{E}\ \mid\ u\text{ is }1\text{-dimensional}\right\}  $.

\textit{2nd Step:} We have $\left\{  u\in\mathbf{E}\ \mid\ u\text{ is
}1\text{-dimensional}\right\}  \subseteq\left\{  u\in\mathbf{E}\ \mid
\ \lambda_{T}\left(  u\right)  =1+uT\right\}  $.

\textit{Proof.} Every $1$-dimensional $u\in\mathbf{E}$ satisfies $\lambda
^{i}\left(  u\right)  =0$ for any $i>1$ (by the definition of "$1$%
-dimensional"). Now, every $1$-dimensional $u\in\mathbf{E}$ satisfies%
\[
\lambda_{T}\left(  u\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
u\right)  T^{i}=\underbrace{\lambda^{0}\left(  u\right)  }_{=1}%
+\underbrace{\lambda^{1}\left(  u\right)  }_{=u}T+\sum\limits_{i\geq
2}\underbrace{\lambda^{i}\left(  u\right)  }_{\substack{=0,\text{ since}%
\\i>1}}T^{i}=1+uT.
\]
Thus, we have shown that every $1$-dimensional $u\in\mathbf{E}$ satisfies
$\lambda_{T}\left(  u\right)  =1+uT$. In other words, $\left\{  u\in
\mathbf{E}\ \mid\ u\text{ is }1\text{-dimensional}\right\}  \subseteq\left\{
u\in\mathbf{E}\ \mid\ \lambda_{T}\left(  u\right)  =1+uT\right\}  $.

\textit{3rd Step:} We have $\left\{  u\in\mathbf{E}\ \mid\ \lambda_{T}\left(
u\right)  =1+uT\right\}  \subseteq\mathbf{L}$.

\textit{Proof.} Let $u\in\mathbf{E}$ be an element satisfying $\lambda
_{T}\left(  u\right)  =1+uT$. Then this $u$ must satisfy%
\[
\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  u\right)  T^{i}=\lambda
_{T}\left(  u\right)  =1+uT,
\]
and thus (by comparison of coefficients) $\lambda^{i}\left(  u\right)  =0$ for
every $i>1$, so that $\varepsilon\left(  u\right)  \leq1$ (because
$\lambda^{\varepsilon\left(  u\right)  }\left(  u\right)  $ is a unit in the
ring $K$ (since $u\in\mathbf{E}$), so that $\lambda^{\varepsilon\left(
u\right)  }\left(  u\right)  \neq0$ and thus $\varepsilon\left(  u\right)
\leq1$). Together with $\varepsilon\left(  u\right)  >0$, this yields
$\varepsilon\left(  u\right)  =1$ and thus $u\in\mathbf{L}$.

We have thus proven that every $u\in\mathbf{E}$ satisfying $\lambda_{T}\left(
u\right)  =1+uT$ must satisfy $u\in\mathbf{L}$. In other words, we have proven
that $\left\{  u\in\mathbf{E}\ \mid\ \lambda_{T}\left(  u\right)
=1+uT\right\}  \subseteq\mathbf{L}$.

\textit{4th Step:} Combining the results of the 1st Step, the 2nd Step and the
3rd Step, we conclude that $\mathbf{L}=\left\{  u\in\mathbf{E}\ \mid
\ \lambda_{T}\left(  u\right)  =1+uT\right\}  =\left\{  u\in\mathbf{E}%
\ \mid\ u\text{ is }1\text{-dimensional}\right\}  $. This proves Theorem X.1
\textbf{(b)}.

\textbf{(a)} \textit{1st Step:} Every $u\in\mathbf{L}$ is invertible in $K$,
and the inverse of every $u\in\mathbf{L}$ lies in $\mathbf{L}$.

\textit{Proof.} Let $u\in\mathbf{L}$. Then, $\lambda^{\varepsilon\left(
u\right)  }\left(  u\right)  $ is a unit in the ring $K$ (since $u\in
\mathbf{E}$). But $\varepsilon\left(  u\right)  =1$ (since $u\in\mathbf{L}$)
and thus $\lambda^{\varepsilon\left(  u\right)  }\left(  u\right)
=\lambda^{1}\left(  u\right)  =u$. Thus, $u$ is a unit in $K$; that is, $u$ is
invertible. Its inverse $u^{-1}$ must lie in $\mathbf{E}$ as well (because
$u\in\mathbf{L}\subseteq\mathbf{E}$, and because of our assumption that for
every invertible element $u\in\mathbf{E}$, the inverse of $u$ must lie in
$\mathbf{E}$ as well). Since $\varepsilon$ is a ring homomorphism, we have
$\varepsilon\left(  u^{-1}\right)  =\left(  \underbrace{\varepsilon\left(
u\right)  }_{=1}\right)  ^{-1}=1^{-1}=1$. This, together with $u^{-1}%
\in\mathbf{E}$, yields $u^{-1}\in\mathbf{L}$ (by the definition of
$\mathbf{L}$).

We have thus proven that every $u\in\mathbf{L}$ is invertible in $K$, and the
inverse of every $u\in\mathbf{L}$ lies in $\mathbf{L}$.

\textit{2nd Step:} The set $\mathbf{L}$ is closed under multiplication and
contains the multiplicative unity of $K$.

\textit{Proof.} This is trivial.

\textit{3rd Step:} Theorem X.1 \textbf{(a)} trivially follows from the 1st
Step and the 2nd Step.

\begin{quote}
\textbf{Theorem X.2.} Let $\left(  K,\left(  \lambda^{i}\right)
_{i\in\mathbb{N}}\right)  $ be a special(?) $\lambda$-ring with a positive
structure $\left(  \varepsilon,\mathbf{E}\right)  $. Let $e\in\mathbf{E}$, and
let $r=\varepsilon\left(  e\right)  -1$. Define a polynomial $p_{e}\in
K\left[  T\right]  $ by $p_{e}\left(  T\right)  =\sum\limits_{i=0}%
^{r+1}\left(  -1\right)  ^{i}\lambda^{i}\left(  e\right)  T^{r+1-i}$. Set
$K_{e}=K\left[  T\right]  \diagup\left(  p_{e}\left(  T\right)  \right)
=K\left[  \ell\right]  $, where $\ell$ denotes the equivalence class of $T$
modulo $p_{e}\left(  T\right)  $. Then, $K_{e}$ is a finite-free extension
ring of $K$. There exists a map $\widetilde{\lambda}^{i}:K_{e}\rightarrow
K_{e}$ for every $i\in\mathbb{N}$ such that $\left(  K_{e},\left(
\widetilde{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda
$-ring such that the inclusion $K\rightarrow K_{e}$ is a $\lambda$-ring
homomorphism and such that $\ell\in K_{e}$ is a $1$-dimensional element.
Moreover, there exists a positive structure $\left(  \varepsilon
_{e},\mathbf{E}_{e}\right)  $ on $K_{e}$ defined by $\varepsilon_{e}\left(
\ell\right)  =1$ and $\mathbf{E}_{e}=\left\{  \sum\limits_{i\in\mathbb{N}%
,\ j\in\mathbb{N}}a_{i,j}\ell^{i}\left(  e-\ell\right)  ^{j}\ \mid\text{
}a_{i,j}\in\mathbf{E}\text{ for all }i\in\mathbb{N}\text{ and }j\in
\mathbb{N}\right\}  .$
\end{quote}

By iterating the construction in Theorem X.2, we can find, for any
$e\in\mathbf{E}$, an extension ring of $K$ with a $\lambda$-ring structure in
which $e$ is the sum of $r$ $1$-dimensional elements. This is called the
\textit{splitting principle}, and is what Fulton/Lang [1] use instead of
Theorem 8.4 above when they want to prove an identity just by verifying it for
sums of $1$-dimensional elements. However, this way they can only show it for
positive elements, while Theorem 8.4 yields it for arbitrary elements.

\begin{quote}
[add noncont. splitting principle generalizing 8.4][...]
\end{quote}

\section{Hints and solutions to exercises}

\subsection{To Section 1}

\subsection{To Section 2}

\textit{Exercise 2.1: Solution:} \textbf{(a)} Theorem 2.1 \textbf{(c)} says
that $f$ is a homomorphism of $\lambda$-rings if and only if $\mu_{T}\circ
f=f\left[  \left[  T\right]  \right]  \circ\lambda_{T}$. Thus, it remains to
show that $\mu_{T}\circ f=f\left[  \left[  T\right]  \right]  \circ\lambda
_{T}$ holds if and only if every $e\in E$ satisfies $\left(  \mu_{T}\circ
f\right)  \left(  e\right)  =\left(  f\left[  \left[  T\right]  \right]
\circ\lambda_{T}\right)  \left(  e\right)  $. Since $E$ is a generating set of
the $\mathbb{Z}$-module $K$, this comes down to proving the following three facts:

\begin{itemize}
\item We have $\left(  \mu_{T}\circ f\right)  \left(  0\right)  =\left(
f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(  0\right)
$.

\item We have $\left(  \mu_{T}\circ f\right)  \left(  -x\right)  =\left(
f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(
-x\right)  $ for every $x\in K$ which satisfies $\left(  \mu_{T}\circ
f\right)  \left(  x\right)  =\left(  f\left[  \left[  T\right]  \right]
\circ\lambda_{T}\right)  \left(  x\right)  $.

\item We have $\left(  \mu_{T}\circ f\right)  \left(  x+y\right)  =\left(
f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(
x+y\right)  $ for any $x\in K$ and $y\in K$ which satisfy $\left(  \mu
_{T}\circ f\right)  \left(  x\right)  =\left(  f\left[  \left[  T\right]
\right]  \circ\lambda_{T}\right)  \left(  x\right)  $ and $\left(  \mu
_{T}\circ f\right)  \left(  y\right)  =\left(  f\left[  \left[  T\right]
\right]  \circ\lambda_{T}\right)  \left(  y\right)  $.
\end{itemize}

We will only prove the last of these three assertions (the other two are
similar): If $\left(  \mu_{T}\circ f\right)  \left(  x\right)  =\left(
f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(  x\right)
$ and $\left(  \mu_{T}\circ f\right)  \left(  y\right)  =\left(  f\left[
\left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(  y\right)  $, then%
\begin{align*}
&  \left(  \mu_{T}\circ f\right)  \left(  x+y\right) \\
&  =\mu_{T}\left(  f\left(  x+y\right)  \right)  =\mu_{T}\left(  f\left(
x\right)  +f\left(  y\right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}f\text{ is a ring homomorphism}\right) \\
&  =\mu_{T}\left(  f\left(  x\right)  \right)  \cdot\mu_{T}\left(  f\left(
y\right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 2.1
\textbf{(a)}, applied to the }\lambda\text{-ring }\left(  L,\left(  \mu
^{i}\right)  _{i\in\mathbb{N}}\right)  \right) \\
&  =\underbrace{\left(  \mu_{T}\circ f\right)  \left(  x\right)  }_{=\left(
f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(  x\right)
}\cdot\underbrace{\left(  \mu_{T}\circ f\right)  \left(  y\right)  }_{=\left(
f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(  y\right)
}=\left(  f\left[  \left[  T\right]  \right]  \circ\lambda_{T}\right)  \left(
x\right)  \cdot\left(  f\left[  \left[  T\right]  \right]  \circ\lambda
_{T}\right)  \left(  y\right) \\
&  =\left(  f\left[  \left[  T\right]  \right]  \right)  \left(
\underbrace{\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)
}_{=\lambda_{T}\left(  x+y\right)  \text{ by Theorem 2.1 \textbf{(a)}}%
}\right)  =\left(  f\left[  \left[  T\right]  \right]  \circ\lambda
_{T}\right)  \left(  x+y\right)  ,
\end{align*}
qed.

\textbf{(b)} This follows from \textbf{(a)} in the same way as Theorem 2.1
\textbf{(c)} was proven.

\textit{Exercise 2.2: Solution:} It is an exercise in basic algebra to see
that $L-L$ is a subring of $K$. Thus, it only remains to show that
$\lambda^{i}\left(  L-L\right)  \subseteq L-L$ for every $i\in\mathbb{N}$. In
other words, we have to prove that $\lambda^{i}\left(  \ell-\ell^{\prime
}\right)  \in L-L$ for every $\ell\in L$ and $\ell^{\prime}\in L$.

We are going to prove this by induction, so we assume that $\lambda^{j}\left(
\ell-\ell^{\prime}\right)  \in L-L$ for all $j<i$. Then,%
\begin{align*}
\lambda^{i}\left(  \ell\right)   &  =\lambda^{i}\left(  \left(  \ell
-\ell^{\prime}\right)  +\ell^{\prime}\right)  =\sum_{j=0}^{i}\lambda
^{j}\left(  \ell-\ell^{\prime}\right)  \lambda^{i-j}\left(  \ell^{\prime
}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }%
\lambda\text{-rings}\right) \\
&  =\sum_{j=0}^{i-1}\underbrace{\lambda^{j}\left(  \ell-\ell^{\prime}\right)
}_{\substack{\in L-L,\text{ since}\\j<i}}\underbrace{\lambda^{i-j}\left(
\ell^{\prime}\right)  }_{\substack{\in L\text{, since}\\\ell^{\prime}\in
L}}+\lambda^{i}\left(  \ell-\ell^{\prime}\right)  \underbrace{\lambda
^{0}\left(  \ell^{\prime}\right)  }_{=1}\\
&  \in\underbrace{\left(  L-L\right)  L}_{\substack{\subseteq LL-LL\subseteq
L-L\\\text{(since }LL\subseteq L\text{)}}}+\lambda^{i}\left(  \ell
-\ell^{\prime}\right)  \subseteq\left(  L-L\right)  +\lambda^{i}\left(
\ell-\ell^{\prime}\right)  .
\end{align*}
But $\lambda^{i}\left(  \ell\right)  $ itself lies in $L-L$ (since $\ell\in
L$, so that $\lambda^{i}\left(  \ell\right)  \in L$ and thus $\lambda
^{i}\left(  \ell\right)  =\underbrace{\lambda^{i}\left(  \ell\right)  }_{\in
L}-\underbrace{0}_{\in L}\in L-L$), so this yields $\lambda^{i}\left(
\ell-\ell^{\prime}\right)  \in L-L,$ and this completes our induction.

\textit{Exercise 2.3:} \textit{Solution:} \textit{Proof of Theorem 2.2.}
\textbf{(a)} Let $x\in K\diagup I$. Let $y\in K$ and $z\in K$ be two elements
of $K$ satisfying $\overline{y}=x$ and $\overline{z}=x$. Then, $\overline
{y}=x=\overline{z}$, so that $y\equiv z\operatorname{mod}I$. In other words,
$y-z\in I$.

We know (from the definition of $\lambda$-ideals) that $I$ is a $\lambda
$-ideal of $K$ if and only if every $t\in I$ and every positive integer $i$
satisfy $\lambda^{i}\left(  t\right)  \in I$. Since we know that $I$ is a
$\lambda$-ideal, we conclude that every $t\in I$ and every positive integer
$i$ satisfy $\lambda^{i}\left(  t\right)  \in I$. Applied to $t=y-z$, this
yields that every positive integer $i$ satisfies $\lambda^{i}\left(
y-z\right)  \in I$.

Fix $k\in\mathbb{N}$. The equality (\ref{lambda1}), applied to $y-z$ and $z$
instead of $x$ and $y$, yields%
\begin{align*}
\lambda^{k}\left(  \left(  y-z\right)  +z\right)   &  =\sum_{i=0}^{k}%
\lambda^{i}\left(  y-z\right)  \lambda^{k-i}\left(  z\right)
=\underbrace{\lambda^{0}\left(  y-z\right)  }_{\substack{=1\\\text{(since
}\lambda^{0}\left(  t\right)  =1\\\text{for every }t\in K\text{)}%
}}\underbrace{\lambda^{k-0}}_{=\lambda^{k}}\left(  z\right)  +\sum_{i=0}%
^{k}\underbrace{\lambda^{i}\left(  y-z\right)  }_{\substack{\in
I\\\text{(since }i\text{ is a positive}\\\text{integer)}}}\lambda^{k-i}\left(
z\right) \\
&  \in\underbrace{1\lambda^{k}\left(  z\right)  }_{=\lambda^{k}\left(
z\right)  }+\underbrace{\sum_{i=0}^{k}I\lambda^{k-i}\left(  z\right)
}_{\substack{\subseteq I\\\text{(since }I\text{ is an ideal)}}}\subseteq
\lambda^{k}\left(  z\right)  +I.
\end{align*}
Since $\left(  y-z\right)  +z=y$, this rewrites as $\lambda^{k}\left(
y\right)  \in\lambda^{k}\left(  z\right)  +I$. In other words, $\overline
{\lambda^{k}\left(  y\right)  }=\overline{\lambda^{k}\left(  z\right)  }$.

Now, forget that we fixed $k$. We thus have proven that $\overline{\lambda
^{k}\left(  y\right)  }=\overline{\lambda^{k}\left(  z\right)  }$ for every
$k\in\mathbb{N}$. Renaming $k$ as $i$ in this claim, we conclude that we have
$\overline{\lambda^{i}\left(  y\right)  }=\overline{\lambda^{i}\left(
z\right)  }$ for every $i\in\mathbb{N}$. Theorem 2.2 \textbf{(a)} is proven.

\textbf{(b)} First of all,%
\begin{equation}
\left(  \widetilde{\lambda}^{0}\left(  x\right)  =1\text{ for every }x\in
K\diagup I\right)  \label{2.3.sol.1}%
\end{equation}
\footnote{\textit{Proof of (\ref{2.3.sol.1}):} Let $x\in K\diagup I$. By the
definition of $\widetilde{\lambda}^{0}$, the value $\widetilde{\lambda}%
^{0}\left(  x\right)  $ is defined as $\overline{\lambda^{0}\left(  w\right)
}$, where $w$ is an element of $K$ satisfying $\overline{w}=x$. So let $w$ be
an element of $K$ satisfying $\overline{w}=x$ (such a $w$ clearly exists).
Then, $\widetilde{\lambda}^{0}\left(  x\right)  =\overline{\lambda^{0}\left(
w\right)  }$. But $\lambda^{0}\left(  w\right)  =1$ (since every $t\in K$
satisfies $\lambda^{0}\left(  t\right)  =1$). Thus, $\overline{\lambda
^{0}\left(  w\right)  }=\overline{1}=1$, so that $\widetilde{\lambda}%
^{0}\left(  x\right)  =\overline{\lambda^{0}\left(  w\right)  }=1$. This
proves (\ref{2.3.sol.1}).}. Next,%
\begin{equation}
\left(  \widetilde{\lambda}^{1}\left(  x\right)  =x\text{ for every }x\in
K\diagup I\right)  \label{2.3.sol.2}%
\end{equation}
\footnote{\textit{Proof of (\ref{2.3.sol.2}):} Let $x\in K\diagup I$. By the
definition of $\widetilde{\lambda}^{1}$, the value $\widetilde{\lambda}%
^{1}\left(  x\right)  $ is defined as $\overline{\lambda^{1}\left(  w\right)
}$, where $w$ is an element of $K$ satisfying $\overline{w}=x$. So let $w$ be
an element of $K$ satisfying $\overline{w}=x$ (such a $w$ clearly exists).
Then, $\widetilde{\lambda}^{1}\left(  x\right)  =\overline{\lambda^{1}\left(
w\right)  }$. But $\lambda^{1}\left(  w\right)  =w$ (since every $t\in K$
satisfies $\lambda^{1}\left(  t\right)  =t$). Thus, $\overline{\lambda
^{1}\left(  w\right)  }=\overline{w}=x$, so that $\widetilde{\lambda}%
^{1}\left(  x\right)  =\overline{\lambda^{1}\left(  w\right)  }=x$. This
proves (\ref{2.3.sol.2}).}. Finally,%
\begin{equation}
\left(  \widetilde{\lambda}^{k}\left(  x+y\right)  =\sum_{i=0}^{k}%
\widetilde{\lambda}^{i}\left(  x\right)  \widetilde{\lambda}^{k-i}\left(
y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }k\in\mathbb{N},\text{ }x\in
K\diagup I\text{ and }y\in K\diagup I\right)  \label{2.3.sol.3}%
\end{equation}
\footnote{\textit{Proof of (\ref{2.3.sol.3}):} Let $x\in K\diagup I$, $y\in
K\diagup I$ and $k\in\mathbb{N}$.
\par
Let $u$ be an element of $K$ satisfying $\overline{u}=x$. (Such a $u$ clearly
exists.) Let $v$ be an element of $K$ satisfying $\overline{v}=y$.
\par
Let $i\in\left\{  0,1,...,k\right\}  $.
\par
By the definition of $\widetilde{\lambda}^{i}$, the value $\widetilde{\lambda
}^{i}\left(  x\right)  $ is defined as $\overline{\lambda^{i}\left(  w\right)
}$, where $w$ is an element of $K$ satisfying $\overline{w}=x$. Thus,
$\widetilde{\lambda}^{i}\left(  x\right)  =\overline{\lambda^{i}\left(
w\right)  }$ for every $w\in K$ satisfying $\overline{w}=x$. Applied to $w=u$,
this yields $\widetilde{\lambda}^{i}\left(  x\right)  =\overline{\lambda
^{i}\left(  u\right)  }$ (since $\overline{u}=x$).
\par
By the definition of $\widetilde{\lambda}^{k-i}$, the value
$\widetilde{\lambda}^{k-i}\left(  y\right)  $ is defined as $\overline
{\lambda^{k-i}\left(  w\right)  }$, where $w$ is an element of $K$ satisfying
$\overline{w}=y$. Thus, $\widetilde{\lambda}^{k-i}\left(  y\right)
=\overline{\lambda^{k-i}\left(  w\right)  }$ for every $w\in K$ satisfying
$\overline{w}=y$. Applied to $w=v$, this yields $\widetilde{\lambda}%
^{k-i}\left(  x\right)  =\overline{\lambda^{k-i}\left(  v\right)  }$ (since
$\overline{v}=y$).
\par
Now forget that we fixed $i\in\left\{  0,1,...,k\right\}  $. We thus have
shown that every $i\in\left\{  0,1,...,k\right\}  $ satisfies
$\widetilde{\lambda}^{i}\left(  x\right)  =\overline{\lambda^{i}\left(
u\right)  }$ and $\widetilde{\lambda}^{k-i}\left(  x\right)  =\overline
{\lambda^{k-i}\left(  v\right)  }$. Thus,%
\[
\sum_{i=0}^{k}\underbrace{\widetilde{\lambda}^{i}\left(  x\right)
}_{=\overline{\lambda^{i}\left(  u\right)  }}\underbrace{\widetilde{\lambda
}^{k-i}\left(  y\right)  }_{=\overline{\lambda^{k-i}\left(  v\right)  }}%
=\sum_{i=0}^{k}\overline{\lambda^{i}\left(  u\right)  }\overline{\lambda
^{k-i}\left(  v\right)  }=\overline{\sum_{i=0}^{k}\lambda^{i}\left(  u\right)
\lambda^{k-i}\left(  v\right)  }.
\]
\par
By the definition of $\widetilde{\lambda}^{k}$, the value $\widetilde{\lambda
}^{k}\left(  x+y\right)  $ is defined as $\overline{\lambda^{k}\left(
w\right)  }$, where $w$ is an element of $K$ satisfying $\overline{w}=x+y$.
Thus, $\widetilde{\lambda}^{k}\left(  x\right)  =\overline{\lambda^{k}\left(
w\right)  }$ for every $w\in K$ satisfying $\overline{w}=x+y$. Applied to
$w=u+v$, this yields $\widetilde{\lambda}^{k}\left(  x+y\right)
=\overline{\lambda^{k}\left(  u+v\right)  }$ (since $\overline{u+v}%
=\underbrace{\overline{u}}_{=x}+\underbrace{\overline{v}}_{=y}=x+y$). Thus,%
\begin{align*}
\widetilde{\lambda}^{k}\left(  x+y\right)   &  =\overline{\lambda^{k}\left(
u+v\right)  }=\overline{\sum_{i=0}^{k}\lambda^{i}\left(  u\right)
\lambda^{k-i}\left(  v\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since (\ref{lambda1}) (applied to }u\text{ and }v\text{ instead of
}x\text{ and }y\text{) yields}\\
\lambda^{k}\left(  u+v\right)  =\sum\limits_{i=0}^{k}\lambda^{i}\left(
u\right)  \lambda^{k-i}\left(  v\right)
\end{array}
\right) \\
&  =\sum_{i=0}^{k}\widetilde{\lambda}^{i}\left(  x\right)  \widetilde{\lambda
}^{k-i}\left(  y\right)  .
\end{align*}
This proves (\ref{2.3.sol.3}).}.

Now, according to the definition of a $\lambda$-ring, we know that $\left(
K\diagup I,\left(  \widetilde{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $
is a $\lambda$-ring if and only if it satisfies the relations (\ref{2.3.sol.1}%
), (\ref{2.3.sol.2}) and (\ref{2.3.sol.3}). Since we have shown that it
satisfies the relations (\ref{2.3.sol.1}), (\ref{2.3.sol.2}) and
(\ref{2.3.sol.3}), we thus conclude that $\left(  K\diagup I,\left(
\widetilde{\lambda}^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a $\lambda
$-ring. Theorem 2.2 \textbf{(b)} is proven.

\textbf{(c)} Let $\pi$ be the canonical projection $K\rightarrow K\diagup I$.

The definition of a $\lambda$-ring homomorphism tells us: The map $\pi$ is a
$\lambda$-ring homomorphism if and only if $\pi$ is a ring homomorphism and
satisfies $\widetilde{\lambda}^{i}\circ\pi=\pi\circ\lambda^{i}$ for every
$i\in\mathbb{N}$. But since $\pi$ is a ring homomorphism (because it is a
canonical projection of a ring onto a factor ring) and satisfies
$\widetilde{\lambda}^{i}\circ\pi=\pi\circ\lambda^{i}$ for every $i\in
\mathbb{N}$\ \ \ \ \footnote{\textit{Proof.} Let $i\in\mathbb{N}$. Let $z\in
K$. Then, $\pi\left(  z\right)  =\overline{z}$ (because $\pi$ is the canonical
projection $K\rightarrow K\diagup I$) and $\pi\left(  \lambda^{i}\left(
z\right)  \right)  =\overline{\lambda^{i}\left(  z\right)  }$ (for the same
reason).
\par
By the definition of $\widetilde{\lambda}^{i}$, the value $\widetilde{\lambda
}^{i}\left(  \overline{z}\right)  $ is defined as $\overline{\lambda
^{i}\left(  w\right)  }$, where $w$ is an element of $K$ satisfying
$\overline{w}=\overline{z}$. Thus, $\widetilde{\lambda}^{i}\left(
\overline{z}\right)  =\overline{\lambda^{i}\left(  w\right)  }$ for every
$w\in K$ satisfying $\overline{w}=\overline{z}$. Applied to $w=z$, this yields
$\widetilde{\lambda}^{i}\left(  \overline{z}\right)  =\overline{\lambda
^{i}\left(  z\right)  }$ (since $\overline{z}=\overline{z}$).
\par
Now, $\left(  \widetilde{\lambda}^{i}\circ\pi\right)  \left(  z\right)
=\widetilde{\lambda}^{i}\left(  \underbrace{\pi\left(  z\right)  }%
_{=\overline{z}}\right)  =\widetilde{\lambda}^{i}\left(  \overline{z}\right)
=\overline{\lambda^{i}\left(  z\right)  }=\pi\left(  \lambda^{i}\left(
z\right)  \right)  =\left(  \pi\circ\lambda^{i}\right)  \left(  z\right)  $.
\par
Now forget that we fixed $z$. We thus have proven that $\left(
\widetilde{\lambda}^{i}\circ\pi\right)  \left(  z\right)  =\left(  \pi
\circ\lambda^{i}\right)  \left(  z\right)  $ for every $z\in K$. In other
words, $\widetilde{\lambda}^{i}\circ\pi=\pi\circ\lambda^{i}$, qed.}, this
yields that $\pi$ is a $\lambda$-ring homomorphism. Since $\pi$ is the
canonical projection $K\rightarrow K\diagup I$, we thus have proven that the
canonical projection $K\rightarrow K\diagup I$ is a $\lambda$-ring
homomorphism. Theorem 2.2 \textbf{(c)} is proven.

\textit{Exercise 2.4:} \textit{Solution:} \textit{Proof of Theorem 2.3.} Let
$t\in\operatorname*{Ker}f$, and let $i$ be a positive integer. Since
$t\in\operatorname*{Ker}f$, we have $f\left(  t\right)  =0$, thus $\mu
^{i}\left(  f\left(  t\right)  \right)  =\mu^{i}\left(  0\right)  =0$ (by
Theorem 2.1 \textbf{(d)}).

Since $f$ is a $\lambda$-ring homomorphism, we have $\mu^{i}\circ
f=f\circ\lambda^{i}$, so that $\left(  \mu^{i}\circ f\right)  \left(
t\right)  =\left(  f\circ\lambda^{i}\right)  \left(  t\right)  =f\left(
\lambda^{i}\left(  t\right)  \right)  $. Thus, $f\left(  \lambda^{i}\left(
t\right)  \right)  =\left(  \mu^{i}\circ f\right)  \left(  t\right)  =\mu
^{i}\left(  f\left(  t\right)  \right)  =0$, so that $\lambda^{i}\left(
t\right)  \in\operatorname*{Ker}f$.

Now forget that we fixed $t$ and $i$. We have thus proven that every
$t\in\operatorname*{Ker}f$ and every positive integer $i$ satisfy $\lambda
^{i}\left(  t\right)  \in\operatorname*{Ker}f$.

But the definition of a $\lambda$-ideal tells us that $\operatorname*{Ker}f$
is a $\lambda$-ideal if and only if every $t\in\operatorname*{Ker}f$ and every
positive integer $i$ satisfy $\lambda^{i}\left(  t\right)  \in
\operatorname*{Ker}f$. Since we know that every $t\in\operatorname*{Ker}f$ and
every positive integer $i$ satisfy $\lambda^{i}\left(  t\right)
\in\operatorname*{Ker}f$, we thus conclude that $\operatorname*{Ker}f$ is a
$\lambda$-ideal. Theorem 2.3 is proven.

\subsection{To Section 3}

\textit{Exercise 3.1: Solution:}

\textit{First solution:} The localization $\left\{  1,p,p^{2},...\right\}
^{-1}\mathbb{Z}$ is the subring $\left\{  \dfrac{u}{p^{i}}\ \mid
\ u\in\mathbb{Z},\ i\in\mathbb{N}\right\}  $ of $\mathbb{Q}$. Let
$x\in\left\{  1,p,p^{2},...\right\}  ^{-1}\mathbb{Z}$. We then must show that
$\dbinom{x}{n}\in\left\{  1,p,p^{2},...\right\}  ^{-1}\mathbb{Z}$ for every
$n\in\mathbb{N}$.

Since $x\in\left\{  1,p,p^{2},...\right\}  ^{-1}\mathbb{Z}=\left\{  \dfrac
{u}{p^{i}}\ \mid\ u\in\mathbb{Z},\ i\in\mathbb{N}\right\}  $, we can write $x$
in the form $\dfrac{u}{p^{i}}$ for some $u\in\mathbb{Z}$ and $i\in\mathbb{N}$.
Thus,%
\begin{align*}
\dbinom{x}{n}  &  =\dfrac{x\left(  x-1\right)  ...\left(  x-n+1\right)  }%
{n!}=\dfrac{\prod\limits_{k=0}^{n-1}\left(  x-k\right)  }{n!}=\dfrac
{\prod\limits_{k=0}^{n-1}\left(  \dfrac{u}{p^{i}}-k\right)  }{n!}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }x=\dfrac{u}{p^{i}}\right) \\
&  =\dfrac{\prod\limits_{k=0}^{n-1}\dfrac{u-kp^{i}}{p^{i}}}{n!}=\dfrac
{\prod\limits_{k=0}^{n-1}\left(  u-kp^{i}\right)  }{n!\cdot\left(
p^{i}\right)  ^{n}}.
\end{align*}


Now, let $p^{v}$ be the highest power of $p$ that divides $n!$. Then,
$\dfrac{n!}{p^{v}}$ is a positive integer not divisible by $p$. Denoting
$\dfrac{n!}{p^{v}}$ by $r$, we thus have shown that $r$ is a positive integer
not divisible by $p$. Thus, $p$ is coprime to $r$ (since $p$ is prime), so
that $p^{\varphi\left(  r\right)  }\equiv1\operatorname{mod}r$ (by Euler's
theorem), where $\varphi$ is Euler's totient function.

Notice that $r=\dfrac{n!}{p^{v}}$ yields $n!=p^{v}r$, so that $n!\equiv
0\operatorname{mod}r$. On the other hand,%
\[
p^{\left(  \varphi\left(  r\right)  -1\right)  in}\cdot\prod\limits_{k=0}%
^{n-1}\left(  u-kp^{i}\right)  =\prod\limits_{k=0}^{n-1}\left(  p^{\left(
\varphi\left(  r\right)  -1\right)  i}\left(  u-kp^{i}\right)  \right)
=\prod\limits_{k=0}^{n-1}\left(  p^{\left(  \varphi\left(  r\right)
-1\right)  i}u-p^{\left(  \varphi\left(  r\right)  -1\right)  i}kp^{i}\right)
.
\]
Since $p^{\left(  \varphi\left(  r\right)  -1\right)  i}kp^{i}=p^{\left(
\varphi\left(  r\right)  -1\right)  i+i}k=p^{\varphi\left(  r\right)
i}k=\left(  \underbrace{p^{\varphi\left(  r\right)  }}_{\equiv
1\operatorname{mod}r}\right)  ^{i}k\equiv1^{r}k=k\operatorname{mod}r$, this
becomes%
\begin{align*}
p^{\left(  \varphi\left(  r\right)  -1\right)  in}\cdot\prod\limits_{k=0}%
^{n-1}\left(  u-kp^{i}\right)   &  \equiv\prod\limits_{k=0}^{n-1}\left(
p^{\left(  \varphi\left(  r\right)  -1\right)  i}u-k\right)  =\underbrace{n!}%
_{\equiv0\operatorname{mod}r}\dbinom{p^{\left(  \varphi\left(  r\right)
-1\right)  i}u}{n}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\dfrac{\prod\limits_{k=0}%
^{n-1}\left(  p^{\left(  \varphi\left(  r\right)  -1\right)  i}u-k\right)
}{n!}=\dbinom{p^{\left(  \varphi\left(  r\right)  -1\right)  i}u}{n}\right) \\
&  \equiv0\operatorname{mod}r.
\end{align*}
Thus, $\dfrac{p^{\left(  \varphi\left(  r\right)  -1\right)  in}\cdot
\prod\limits_{k=0}^{n-1}\left(  u-kp^{i}\right)  }{r}$ is an integer. Now,%
\begin{align*}
\dbinom{x}{n}  &  =\dfrac{\prod\limits_{k=0}^{n-1}\left(  u-kp^{i}\right)
}{n!\cdot\left(  p^{i}\right)  ^{n}}=\dfrac{r}{p^{\left(  \varphi\left(
r\right)  -1\right)  in}\cdot\left(  p^{i}\right)  ^{n}n!}\cdot\dfrac
{p^{\left(  \varphi\left(  r\right)  -1\right)  in}\cdot\prod\limits_{k=0}%
^{n-1}\left(  u-kp^{i}\right)  }{r}\\
&  =\underbrace{\dfrac{r}{p^{\left(  \varphi\left(  r\right)  -1\right)
in}\cdot\left(  p^{i}\right)  ^{n}p^{v}r}}_{=p^{-v-in-\left(  \varphi\left(
r\right)  -1\right)  in}}\cdot\underbrace{\dfrac{p^{\left(  \varphi\left(
r\right)  -1\right)  in}\cdot\prod\limits_{k=0}^{n-1}\left(  u-kp^{i}\right)
}{r}}_{\text{an integer}}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }%
n!=p^{v}r\right)
\end{align*}
is a product of a negative power of $p$ with an integer, and therefore lies in
$\left\{  1,p,p^{2},...\right\}  ^{-1}\mathbb{Z}$.

So we have shown that $\dbinom{x}{n}\in\left\{  1,p,p^{2},...\right\}
^{-1}\mathbb{Z}$ for every $x\in\left\{  1,p,p^{2},...\right\}  ^{-1}%
\mathbb{Z}$. This proves that $\left\{  1,p,p^{2},...\right\}  ^{-1}%
\mathbb{Z}$ is a binomial ring, qed.

\textit{Second solution (sketched):} Let $x\in\left\{  1,p,p^{2},...\right\}
^{-1}\mathbb{Z}$. Just as in the First solution, we can write $x$ in the form
$\dfrac{u}{p^{i}}$ for some $u\in\mathbb{Z}$ and $i\in\mathbb{N}$, and we see
that $\dbinom{x}{n}=\dfrac{\prod\limits_{k=0}^{n-1}\left(  u-kp^{i}\right)
}{n!\cdot\left(  p^{i}\right)  ^{n}}$. A careful analysis now shows that every
prime $q$ that is distinct from $p$ appears in the prime factor decomposition
of $\prod\limits_{k=0}^{n-1}\left(  u-kp^{i}\right)  $ at least as often as it
appears in that of $n!\cdot\left(  p^{i}\right)  ^{n}$. As a consequence, the
ratio $\dfrac{\prod\limits_{k=0}^{n-1}\left(  u-kp^{i}\right)  }%
{n!\cdot\left(  p^{i}\right)  ^{n}}$, once brought to simplest form, can have
no primes distinct from $p$ in its denominator. Thus, this ratio (which, as we
know, is $\dbinom{x}{n}$) lies in $\left\{  1,p,p^{2},...\right\}
^{-1}\mathbb{Z}$. So we have shown that $\dbinom{x}{n}\in\left\{
1,p,p^{2},...\right\}  ^{-1}\mathbb{Z}$ for every $x\in\left\{  1,p,p^{2}%
,...\right\}  ^{-1}\mathbb{Z}$. This proves that $\left\{  1,p,p^{2}%
,...\right\}  ^{-1}\mathbb{Z}$ is a binomial ring, qed.

\textit{Exercise 3.2:} \textit{Hints to solution:} Let $\mathbb{N}_{K}^{+}$ be
the subset $\left\{  1,2,3,...\right\}  $ of $K$. Obviously, this subset is
multiplicatively closed and contains no zero-divisors. Hence, the localization
$\left(  \mathbb{N}_{K}^{+}\right)  ^{-1}K$ can be considered as an extension
ring of $K$. We now can define $\dbinom{x}{i}\in\left(  \mathbb{N}_{K}%
^{+}\right)  ^{-1}K$ for every $x\in\left(  \mathbb{N}_{K}^{+}\right)  ^{-1}K$
and $i\in\mathbb{N}$. It remains to show that $\dbinom{x}{i}\in K$ for every
$x\in K$ and $i\in\mathbb{N}$, given that $\dbinom{x}{i}\in K$ for every $x\in
E$ and $i\in\mathbb{N}$.

This will follow once we have seen that for $i\in\mathbb{N}$ fixed,

\begin{itemize}
\item the polynomial $\dbinom{X+Y}{i}\in\mathbb{Q}\left[  X,Y\right]  $ is a
polynomial in $\dbinom{X}{0},$ $\dbinom{X}{1},$ $...,$ $\dbinom{X}{i},$
$\dbinom{Y}{0},$ $\dbinom{Y}{1},$ $...,$ $\dbinom{Y}{i}$ with integer coefficients;

\item the polynomial $\dbinom{-X}{i}\in\mathbb{Q}\left[  X\right]  $ is a
polynomial in $\dbinom{X}{0},$ $\dbinom{X}{1},$ $...,$ $\dbinom{X}{i}$ with
integer coefficients;

\item the polynomial $\dbinom{XY}{i}\in\mathbb{Q}\left[  X,Y\right]  $ is a
polynomial in $\dbinom{X}{0},$ $\dbinom{X}{1},$ $...,$ $\dbinom{X}{i},$
$\dbinom{Y}{0},$ $\dbinom{Y}{1},$ $...,$ $\dbinom{Y}{i}$ with integer coefficients.
\end{itemize}

The first of these three properties follows from (\ref{vandermonde}) (applied
to $x=X$ and $y=Y$, which is not tragic since it holds in every binomial ring,
in particular $\mathbb{Q}\left[  X,Y\right]  $). The second one follows from
the first one and the identity $\dbinom{-x}{i}=\left(  -1\right)  ^{i}%
\dbinom{x+i-1}{i}$ for every $x\in\mathbb{Z}$ and $i\in\mathbb{N}$ (this is
the so-called \textit{upper negation identity}). The third one, alas, doesn't
seem to be that easy. One way to prove it is to use the proof of Theorem 7.1
below. Another, more elementary way (leading to a different polynomial!!) is
by recalling the fact ([4], Proposition I.7.3) that the subset%
\[
\left\{  p\in\mathbb{Q}\left[  X\right]  \text{ }\mid\ p\left(  n\right)
\in\mathbb{Z}\text{ for every }n\in\mathbb{Z}\right\}
\]
of the polynomial ring $\mathbb{Q}\left[  X\right]  $ is the $\mathbb{Z}%
$-linear span of the polynomials $\dbinom{X}{0},$ $\dbinom{X}{1},$ $\dbinom
{X}{2},$ $...$. This generalizes to two variables: The subset
\[
\left\{  p\in\mathbb{Q}\left[  X,Y\right]  \text{ }\mid\ p\left(  n,m\right)
\in\mathbb{Z}\text{ for every }n\in\mathbb{Z}\text{ and every }m\in
\mathbb{Z}\right\}
\]
of the polynomial ring $\mathbb{Q}\left[  X,Y\right]  $ is the $\mathbb{Z}%
$-linear span of the polynomials $\dbinom{X}{i}\dbinom{Y}{j}$ for
$i\in\mathbb{N}$ and $j\in\mathbb{N}$. Of course, the polynomial $\dbinom
{XY}{i}$ belongs to this subset, so all we need is proven.

\textit{Exercise 3.3: Hints to solution:} \textbf{(a)} Use Theorem 2.1
\textbf{(a)} and $\left(  1+pT\right)  ^{x}\left(  1+pT\right)  ^{y}=\left(
1+pT\right)  ^{x+y}$.

\textbf{(b)} Use the binomial formula.

\textit{Exercise 3.4: Hints to solution:} It is clear from the very definition
of $\lambda^{i}$ that Theorem 2.1 \textbf{(a)} is to be applied here.

\textit{Exercise 3.5: Hints to solution:} Same idea as for Exercise 3.4.

\subsection{To Section 4}

\textit{Exercise 4.2: Detailed solution:} There are several ways to solve
Exercise 4.2 (many people would call it trivial). Here is not the simplest
one, but the easiest-to-formalize one:

\textbf{(a)} Let us prove that every $n\in\left\{  0,1,...,m\right\}  $
satisfies%
\begin{equation}
\prod\limits_{i=1}^{n}\left(  1+\alpha_{i}\right)  =\sum\limits_{S\subseteq
\left\{  1,2,...,n\right\}  }\prod\limits_{k\in S}\alpha_{k}. \label{4.2.pf.1}%
\end{equation}


\textit{Proof of (\ref{4.2.pf.1}).} We will prove (\ref{4.2.pf.1}) by
induction over $n$:

\textit{Induction base:} If $n=0$, then $\prod\limits_{i=1}^{n}\left(
1+\alpha_{i}\right)  =\left(  \text{empty product}\right)  =1$ and
\begin{align*}
\sum\limits_{S\subseteq\left\{  1,2,...,n\right\}  }\prod\limits_{k\in
S}\alpha_{k}  &  =\sum\limits_{S\subseteq\left\{  1,2,...,0\right\}  }%
\prod\limits_{k\in S}\alpha_{k}=\prod\limits_{k\in\varnothing}\alpha_{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since the only subset }S\ \text{of
}\left\{  1,2,...,0\right\}  \text{ is }\varnothing\right) \\
&  =\left(  \text{empty product}\right)  =1.
\end{align*}
Thus, $\prod\limits_{i=1}^{n}\left(  1+\alpha_{i}\right)  =\sum
\limits_{S\subseteq\left\{  1,2,...,n\right\}  }\prod\limits_{k\in S}%
\alpha_{k}$ holds for $n=0$. In other words, we have proven (\ref{4.2.pf.1})
for $n=0$. This completes the induction base.

\textit{Induction step:} Let $N\in\left\{  0,1,...,m-1\right\}  $. Assume that
(\ref{4.2.pf.1}) holds for $n=N$. Now let us prove (\ref{4.2.pf.1}) for
$n=N+1$.

Since (\ref{4.2.pf.1}) holds for $n=N$, we have%
\[
\prod\limits_{i=1}^{N}\left(  1+\alpha_{i}\right)  =\sum\limits_{S\subseteq
\left\{  1,2,...,N\right\}  }\prod\limits_{k\in S}\alpha_{k}.
\]


Now, let $P$ be the set of all subsets of $\left\{  1,2,...,N\right\}  $.
Then, $P$ is the set of all subsets $S$ of $\left\{  1,2,...,N+1\right\}  $
satisfying $N+1\notin S$ (because subsets $S$ of $\left\{
1,2,...,N+1\right\}  $ satisfying $N+1\notin S$ are the same thing as subsets
of $\left\{  1,2,...,N\right\}  $). Therefore, summing over all $S\in P$ is
the same as summing over all subsets $S$ of $\left\{  1,2,...,N+1\right\}  $
satisfying $N+1\notin S$. Hence, $\sum\limits_{S\in P}\prod\limits_{k\in
S}\alpha_{k}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,N+1\right\}
;\\N+1\notin S}}\prod\limits_{k\in S}\alpha_{k}$.

On the other hand, summing over all $S\in P$ is the same as summing over all
subsets $S$ of $\left\{  1,2,...,N\right\}  $ (since $P$ is the set of all
subsets of $\left\{  1,2,...,N\right\}  $). Thus, $\sum\limits_{S\in P}%
\prod\limits_{k\in S}\alpha_{k}=\sum\limits_{S\subseteq\left\{
1,2,...,N\right\}  }\prod\limits_{k\in S}\alpha_{k}$.

Notice that every $S\in P$ is a subset of $\left\{  1,2,...,N\right\}  $
(since $P$ is the set of all subsets of $\left\{  1,2,...,N\right\}  $) and
thus satisfies $N+1\notin S$.

Now, let $Q$ be the set of all subsets $T$ of $\left\{  1,2,...,N+1\right\}  $
satisfying $N+1\in T$. Then, summing over all $T\in Q$ is the same as summing
over all subsets $T$ of $\left\{  1,2,...,N+1\right\}  $ satisfying $N+1\in
T$. Thus, $\sum\limits_{T\in Q}\prod\limits_{k\in T}\alpha_{k}=\sum
\limits_{\substack{T\subseteq\left\{  1,2,...,N+1\right\}  ;\\N+1\in T}%
}\prod\limits_{k\in T}\alpha_{k}$. Renaming the index $T$ as $S$ in both sides
of this equation, we obtain $\sum\limits_{S\in Q}\prod\limits_{k\in S}%
\alpha_{k}=\sum\limits_{\substack{S\subseteq\left\{  1,2,...,N+1\right\}
;\\N+1\in S}}\prod\limits_{k\in S}\alpha_{k}$.

From the definitions of $P$ and $Q$, it easily follows that every $S\in P$
satisfies $S\cup\left\{  N+1\right\}  \in Q$\ \ \ \ \footnote{\textit{Proof.}
Let $S\in P$. Then, $S$ is a subset of $\left\{  1,2,...,N\right\}  $ (since
$P$ is the set of all subsets of $\left\{  1,2,...,N\right\}  $). Thus,
$S\cup\left\{  N+1\right\}  $ is a subset of $\left\{  1,2,...,N+1\right\}  $.
Clearly, $N+1\in S\cup\left\{  N+1\right\}  $. Thus, $S\cup\left\{
N+1\right\}  $ is a subset of $\left\{  1,2,...,N+1\right\}  $ satisfying
$N+1\in S\cup\left\{  N+1\right\}  $. In other words, $S\cup\left\{
N+1\right\}  \in Q$ (since $Q$ is the set of all subsets $T$ of $\left\{
1,2,...,N+1\right\}  $ satisfying $N+1\in T$), qed.}. Hence, we can define a
map $\iota:P\rightarrow Q$ by%
\[
\left(  \iota\left(  S\right)  =S\cup\left\{  N+1\right\}
\ \ \ \ \ \ \ \ \ \ \text{for any }S\in P\right)  .
\]
This map $\iota$ is injective (because if two sets $S\in P$ and $S^{\prime}\in
P$ satisfy $\iota\left(  S\right)  =\iota\left(  S^{\prime}\right)  $, then
$S=S^{\prime}$\ \ \ \ \footnote{\textit{Proof.} Let $S\in P$ and $S^{\prime
}\in P$ be two sets satisfying $\iota\left(  S\right)  =\iota\left(
S^{\prime}\right)  $.
\par
The set $S$ is a subset of $\left\{  1,2,...,N\right\}  $ (since $S\in P$ and
since $P$ is the set of all subsets of $\left\{  1,2,...,N\right\}  $). Hence,
$N+1\notin S$. But $\iota\left(  S\right)  =S\cup\left\{  N+1\right\}  $, so
that%
\[
\iota\left(  S\right)  \setminus\left\{  N+1\right\}  =\left(  S\cup\left\{
N+1\right\}  \right)  \setminus\left\{  N+1\right\}  =\underbrace{\left(
S\setminus\left\{  N+1\right\}  \right)  }_{=S\text{ (since }N+1\notin
S\text{)}}\cup\underbrace{\left(  \left\{  N+1\right\}  \setminus\left\{
N+1\right\}  \right)  }_{=\varnothing}=S\cup\varnothing=S.
\]
Similarly, $\iota\left(  S^{\prime}\right)  \setminus\left\{  N+1\right\}
=S^{\prime}$. Hence, $S=\underbrace{\iota\left(  S\right)  }_{=\iota\left(
S^{\prime}\right)  }\setminus\left\{  N+1\right\}  =\iota\left(  S^{\prime
}\right)  \setminus\left\{  N+1\right\}  =S^{\prime}$, qed.}) and surjective
(because every $T\in Q$ satisfies $T=\iota\left(  S\right)  $ for some $S\in
P$\ \ \ \ \footnote{\textit{Proof.} Let $S=T\setminus\left\{  N+1\right\}  $.
Now, $T$ is a subset of $\left\{  1,2,...,N+1\right\}  $ satisfying $N+1\in T$
(since $T\in Q$, and since $Q$ is the set of all subsets $T$ of $\left\{
1,2,...,N+1\right\}  $ satisfying $N+1\in T$).
\par
Since $T$ is a subset of $\left\{  1,2,...,N+1\right\}  $, it is clear that
$T\setminus\left\{  N+1\right\}  $ is a subset of $\left\{
1,2,...,N+1\right\}  \setminus\left\{  N+1\right\}  =\left\{
1,2,...,N\right\}  $, so that $T\setminus\left\{  N+1\right\}  \in P$ (since
$P$ is the set of all subsets of $\left\{  1,2,...,N\right\}  $). Hence,
$S=T\setminus\left\{  N+1\right\}  \in P$.
\par
Since $N+1\in T$, we have $\left\{  N+1\right\}  \subseteq T$ and thus
$\left(  T\setminus\left\{  N+1\right\}  \right)  \cup\left\{  N+1\right\}
=T$. Now, $\iota\left(  S\right)  =S\cup\left\{  N+1\right\}  =\left(
T\setminus\left\{  N+1\right\}  \right)  \cup\left\{  N+1\right\}  =T$,
qed.}). Thus, $\iota$ is a bijective map. Hence, we can substitute $S$ for
$\iota\left(  S\right)  $ in the sum $\sum\limits_{S\in P}\prod\limits_{k\in
\iota\left(  S\right)  }\alpha_{k}$, so that $\sum\limits_{S\in P}%
\prod\limits_{k\in\iota\left(  S\right)  }\alpha_{k}=\sum\limits_{S\in Q}%
\prod\limits_{k\in S}\alpha_{k}$. Since every $S\in P$ satisfies
\begin{align*}
\prod\limits_{k\in\iota\left(  S\right)  }\alpha_{k}  &  =\prod\limits_{k\in
S\cup\left\{  N+1\right\}  }\alpha_{k}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\iota\left(  S\right)  =S\cup\left\{  N+1\right\}  \right) \\
&  =\alpha_{N+1}\prod\limits_{k\in S}\alpha_{k}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }S\in P\text{, so that }N+1\notin S\right)  ,
\end{align*}
this rewrites as $\sum\limits_{S\in P}\left(  \alpha_{N+1}\prod\limits_{k\in
S}\alpha_{k}\right)  =\sum\limits_{S\in Q}\prod\limits_{k\in S}\alpha_{k}$.

Now,%
\begin{align*}
\sum\limits_{S\subseteq\left\{  1,2,...,N+1\right\}  }\prod\limits_{k\in
S}\alpha_{k}  &  =\underbrace{\sum\limits_{\substack{S\subseteq\left\{
1,2,...,N+1\right\}  ;\\N+1\notin S}}\prod\limits_{k\in S}\alpha_{k}}%
_{=\sum\limits_{S\in P}\prod\limits_{k\in S}\alpha_{k}}+\underbrace{\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,N+1\right\}  ;\\N+1\in S}%
}\prod\limits_{k\in S}\alpha_{k}}_{=\sum\limits_{S\in Q}\prod\limits_{k\in
S}\alpha_{k}=\sum\limits_{S\in P}\left(  \alpha_{N+1}\prod\limits_{k\in
S}\alpha_{k}\right)  }\\
&  =\sum\limits_{S\in P}\prod\limits_{k\in S}\alpha_{k}+\sum\limits_{S\in
P}\left(  \alpha_{N+1}\prod\limits_{k\in S}\alpha_{k}\right)  =\sum
\limits_{S\in P}\underbrace{\left(  \prod\limits_{k\in S}\alpha_{k}%
+\alpha_{N+1}\prod\limits_{k\in S}\alpha_{k}\right)  }_{=\left(
1+\alpha_{N+1}\right)  \prod\limits_{k\in S}\alpha_{k}}\\
&  =\sum\limits_{S\in P}\left(  1+\alpha_{N+1}\right)  \prod\limits_{k\in
S}\alpha_{k}=\left(  1+\alpha_{N+1}\right)  \underbrace{\sum\limits_{S\in
P}\prod\limits_{k\in S}\alpha_{k}}_{=\sum\limits_{S\subseteq\left\{
1,2,...,N\right\}  }\prod\limits_{k\in S}\alpha_{k}=\prod\limits_{i=1}%
^{N}\left(  1+\alpha_{i}\right)  }\\
&  =\left(  1+\alpha_{N+1}\right)  \prod\limits_{i=1}^{N}\left(  1+\alpha
_{i}\right)  =\prod\limits_{i=1}^{N+1}\left(  1+\alpha_{i}\right)  .
\end{align*}
We have thus shown that $\prod\limits_{i=1}^{N+1}\left(  1+\alpha_{i}\right)
=\sum\limits_{S\subseteq\left\{  1,2,...,N+1\right\}  }\prod\limits_{k\in
S}\alpha_{k}$. In other words, (\ref{4.2.pf.1}) holds for $n=N+1$. This
completes the induction step.

We have thus shown that (\ref{4.2.pf.1}) holds for every $n\in\left\{
0,1,...,m\right\}  $. Thus, we can now apply (\ref{4.2.pf.1}) to $n=m$, and
obtain $\prod\limits_{i=1}^{m}\left(  1+\alpha_{i}\right)  =\sum
\limits_{S\subseteq\left\{  1,2,...,m\right\}  }\prod\limits_{k\in S}%
\alpha_{k}$. This solves Exercise 4.2 \textbf{(a)}.

\textbf{(b)} Applying Exercise 4.2 \textbf{(a)} to $\alpha_{k}t$ instead of
$\alpha_{k}$, we obtain%
\begin{align*}
\prod\limits_{i=1}^{m}\left(  1+\alpha_{i}t\right)   &  =\underbrace{\sum
\limits_{S\subseteq\left\{  1,2,...,m\right\}  }}_{=\sum\limits_{i\in
\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}}\underbrace{\prod\limits_{k\in S}\left(
\alpha_{k}t\right)  }_{=\left(  \prod\limits_{k\in S}\alpha_{k}\right)
t^{\left\vert S\right\vert }}\\
&  =\sum\limits_{i\in\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\left(  \prod\limits_{k\in
S}\alpha_{k}\right)  \underbrace{t^{\left\vert S\right\vert }}%
_{\substack{=t^{i}\\\text{(since }\left\vert S\right\vert =i\text{)}}%
}=\sum\limits_{i\in\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
\alpha_{k}t^{i}.
\end{align*}
This solves Exercise 4.2 \textbf{(b)}.

\textbf{(c)} Applying Exercise 4.2 \textbf{(b)} to $-\alpha_{k}$ instead of
$\alpha_{k}$, we obtain%
\begin{align*}
\prod\limits_{i=1}^{m}\left(  1+\left(  -\alpha_{i}\right)  t\right)   &
=\sum\limits_{i\in\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
\alpha_{k}\underbrace{\left(  -t\right)  ^{i}}_{=\left(  -1\right)  ^{i}t^{i}%
}=\sum\limits_{i\in\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
\alpha_{k}\left(  -1\right)  ^{i}t^{i}\\
&  =\sum\limits_{i\in\mathbb{N}}\left(  -1\right)  ^{i}\sum
\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =i}}\prod\limits_{k\in S}\alpha_{k}t^{i}.
\end{align*}
This simplifies to%
\[
\prod\limits_{i=1}^{m}\left(  1-\alpha_{i}t\right)  =\sum\limits_{i\in
\mathbb{N}}\left(  -1\right)  ^{i}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
\alpha_{k}t^{i}.
\]
This proves Exercise 4.2 \textbf{(c)}.

\textbf{(d)} Since $Q$ is a finite set, and we only use the elements of $Q$ as
labels, we can WLOG assume that $Q=\left\{  1,2,...,m\right\}  $ for some
$m\in\mathbb{N}$ (because otherwise, we can just relabel the elements of $Q$
as $1$, $2$, $...$, $m$ for some $m\in\mathbb{N}$). Then,
\begin{align*}
\prod\limits_{q\in Q}\left(  1+\alpha_{q}t\right)   &  =\prod\limits_{i\in
Q}\left(  1+\alpha_{i}t\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{here we
substituted }i\text{ for }q\right) \\
&  =\prod\limits_{i=1}^{m}\left(  1+\alpha_{i}t\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }Q=\left\{  1,2,...,m\right\}  \right)
\\
&  =\sum\limits_{i\in\mathbb{N}}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
\alpha_{k}t^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{by Exercise 4.2 \textbf{(b)}%
}\right) \\
&  =\sum\limits_{i\in\mathbb{N}}\sum\limits_{\substack{S\subseteq
Q;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}\alpha_{k}t^{i}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left\{  1,2,...,m\right\}  =Q\right)
\\
&  =\sum\limits_{k\in\mathbb{N}}\sum\limits_{\substack{S\subseteq
Q;\\\left\vert S\right\vert =k}}\prod\limits_{q\in S}\alpha_{q}t^{k}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{here we renamed }i\text{ and }k\text{ as
}k\text{ and }q\right)  .
\end{align*}
This solves Exercise 4.2 \textbf{(d)}.

\textit{Exercise 4.3: Detailed solution:} Let $P\in K\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{m},\beta_{1},\beta_{2},...,\beta_{n}\right]  $ be a
polynomial satisfying $P\left(  p_{1},p_{2},...,p_{m},q_{1},q_{2}%
,...,q_{n}\right)  =0$ (where $K\left[  \alpha_{1},\alpha_{2},...,\alpha
_{m},\beta_{1},\beta_{2},...,\beta_{n}\right]  $ denotes the polynomial ring
in the $m+n$ indeterminates $\alpha_{1}$, $\alpha_{2}$, $...$, $\alpha_{m}$,
$\beta_{1}$, $\beta_{2}$, $...$, $\beta_{n}$ over $K$). We want to prove that
$P=0$ (as a polynomial).

Let $\iota$ be the canonical $K$-algebra isomorphism%
\[
K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m},\beta_{1},\beta_{2}%
,...,\beta_{n}\right]  \rightarrow\left(  K\left[  \beta_{1},\beta
_{2},...,\beta_{n}\right]  \right)  \left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{m}\right]  .
\]
Then,%
\[
\left(  \left(  \iota\left(  P\right)  \right)  \left(  p_{1},p_{2}%
,...,p_{m}\right)  \right)  \left(  q_{1},q_{2},...,q_{n}\right)  =P\left(
p_{1},p_{2},...,p_{m},q_{1},q_{2},...,q_{n}\right)  =0.
\]
Since $q_{1}$, $q_{2}$, $...$, $q_{n}$ are algebraically independent over $T$
(and since $\left(  \iota\left(  P\right)  \right)  \left(  p_{1}%
,p_{2},...,p_{m}\right)  $ is a polynomial over $T$ (because $p_{1}$, $p_{2}$,
$...$, $p_{m}$ lie in $T$)), this yields that $\left(  \iota\left(  P\right)
\right)  \left(  p_{1},p_{2},...,p_{m}\right)  =0$.

But in the polynomial ring $K\left[  \beta_{1},\beta_{2},...,\beta_{n}\right]
$, we have%
\begin{align*}
0  &  =\left(  \iota\left(  P\right)  \right)  \left(  p_{1},p_{2}%
,...,p_{m}\right)  =\left(  \left(  \iota\left(  P\right)  \right)  \left(
p_{1},p_{2},...,p_{m}\right)  \right)  \left(  \beta_{1},\beta_{2}%
,...,\beta_{n}\right) \\
&  =P\left(  p_{1},p_{2},...,p_{m},\beta_{1},\beta_{2},...,\beta_{n}\right)
\end{align*}
(since $\iota$ is the canonical $K$-algebra isomorphism
\[
K\left[  \alpha_{1},\alpha_{2},...,\alpha_{m},\beta_{1},\beta_{2}%
,...,\beta_{n}\right]  \rightarrow\left(  K\left[  \beta_{1},\beta
_{2},...,\beta_{n}\right]  \right)  \left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{m}\right]
\]
).

Since $P$ is a polynomial in $K\left[  \alpha_{1},\alpha_{2},...,\alpha
_{m},\beta_{1},\beta_{2},...,\beta_{n}\right]  $, we can write it in the form%
\begin{equation}
P=\sum\limits_{\left(  \left(  i_{1},i_{2},...,i_{m}\right)  ,\left(
j_{1},j_{2},...,j_{n}\right)  \right)  \in\mathbb{N}^{m}\times\mathbb{N}^{n}%
}\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1},j_{2}%
,...,j_{n}\right)  }\cdot\alpha_{1}^{i_{1}}\alpha_{2}^{i_{2}}...\alpha
_{m}^{i_{m}}\cdot\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}},
\label{4.3.sol.1}%
\end{equation}
where $\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1}%
,j_{2},...,j_{n}\right)  }$ is the coefficient of the polynomial $P$ before
the monomial $\alpha_{1}^{i_{1}}\alpha_{2}^{i_{2}}...\alpha_{m}^{i_{m}}%
\cdot\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}$ for every
$\left(  \left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1},j_{2}%
,...,j_{n}\right)  \right)  \in\mathbb{N}^{m}\times\mathbb{N}^{n}$. So let us
write it in this way. Then,%
\begin{align}
0  &  =P\left(  p_{1},p_{2},...,p_{m},\beta_{1},\beta_{2},...,\beta_{n}\right)
\nonumber\\
&  =\sum\limits_{\left(  \left(  i_{1},i_{2},...,i_{m}\right)  ,\left(
j_{1},j_{2},...,j_{n}\right)  \right)  \in\mathbb{N}^{m}\times\mathbb{N}^{n}%
}\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1},j_{2}%
,...,j_{n}\right)  }\cdot p_{1}^{i_{1}}p_{2}^{i_{2}}...p_{m}^{i_{m}}\cdot
\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}\nonumber\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{because of (\ref{4.3.sol.1})}\right)
\nonumber\\
&  =\sum\limits_{\left(  j_{1},j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}}%
\sum\limits_{\left(  i_{1},i_{2},...,i_{m}\right)  \in\mathbb{N}^{m}}%
\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1},j_{2}%
,...,j_{n}\right)  }\cdot p_{1}^{i_{1}}p_{2}^{i_{2}}...p_{m}^{i_{m}}\cdot
\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}. \label{4.3.sol.2}%
\end{align}


For every $\left(  j_{1},j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}$, define a
polynomial $P_{\left(  j_{1},j_{2},...,j_{n}\right)  }\in K\left[  \alpha
_{1},\alpha_{2},...,\alpha_{m}\right]  $ by $P_{\left(  j_{1},j_{2}%
,...,j_{n}\right)  }=\sum\limits_{\left(  i_{1},i_{2},...,i_{m}\right)
\in\mathbb{N}^{m}}\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(
j_{1},j_{2},...,j_{n}\right)  }\cdot\alpha_{1}^{i_{1}}\alpha_{2}^{i_{2}%
}...\alpha_{m}^{i_{m}}$. Then,
\[
P_{\left(  j_{1},j_{2},...,j_{n}\right)  }\left(  p_{1},p_{2},...,p_{m}%
\right)  =\sum\limits_{\left(  i_{1},i_{2},...,i_{m}\right)  \in\mathbb{N}%
^{m}}\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1}%
,j_{2},...,j_{n}\right)  }\cdot p_{1}^{i_{1}}p_{2}^{i_{2}}...p_{m}^{i_{m}}
\]
for every $\left(  j_{1},j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}$. Thus,%
\begin{align*}
&  \sum\limits_{\left(  j_{1},j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}%
}P_{\left(  j_{1},j_{2},...,j_{n}\right)  }\left(  p_{1},p_{2},...,p_{m}%
\right)  \cdot\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}\\
&  =\sum\limits_{\left(  j_{1},j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}}%
\sum\limits_{\left(  i_{1},i_{2},...,i_{m}\right)  \in\mathbb{N}^{m}}%
\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1},j_{2}%
,...,j_{n}\right)  }\cdot p_{1}^{i_{1}}p_{2}^{i_{2}}...p_{m}^{i_{m}}\cdot
\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}=0
\end{align*}
(by (\ref{4.3.sol.2})). Since the elements $\beta_{1}^{j_{1}}\beta_{2}^{j_{2}%
}...\beta_{n}^{j_{n}}$ (with $\left(  j_{1},j_{2},...,j_{n}\right)
\in\mathbb{N}^{n}$) of the $K$-module $K\left[  \beta_{1},\beta_{2}%
,...,\beta_{n}\right]  $ are linearly independent (because these elements are
the monomials), this yields that $P_{\left(  j_{1},j_{2},...,j_{n}\right)
}\left(  p_{1},p_{2},...,p_{m}\right)  =0$ for every $\left(  j_{1}%
,j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}$. Hence, $P_{\left(  j_{1}%
,j_{2},...,j_{n}\right)  }=0$ for every $\left(  j_{1},j_{2},...,j_{n}\right)
\in\mathbb{N}^{n}$ (since $p_{1}$, $p_{2}$, $...$, $p_{m}$ are algebraically
independent over $K$). Now,%
\begin{align*}
P  &  =\sum\limits_{\left(  \left(  i_{1},i_{2},...,i_{m}\right)  ,\left(
j_{1},j_{2},...,j_{n}\right)  \right)  \in\mathbb{N}^{m}\times\mathbb{N}^{n}%
}\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(  j_{1},j_{2}%
,...,j_{n}\right)  }\cdot\alpha_{1}^{i_{1}}\alpha_{2}^{i_{2}}...\alpha
_{m}^{i_{m}}\cdot\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}\\
&  =\sum\limits_{\left(  j_{1},j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}%
}\underbrace{\sum\limits_{\left(  i_{1},i_{2},...,i_{m}\right)  \in
\mathbb{N}^{m}}\lambda_{\left(  i_{1},i_{2},...,i_{m}\right)  ,\left(
j_{1},j_{2},...,j_{n}\right)  }\cdot\alpha_{1}^{i_{1}}\alpha_{2}^{i_{2}%
}...\alpha_{m}^{i_{m}}}_{=P_{\left(  j_{1},j_{2},...,j_{n}\right)  }=0}%
\cdot\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}\\
&  =\sum\limits_{\left(  j_{1},j_{2},...,j_{n}\right)  \in\mathbb{N}^{n}%
}0\cdot\beta_{1}^{j_{1}}\beta_{2}^{j_{2}}...\beta_{n}^{j_{n}}=0.
\end{align*}


We have thus proven that every polynomial $P\in K\left[  \alpha_{1},\alpha
_{2},...,\alpha_{m},\beta_{1},\beta_{2},...,\beta_{n}\right]  $ satisfying
$P\left(  p_{1},p_{2},...,p_{m},q_{1},q_{2},...,q_{n}\right)  =0$ must satisfy
$P=0$. In other words, the $m+n$ elements $p_{1}$, $p_{2}$, $...$, $p_{m}$,
$q_{1}$, $q_{2}$, $...$, $q_{n}$ are algebraically independent over $K$.
Exercise 4.3 is solved.

\textit{Exercise 4.4:} \textit{Detailed solution:} Fix some $j\in\mathbb{N}$.

\textit{1st Step:} Let $m\in\mathbb{N}$. We are going to prove that%
\[
P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)  =\sum\limits_{i=0}^{j-1}\left(
-1\right)  ^{i+j-1}X_{i}X_{2j-i}%
\]
in the ring $\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $.

\textit{Proof.} It is a known (and very easy) fact that whenever $A$ is a
ring, $F$ is a finite set and $a_{I}$ is an element of $A$ for every $I\in F$,
then%
\begin{equation}
\left(  \sum\limits_{I\in F}a_{I}\right)  ^{2}=\sum\limits_{I\in F}a_{I}%
^{2}+2\sum\limits_{S\in\mathcal{P}_{2}\left(  F\right)  }\prod\limits_{I\in
S}a_{I}. \label{4.4.sol.1}%
\end{equation}
\footnote{\textit{Proof of (\ref{4.4.sol.1}).} Let $A$ be a ring, let $F$ be a
finite set, and let $a_{I}$ be an element of $A$ for every $I\in F$. We must
prove (\ref{4.4.sol.1}).
\par
Clearly, the set $F$ is used only for indexing in (\ref{4.4.sol.1}). Hence, we
can WLOG assume that $F=\left\{  1,2,...,n\right\}  $ for some $n\in
\mathbb{N}$. Assume this, and consider this $n$.
\par
Since $F=\left\{  1,2,...,n\right\}  $, we have $\sum\limits_{I\in F}%
a_{I}=\sum\limits_{I\in\left\{  1,2,...,n\right\}  }a_{I}=a_{1}+a_{2}%
+...+a_{n}$ and $\sum\limits_{I\in F}a_{I}^{2}=\sum\limits_{I\in\left\{
1,2,...,n\right\}  }a_{I}^{2}=a_{1}^{2}+a_{2}^{2}+...+a_{n}^{2}$.
\par
On the other hand, let $L$ be the set of all pairs $\left(  i,j\right)  \in
F\times F$ satisfying $i<j$. Then, $\sum\limits_{\left(  i,j\right)  \in
L}a_{i}a_{j}=\sum\limits_{\substack{\left(  i,j\right)  \in F\times
F;\\i<j}}a_{i}a_{j}$. From the definition of $L$, it is clear that every
$\left(  i,j\right)  \in L$ satisfies $i<j$.
\par
Let $\mathfrak{S}$ denote the map%
\[
L\rightarrow\mathcal{P}_{2}\left(  F\right)  ,\ \ \ \ \ \ \ \ \ \ \left(
i,j\right)  \mapsto\left\{  i,j\right\}  .
\]
This map is a bijection. (In fact, the elements of $L$ are pairs $\left(
i,j\right)  \in F\times F$ satisfying $i<j$; such pairs are clearly in
bijection with the $2$-element subsets of $F$, and this bijection is given by
the map $\mathfrak{S}$.)
\par
For every $\left(  i,j\right)  \in L$, we have%
\begin{align*}
\prod_{I\in\mathfrak{S}\left(  i,j\right)  }a_{I}  &  =\prod_{I\in\left\{
i,j\right\}  }a_{I}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{S}%
\left(  i,j\right)  =\left\{  i,j\right\}  \text{ by the definition of
}\mathfrak{S}\right) \\
&  =a_{i}a_{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left(  i,j\right)  \in
L\text{, so that }i<j\right)  .
\end{align*}
\par
Now,%
\[
\sum\limits_{\substack{\left(  i,j\right)  \in F\times F;\\i<j}}a_{i}%
a_{j}=\sum\limits_{\left(  i,j\right)  \in L}\underbrace{a_{i}a_{j}}%
_{=\prod\limits_{I\in\mathfrak{S}\left(  i,j\right)  }a_{I}}=\sum
\limits_{\left(  i,j\right)  \in L}\prod_{I\in\mathfrak{S}\left(  i,j\right)
}a_{I}=\sum\limits_{S\in\mathcal{P}_{2}\left(  F\right)  }\prod\limits_{I\in
S}a_{I}%
\]
(here we substituted $S$ for $\mathfrak{S}\left(  i,j\right)  $ in the sum,
since $\mathfrak{S}$ is a bijection). But $\sum\limits_{I\in F}a_{I}%
=a_{1}+a_{2}+...+a_{n}$, so that%
\[
\left(  \sum\limits_{I\in F}a_{I}\right)  ^{2}=\left(  a_{1}+a_{2}%
+...+a_{n}\right)  ^{2}=\underbrace{\left(  a_{1}^{2}+a_{2}^{2}+...+a_{n}%
^{2}\right)  }_{=\sum\limits_{I\in F}a_{I}^{2}}+2\underbrace{\sum
\limits_{\substack{\left(  i,j\right)  \in F\times F;\\i<j}}a_{i}a_{j}}%
_{=\sum\limits_{S\in\mathcal{P}_{2}\left(  F\right)  }\prod\limits_{I\in
S}a_{I}}=\sum\limits_{I\in F}a_{I}^{2}+2\sum\limits_{S\in\mathcal{P}%
_{2}\left(  F\right)  }\prod\limits_{I\in S}a_{I}.
\]
This proves (\ref{4.4.sol.1}).} Applied to $A=\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  $, $F=\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  $ and $a_{I}=\prod\limits_{i\in I}U_{i}$, this
yields%
\[
\left(  \sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  }\prod\limits_{i\in I}U_{i}\right)  ^{2}=\sum\limits_{I\in
\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)  }\left(
\prod\limits_{i\in I}U_{i}\right)  ^{2}+2\sum\limits_{S\in\mathcal{P}%
_{2}\left(  \mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
\right)  }\prod\limits_{I\in S}\prod\limits_{i\in I}U_{i}.
\]
Since
\begin{align*}
\sum\limits_{S\in\mathcal{P}_{2}\left(  \mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  \right)  }\prod\limits_{I\in S}\prod\limits_{i\in
I}U_{i}  &  =\sum\limits_{\substack{S\in\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  ;\\\left\vert S\right\vert =2}}\prod\limits_{I\in
S}\prod\limits_{i\in I}U_{i}=P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{Pkj1}), applied to }k=2\right)
,
\end{align*}
this becomes%
\begin{align*}
\left(  \sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  }\prod\limits_{i\in I}U_{i}\right)  ^{2}  &  =\sum\limits_{I\in
\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)  }%
\underbrace{\left(  \prod\limits_{i\in I}U_{i}\right)  ^{2}}_{=\prod
\limits_{i\in I}U_{i}^{2}}+2\underbrace{\sum\limits_{S\in\mathcal{P}%
_{2}\left(  \mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
\right)  }\prod\limits_{I\in S}\prod\limits_{i\in I}U_{i}}_{=P_{2,j}\left(
X_{1},X_{2},...,X_{2j}\right)  }\\
&  =\sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  }\prod\limits_{i\in I}U_{i}^{2}+2P_{2,j}\left(  X_{1},X_{2}%
,...,X_{2j}\right)  .
\end{align*}
Since%
\begin{align*}
\sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\prod\limits_{i\in I}U_{i}  &  =\sum\limits_{\substack{I\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert I\right\vert =j}}\prod\limits_{i\in I}%
U_{i}=\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =j}}\prod_{k\in S}U_{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we renamed the indices }I\text{ and
}i\text{ as }S\text{ and }k\right) \\
&  =X_{j}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }X_{j}\text{ was defined as
}\sum_{\substack{S\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
S\right\vert =j}}\prod_{k\in S}U_{k}\right)  ,
\end{align*}
this rewrites as%
\begin{equation}
X_{j}^{2}=\sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}
\right)  }\prod\limits_{i\in I}U_{i}^{2}+2P_{2,j}\left(  X_{1},X_{2}%
,...,X_{2j}\right)  . \label{4.4.sol.2}%
\end{equation}


We will now show that%
\begin{equation}
\sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\prod\limits_{i\in I}U_{i}^{2}=\sum\limits_{i=0}^{2j}\left(  -1\right)
^{i+j}X_{i}X_{2j-i} \label{4.4.sol.3}%
\end{equation}
(an identity interesting for its own).

In fact, consider the polynomial $\prod\limits_{i=1}^{m}\left(  1-U_{i}%
^{2}T^{2}\right)  \in\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]
\right)  \left[  T\right]  $. Exercise 4.2 \textbf{(c)} (applied to $A=\left(
\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  \right)  \left[  T\right]  $,
$t=T^{2}$ and $\alpha_{i}=U_{i}^{2}$) yields%
\[
\prod\limits_{i=1}^{m}\left(  1-U_{i}^{2}T^{2}\right)  =\sum_{i\in\mathbb{N}%
}\left(  -1\right)  ^{i}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
U_{k}^{2}\underbrace{\left(  T^{2}\right)  ^{i}}_{=T^{2i}}=\sum_{i\in
\mathbb{N}}\left(  \left(  -1\right)  ^{i}\sum\limits_{\substack{S\subseteq
\left\{  1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in
S}U_{k}^{2}\right)  T^{2i}.
\]
Thus,%
\begin{align}
&  \left(  \text{the coefficient of the polynomial }\prod\limits_{i=1}%
^{m}\left(  1-U_{i}^{2}T^{2}\right)  \text{ before }T^{2j}\right) \nonumber\\
&  =\left(  \text{the coefficient of the polynomial }\sum_{i\in\mathbb{N}%
}\left(  \left(  -1\right)  ^{i}\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}%
U_{k}^{2}\right)  T^{2i}\text{ before }T^{2j}\right) \nonumber\\
&  =\left(  -1\right)  ^{j}\underbrace{\sum\limits_{\substack{S\subseteq
\left\{  1,2,...,m\right\}  ;\\\left\vert S\right\vert =j}}}_{=\sum
\limits_{S\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)  }%
}\prod\limits_{k\in S}U_{k}^{2}=\left(  -1\right)  ^{j}\sum\limits_{S\in
\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)  }\prod
\limits_{k\in S}U_{k}^{2}=\left(  -1\right)  ^{j}\sum\limits_{I\in
\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)  }\prod
\limits_{i\in I}U_{i}^{2}\label{4.4.sol.4}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we renamed the indices }S\text{ and
}k\text{ as }I\text{ and }i\right)  .\nonumber
\end{align}


But Exercise 4.2 \textbf{(c)} (applied to $A=\left(  \mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  \right)  \left[  T\right]  $, $t=T$ and
$\alpha_{i}=U_{i}$) yields%
\[
\prod\limits_{i=1}^{m}\left(  1-U_{i}T\right)  =\sum_{i\in\mathbb{N}}\left(
-1\right)  ^{i}\underbrace{\sum\limits_{\substack{S\subseteq\left\{
1,2,...,m\right\}  ;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}%
}_{=X_{i}}T^{i}=\sum_{i\in\mathbb{N}}\left(  -1\right)  ^{i}X_{i}T^{i}.
\]
Also, Exercise 4.2 \textbf{(b)} (applied to $A=\left(  \mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  \right)  \left[  T\right]  $, $t=T$ and
$\alpha_{i}=U_{i}$) yields%
\[
\prod\limits_{i=1}^{m}\left(  1+U_{i}T\right)  =\sum_{i\in\mathbb{N}%
}\underbrace{\sum\limits_{\substack{S\subseteq\left\{  1,2,...,m\right\}
;\\\left\vert S\right\vert =i}}\prod\limits_{k\in S}U_{k}}_{=X_{i}}T^{i}%
=\sum_{i\in\mathbb{N}}X_{i}T^{i}.
\]
Now,%
\begin{align*}
\prod\limits_{i=1}^{m}\underbrace{\left(  1-U_{i}^{2}T^{2}\right)  }_{=\left(
1-U_{i}T\right)  \left(  1+U_{i}T\right)  }  &  =\prod\limits_{i=1}^{m}\left(
\left(  1-U_{i}T\right)  \left(  1+U_{i}T\right)  \right)
=\underbrace{\left(  \prod\limits_{i=1}^{m}\left(  1-U_{i}T\right)  \right)
}_{=\sum\limits_{i\in\mathbb{N}}\left(  -1\right)  ^{i}X_{i}T^{i}%
}\underbrace{\left(  \prod\limits_{i=1}^{m}\left(  1+U_{i}T\right)  \right)
}_{=\sum\limits_{i\in\mathbb{N}}X_{i}T^{i}}\\
&  =\left(  \sum\limits_{i\in\mathbb{N}}\left(  -1\right)  ^{i}X_{i}%
T^{i}\right)  \cdot\left(  \sum\limits_{i\in\mathbb{N}}X_{i}T^{i}\right)
=\sum\limits_{i\in\mathbb{N}}\left(  \sum_{k=0}^{i}\left(  -1\right)
^{k}X_{k}X_{i-k}\right)  T^{i}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of the product of two
polynomials}\right)  .
\end{align*}
Hence,
\begin{align*}
&  \left(  \text{the coefficient of the polynomial }\prod\limits_{i=1}%
^{m}\left(  1-U_{i}^{2}T^{2}\right)  \text{ before }T^{2j}\right) \\
&  =\left(  \text{the coefficient of the polynomial }\sum\limits_{i\in
\mathbb{N}}\left(  \sum_{k=0}^{i}\left(  -1\right)  ^{k}X_{k}X_{i-k}\right)
T^{i}\text{ before }T^{2j}\right) \\
&  =\sum\limits_{k=0}^{2j}\left(  -1\right)  ^{k}X_{k}X_{2j-k}=\sum
\limits_{i=0}^{2j}\left(  -1\right)  ^{i}X_{i}X_{2j-i}%
\end{align*}
(here we renamed the index $k$ as $i$). Compared to (\ref{4.4.sol.4}), this
yields%
\[
\left(  -1\right)  ^{j}\sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{
1,2,...,m\right\}  \right)  }\prod\limits_{i\in I}U_{i}^{2}=\sum
\limits_{i=0}^{2j}\left(  -1\right)  ^{i}X_{i}X_{2j-i}.
\]
Divided by $\left(  -1\right)  ^{j}$, this yields%
\[
\sum\limits_{I\in\mathcal{P}_{j}\left(  \left\{  1,2,...,m\right\}  \right)
}\prod\limits_{i\in I}U_{i}^{2}=\sum\limits_{i=0}^{2j}\underbrace{\dfrac
{\left(  -1\right)  ^{i}}{\left(  -1\right)  ^{j}}}_{=\left(  -1\right)
^{i+j}}X_{i}X_{2j-i}=\sum\limits_{i=0}^{2j}\left(  -1\right)  ^{i+j}%
X_{i}X_{2j-i}.
\]
Thus we have proven (\ref{4.4.sol.3}).

Substituting (\ref{4.4.sol.3}) into (\ref{4.4.sol.2}), we obtain%
\[
X_{j}^{2}=\sum\limits_{i=0}^{2j}\left(  -1\right)  ^{i+j}X_{i}X_{2j-i}%
+2P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)  .
\]
Since%
\begin{align*}
\sum\limits_{i=0}^{2j}\left(  -1\right)  ^{i+j}X_{i}X_{2j-i}  &
=\sum\limits_{i=0}^{j}\left(  -1\right)  ^{i+j}X_{i}X_{2j-i}+\sum
\limits_{i=j+1}^{2j}\left(  -1\right)  ^{i+j}X_{i}X_{2j-i}\\
&  =\underbrace{\sum\limits_{i=0}^{j}\left(  -1\right)  ^{i+j}X_{i}X_{2j-i}%
}_{=\left(  -1\right)  ^{j+j}X_{j}X_{2j-j}+\sum\limits_{i=0}^{j-1}\left(
-1\right)  ^{i+j}X_{i}X_{2j-i}}+\sum\limits_{i=0}^{j-1}\underbrace{\left(
-1\right)  ^{\left(  2j-i\right)  +j}}_{=\left(  -1\right)  ^{2\left(
j-i\right)  +i+j}=\left(  -1\right)  ^{i+j}}X_{2j-i}\underbrace{X_{2j-\left(
2j-i\right)  }}_{=X_{i}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }2j-i\text{ for
}i\text{ in the second sum}\right) \\
&  =\underbrace{\left(  -1\right)  ^{j+j}}_{=\left(  -1\right)  ^{2j}%
=1}\underbrace{X_{j}X_{2j-j}}_{=X_{j}X_{j}=X_{j}^{2}}+\sum\limits_{i=0}%
^{j-1}\left(  -1\right)  ^{i+j}X_{i}X_{2j-i}+\sum\limits_{i=0}^{j-1}\left(
-1\right)  ^{i+j}\underbrace{X_{2j-i}X_{i}}_{=X_{i}X_{2j-i}}\\
&  =X_{j}^{2}+\underbrace{\sum\limits_{i=0}^{j-1}\left(  -1\right)
^{i+j}X_{i}X_{2j-i}+\sum\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j}%
X_{i}X_{2j-i}}_{=2\sum\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j}%
X_{i}X_{2j-i}}=X_{j}^{2}+2\sum\limits_{i=0}^{j-1}\left(  -1\right)
^{i+j}X_{i}X_{2j-i},
\end{align*}
this becomes%
\[
X_{j}^{2}=X_{j}^{2}+2\sum\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j}%
X_{i}X_{2j-i}+2P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)  .
\]
Subtracting $X_{j}^{2}$ from this and dividing by $2$ (we are allowed to
divide by $2$ since $2$ is not a zero-divisor in $\mathbb{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $), we obtain%
\[
0=\sum\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j}X_{i}X_{2j-i}+P_{2,j}\left(
X_{1},X_{2},...,X_{2j}\right)  ,
\]
so that%
\[
P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)  =-\sum\limits_{i=0}^{j-1}\left(
-1\right)  ^{i+j}X_{i}X_{2j-i}=\sum\limits_{i=0}^{j-1}\underbrace{\left(
-\left(  -1\right)  ^{i+j}\right)  }_{=\left(  -1\right)  ^{i+j-1}}%
X_{i}X_{2j-i}=\sum\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j-1}X_{i}%
X_{2j-i}.
\]
This proves the 1st Step.

\textit{2nd Step:} Let us now prove $P_{2,j}=\sum\limits_{i=0}^{j-1}\left(
-1\right)  ^{i+j-1}\alpha_{i}\alpha_{2j-i}$ now.

\textit{Proof.} Let $m=2j$. Define a polynomial $\mathfrak{Q}_{1}\in
\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $ by
$\mathfrak{Q}_{1}=P_{2,j}$, and define a polynomial $\mathfrak{Q}_{2}%
\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $ by
$\mathfrak{Q}_{2}=\sum\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j-1}\alpha
_{i}\alpha_{2j-i}$. We are going to prove that $\mathfrak{Q}_{1}%
=\mathfrak{Q}_{2}$.

Applying Theorem 4.1 \textbf{(a)} to $K=\mathbb{Z}$ and $P=P_{2,j}\left(
X_{1},X_{2},...,X_{2j}\right)  $, we conclude that there exists one and only
one polynomial $Q\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{m}\right]  $ such that $P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)
=Q\left(  X_{1},X_{2},...,X_{m}\right)  $. In particular, there exists
\textit{at most one} such polynomial $Q\in\mathbb{Z}\left[  \alpha_{1}%
,\alpha_{2},...,\alpha_{m}\right]  $. Hence,
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{if }\mathfrak{Q}_{1}\in\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{m}\right]  \text{ and }\mathfrak{Q}_{2}\in\mathbb{Z}\left[
\alpha_{1},\alpha_{2},...,\alpha_{m}\right]  \text{ are two polynomials}\\
\text{such that }P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)  =\mathfrak{Q}%
_{1}\left(  X_{1},X_{2},...,X_{m}\right)  \text{ and}\\
P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)  =\mathfrak{Q}_{2}\left(
X_{1},X_{2},...,X_{m}\right)  \text{, then }\mathfrak{Q}_{1}=\mathfrak{Q}_{2}%
\end{array}
\right)  . \label{4.4.sol.15}%
\end{equation}


Since our two polynomials $\mathfrak{Q}_{1}$ and $\mathfrak{Q}_{2}$ satisfy%
\[
\mathfrak{Q}_{1}\left(  X_{1},X_{2},...,X_{m}\right)  =P_{2,j}\left(
X_{1},X_{2},...,X_{2j}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\mathfrak{Q}_{1}=P_{2,j}\text{ and }m=2j\right)
\]
and%
\begin{align*}
\mathfrak{Q}_{2}\left(  X_{1},X_{2},...,X_{m}\right)   &  =\left(
\sum\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j-1}\alpha_{i}\alpha
_{2j-i}\right)  \left(  X_{1},X_{2},...,X_{j}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\mathfrak{Q}_{2}=\sum
\limits_{i=0}^{j-1}\left(  -1\right)  ^{i+j-1}\alpha_{i}\alpha_{2j-i}\right)
\\
&  =P_{2,j}\left(  X_{1},X_{2},...,X_{2j}\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{by the 1st Step}\right)  ,
\end{align*}
we can conclude from (\ref{4.4.sol.15}) that $\mathfrak{Q}_{1}=\mathfrak{Q}%
_{2}$. Hence, $P_{2,j}=\mathfrak{Q}_{1}=\mathfrak{Q}_{2}=\sum\limits_{i=0}%
^{j-1}\left(  -1\right)  ^{i+j-1}\alpha_{i}\alpha_{2j-i}$. This solves
Exercise 4.4.

\subsection{To Section 5}

\textit{Exercise 5.1: Hints to solution:} This can be proven by induction over
$n$: The ring $K\left[  T\right]  \diagup\left(  P\right)  $ is a finite-free
extension of $K$ containing a root of the polynomial $P$ (namely, the
equivalence class $\overline{T}$ of $T\in K\left[  T\right]  $ modulo $\left(
P\right)  $). Now, the polynomial $\dfrac{P\left(  S\right)  }{S-\overline{T}%
}\in\left(  K\left[  T\right]  \diagup\left(  P\right)  \right)  \left[
S\right]  $ is monic and has degree $n-1$, so by induction there exists a
finite-free extension ring $K_{P}$ of the ring $K\left[  T\right]
\diagup\left(  P\right)  $ and $n-1$ elements $p_{2},$ $...,$ $p_{n}$ of this
extension ring $K_{P}$ such that $\dfrac{P\left(  S\right)  }{S-\overline{T}%
}=\prod\limits_{i=2}^{n}\left(  T-p_{i}\right)  $ in $K_{P}\left[  S\right]
$. Thus, $P\left(  S\right)  =\left(  S-\overline{T}\right)  \prod
\limits_{i=2}^{n}\left(  T-p_{i}\right)  $ in $K_{P}\left[  S\right]  $. If we
denote $\overline{T}$ by $p_{1},$ this takes the form $P\left(  S\right)
=\prod\limits_{i=1}^{n}\left(  T-p_{i}\right)  ,$ which shows that we have
just completed the induction step.

Notice the similarity between this solution and the proof of the existence of
splitting fields in Galois theory.

\textit{Detailed solution:} We first show a lemma:

\begin{quote}
\textbf{Lemma 5.1.S.1.} Let $K$ be a ring, and $P\in K\left[  T\right]  $ be a
monic polynomial. Then, there exists a finite-free extension ring $K^{\prime}$
of the ring $K$ and an element $p\in K^{\prime}$ such that $P\left(  p\right)
=0$ in $K^{\prime}$.
\end{quote}

\textit{Proof of Lemma 5.1.S.1.} Let $n=\deg P$. Let $K^{\prime}$ be the
quotient ring $K\left[  T\right]  \diagup\left(  P\right)  $. For every $Q\in
K\left[  T\right]  $, let us denote by $\overline{Q}$ the projection of $Q$
onto $K\left[  T\right]  \diagup\left(  P\right)  $ (that is, the residue
class of $Q$ modulo $\left(  P\right)  $).

Since the polynomial $P$ is monic of degree $n$, we can easily see that
$\left(  \overline{T^{0}},\overline{T^{1}},...,\overline{T^{n-1}}\right)  $ is
a basis of the $K$-module $K^{\prime}$. This is because the sequence $\left(
\overline{T^{0}},\overline{T^{1}},...,\overline{T^{n-1}}\right)  $ is linearly
independent\footnote{\textit{Proof.} In fact, assume that we have a sequence
$\left(  \alpha_{0},\alpha_{1},...,\alpha_{n-1}\right)  \in K^{n}$ such that
$\alpha_{0}\overline{T^{0}}+\alpha_{1}\overline{T^{1}}+...+\alpha
_{n-1}\overline{T^{n-1}}=0$.
\par
Then, $0=\alpha_{0}\overline{T^{0}}+\alpha_{1}\overline{T^{1}}+...+\alpha
_{n-1}\overline{T^{n-1}}=\overline{\alpha_{0}T^{0}+\alpha_{1}T^{1}%
+...+\alpha_{n-1}T^{n-1}}$, so that $0\equiv\alpha_{0}T^{0}+\alpha_{1}%
T^{1}+...+\alpha_{n-1}T^{n-1}\operatorname{mod}\left(  P\right)  $. In other
words, $\alpha_{0}T^{0}+\alpha_{1}T^{1}+...+\alpha_{n-1}T^{n-1}\in\left(
P\right)  $. In other words, $P\mid\alpha_{0}T^{0}+\alpha_{1}T^{1}%
+...+\alpha_{n-1}T^{n-1}$. But $P$ is a monic polynomial of degree $n$, and
thus every polynomial divisible by $P$ has either degree $\geq n$ or is the
zero polynomial. Hence, the polynomial $\alpha_{0}T^{0}+\alpha_{1}%
T^{1}+...+\alpha_{n-1}T^{n-1}$ must have either degree $\geq n$ or be the zero
polynomial (since $P\mid\alpha_{0}T^{0}+\alpha_{1}T^{1}+...+\alpha
_{n-1}T^{n-1}$). Since this polynomial does not have degree $\geq n$, it must
thus be the zero polynomial. This means that all its coefficients are zero.
That is, $\alpha_{i}=0$ for every $i\in\left\{  0,1,...,n-1\right\}  $.
\par
We have thus proven that whenever a sequence $\left(  \alpha_{0},\alpha
_{1},...,\alpha_{n-1}\right)  \in K^{n}$ satisfies $\alpha_{0}\overline{T^{0}%
}+\alpha_{1}\overline{T^{1}}+...+\alpha_{n-1}\overline{T^{n-1}}=0$, it must
satisfy $\alpha_{i}=0$ for every $i\in\left\{  0,1,...,n-1\right\}  $. In
other words, the sequence $\left(  \overline{T^{0}},\overline{T^{1}%
},...,\overline{T^{n-1}}\right)  $ is linearly independent.} and generates the
$K$-module $K^{\prime}$\ \ \ \ \footnote{\textit{Proof.} Let $K_{1}^{\prime}$
be the $K$-submodule of $K^{\prime}$ generated by $\left(  \overline{T^{0}%
},\overline{T^{1}},...,\overline{T^{n-1}}\right)  $. Then, we will prove that
$K_{1}^{\prime}=K^{\prime}$.
\par
From the definition of $K_{1}^{\prime}$, it follows that $\overline{T^{j}}\in
K_{1}^{\prime}$ for every $j\in\left\{  0,1,...,n-1\right\}  $.
\par
Write the polynomial $P$ in the form $P=\sum\limits_{i=0}^{n}\beta_{i}T^{i}$
for some $\left(  \beta_{0},\beta_{1},...,\beta_{n}\right)  \in K^{n+1}$ (this
is possible since $\deg P=n$). Since $P$ is monic of degree $n$, we must then
have $\beta_{n}=1$.
\par
Let us prove that every $j\in\mathbb{N}$ satisfies $\overline{T^{j}}\in
K_{1}^{\prime}$.
\par
In fact, we will prove this by strong induction over $j$:
\par
\textit{Induction step:} Let $j\in\mathbb{N}$ be arbitrary. Assume that
$\overline{T^{\ell}}\in K_{1}^{\prime}$ is already proven for every $\ell
\in\mathbb{N}$ satisfying $\ell<j$. We must now prove that $\overline{T^{j}%
}\in K_{1}^{\prime}$.
\par
If $j\in\left\{  0,1,...,n-1\right\}  $, then we are immediately done with
proving $\overline{T^{j}}\in K_{1}^{\prime}$ (since we already know that
$\overline{T^{j}}\in K_{1}^{\prime}$ for every $j\in\left\{
0,1,...,n-1\right\}  $). Thus, we assume that $j\in\left\{
0,1,...,n-1\right\}  $ is not the case. Hence, $j\geq n$, so that $j-n\geq0$.
Now, $P=\sum\limits_{i=0}^{n}\beta_{i}T^{i}$, so that%
\[
P\cdot T^{j-n}=\sum\limits_{i=0}^{n}\beta_{i}T^{i}\cdot T^{j-n}=\sum
\limits_{i=0}^{n}\beta_{i}T^{i+j-n}=\sum\limits_{i=0}^{n-1}\beta_{i}%
T^{i+j-n}+\underbrace{\beta_{n}}_{=1}\underbrace{T^{n+j-n}}_{=T^{j}}%
=\sum\limits_{i=0}^{n-1}\beta_{i}T^{i+j-n}+T^{j}.
\]
Hence, $T^{j}=P\cdot T^{j-n}-\sum\limits_{i=0}^{n-1}\beta_{i}T^{i+j-n}%
\equiv-\sum\limits_{i=0}^{n-1}\beta_{i}T^{i+j-n}\operatorname{mod}\left(
P\right)  $, so that%
\[
\overline{T^{j}}=\overline{-\sum\limits_{i=0}^{n-1}\beta_{i}T^{i+j-n}}%
=-\sum\limits_{i=0}^{n-1}\beta_{i}\overline{T^{i+j-n}}.
\]
Every $i\in\left\{  0,1,...,n-1\right\}  $ satisfies $\overline{T^{i+j-n}}\in
K_{1}^{\prime}$ (since $\overline{T^{\ell}}\in K_{1}^{\prime}$ is already
proven for every $\ell\in\mathbb{N}$ satisfying $\ell<j$, and since every
$i\in\left\{  0,1,...,n-1\right\}  $ satisfies $\underbrace{i}_{<n}+j-n<j$).
Thus,%
\[
\overline{T^{j}}=-\sum\limits_{i=0}^{n-1}\beta_{i}\underbrace{\overline
{T^{i+j-n}}}_{\in K_{1}^{\prime}}\in K_{1}^{\prime}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }K_{1}^{\prime}\text{ is a }K\text{-module}\right)  .
\]
This proves that $\overline{T^{j}}\in K_{1}^{\prime}$. The induction step is
thus complete.
\par
We have thus proven by strong induction that every $j\in\mathbb{N}$ satisfies
$\overline{T^{j}}\in K_{1}^{\prime}$.
\par
The $K$-module $K\left[  T\right]  $ is generated by the elements $T^{j}$ with
$j\in\mathbb{N}$. Hence, the $K$-module $K^{\prime}=K\left[  T\right]
\diagup\left(  P\right)  $ (being a quotient module of $K\left[  T\right]  $)
is generated by the elements $\overline{T^{j}}$ with $j\in\mathbb{N}$. Since
all of these generators lie in $K_{1}^{\prime}$ (because every $j\in
\mathbb{N}$ satisfies $\overline{T^{j}}\in K_{1}^{\prime}$), we can conclude
that $K^{\prime}\subseteq K_{1}^{\prime}$. Combined with $K_{1}^{\prime
}\subseteq K^{\prime}$ (this is trivial), this yields $K^{\prime}%
=K_{1}^{\prime}$. Since $K_{1}^{\prime}$ is the $K$-submodule of $K^{\prime}$
generated by $\left(  \overline{T^{0}},\overline{T^{1}},...,\overline{T^{n-1}%
}\right)  $, this yields that the $K$-module $K^{\prime}$ is generated by
$\left(  \overline{T^{0}},\overline{T^{1}},...,\overline{T^{n-1}}\right)  $.}.
Thus, the $K$-module $K^{\prime}$ is finite-free. Also, since $\left(
\overline{T^{0}},\overline{T^{1}},...,\overline{T^{n-1}}\right)  $ is a basis
of the $K$-module $K^{\prime}$, its subsequence $\left(  \overline{T^{0}%
}\right)  =\left(  \overline{1}\right)  $ is linearly independent. Hence, the
canonical map $K\rightarrow K^{\prime}$ is injective (because it maps the
basis $\left(  1\right)  $ of the $K$-module $K$ to the linearly independent
sequence $\left(  \overline{1}\right)  $ of the $K$-module $K^{\prime}$).
Hence, we can view $K^{\prime}$ as an extension ring of $K$.

Let $p=\overline{T}$. Then, $P\left(  p\right)  =P\left(  \overline{T}\right)
=\overline{P\left(  T\right)  }=\overline{P}=0$ (since $P\equiv
0\operatorname{mod}\left(  P\right)  $). This proves Lemma 5.1.S.1.

Another lemma:

\begin{quote}
\textbf{Lemma 5.1.S.2.} Let $\mathbf{Z}$ be a ring and $P\in\mathbf{Z}\left[
T\right]  $ be a polynomial. Let $p$ be an element of $\mathbf{Z}$ such that
$P\left(  p\right)  =0$.

\textbf{(a)} Then, there exists a polynomial $Q\in\mathbf{Z}\left[  T\right]
$ of degree $\leq\deg P-1$ such that $P=Q\cdot\left(  T-p\right)  $.

\textbf{(b)} If the polynomial $P$ is monic, then this polynomial $Q$ is a
monic polynomial of degree $N-1$, where $N=\deg P$.
\end{quote}

\textit{Proof of Lemma 5.1.S.2.} \textbf{(a)} Lemma 5.1.S.2 \textbf{(a)} is a
known fact from basic algebra. We are not going to prove it.

\textbf{(b)} Assume that the polynomial $P$ is monic. Consider the polynomial
$Q$ from Lemma 5.1.S.2 \textbf{(a)}.

Let $N=\deg P$. Since $Q$ has degree $\leq\deg P-1$, we have $\deg
Q\leq\underbrace{\deg P}_{=N}-1=N-1$. We can thus write the polynomial $Q$ in
the form $Q=\sum\limits_{i=0}^{N-1}q_{i}T^{i}$ for some $\left(  q_{0}%
,q_{1},...,q_{N-1}\right)  \in\mathbf{Z}^{N}$. Writing it this way, we have%
\begin{align*}
Q\cdot\left(  T-p\right)   &  =\sum\limits_{i=0}^{N-1}q_{i}T^{i}\cdot\left(
T-p\right)  =\sum\limits_{i=0}^{N-1}q_{i}\underbrace{T^{i}T}_{=T^{i+1}}%
-\sum\limits_{i=0}^{N-1}q_{i}\underbrace{T^{i}p}_{=pT^{i}}=\sum\limits_{i=0}%
^{N-1}q_{i}T^{i+1}-\sum\limits_{i=0}^{N-1}q_{i}pT^{i}\\
&  =\sum\limits_{i=1}^{N}q_{i-1}T^{i}-\sum\limits_{i=0}^{N-1}q_{i}%
pT^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }i\text{ for
}i+1\text{ in the first sum}\right)  .
\end{align*}
Thus,%
\[
P=Q\cdot\left(  T-p\right)  =\sum\limits_{i=1}^{N}q_{i-1}T^{i}-\sum
\limits_{i=0}^{N-1}q_{i}pT^{i}.
\]
Hence,%
\begin{align*}
&  \left(  \text{the coefficient of the polynomial }P\text{ before }%
T^{N}\right) \\
&  =\left(  \text{the coefficient of the polynomial }\sum\limits_{i=1}%
^{N}q_{i-1}T^{i}-\sum\limits_{i=0}^{N-1}q_{i}pT^{i}\text{ before }T^{N}\right)
\\
&  =\underbrace{\left(  \text{the coefficient of the polynomial }%
\sum\limits_{i=1}^{N}q_{i-1}T^{i}\text{ before }T^{N}\right)  }_{=q_{N-1}}\\
&  \ \ \ \ \ \ \ \ \ \ -\underbrace{\left(  \text{the coefficient of the
polynomial }\sum\limits_{i=0}^{N-1}q_{i}pT^{i}\text{ before }T^{N}\right)
}_{=0}\\
&  =q_{N-1}-0=q_{N-1}.
\end{align*}
Since $\left(  \text{the coefficient of the polynomial }P\text{ before }%
T^{N}\right)  =1$ (because $P$ is a monic polynomial with $\deg P=N$), this
rewrites as $1=q_{N-1}$. Since $\deg q\leq N-1$, this yields that $q$ is a
monic polynomial of degree $N-1$. This proves Lemma 5.1.S.2.

Now, let us solve Exercise 5.1:

We will prove the assertion of Exercise 5.1 by induction over $n$.

\textit{Induction base:} For $n=0$, the assertion of Exercise 5.1 is trivially
true (take $K_{P}=K$). This completes the induction base.

\textit{Induction step:} Let $N\in\mathbb{N}$ be positive. Assume that the
assertion of Exercise 5.1 is true for $n=N-1$. Let us now prove the assertion
of Exercise 5.1 for $n=N$.

First we recall that we assumed that the assertion of Exercise 5.1 is true for
$n=N-1$. Hence,%
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{If }K^{\prime}\text{ is a ring, and if }Q\in K^{\prime}\left[  T\right]
\text{ is a monic polynomial such that}\\
\deg Q=N-1\text{, then there exists a finite-free extension ring }%
K_{Q}^{\prime}\text{ of}\\
\text{the ring }K^{\prime}\text{ and }N-1\text{ elements }p_{1}\text{, }%
p_{2}\text{, }...\text{, }p_{N-1}\text{ of this extension}\\
\text{ring }K_{Q}^{\prime}\text{ such that }Q=\prod\limits_{i=1}^{N-1}\left(
T-p_{i}\right)  \text{ in }K_{Q}^{\prime}\left[  T\right]
\end{array}
\right)  \label{5.1.sol.1}%
\end{equation}
(this follows from Exercise 5.1, applied to $K^{\prime}$, $Q$ and $N-1$
instead of $K$, $P$ and $n$\ \ \ \ \footnote{In fact, we are allowed to apply
Exercise 5.1 to $K^{\prime}$, $Q$ and $N-1$ instead of $K$, $P$ and $n$,
because we assumed that the assertion of Exercise 5.1 is true for $n=N-1$.}).

Let $K$ be a ring, and let $P\in K\left[  T\right]  $ be a monic polynomial
such that $\deg P=N$. According to Lemma 5.1.S.1, there exists a finite-free
extension ring $K^{\prime}$ of the ring $K$ and an element $p\in K^{\prime}$
such that $P\left(  p\right)  =0$ in $K^{\prime}$. Consider these $K^{\prime}$
and $p$.

By Lemma 5.1.S.2 \textbf{(a)} (applied to $\mathbf{Z}=K^{\prime}$), there
exists a polynomial $Q\in K^{\prime}\left[  T\right]  $ of degree $\leq\deg
P-1$ such that $P=Q\cdot\left(  T-p\right)  $ (since $P\left(  p\right)
=0$)\ \ \ \ \footnote{Note that $K^{\prime}\left[  T\right]  $ denotes the
polynomial ring in one indeterminate $T$ over $K^{\prime}$. This $T$ here is
\textit{not} the $T$ that was used to construct $K^{\prime}$ in the proof of
Lemma 5.1.S.1. In order to avoid confusing these two $T$'s, you are advised to
forget the proof of Lemma 5.1.S.1 (you won't need it any more).}. Consider
this $Q$. By Lemma 5.1.S.2 \textbf{(b)} (applied to $\mathbf{Z}=K^{\prime}$),
this polynomial $Q$ is a monic polynomial of degree $N-1$. That is, $Q$ is
monic and $\deg Q=N-1$. According to (\ref{5.1.sol.1}), there therefore exists
a finite-free extension ring $K_{Q}^{\prime}$ of the ring $K^{\prime}$ and
$N-1$ elements $p_{1}$, $p_{2}$, $...$, $p_{N-1}$ of this extension ring
$K_{Q}^{\prime}$ such that $Q=\prod\limits_{i=1}^{N-1}\left(  T-p_{i}\right)
$ in $K_{Q}^{\prime}\left[  T\right]  $. Consider this $K_{Q}^{\prime}$ and
these $p_{1}$, $p_{2}$, $...$, $p_{N-1}$.

Since $K_{Q}^{\prime}$ is a finite-free $K^{\prime}$-module, and since
$K^{\prime}$ is a finite-free $K$-module, it is clear that $K_{Q}^{\prime}$ is
a finite-free $K$-module\footnote{Here we are using the following general fact
from algebra: If $K$ is a ring, if $A$ is a $K$-algebra which is a finite-free
$K$-module, and if $B$ is a finite-free $A$-module, then $B$ is a finite-free
$K$-module.
\par
\textit{Proof of this fact.} Since $A$ is a finite-free $K$-module, we have
$A\cong K^{n}$ as $K$-modules for some $n\in\mathbb{N}$. Consider this $n$.
Since $B$ is a finite-free $A$-module, we have $B\cong A^{m}$ as $A$-modules
for some $m\in\mathbb{N}$. Consider this $m$. Since $B\cong A^{m}$ as
$A$-modules, we also have%
\begin{align*}
B  &  \cong A^{m}\cong\left(  K^{n}\right)  ^{m}\ \ \ \ \ \ \ \ \ \ \left(
\text{since }A\cong K^{n}\right) \\
&  \cong K^{nm}%
\end{align*}
as $K$-modules. Thus, $B$ is a finite-free $K$-module, qed.}. Also, since
$K_{Q}^{\prime}$ is an extension ring of $K^{\prime}$, and since $K^{\prime}$
is an extension ring of $K$, it is clear that $K_{Q}^{\prime}$ is an extension
ring of $K$. Thus, $K_{Q}^{\prime}$ is a finite-free extension ring of $K$.

Define $K_{P}=K_{Q}^{\prime}$ and $p_{N}=p$. Then, $p_{1}$, $p_{2}$, $...$,
$p_{N-1}$, $p_{N}$ are $N$ elements of the ring $K_{Q}^{\prime}=K_{P}$. In
$K_{P}\left[  T\right]  =K_{Q}^{\prime}\left[  T\right]  $, we have%
\[
P=\underbrace{Q}_{=\prod\limits_{i=1}^{N-1}\left(  T-p_{i}\right)  }%
\cdot\left(  T-\underbrace{p}_{=p_{N}}\right)  =\prod\limits_{i=1}%
^{N-1}\left(  T-p_{i}\right)  \cdot\left(  T-p_{N}\right)  =\prod
\limits_{i=1}^{N}\left(  T-p_{i}\right)  .
\]
The ring $K_{P}$ is a finite-free extension ring of $K$ (since $K_{P}%
=K_{Q}^{\prime}$, and since we know that $K_{Q}^{\prime}$ is a finite-free
extension ring of $K$).

So we have proven that if $K$ is a ring, and if $P\in K\left[  T\right]  $ is
a monic polynomial such that $\deg P=N$, then there exists a finite-free
extension ring $K_{P}$ of the ring $K$ and $N$ elements $p_{1},$ $p_{2},$
$...,$ $p_{N}$ of this extension ring $K_{P}$ such that $P=\prod
\limits_{i=1}^{N}\left(  T-p_{i}\right)  $ in $K_{P}\left[  T\right]  $. In
other words, we have proven the assertion of Exercise 5.1 for $n=N$. Thus, the
induction step is complete, and Exercise 5.1 is solved.

\textit{Exercise 5.2:} \textit{Hints to solution:} \textbf{(a)} The idea is to
evaluate the identity $\sum\limits_{i=0}^{n}a_{n-i}T^{i}=\prod\limits_{i=1}%
^{n}\left(  p_{i}+T\right)  $ at $T=\dfrac{1}{S}$, where $S$ is a new
variable. The only nontrivial part of the solution is to make formal sense of
this idea (this is what Lemma 5.2.S.1 in the solution below is for).
\textbf{(b)} is similar.

\textit{Detailed solution:} First we need the following lemma:

\begin{quote}
\textbf{Lemma 5.2.S.1.} Let $L$ be a ring. Consider the polynomial ring
$L\left[  T\right]  $ as a subring of the polynomial ring $L\left[
T,S\right]  $. Let $P\in L\left[  T\right]  $ be a polynomial such that
$TS-1\mid P$ in $L\left[  T,S\right]  $. Then, $P=0$.
\end{quote}

This is a known and very basic lemma and can be proven, for instance, using
the fact that the inclusion $L\left[  T\right]  \rightarrow L\left[
T,S\right]  $ induces an injective map $L\left[  T\right]  \rightarrow
L\left[  T,S\right]  \diagup\left(  TS-1\right)  $. But let us give a slightly
different proof of this lemma, in the hope that a clever reader will find a
better use for the trick it involves:

\textit{Proof of Lemma 5.2.S.1.} Since $TS-1\mid P$ in $L\left[  T,S\right]
$, there exists a polynomial $Q\in L\left[  T,S\right]  $ such that $P=\left(
TS-1\right)  \cdot Q$. Consider this $Q$.

Let $m$ be the degree of the polynomial $P\in L\left[  T\right]  $.

By the universal property of the polynomial ring $L\left[  T,S\right]  $,
there exists a unique $L$-algebra homomorphism $L\left[  T,S\right]
\rightarrow L\left[  T\right]  $ which maps $T$ and $S$ to $T$ and $T^{m}$,
respectively. Denote this homomorphism by $\varphi$. Then, $\varphi$ maps $T$
and $S$ to $T$ and $T^{m}$, respectively, so that $\varphi\left(  T\right)
=T$ and $\varphi\left(  S\right)  =T^{m}$. Since $\varphi$ is an $L$-algebra
homomorphism, we have
\[
\varphi\left(  \left(  TS-1\right)  \cdot Q\right)  =\left(
\underbrace{\varphi\left(  T\right)  }_{=T}\underbrace{\varphi\left(
S\right)  }_{=T^{m}}-1\right)  \cdot\varphi\left(  Q\right)  =\left(
TT^{m}-1\right)  \cdot\varphi\left(  Q\right)  =\left(  T^{m+1}-1\right)
\cdot\varphi\left(  Q\right)  .
\]


On the other hand, $\varphi\left(  P\right)  =P$%
\ \ \ \ \footnote{\textit{Proof.} Since $P\in L\left[  X\right]  $ and $\deg
P=m$, we can write $P$ in the form $P=\sum\limits_{i=0}^{m}\beta_{i}X^{i}$ for
some $\left(  \beta_{0},\beta_{1},...,\beta_{m}\right)  \in L^{m+1}$. Thus,%
\begin{align*}
\varphi\left(  P\right)   &  =\varphi\left(  \sum\limits_{i=0}^{m}\beta
_{i}X^{i}\right)  =\sum\limits_{i=0}^{m}\beta_{i}\left(  \underbrace{\varphi
\left(  X\right)  }_{=X}\right)  ^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{since
}\varphi\text{ is an }L\text{-algebra homomorphism}\right) \\
&  =\sum\limits_{i=0}^{m}\beta_{i}X^{i}=P.
\end{align*}
}. Now,%
\[
P=\varphi\left(  \underbrace{P}_{=\left(  TS-1\right)  \cdot Q}\right)
=\varphi\left(  \left(  TS-1\right)  \cdot Q\right)  =\left(  T^{m+1}%
-1\right)  \cdot\varphi\left(  Q\right)  .
\]
Hence, the polynomial $P$ is a multiple of $T^{m+1}-1$ in $L\left[  T\right]
$. Since $T^{m+1}-1$ is a monic polynomial of degree $m+1$, this yields that
$P$ is a multiple of a monic polynomial of degree $m+1$. But it is known that
a multiple of a monic polynomial of degree $m+1$ must either have degree $\geq
m+1$ or be the zero polynomial. Hence, the fact that $P$ is a multiple of a
monic polynomial of degree $m+1$ yields that $P$ has either degree $\geq m+1$
or is the zero polynomial. Since we know that $P$ does not have degree $\geq
m+1$ (because $\deg P=m<m+1$), this tells us that $P$ is the zero polynomial.
In other words, $P=0$. Lemma 5.2.S.1 is proven.

Now let us solve Exercise 5.2. Consider the polynomial ring $L\left[
T\right]  $ as a subring of the polynomial ring $L\left[  T,S\right]  $.

\textbf{(a)} Assume that $\sum\limits_{i=0}^{n}a_{n-i}T^{i}=\prod
\limits_{i=1}^{n}\left(  p_{i}+T\right)  $. This is a polynomial identity, so
we can evaluate it at $T=S$ and obtain $\sum\limits_{i=0}^{n}a_{n-i}%
S^{i}=\prod\limits_{i=1}^{n}\left(  p_{i}+S\right)  $. Thus,%
\begin{align*}
T^{n}\sum\limits_{i=0}^{n}a_{n-i}S^{i}  &  =\underbrace{T^{n}}_{=\prod
\limits_{i=1}^{n}T}\prod\limits_{i=1}^{n}\left(  p_{i}+S\right)
=\prod\limits_{i=1}^{n}T\prod\limits_{i=1}^{n}\left(  p_{i}+S\right)
=\prod\limits_{i=1}^{n}\underbrace{\left(  T\left(  p_{i}+S\right)  \right)
}_{=p_{i}T+TS}\\
&  =\prod\limits_{i=1}^{n}\left(  p_{i}T+\underbrace{TS}_{\equiv
1\operatorname{mod}\left(  TS-1\right)  }\right)  \equiv\prod\limits_{i=1}%
^{n}\left(  p_{i}T+1\right)  =\prod\limits_{i=1}^{n}\left(  1+p_{i}T\right)
\operatorname{mod}\left(  TS-1\right)  .
\end{align*}
Combined with%
\begin{align*}
T^{n}\sum\limits_{i=0}^{n}a_{n-i}S^{i}  &  =\sum\limits_{i=0}^{n}%
a_{n-i}\underbrace{T^{n}}_{=T^{n-i}T^{i}}S^{i}=\sum\limits_{i=0}^{n}%
a_{n-i}T^{n-i}\underbrace{T^{i}S^{i}}_{=\left(  TS\right)  ^{i}\equiv
1^{i}\operatorname{mod}\left(  TS-1\right)  }\equiv\sum\limits_{i=0}%
^{n}a_{n-i}T^{n-i}1^{i}=\sum\limits_{i=0}^{n}a_{n-i}T^{n-i}\\
&  =\sum\limits_{i=0}^{n}a_{i}T^{i}\operatorname{mod}\left(  TS-1\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{here we renamed }n-i\text{ as }i\right)  ,
\end{align*}
this yields $\sum\limits_{i=0}^{n}a_{i}T^{i}\equiv\prod\limits_{i=1}%
^{n}\left(  1+p_{i}T\right)  \operatorname{mod}\left(  TS-1\right)  $. In
other words, $TS-1\mid\sum\limits_{i=0}^{n}a_{i}T^{i}-\prod\limits_{i=1}%
^{n}\left(  1+p_{i}T\right)  $. Thus, Lemma 5.2.S.1 (applied to $P=\sum
\limits_{i=0}^{n}a_{i}T^{i}-\prod\limits_{i=1}^{n}\left(  1+p_{i}T\right)  $)
yields that $\sum\limits_{i=0}^{n}a_{i}T^{i}-\prod\limits_{i=1}^{n}\left(
1+p_{i}T\right)  =0$. In other words, $\sum\limits_{i=0}^{n}a_{i}T^{i}%
=\prod\limits_{i=1}^{n}\left(  1+p_{i}T\right)  $. This proves Exercise 5.2
\textbf{(a)}.

\textbf{(b)} Assume that $\sum\limits_{i=0}^{n}a_{i}T^{i}=\prod\limits_{i=1}%
^{n}\left(  1+p_{i}T\right)  $. This is a polynomial identity, so we can
evaluate it at $T=S$ and obtain $\sum\limits_{i=0}^{n}a_{i}S^{i}%
=\prod\limits_{i=1}^{n}\left(  1+p_{i}S\right)  $. Thus,%
\begin{align*}
T^{n}\sum\limits_{i=0}^{n}a_{i}S^{i}  &  =\underbrace{T^{n}}_{=\prod
\limits_{i=1}^{n}T}\prod\limits_{i=1}^{n}\left(  1+p_{i}S\right)
=\prod\limits_{i=1}^{n}T\prod\limits_{i=1}^{n}\left(  1+p_{i}S\right)
=\prod\limits_{i=1}^{n}\underbrace{\left(  T\left(  1+p_{i}S\right)  \right)
}_{=T+p_{i}TS}\\
&  =\prod\limits_{i=1}^{n}\left(  T+p_{i}\underbrace{TS}_{\equiv
1\operatorname{mod}\left(  TS-1\right)  }\right)  \equiv\prod\limits_{i=1}%
^{n}\underbrace{\left(  T+p_{i}1\right)  }_{=p_{i}+T}=\prod\limits_{i=1}%
^{n}\left(  p_{i}+T\right)  \operatorname{mod}\left(  TS-1\right)  .
\end{align*}
Combined with%
\begin{align*}
T^{n}\sum\limits_{i=0}^{n}a_{i}S^{i}  &  =\sum\limits_{i=0}^{n}a_{i}%
\underbrace{T^{n}}_{=T^{n-i}T^{i}}S^{i}=\sum\limits_{i=0}^{n}a_{i}%
T^{n-i}\underbrace{T^{i}S^{i}}_{=\left(  TS\right)  ^{i}\equiv1^{i}%
\operatorname{mod}\left(  TS-1\right)  }\equiv\sum\limits_{i=0}^{n}%
a_{i}T^{n-i}1^{i}=\sum\limits_{i=0}^{n}a_{i}T^{n-i}\\
&  =\sum\limits_{i=0}^{n}a_{n-i}T^{i}\operatorname{mod}\left(  TS-1\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{here we renamed }n-i\text{ as }i\right)  ,
\end{align*}
this yields $\sum\limits_{i=0}^{n}a_{n-i}T^{i}\equiv\prod\limits_{i=1}%
^{n}\left(  p_{i}+T\right)  \operatorname{mod}\left(  TS-1\right)  $. In other
words, $TS-1\mid\sum\limits_{i=0}^{n}a_{n-i}T^{i}-\prod\limits_{i=1}%
^{n}\left(  p_{i}+T\right)  $. Thus, Lemma 5.2.S.1 (applied to $P=\sum
\limits_{i=0}^{n}a_{n-i}T^{i}-\prod\limits_{i=1}^{n}\left(  p_{i}+T\right)  $)
yields that $\sum\limits_{i=0}^{n}a_{n-i}T^{i}-\prod\limits_{i=1}^{n}\left(
p_{i}+T\right)  =0$. In other words, $\sum\limits_{i=0}^{n}a_{n-i}T^{i}%
=\prod\limits_{i=1}^{n}\left(  p_{i}+T\right)  $. This proves Exercise 5.2
\textbf{(b)}.

\textit{Exercise 5.3: Hints to solution:} Exercise 5.3 follows from Exercise
5.1, applied to $\dfrac{P}{T-p}$ instead of $P$.

\textit{Detailed solution:} By Lemma 5.1.S.2 \textbf{(a)} (applied to
$\mathbf{Z}=K$), there exists a polynomial $Q\in K\left[  T\right]  $ of
degree $\leq\deg P-1$ such that $P=Q\cdot\left(  T-p\right)  $. Consider this
$Q$. By Lemma 5.1.S.2 \textbf{(b)} (applied to $\mathbf{Z}=K$), this
polynomial $Q$ is a monic polynomial of degree $N-1$, where $N=\deg P$. Since
$N=\deg P=n$, this rewrites as follows: The polynomial $Q$ is a monic
polynomial of degree $n-1$.

Thus, Exercise 5.1 (applied to $Q$ and $n-1$ instead of $P$ and $n$) yields
that there exists a finite-free extension ring $K_{Q}$ of the ring $K$ and
$n-1$ elements $p_{1},$ $p_{2},$ $...,$ $p_{n-1}$ of this extension ring
$K_{Q}$ such that $Q=\prod\limits_{i=1}^{n-1}\left(  T-p_{i}\right)  $ in
$K_{Q}\left[  T\right]  $. Consider this ring $K_{Q}$ and these $n-1$ elements
$p_{1},$ $p_{2},$ $...,$ $p_{n-1}$.

Define a further element $p_{n}$ of $K_{Q}$ by $p_{n}=p$. Then, $p_{1},$
$p_{2},$ $...,$ $p_{n}$ are $n$ elements of $K_{Q}$ satisfying%
\[
P=\underbrace{Q}_{=\prod\limits_{i=1}^{n-1}\left(  T-p_{i}\right)  }%
\cdot\left(  T-\underbrace{p}_{=p_{n}}\right)  =\prod\limits_{i=1}%
^{n-1}\left(  T-p_{i}\right)  \cdot\left(  T-p_{n}\right)  =\prod
\limits_{i=1}^{n}\left(  T-p_{i}\right)
\]
in $K_{Q}\left[  T\right]  $.

Let $K_{P}^{\prime}=K_{Q}$. Then, $K_{P}^{\prime}$ is a finite-free extension
ring of the ring $K$ (since $K_{Q}$ is a finite-free extension ring of the
ring $K$), and the $n$ elements $p_{1},$ $p_{2},$ $...,$ $p_{n}$ of $K_{Q}$
satisfy $P=\prod\limits_{i=1}^{n}\left(  T-p_{i}\right)  $ in $K_{P}^{\prime
}\left[  T\right]  $ and $p=p_{n}$. Thus, Exercise 5.3 is solved.

\textit{Exercise 5.4: Hints to solution:} First here is a rewriting of
Exercise 5.2 \textbf{(b)}:

\begin{quote}
\textbf{Lemma 5.4.S.1.} Let $L$ be a ring. Let $\ell\in\mathbb{N}$. Let
$a_{0}$, $a_{1}$, $...$, $a_{\ell}$ be elements of $L$. Let $S$ be a finite
set with $\left\vert S\right\vert =\ell$. For every $s\in S$, let $p_{s}$ be
an element of $L$. If $\sum\limits_{i=0}^{\ell}a_{i}T^{i}=\prod\limits_{s\in
S}\left(  1+p_{s}T\right)  $ in the polynomial ring $L\left[  T\right]  $,
then $\sum\limits_{i=0}^{\ell}a_{\ell-i}T^{i}=\prod\limits_{s\in S}\left(
p_{s}+T\right)  $.
\end{quote}

\textit{Proof of Lemma 5.4.S.1.} Assume that $\sum\limits_{i=0}^{\ell}%
a_{i}T^{i}=\prod\limits_{s\in S}\left(  1+p_{s}T\right)  $.

Since the finite set $S$ is used only for labelling the elements $p_{s}$, we
can WLOG assume that $S=\left\{  1,2,...,\ell\right\}  $ (since $\left\vert
S\right\vert =\ell$). Assume this. Then,
\[
\prod\limits_{s\in S}\left(  1+p_{s}T\right)  =\prod\limits_{s\in\left\{
1,2,...,\ell\right\}  }\left(  1+p_{s}T\right)  =\prod\limits_{s=1}^{\ell
}\left(  1+p_{s}T\right)  =\prod\limits_{i=1}^{\ell}\left(  1+p_{i}T\right)
\]
(here we renamed the index $s$ as $i$) and%
\[
\prod\limits_{s\in S}\left(  p_{s}+T\right)  =\prod\limits_{s\in\left\{
1,2,...,\ell\right\}  }\left(  p_{s}+T\right)  =\prod\limits_{s=1}^{\ell
}\left(  p_{s}+T\right)  =\prod\limits_{i=1}^{\ell}\left(  p_{i}+T\right)
\]
(here we renamed the index $s$ as $i$).

Now, $\sum\limits_{i=0}^{\ell}a_{i}T^{i}=\prod\limits_{s\in S}\left(
1+p_{s}T\right)  =\prod\limits_{i=1}^{\ell}\left(  1+p_{i}T\right)  $. Hence,
Exercise 5.2 \textbf{(b)} (applied to $n=\ell$) yields $\sum\limits_{i=0}%
^{\ell}a_{\ell-i}T^{i}=\prod\limits_{i=1}^{\ell}\left(  p_{i}+T\right)
=\prod\limits_{s\in S}\left(  p_{s}+T\right)  $. This proves Lemma 5.4.S.1.

The next lemma is more or less the statement of our exercise (except for that
it has $-\alpha\beta$ instead of $\alpha\beta$, but this doesn't make that
much of a difference):

\begin{quote}
\textbf{Lemma 5.4.S.2.} Let $K$ be a ring, and $L$ an extension ring of $K$.
Let $n\in\mathbb{N}$ and $m\in\mathbb{N}$. Let $\alpha$ and $\beta$ be two
elements of $L$ such that $\alpha$ is $n$-integral over $K$ and $\beta$ is
$m$-integral over $K$. Then, $-\alpha\beta$ is $nm$-integral over $K$.
\end{quote}

\textit{Proof of Lemma 5.4.S.2.} Since $\alpha$ is $n$-integral over $K$,
there exists a monic polynomial $P\in K\left[  T\right]  $ such that $\deg
P=n$ and $P\left(  \alpha\right)  =0$ (by the definition of "$n$-integral").

Since $\beta$ is $m$-integral over $K$, there exists a monic polynomial $Q\in
K\left[  T\right]  $ such that $\deg Q=m$ and $Q\left(  \beta\right)  =0$ (by
the definition of "$m$-integral").

Since $\deg P=n$, we can write the polynomial $P\in K\left[  T\right]  $ in
the form $P=\sum\limits_{i=0}^{n}c_{i}T^{i}$ for some $\left(  c_{0}%
,c_{1},...,c_{n}\right)  \in K^{n+1}$. Consider this $\left(  c_{0}%
,c_{1},...,c_{n}\right)  $. Then, $c_{n}=\left(  \text{the coefficient of
}P\text{ before }T^{n}\right)  =1$ (since $P$ is a monic polynomial with $\deg
P=n$).

Since $\deg Q=m$, we can write the polynomial $Q\in K\left[  T\right]  $ in
the form $Q=\sum\limits_{i=0}^{m}d_{i}T^{i}$ for some $\left(  d_{0}%
,d_{1},...,d_{m}\right)  \in K^{m+1}$. Consider this $\left(  d_{0}%
,d_{1},...,d_{m}\right)  $. Then, $d_{m}=\left(  \text{the coefficient of
}Q\text{ before }T^{m}\right)  =1$ (since $Q$ is a monic polynomial with $\deg
Q=m$).

For every $i\in\mathbb{N}$, define an element $a_{i}\in K$ by $a_{i}=\left\{
\begin{array}
[c]{c}%
c_{n-i}\text{, if }i\leq n;\\
0\text{, if }i>n
\end{array}
\right.  $. For every $i\in\mathbb{N}$, define an element $b_{i}\in K$ by
$b_{i}=\left\{
\begin{array}
[c]{c}%
d_{m-i}\text{, if }i\leq m;\\
0\text{, if }i>m
\end{array}
\right.  $.

Let $R\in K\left[  T\right]  $ be the polynomial defined by%
\[
R=\sum\limits_{i=0}^{mn}P_{mn-i}\left(  a_{1},a_{2},...,a_{mn-i},b_{1}%
,b_{2},...,b_{mn-i}\right)  T^{i}.
\]


Now we claim that $R$ is a monic polynomial, that $\deg R=mn$ and that
$R\left(  -\alpha\beta\right)  =0$.

\textit{Proof.} Exercise 5.3 (applied to $\alpha$ and $L$ instead of $p$ and
$K$) yields that there exists a finite-free extension ring $L_{P}^{\prime}$ of
$L$ and $n$ elements $p_{1}$, $p_{2}$, $...$, $p_{n}$ of this extension ring
$L_{P}^{\prime}$ such that $P=\prod\limits_{i=1}^{n}\left(  T-p_{i}\right)  $
in $L_{P}^{\prime}\left[  T\right]  $ and such that $\alpha=p_{n}$. Consider
this extension ring $L_{P}^{\prime}$ and these elements $p_{1}$, $p_{2}$,
$...$, $p_{n}$. Denote this extension ring $L_{P}^{\prime}$ by $M$. All we
need to know about $M$ is that $M$ is an extension ring of $L$ containing
$p_{1}$, $p_{2}$, $...$, $p_{n}$.

Exercise 5.3 (applied to $Q$, $m$, $\beta$ and $M$ instead of $P$, $n$, $p$
and $K$) yields that there exists a finite-free extension ring $M_{Q}^{\prime
}$ of $M$ and $m$ elements $q_{1}$, $q_{2}$, $...$, $q_{m}$ of this extension
ring $M_{Q}^{\prime}$ such that $Q=\prod\limits_{i=1}^{m}\left(
T-q_{i}\right)  $ in $M_{Q}^{\prime}\left[  T\right]  $ and such that
$\beta=q_{m}$. Consider this extension ring $M_{Q}^{\prime}$ and these
elements $q_{1}$, $q_{2}$, $...$, $q_{m}$. Denote this extension ring
$M_{Q}^{\prime}$ by $N$. All we need to know about $N$ is that $N$ is an
extension ring of $L$ (since $N$ is an extension ring of $M$, which, in turn,
is an extension ring of $L$) containing $p_{1}$, $p_{2}$, $...$, $p_{n}$
(because it contains $L$ and because $L$ contains $p_{1}$, $p_{2}$, $...$,
$p_{n}$) and containing $q_{1}$, $q_{2}$, $...$, $q_{m}$.

Let $\widetilde{P}\in K\left[  T\right]  $ be the polynomial $\sum
\limits_{i=0}^{n}c_{n-i}T^{i}$. This polynomial $\widetilde{P}$ has constant
term $c_{n-0}=c_{n}=1$, hence lies in $1+K\left[  T\right]  ^{+}$.

Let $\widetilde{Q}\in K\left[  T\right]  $ be the polynomial $\sum
\limits_{i=0}^{m}d_{m-i}T^{i}$. This polynomial $\widetilde{Q}$ has constant
term $d_{m-0}=d_{m}=1$, hence lies in $1+K\left[  T\right]  ^{+}$.

We have $\sum\limits_{i=0}^{n}\underbrace{c_{n-\left(  n-i\right)  }}_{=c_{i}%
}T^{i}=\sum\limits_{i=0}^{n}c_{i}T^{i}=P=\prod\limits_{i=1}^{n}%
\underbrace{\left(  T-p_{i}\right)  }_{=-p_{i}+T}=\prod\limits_{i=1}%
^{n}\left(  -p_{i}+T\right)  $. Therefore, Exercise 5.2 \textbf{(a)} (applied
to $N$, $c_{n-i}$ and $-p_{i}$ instead of $L$, $a_{i}$ and $p_{i}$) yields
that%
\[
\sum\limits_{i=0}^{n}c_{n-i}T^{i}=\prod\limits_{i=1}^{n}\left(  1+\left(
-p_{i}\right)  T\right)  .
\]
Thus,%
\[
\widetilde{P}=\sum\limits_{i=0}^{n}c_{n-i}T^{i}=\prod\limits_{i=1}^{n}\left(
1+\left(  -p_{i}\right)  T\right)  =\Pi\left(  N,\left[  -p_{1},-p_{2}%
,...,-p_{n}\right]  \right)  .
\]


We have $\sum\limits_{i=0}^{m}\underbrace{d_{m-\left(  m-i\right)  }}_{=d_{i}%
}T^{i}=\sum\limits_{i=0}^{m}d_{i}T^{i}=Q=\prod\limits_{i=1}^{m}%
\underbrace{\left(  T-q_{i}\right)  }_{=-q_{i}+T}=\prod\limits_{i=1}%
^{m}\left(  -q_{i}+T\right)  $. Therefore, Exercise 5.2 \textbf{(a)} (applied
to $N$, $m$, $d_{m-i}$ and $-q_{i}$ instead of $L$, $n$, $a_{i}$ and $p_{i}$)
yields that%
\[
\sum\limits_{i=0}^{m}d_{m-i}T^{i}=\prod\limits_{i=1}^{m}\left(  1+\left(
-q_{i}\right)  T\right)  .
\]
Thus,%
\[
\widetilde{Q}=\sum\limits_{i=0}^{m}d_{m-i}T^{i}=\prod\limits_{i=1}^{m}\left(
1+\left(  -q_{i}\right)  T\right)  =\Pi\left(  N,\left[  -q_{1},-q_{2}%
,...,-q_{m}\right]  \right)  .
\]


Since $\widetilde{Q}=\Pi\left(  N,\left[  -q_{1},-q_{2},...,-q_{n}\right]
\right)  $ and $\widetilde{P}=\Pi\left(  N,\left[  -p_{1},-p_{2}%
,...,-p_{n}\right]  \right)  $, we can apply Theorem 5.3 \textbf{(c)} to
$u=\widetilde{Q}$, $v=\widetilde{P}$, $\widetilde{K}_{u}=N$, $\widetilde{K}%
_{v}=N$, $\widetilde{K}_{u,v}=N$, $u_{i}=-q_{i}$ and $v_{j}=-p_{j}$. As a
result we obtain%
\begin{align*}
\widetilde{Q}\widehat{\cdot}\widetilde{P}  &  =\Pi\left(  N,\left[
\underbrace{\left(  -q_{i}\right)  \left(  -p_{j}\right)  }_{=p_{j}q_{i}%
}\ \mid\ \left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  \right]  \right) \\
&  =\Pi\left(  N,\left[  p_{j}q_{i}\ \mid\ \left(  i,j\right)  \in\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  \right]  \right)
=\prod\limits_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  }\left(  1+p_{j}q_{i}T\right)  .
\end{align*}
Thus, $\widetilde{Q}\widehat{\cdot}\widetilde{P}$ is a polynomial of degree%
\begin{align*}
\deg\left(  \widetilde{Q}\widehat{\cdot}\widetilde{P}\right)   &  =\deg\left(
\prod\limits_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  }\left(  1+p_{j}q_{i}T\right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\widetilde{Q}\widehat{\cdot
}\widetilde{P}=\prod\limits_{\left(  i,j\right)  \in\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  }\left(  1+p_{j}%
q_{i}T\right)  \right) \\
&  \leq\sum\limits_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  }\underbrace{\left(  1+p_{j}q_{i}T\right)
}_{\leq1}\\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since the degree of a product of some polynomials}\\
\text{is }\leq\text{ to the sum of the degrees of these polynomials}%
\end{array}
\right) \\
&  \leq\sum\limits_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  }1=\left\vert \left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  \right\vert =mn.
\end{align*}


But%
\begin{align*}
\sum\limits_{i\in\mathbb{N}}a_{i}T^{i}  &  =\sum\limits_{i\in\mathbb{N}%
}\left\{
\begin{array}
[c]{c}%
c_{n-i}\text{, if }i\leq n;\\
0\text{, if }i>n
\end{array}
\right.  T^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }a_{i}=\left\{
\begin{array}
[c]{c}%
c_{n-i}\text{, if }i\leq n;\\
0\text{, if }i>n
\end{array}
\right.  \right) \\
&  =\sum\limits_{i=0}^{n}\underbrace{\left\{
\begin{array}
[c]{c}%
c_{n-i}\text{, if }i\leq n;\\
0\text{, if }i>n
\end{array}
\right.  }_{=c_{n-i}\text{ (since }i\leq n\text{)}}T^{i}+\sum\limits_{i=n+1}%
^{\infty}\underbrace{\left\{
\begin{array}
[c]{c}%
c_{n-i}\text{, if }i\leq n;\\
0\text{, if }i>n
\end{array}
\right.  }_{=0}T^{i}\\
&  =\sum\limits_{i=0}^{n}c_{n-i}T^{i}+\underbrace{\sum\limits_{i=n+1}^{\infty
}0T^{i}}_{=0}=\sum\limits_{i=0}^{n}c_{n-i}T^{i}=\widetilde{P}%
\end{align*}
and similarly $\sum\limits_{i\in\mathbb{N}}b_{i}T^{i}=\widetilde{Q}$. Now,%
\begin{align*}
\widetilde{Q}\widehat{\cdot}\widetilde{P}  &  =\widetilde{P}\widehat{\cdot
}\widetilde{Q}=\left(  \sum\limits_{i\in\mathbb{N}}a_{i}T^{i}\right)
\widehat{\cdot}\left(  \sum\limits_{i\in\mathbb{N}}b_{i}T^{i}\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\widetilde{P}=\sum\limits_{i\in
\mathbb{N}}a_{i}T^{i}\text{ and }\widetilde{Q}=\sum\limits_{i\in\mathbb{N}%
}b_{i}T^{i}\right) \\
&  =\sum_{k\in\mathbb{N}}P_{k}\left(  a_{1},a_{2},...,a_{k},b_{1}%
,b_{2},...,b_{k}\right)  T^{k}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\widehat{\cdot
}\text{ at the beginning of Section 5}\right)  .
\end{align*}
Hence, for every $k\in\mathbb{N}$, we have%
\[
\left(  \text{the coefficient of the polynomial }\widetilde{Q}\widehat{\cdot
}\widetilde{P}\text{ before }T^{k}\right)  =P_{k}\left(  a_{1},a_{2}%
,...,a_{k},b_{1},b_{2},...,b_{k}\right)  .
\]


But since $\widetilde{Q}\widehat{\cdot}\widetilde{P}$ is a polynomial of
degree $\leq mn$, we have%
\begin{align*}
\widetilde{Q}\widehat{\cdot}\widetilde{P}  &  =\sum_{k=0}^{mn}%
\underbrace{\left(  \text{the coefficient of the polynomial }\widetilde{Q}%
\widehat{\cdot}\widetilde{P}\text{ before }T^{k}\right)  }_{=P_{k}\left(
a_{1},a_{2},...,a_{k},b_{1},b_{2},...,b_{k}\right)  }T^{k}\\
&  =\sum_{k=0}^{mn}P_{k}\left(  a_{1},a_{2},...,a_{k},b_{1},b_{2}%
,...,b_{k}\right)  T^{k}\\
&  =\sum_{i=0}^{mn}P_{i}\left(  a_{1},a_{2},...,a_{i},b_{1},b_{2}%
,...,b_{i}\right)  T^{i}\ \ \ \ \ \ \ \ \ \ \left(  \text{here, we renamed
}k\text{ as }i\right)  .
\end{align*}
Thus,%
\[
\sum_{i=0}^{mn}P_{i}\left(  a_{1},a_{2},...,a_{i},b_{1},b_{2},...,b_{i}%
\right)  T^{i}=\widetilde{Q}\widehat{\cdot}\widetilde{P}=\prod\limits_{\left(
i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}
}\left(  1+p_{j}q_{i}T\right)  .
\]
Define $r_{\left(  i,j\right)  }$ to mean $p_{j}q_{i}$ for every $\left(
i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}
$. Then,%
\begin{align*}
&  \sum_{i=0}^{mn}P_{i}\left(  a_{1},a_{2},...,a_{i},b_{1},b_{2}%
,...,b_{i}\right)  T^{i}\\
&  =\prod\limits_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  }\left(  1+\underbrace{p_{j}q_{i}%
}_{=r_{\left(  i,j\right)  }}T\right)  =\prod\limits_{\left(  i,j\right)
\in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  }\left(
1+r_{\left(  i,j\right)  }T\right) \\
&  =\prod\limits_{s\in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }\left(  1+r_{s}T\right)
\end{align*}
(here, we renamed the index $\left(  i,j\right)  $ as $s$). Thus, Lemma
5.4.S.1 (applied to $N$, $mn$, $P_{i}\left(  a_{1},a_{2},...,a_{i},b_{1}%
,b_{2},...,b_{i}\right)  $, $\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  $ and $r_{s}$ instead of $L$, $\ell$, $a_{i}$, $S$ and
$p_{s}$) yields that%
\[
\sum\limits_{i=0}^{mn}P_{mn-i}\left(  a_{1},a_{2},...,a_{mn-i},b_{1}%
,b_{2},...,b_{mn-i}\right)  T^{i}=\prod\limits_{s\in\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  }\left(  r_{s}+T\right)
.
\]
Since $\sum\limits_{i=0}^{mn}P_{mn-i}\left(  a_{1},a_{2},...,a_{mn-i}%
,b_{1},b_{2},...,b_{mn-i}\right)  T^{i}=R$, this rewrites as%
\begin{align*}
R  &  =\prod\limits_{s\in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }\left(  r_{s}+T\right)  =\prod\limits_{\left(  i,j\right)
\in\left\{  1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  }\left(
\underbrace{r_{\left(  i,j\right)  }}_{=p_{j}q_{i}}+T\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we renamed the index }s\text{ as
}\left(  i,j\right)  \right) \\
&  =\prod\limits_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}
\times\left\{  1,2,...,n\right\}  }\left(  p_{j}q_{i}+T\right)  .
\end{align*}
Therefore,%
\begin{equation}
R\left(  -\alpha\beta\right)  =\prod\limits_{\left(  i,j\right)  \in\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  }\left(  p_{j}%
q_{i}+\left(  -\alpha\beta\right)  \right)  . \label{5.4.sol.1}%
\end{equation}
One of the factors of the product on the right hand side of (\ref{5.4.sol.1})
(namely, the one for $\left(  i,j\right)  =\left(  m,n\right)  $) is%
\[
\underbrace{p_{n}}_{=\alpha}\underbrace{q_{m}}_{=\beta}+\left(  -\alpha
\beta\right)  =\alpha\beta+\left(  -\alpha\beta\right)  =0.
\]
Hence, the product on the right hand side of (\ref{5.4.sol.1}) is $0$. Thus,
(\ref{5.4.sol.1}) simplifies to $R\left(  -\alpha\beta\right)  =0$.

Since $R$ was defined by
\[
R=\sum\limits_{i=0}^{mn}P_{mn-i}\left(  a_{1},a_{2},...,a_{mn-i},b_{1}%
,b_{2},...,b_{mn-i}\right)  T^{i},
\]
it is clear that the polynomial $R$ has degree $\leq mn$, and that the
coefficient of $R$ before $T^{mn}$ is%
\[
P_{mn-mn}\left(  a_{1},a_{2},...,a_{mn-mn},b_{1},b_{2},...,b_{mn-mn}\right)
=P_{0}\left(  a_{1},a_{2},...,a_{0},b_{1},b_{2},...,b_{0}\right)  =P_{0}=1
\]
(here we are using the fact that $P_{0}=1$; this is very easy to see from the
definition of $P_{0}$). Thus, $R$ is a monic polynomial of degree $mn$. Hence
$\deg R=mn=nm$.

So we have found a monic polynomial $R\in K\left[  T\right]  $ such that $\deg
R=nm$ and $R\left(  -\alpha\beta\right)  =0$. By the definition of
"$nm$-integral", this yields that $-\alpha\beta$ is $nm$-integral over $K$.
This proves Lemma 5.4.S.2.

Now let us finally solve the problem. Let $\alpha$ and $\beta$ be two elements
of $L$ such that $\alpha$ is $n$-integral over $K$ and $\beta$ is $m$-integral
over $K$. Then, Lemma 5.4.S.2 yields $-\alpha\beta$ is $nm$-integral over $K$.
Hence, Lemma 5.4.S.2 (applied to $nm$, $1$, $-\alpha\beta$ and $-1$ instead of
$n$, $m$, $\alpha$ and $\beta$) yields that $\left(  -\alpha\beta\right)
\left(  -1\right)  $ is $\left(  nm\right)  \cdot1$-integral over $K$ (since
$-1$ is $1$-integral over $K$). In other words, $\alpha\beta$ is $nm$-integral
over $K$. This solves Exercise 5.4.

\textit{Exercise 5.5:} \textit{Detailed solution:} \textbf{(a)} Let $\pi$ be
the canonical projection $K\rightarrow K\diagup I$. Then, $\pi$ is a ring
homomorphism, and thus induces a canonical ring homomorphism $\pi\left[
\left[  T\right]  \right]  :K\left[  \left[  T\right]  \right]  \rightarrow
L\left[  \left[  T\right]  \right]  $ (which sends every $\sum\limits_{i\in
\mathbb{N}}a_{i}T^{i}\in K\left[  \left[  T\right]  \right]  $ to
$\sum\limits_{i\in\mathbb{N}}\pi\left(  a_{i}\right)  T^{i}\in L\left[
\left[  T\right]  \right]  $). The morphism $\Lambda\left(  \pi\right)  $ is
merely the restriction of this homomorphism $\pi\left[  \left[  T\right]
\right]  $ to the subset $\Lambda\left(  K\right)  $ of $K\left[  \left[
T\right]  \right]  $ (due to the definition of $\Lambda\left(  \pi\right)  $).

Notice that $1+I\left[  \left[  T\right]  \right]  ^{+}\subseteq1+K\left[
\left[  T\right]  \right]  ^{+}=\Lambda\left(  K\right)  $.

\textit{1st step:} We have $1+I\left[  \left[  T\right]  \right]
^{+}\subseteq\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)  $.

\textit{Proof:} Let $q\in1+I\left[  \left[  T\right]  \right]  ^{+}$. Then,
$q-1\in I\left[  \left[  T\right]  \right]  ^{+}=TI\left[  \left[  T\right]
\right]  \subseteq I\left[  \left[  T\right]  \right]  $. Thus, we can write
$q-1$ in the form $q-1=\sum\limits_{i\geq0}r_{i}T^{i}$ for some sequence
$\left(  r_{0},r_{1},r_{2},...\right)  $ of elements of $I$. Consider this
$\left(  r_{0},r_{1},r_{2},...\right)  $. Clearly, $r_{i}\in I$ for every
$i\geq0$. Thus, $\pi\left(  r_{i}\right)  =0$ for every $i\geq0$ (because
$\pi$ is the canonical projection $K\rightarrow K\diagup I$). Now, by the
definition of $\pi\left[  \left[  T\right]  \right]  $, we have%
\[
\left(  \pi\left[  \left[  T\right]  \right]  \right)  \left(  \sum
\limits_{i\geq0}r_{i}T^{i}\right)  =\sum\limits_{i\geq0}\underbrace{\pi\left(
r_{i}\right)  }_{=0}T^{i}=\sum\limits_{i\geq0}0T^{i}=0.
\]
Since $\sum\limits_{i\geq0}r_{i}T^{i}=q-1$, this rewrites as $\left(
\pi\left[  \left[  T\right]  \right]  \right)  \left(  q-1\right)  =0$. Since%
\[
\left(  \pi\left[  \left[  T\right]  \right]  \right)  \left(  q-1\right)
=\left(  \pi\left[  \left[  T\right]  \right]  \right)  \left(  q\right)
-1\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\pi\left[  \left[  T\right]
\right]  \text{ is a ring homomorphism}\right)  ,
\]
this rewrites as $\left(  \pi\left[  \left[  T\right]  \right]  \right)
\left(  q\right)  -1=0$. That is, $\left(  \pi\left[  \left[  T\right]
\right]  \right)  \left(  q\right)  =1$. Since $\Lambda\left(  \pi\right)  $
is the restriction of $\pi\left[  \left[  T\right]  \right]  $ to the subset
$\Lambda\left(  K\right)  $ of $K\left[  \left[  T\right]  \right]  $, and
since $q\in\Lambda\left(  K\right)  $, we have $\left(  \Lambda\left(
\pi\right)  \right)  \left(  q\right)  =\left(  \pi\left[  \left[  T\right]
\right]  \right)  \left(  q\right)  =1$, so that $q\in\operatorname*{Ker}%
\left(  \Lambda\left(  \pi\right)  \right)  $ (because the power series
$1\in\Lambda\left(  K\diagup I\right)  $ is the zero of the ring
$\Lambda\left(  K\diagup I\right)  $).

Now forget that we fixed $q$. We thus have proven that every $q\in1+I\left[
\left[  T\right]  \right]  ^{+}$ satisfies $q\in\operatorname*{Ker}\left(
\Lambda\left(  \pi\right)  \right)  $. In other words, $1+I\left[  \left[
T\right]  \right]  ^{+}\subseteq\operatorname*{Ker}\left(  \Lambda\left(
\pi\right)  \right)  $. This completes the proof of the 1st step.

\textit{2nd step:} We have $\operatorname*{Ker}\left(  \Lambda\left(
\pi\right)  \right)  \subseteq1+I\left[  \left[  T\right]  \right]  ^{+}$.

\textit{Proof:} Let $q\in\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)
\right)  $. Then, $q\in\Lambda\left(  K\right)  $ and $\left(  \Lambda\left(
\pi\right)  \right)  \left(  q\right)  =1$ (because $1\in\Lambda\left(
K\diagup I\right)  $ is the zero of the ring $\Lambda\left(  K\diagup
I\right)  $).

Since $q\in\Lambda\left(  K\right)  \subseteq K\left[  \left[  T\right]
\right]  $, we can write $q$ in the form $q=\sum\limits_{i\geq0}q_{i}T^{i}$
for some sequence $\left(  q_{0},q_{1},q_{2},...\right)  $ of elements of $K$.
Consider this $\left(  q_{0},q_{1},q_{2},...\right)  $. Then, $q_{0}$ is the
constant term of the power series $q$.

Since $q\in\Lambda\left(  K\right)  =1+K\left[  \left[  T\right]  \right]
^{+}=\left\{  p\in K\left[  \left[  T\right]  \right]  \ \mid\ p\text{ is a
power series with constant term }1\right\}  $, we know that $q$ is a power
series with constant term $1$. In other words, the constant term of the power
series $q$ is $1$. Since $q_{0}$ is the constant term of the power series $q$,
this yields that $q_{0}=1$.

Since $\Lambda\left(  \pi\right)  $ is the restriction of $\pi\left[  \left[
T\right]  \right]  $ to the subset $\Lambda\left(  K\right)  $ of $K\left[
\left[  T\right]  \right]  $, we have
\begin{align*}
\left(  \Lambda\left(  \pi\right)  \right)  \left(  q\right)   &  =\left(
\pi\left[  \left[  T\right]  \right]  \right)  \left(  q\right)  =\left(
\pi\left[  \left[  T\right]  \right]  \right)  \left(  \sum\limits_{i\geq
0}q_{i}T^{i}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }q=\sum
\limits_{i\geq0}q_{i}T^{i}\right) \\
&  =\sum\limits_{i\geq0}\pi\left(  q_{i}\right)  T^{i}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by the definition of }\pi\left[  \left[
T\right]  \right]  \right)  .
\end{align*}
Since $\left(  \Lambda\left(  \pi\right)  \right)  \left(  q\right)  =1$, this
rewrites as $1=\sum\limits_{i\geq0}\pi\left(  q_{i}\right)  T^{i}$.

Now, let $j$ be a positive integer. Then, the coefficient of $T^{j}$ on the
left hand side of the equality $1=\sum\limits_{i\geq0}\pi\left(  q_{i}\right)
T^{i}$ is $0$, while the coefficient of $T^{j}$ on the right hand side of this
equality is $\pi\left(  q_{j}\right)  $. Since the coefficients of $T^{j}$ on
the two sides of an equality must always be equal, this yields that
$0=\pi\left(  q_{j}\right)  $. But $\pi$ is the canonical projection
$K\rightarrow K\diagup I$. Hence, since we have $\pi\left(  q_{j}\right)  =0$,
we conclude that $q_{j}\in I$.

Now forget that we fixed $j$. We thus have shown that $q_{j}\in I$ for every
positive integer $j$. Thus, $\sum\limits_{j>0}q_{j}T^{j}\in I\left[  \left[
T\right]  \right]  $. Since $\sum\limits_{j>0}q_{j}T^{j}$ is a power series
with constant term $0$, we thus have%
\[
\sum\limits_{j>0}q_{j}T^{j}\in\left\{  p\in I\left[  \left[  T\right]
\right]  \ \mid\ p\text{ is a power series with constant term }0\right\}
=TI\left[  \left[  T\right]  \right]  =I\left[  \left[  T\right]  \right]
^{+}.
\]
Now,%
\[
q=\sum\limits_{i\geq0}q_{i}T^{i}=\underbrace{q_{0}}_{=1}\underbrace{T^{0}%
}_{=1}+\underbrace{\sum\limits_{i>0}q_{i}T^{i}}_{\in I\left[  \left[
T\right]  \right]  ^{+}}\in1+I\left[  \left[  T\right]  \right]  ^{+}.
\]


Now forget that we fixed $q$. We thus have proven that every $q\in
\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)  $ satisfies
$q\in1+I\left[  \left[  T\right]  \right]  ^{+}$. In other words,
$\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)  \subseteq
1+I\left[  \left[  T\right]  \right]  ^{+}$. This completes the proof of the
2nd step.

\textit{3rd step:} We have proven that $1+I\left[  \left[  T\right]  \right]
^{+}\subseteq\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)  $
and $\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)
\subseteq1+I\left[  \left[  T\right]  \right]  ^{+}$. Combining these two
relations, we obtain $1+I\left[  \left[  T\right]  \right]  ^{+}%
=\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)  $. This solves
Exercise 5.5 \textbf{(a)}.

\textbf{(b)} We know that $\Lambda\left(  \pi\right)  $ is a $\lambda$-ring
homomorphism (since $\pi$ is a ring homomorphism). Thus, $\operatorname*{Ker}%
\left(  \Lambda\left(  \pi\right)  \right)  $ is a $\lambda$-ideal of
$\Lambda\left(  K\right)  $ (by Theorem 2.3, applied to $\Lambda\left(
K\right)  $, $\Lambda\left(  K\diagup I\right)  $ and $\pi$ instead of
$\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $, $\left(
L,\left(  \mu^{i}\right)  _{i\in\mathbb{N}}\right)  $ and $f$). Since
$\operatorname*{Ker}\left(  \Lambda\left(  \pi\right)  \right)  =1+I\left[
\left[  T\right]  \right]  ^{+}$ (by Exercise 5.5 \textbf{(a)}), this yields
that $1+I\left[  \left[  T\right]  \right]  ^{+}$ is a $\lambda$-ideal of
$\Lambda\left(  K\right)  $. This solves Exercise 5.5 \textbf{(b)}.

\subsection{To Section 6}

\textit{Exercise 6.1: Hints to solution:} We have%
\[
\left(  1+K\left[  T\right]  ^{+}\right)  ^{-1}K\left[  T\right]  \cap
\Lambda\left(  K\right)  =\left(  1+K\left[  T\right]  ^{+}\right)
\widehat{-}\left(  1+K\left[  T\right]  ^{+}\right)  ,
\]
where $U\widehat{-}U$ denotes the set $\left\{  u\widehat{-}u^{\prime}\mid
u\in U,\ u^{\prime}\in U\right\}  $ for every subset $U$ of $\Lambda\left(
K\right)  $ (where $\widehat{-}$ means subtraction with respect to the
addition $\widehat{+}$ in $\Lambda\left(  K\right)  $). The subset $1+K\left[
T\right]  ^{+}$ of $\Lambda\left(  K\right)  $ is closed under the addition
$\widehat{+}$, the multiplication $\widehat{\cdot}$ and the maps
$\widehat{\lambda}^{i}$ (according to Theorem 5.3, since $1+K\left[  T\right]
^{+}=\Pi\left(  K^{\operatorname*{int}}\right)  $) and contains the zero $1$
and the unity $1+T$. Thus, by Exercise 2.2 (applied to $\Lambda\left(
K\right)  $ and $1+K\left[  T\right]  ^{+}$ instead of $K$ and $L$), the
conclusion follows.

\textit{Exercise 6.2: Solution:} \textbf{(a)} Consider the map $\lambda_{T}$
defined in Theorem 2.1. Fix some $x\in K$. Define a map $\Upsilon
:\mathbb{Z}\rightarrow K\left[  \left[  T\right]  \right]  $ by%
\[
\Upsilon\left(  n\right)  =\lambda_{T}\left(  nx\right)
\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{Z}\text{.}%
\]
This map $\Upsilon$ is a group homomorphism from the group $\left(
\mathbb{Z},+\right)  $ to the group $\left(  K\left[  \left[  T\right]
\right]  ^{\times},\cdot\right)  $ (because every two elements $n$ and $m$ of
$\mathbb{Z}$ satisfy
\begin{align*}
\Upsilon\left(  n\right)  \cdot\Upsilon\left(  m\right)   &  =\lambda
_{T}\left(  nx\right)  \cdot\lambda_{T}\left(  mx\right)  =\lambda_{T}\left(
nx+mx\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{according to the formula }\lambda_{T}\left(  x\right)  \cdot\lambda
_{T}\left(  y\right)  =\lambda_{T}\left(  x+y\right) \\
\text{given in Theorem 2.1 \textbf{(b)}}%
\end{array}
\right) \\
&  =\lambda_{T}\left(  \left(  n+m\right)  x\right)  =\Upsilon\left(
n+m\right)  ,
\end{align*}
and we have $\Upsilon\left(  0\right)  =\lambda_{T}\left(  0x\right)
=\lambda_{T}\left(  0\right)  =1$ by Theorem 2.1 \textbf{(b)}). Thus,
$\Upsilon\left(  n\cdot1\right)  =\left(  \Upsilon\left(  1\right)  \right)
^{n}$ for every $n\in\mathbb{Z}$. Since $\Upsilon\left(  n\cdot1\right)
=\Upsilon\left(  n\right)  =\lambda_{T}\left(  nx\right)  $ and $\Upsilon
\left(  1\right)  =\lambda_{T}\left(  1x\right)  =\lambda_{T}\left(  x\right)
$, this rewrites as $\lambda_{T}\left(  nx\right)  =\left(  \lambda_{T}\left(
x\right)  \right)  ^{n}$. Applying this to $x=1_{K}$, we obtain%
\begin{align*}
\lambda_{T}\left(  n\cdot1\right)   &  =\left(  \lambda_{T}\left(  1\right)
\right)  ^{n}=\left(  1+T\right)  ^{n}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\lambda_{T}\left(  1\right)
=1+T\text{, because the }\lambda\text{-ring }K\text{ is special}\right) \\
&  =\sum_{i=0}^{n}\dbinom{n}{i}T^{i}.
\end{align*}
Comparing this with $\lambda_{T}\left(  n\cdot1\right)  =\sum\limits_{i=0}%
^{n}\lambda^{i}\left(  n\cdot1\right)  T^{i}$, we conclude that $\lambda
^{i}\left(  n\cdot1\right)  =\dbinom{n}{i}\cdot1$ for every $i\in\mathbb{N}$.

\textbf{(b)} Assume, for the sake of contradiction, that $m=0$ in $K$ for some
positive integer $m$. Then, Theorem 2.1 \textbf{(a)} yields%
\begin{align*}
\lambda_{T}\left(  m\right)   &  =\lambda_{T}\left(  \underbrace{1+1+...+1}%
_{m\text{ times}}\right)  =\underbrace{\lambda_{T}\left(  1\right)
\cdot\lambda_{T}\left(  1\right)  \cdot...\cdot\lambda_{T}\left(  1\right)
}_{m\text{ times}}=\left(  \lambda_{T}\left(  1\right)  \right)  ^{m}\\
&  =\left(  \lambda_{T}\left(  1\right)  \right)  ^{m}=\left(  1+T\right)
^{m}=1+\sum_{i=1}^{m-1}\dbinom{m}{i}T^{i}+T^{m}\ \ \ \ \ \ \ \ \ \ \left(
\text{by the binomial formula}\right)
\end{align*}
in $K\left[  \left[  T\right]  \right]  $. On the other hand, $\lambda
_{T}\left(  m\right)  =\lambda_{T}\left(  0\right)  =1.$ Contradiction (unless
$K$ is the trivial ring).

\textit{Exercise 6.3: Hints to solution:} Use Exercise 6.4 or the very
definition of special $\lambda$-rings together with Exercise 2.1. Do not
forget to check that the map $\lambda_{T}$ is well-defined.

\textit{Exercise 6.4: Hints to solution:} Repeat the proof of Theorem 6.1,
replacing every appearance of "$x\in K$" by "$x\in E$" and every appearance of
"$y\in K$" by "$y\in E$". You need the fact that $\lambda_{T}$ is a $\lambda
$-ring homomorphism if and only if it satisfies the three conditions%
\begin{align*}
\lambda_{T}\left(  xy\right)   &  =\lambda_{T}\left(  x\right)  \widehat{\cdot
}\lambda_{T}\left(  y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }x\in
E\text{ and }y\in E,\\
\lambda_{T}\left(  1\right)   &  =1+T,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\lambda_{T}\left(  \lambda^{j}\left(  x\right)  \right)   &  =\widehat{\lambda
}^{j}\left(  \lambda_{T}\left(  x\right)  \right)
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\mathbb{N}\text{ and }x\in E.
\end{align*}
This is because the first two of these conditions, together with the
preassumptions that $E$ is a generating set of $K$ as a $\mathbb{Z}$-module
and that $\lambda_{T}$ is an additive group homomorphism, are equivalent to
claiming that $\lambda_{T}$ is a ring homomorphism; and the third condition
then makes $\lambda_{T}$ a $\lambda$-ring homomorphism (according to Exercise
2.1 \textbf{(b)}).

\textit{Exercise 6.5: Hints to solution:} First, the mapping
$\operatorname*{coeff}\nolimits_{i}:\Lambda\left(  K\right)  \rightarrow K$ is
continuous (with respect to the $\left(  T\right)  $-topology on
$\Lambda\left(  K\right)  $ and \textit{any arbitrary topology} on $K$), and
the operation $\widehat{\lambda}^{i}$ is continuous as well (by Theorem 5.5
\textbf{(d)}); besides, the subset $1+K\left[  T\right]  ^{+}$ of $1+K\left[
\left[  T\right]  \right]  ^{+}=\Lambda\left(  K\right)  $ is dense (by
Theorem 5.5 \textbf{(a)}). Hence, in order to prove that
$\operatorname*{coeff}\nolimits_{i}\left(  u\right)  =\operatorname*{coeff}%
\nolimits_{1}\left(  \widehat{\lambda}^{i}\left(  u\right)  \right)  $ for
every $u\in\Lambda\left(  K\right)  ,$ it is enough to verify that
$\operatorname*{coeff}\nolimits_{i}\left(  u\right)  =\operatorname*{coeff}%
\nolimits_{1}\left(  \widehat{\lambda}^{i}\left(  u\right)  \right)  $ for
every $u\in1+K\left[  T\right]  ^{+}$.\ \ \ \ \footnote{At this point, we are
slightly cheating: This argument works only if the topological space $K$ is
Hausdorff. Thus we are not completely free in choosing the topology on $K$.
However, there are still enough Hausdorff topologies on $K$ (for example, the
discrete topology) to choose from - the argument works if we take any of
them.} So let us assume that $u\in1+K\left[  T\right]  ^{+}$. Then, there
exist some $\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]
\right)  \in K^{\operatorname*{int}}$ such that $u=\Pi\left(  \widetilde{K}%
_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  .$ Consider this $\left(
\widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  $. Then,
\begin{align*}
u  &  =\Pi\left(  \widetilde{K},\left[  u_{1},u_{2},...,u_{m}\right]  \right)
=\prod_{i=1}^{m}\left(  1+u_{i}T\right)  =\sum_{i\in\mathbb{N}}\left(
\sum_{\substack{K\subseteq\left\{  1,2,...,m\right\}  ;\\\left\vert
K\right\vert =i}}\prod\limits_{k\in K}u_{k}\right)  \cdot T^{i}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Exercise 4.2 \textbf{(b)}, applied to
}A=\widetilde{K}\left[  \left[  T\right]  \right]  \text{, }\alpha_{i}%
=u_{i}\text{ and }t=T\right) \\
&  =\sum_{i\in\mathbb{N}}\left(  \sum_{K\in\mathcal{P}_{i}\left(  \left\{
1,2,...,m\right\}  \right)  }\prod\limits_{k\in K}u_{k}\right)  \cdot T^{i}%
\end{align*}
and therefore $\operatorname*{coeff}\nolimits_{i}u=\sum\limits_{K\in
\mathcal{P}_{i}\left(  \left\{  1,2,...,m\right\}  \right)  }\prod
\limits_{k\in K}u_{k}.$ On the other hand, Theorem 5.3 \textbf{(d)} yields%
\begin{align*}
\widehat{\lambda}^{i}\left(  u\right)   &  =\Pi\left(  \widetilde{K}%
_{u},\left[  \prod\limits_{k\in K}u_{k}\ \mid\ K\in\mathcal{P}_{i}\left(
\left\{  1,2,...,m\right\}  \right)  \right]  \right) \\
&  =\prod_{K\in\mathcal{P}_{i}\left(  \left\{  1,2,...,m\right\}  \right)
}\left(  1+\prod\limits_{k\in K}u_{k}T\right)  =1+\sum_{K\in\mathcal{P}%
_{i}\left(  \left\{  1,2,...,m\right\}  \right)  }\prod\limits_{k\in K}%
u_{k}\cdot T+\left(  \text{higher powers of }T\right)  ,
\end{align*}
so that%
\[
\operatorname*{coeff}\nolimits_{1}\left(  \widehat{\lambda}^{i}\left(
u\right)  \right)  =\sum_{K\in\mathcal{P}_{i}\left(  \left\{
1,2,...,m\right\}  \right)  }\prod\limits_{k\in K}u_{k}.
\]
Comparing with $\operatorname*{coeff}\nolimits_{i}u=\sum\limits_{K\in
\mathcal{P}_{i}\left(  \left\{  1,2,...,m\right\}  \right)  }\prod
\limits_{k\in K}u_{k},$ we get $\operatorname*{coeff}\nolimits_{i}\left(
u\right)  =\operatorname*{coeff}\nolimits_{1}\left(  \widehat{\lambda}%
^{i}\left(  u\right)  \right)  ,$ qed.

\textit{Exercise 6.6: Hints to solution:} Consider the maps $\widehat{\lambda
}^{i}:\Lambda\left(  K\right)  \rightarrow\Lambda\left(  K\right)  $ that we
have defined in Section 5. Theorem 5.1 \textbf{(b)} yields that $\left(
\Lambda\left(  K\right)  ,\left(  \widehat{\lambda}^{i}\right)  _{i\in
\mathbb{N}}\right)  $ is a $\lambda$-ring. Since $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a special $\lambda$-ring,
the map $\lambda_{T}:K\rightarrow\Lambda\left(  K\right)  $ defined in Theorem
5.6 is a $\lambda$-ring homomorphism. Also, we know that the ring homomorphism
$\varphi:K\rightarrow A$ induces a $\lambda$-ring homomorphism $\Lambda\left(
\varphi\right)  :\Lambda\left(  K\right)  \rightarrow\Lambda\left(  A\right)
$. Now, consider the composed $\lambda$-ring homomorphism $\Lambda\left(
\varphi\right)  \circ\lambda_{T}:K\rightarrow\Lambda\left(  A\right)  $.

\textit{1st Step:} We claim that $\operatorname*{coeff}\nolimits_{1}^{A}%
\circ\Lambda\left(  \varphi\right)  \circ\lambda_{T}=\varphi.$

\textit{Proof.} Define a mapping $\operatorname*{coeff}\nolimits_{i}%
:\Lambda\left(  K\right)  \rightarrow K$ for every $i\in\mathbb{N}$ as in
Exercise 6.5. Then, $\operatorname*{coeff}\nolimits_{1}^{A}\circ\Lambda\left(
\varphi\right)  =\varphi\circ\operatorname*{coeff}\nolimits_{1}$ (by the
definition of $\Lambda\left(  \varphi\right)  $) and $\operatorname*{coeff}%
\nolimits_{1}\circ\lambda_{T}=\operatorname*{id}_{K}$ (by Theorem 8.2). Thus,
$\underbrace{\operatorname*{coeff}\nolimits_{1}^{A}\circ\Lambda\left(
\varphi\right)  }_{=\varphi\circ\operatorname*{coeff}\nolimits_{1}}%
\circ\lambda_{T}=\varphi\circ\underbrace{\operatorname*{coeff}\nolimits_{1}%
\circ\lambda_{T}}_{=\operatorname*{id}_{K}}=\varphi,$ and the 1st Step is proven.

\textit{2nd Step:} We claim that if $\widetilde{\varphi}:K\rightarrow
\Lambda\left(  A\right)  $ is a $\lambda$-ring homomorphism such that
$\operatorname*{coeff}\nolimits_{1}^{A}\circ\widetilde{\varphi}=\varphi,$ then
$\widetilde{\varphi}=\Lambda\left(  \varphi\right)  \circ\lambda_{T}.$

\textit{Proof.} For every $i\in\mathbb{N},$ define a mapping
$\operatorname*{coeff}\nolimits_{i}^{A}:\Lambda\left(  A\right)  \rightarrow
A$ by $\operatorname*{coeff}\nolimits_{i}^{A}\left(  \sum\limits_{j\in
\mathbb{N}}a_{j}T^{j}\right)  =a_{i}$ for every $\sum\limits_{j\in\mathbb{N}%
}a_{j}T^{j}\in\Lambda\left(  A\right)  $ (with $a_{j}\in A$ for every
$j\in\mathbb{N}$). (In other words, $\operatorname*{coeff}\nolimits_{i}^{A}$
is the mapping that takes a power series and returns its coefficient before
$T^{i}.$) Then, Exercise 6.5 (applied to the ring $A$ instead of $K$) yields
$\operatorname*{coeff}\nolimits_{i}^{A}=\operatorname*{coeff}\nolimits_{1}%
^{A}\circ\widehat{\lambda}_{A}^{i}.$ Hence,%
\[
\operatorname*{coeff}\nolimits_{i}^{A}\circ\widetilde{\varphi}%
=\operatorname*{coeff}\nolimits_{1}^{A}\circ\underbrace{\widehat{\lambda}%
_{A}^{i}\circ\widetilde{\varphi}}_{\substack{=\widetilde{\varphi}\circ
\lambda^{i},\\\text{since }\widetilde{\varphi}\text{ is a}\\\lambda
\text{-ring}\\\text{homomorphism}}}=\underbrace{\operatorname*{coeff}%
\nolimits_{1}^{A}\circ\widetilde{\varphi}}_{=\varphi}\circ\lambda^{i}%
=\varphi\circ\lambda^{i}.
\]
But on the other hand,%
\[
\underbrace{\operatorname*{coeff}\nolimits_{i}^{A}\circ\Lambda\left(
\varphi\right)  }_{\substack{=\varphi\circ\operatorname*{coeff}\nolimits_{i}%
\text{ by the}\\\text{definition of }\Lambda\left(  \varphi\right)  }%
}\circ\lambda_{T}=\varphi\circ\underbrace{\operatorname*{coeff}\nolimits_{i}%
\circ\lambda_{T}}_{\substack{=\lambda^{i}\text{, by the}\\\text{definition of
}\lambda_{T}}}=\varphi\circ\lambda^{i}.
\]
Therefore, $\operatorname*{coeff}\nolimits_{i}^{A}\circ\widetilde{\varphi
}=\operatorname*{coeff}\nolimits_{i}^{A}\circ\Lambda\left(  \varphi\right)
\circ\lambda_{T}$ for every $i\in\mathbb{N}$. Thus, $\left(
\operatorname*{coeff}\nolimits_{i}^{A}\circ\widetilde{\varphi}\right)  \left(
u\right)  =\left(  \operatorname*{coeff}\nolimits_{i}^{A}\circ\Lambda\left(
\varphi\right)  \circ\lambda_{T}\right)  \left(  u\right)  $ for every
$i\in\mathbb{N}$ for every $u\in K$. In other words, for every $u\in K$ and
for every $i\in\mathbb{N}$, the power series $\widetilde{\varphi}\left(
u\right)  \in\Lambda\left(  A\right)  $ and $\left(  \Lambda\left(
\varphi\right)  \circ\lambda_{T}\right)  \left(  u\right)  $ have the same
coefficient before $T^{i}$. Since this holds for all $i\in\mathbb{N}$ at the
same time, this simply means that for every $u\in K$, the power series
$\widetilde{\varphi}\left(  u\right)  \in\Lambda\left(  A\right)  $ and
$\left(  \Lambda\left(  \varphi\right)  \circ\lambda_{T}\right)  \left(
u\right)  $ are equal. In other words, $\widetilde{\varphi}=\Lambda\left(
\varphi\right)  \circ\lambda_{T},$ and thus the 2nd Step is proven.

Together, the 1st and the 2nd Steps yield the assertion of Exercise 6.6 (in
fact, the 1st Step yields the existence of a $\lambda$-ring homomorphism
$\widetilde{\varphi}:K\rightarrow\Lambda\left(  A\right)  $ such that
$\operatorname*{coeff}\nolimits_{1}^{A}\circ\widetilde{\varphi}=\varphi,$
namely the homomorphism $\Lambda\left(  \varphi\right)  \circ\lambda_{T},$ and
the 2nd Step proves that this is the only such homomorphism).

\textit{Exercise 6.7:} \textit{Solution:} Let $t\in I$. Since $S$ generates
the ideal $I$, there exists some $r\in\mathbb{N}$, some elements $s_{1}$,
$s_{2}$, $...$, $s_{r}$ of $S$, and some elements $a_{1}$, $a_{2}$, $...$,
$a_{r}$ of $A$ such that $t=\sum\limits_{j=1}^{r}a_{j}s_{j}$. Consider this
$r$, these $s_{1}$, $s_{2}$, $...$, $s_{r}$ and these $a_{1}$, $a_{2}$, $...$,
$a_{r}$.

Consider the map $\lambda_{T}:K\rightarrow\Lambda\left(  K\right)  $ defined
in Theorem 5.6. Since $K$ is a special $\lambda$-ring, this map $\lambda_{T}$
is a $\lambda$-ring homomorphism. In particular, $\lambda_{T}$ is a ring homomorphism.

Consider the set $1+I\left[  \left[  T\right]  \right]  ^{+}$ defined in
Exercise 5.5. By Exercise 5.5 \textbf{(b)}, this set $1+I\left[  \left[
T\right]  \right]  ^{+}$ is a $\lambda$-ideal of $\Lambda\left(  K\right)  $,
thus also an ideal of $\Lambda\left(  K\right)  $.

Now, for every $j\in\left\{  1,2,...,r\right\}  $, we have $\lambda_{T}\left(
s_{j}\right)  \in1+I\left[  \left[  T\right]  \right]  ^{+}$%
.\ \ \ \ \footnote{\textit{Proof.} Let $j\in\left\{  1,2,...,r\right\}  $. By
the definition of $\lambda_{T}$, we have%
\[
\lambda_{T}\left(  s_{j}\right)  =\sum\limits_{i\in\mathbb{N}}\lambda
^{i}\left(  s_{j}\right)  T^{i}=\underbrace{\lambda^{0}\left(  s_{j}\right)
}_{\substack{=1\\\text{(since }\lambda^{0}\left(  x\right)  =1\\\text{for
every }x\in K\text{)}}}\underbrace{T^{0}}_{=1}+\sum\limits_{i>0}\lambda
^{i}\left(  s_{j}\right)  T^{i}=1+\sum\limits_{i>0}\lambda^{i}\left(
s_{j}\right)  T^{i}.
\]
\par
Now, we have assumed that every $s\in S$ and every positive integer $i$
satisfy $\lambda^{i}\left(  s\right)  \in I$. Applied to $s=s_{j}$, this
yields that every positive integer $i$ satisfies $\lambda^{i}\left(
s_{j}\right)  \in I$. Thus, $\sum\limits_{i>0}\lambda^{i}\left(  s_{j}\right)
T^{i}\in I\left[  \left[  T\right]  \right]  $. Since $\sum\limits_{i>0}%
\lambda^{i}\left(  s_{j}\right)  T^{i}$ is a power series with constant term
$0$, we thus have%
\[
\sum\limits_{i>0}\lambda^{i}\left(  s_{j}\right)  T^{i}\in\left\{  p\in
I\left[  \left[  T\right]  \right]  \ \mid\ p\text{ is a power series with
constant term }0\right\}  =TI\left[  \left[  T\right]  \right]  =I\left[
\left[  T\right]  \right]  ^{+}.
\]
Now, $\lambda_{T}\left(  s_{j}\right)  =1+\underbrace{\sum\limits_{i>0}%
\lambda^{i}\left(  s_{j}\right)  T^{i}}_{\in I\left[  \left[  T\right]
\right]  ^{+}}\in1+I\left[  \left[  T\right]  \right]  ^{+}$, qed.} But since
$t=\sum\limits_{j=1}^{r}a_{j}s_{j}$, we have%
\begin{align*}
\lambda_{T}\left(  t\right)   &  =\lambda_{T}\left(  \sum\limits_{j=1}%
^{r}a_{j}s_{j}\right)  =\widehat{\sum\limits_{j=1}^{r}}\lambda_{T}\left(
a_{j}\right)  \widehat{\cdot}\underbrace{\lambda_{T}\left(  s_{j}\right)
}_{\in1+I\left[  \left[  T\right]  \right]  ^{+}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\lambda_{T}:K\rightarrow
\Lambda\left(  K\right)  \text{ is a ring homomorphism}\right) \\
&  \in\widehat{\sum\limits_{j=1}^{r}}\lambda_{T}\left(  a_{j}\right)
\widehat{\cdot}\left(  1+I\left[  \left[  T\right]  \right]  ^{+}\right)
\subseteq1+I\left[  \left[  T\right]  \right]  ^{+}%
\end{align*}
(since $1+I\left[  \left[  T\right]  \right]  ^{+}$ is an ideal of
$\Lambda\left(  K\right)  $). In other words, $\lambda_{T}\left(  t\right)
-1\in I\left[  \left[  T\right]  \right]  ^{+}\subseteq I\left[  \left[
T\right]  \right]  $. Thus, $\lambda_{T}\left(  t\right)  -1$ is a power
series with all its coefficients lying in $I$.

By the definition of $\lambda_{T}$, we have $\lambda_{T}\left(  t\right)
=\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(  t\right)  T^{i}$. Thus,
$\left(  \text{the coefficient before }T^{i}\text{ in }\lambda_{T}\left(
t\right)  \right)  =\lambda^{i}\left(  t\right)  $ for every $i\in\mathbb{N}$.

Now, let $i$ be a positive integer. Then, $\left(  \text{the coefficient
before }T^{i}\text{ in }\lambda_{T}\left(  t\right)  -1\right)  \in I$
(because $\lambda_{T}\left(  t\right)  -1$ is a power series with all its
coefficients lying in $I$). In view of%
\begin{align*}
&  \left(  \text{the coefficient before }T^{i}\text{ in }\lambda_{T}\left(
t\right)  -1\right) \\
&  =\underbrace{\left(  \text{the coefficient before }T^{i}\text{ in }%
\lambda_{T}\left(  t\right)  \right)  }_{=\lambda^{i}\left(  t\right)
}-\underbrace{\left(  \text{the coefficient before }T^{i}\text{ in }1\right)
}_{\substack{=0\\\text{(since }i\text{ is positive)}}}=\lambda^{i}\left(
t\right)  ,
\end{align*}
this rewrites as $\lambda^{i}\left(  t\right)  \in I$.

Now, forget that we fixed $t$ and $i$. We thus have proven that every $t\in I$
and every positive integer $i$ satisfy $\lambda^{i}\left(  t\right)  \in I$.
But due to the definition of a $\lambda$-ideal, this means precisely that $I$
is a $\lambda$-ideal of $K$.

Thus, we have proven that $I$ is a $\lambda$-ideal of $K$. Exercise 6.7 is solved.

\subsection{To Section 7}

\textit{Exercise 7.1: Hints to solution:} See the more general Exercise 7.2.

\textit{Exercise 7.2: Hints to solution:} Repeat the argument used in the
proof of Theorem 7.3.

\subsection{To Section 8}

\textit{Exercise 8.1: Solution:}

\textit{First solution:} In order to prove this, we must verify that%
\begin{align}
\operatorname*{coeff}\nolimits_{1}\left(  1\right)   &  =0;\label{8.2.1}\\
\operatorname*{coeff}\nolimits_{1}\left(  u\widehat{+}v\right)   &
=\operatorname*{coeff}\nolimits_{1}u+\operatorname*{coeff}\nolimits_{1}%
v\ \ \ \ \ \ \ \ \ \ \text{for every }u\in\Lambda\left(  K\right)  \text{ and
}v\in\Lambda\left(  K\right)  ;\label{8.2.2}\\
\operatorname*{coeff}\nolimits_{1}\left(  1+T\right)   &  =1;\label{8.2.3}\\
\operatorname*{coeff}\nolimits_{1}\left(  u\widehat{\cdot}v\right)   &
=\operatorname*{coeff}\nolimits_{1}u\cdot\operatorname*{coeff}\nolimits_{1}%
v\ \ \ \ \ \ \ \ \ \ \text{for every }u\in\Lambda\left(  K\right)  \text{ and
}v\in\Lambda\left(  K\right)  . \label{8.2.4}%
\end{align}
The equations (\ref{8.2.1}) and (\ref{8.2.3}) are immediately obvious. In
order to verify the equations (\ref{8.2.2}) and (\ref{8.2.4}), we notice that
$\operatorname*{coeff}\nolimits_{1}:\Lambda\left(  K\right)  \rightarrow K$ is
a continuous mapping (with respect to the $\left(  T\right)  $-topology on
$\Lambda\left(  K\right)  $ and \textit{any arbitrary topology} on $K$) and
the operations $\widehat{+}$ and $\widehat{\cdot}$ are continuous as well (by
Theorem 5.5 \textbf{(d)}), and the subset $1+K\left[  T\right]  ^{+}$ of
$1+K\left[  \left[  T\right]  \right]  ^{+}=\Lambda\left(  K\right)  $ is
dense (by Theorem 5.5 \textbf{(a)}), so it suffices to verify the equations
(\ref{8.2.2}) and (\ref{8.2.4}) for $u\in1+K\left[  T\right]  ^{+}$ and
$v\in1+K\left[  T\right]  ^{+}$ only.\footnote{At this point, we are slightly
cheating: This argument works only if the topological space $K$ is Hausdorff.
Thus we are not completely free in choosing the topology on $K$. However,
there are still enough Hausdorff topologies on $K$ (for example, the discrete
topology) to choose from - the argument works if we take any of them.} So let
$u\in1+K\left[  T\right]  ^{+}$ and $v\in1+K\left[  T\right]  ^{+}$.

Then, there exist some $\left(  \widetilde{K}_{u},\left[  u_{1},u_{2}%
,...,u_{m}\right]  \right)  \in K^{\operatorname*{int}}$ such that
$u=\Pi\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)
,$ and some $\left(  \widetilde{K}_{v},\left[  v_{1},v_{2},...,v_{n}\right]
\right)  \in K^{\operatorname*{int}}$ such that $v=\Pi\left(  \widetilde{K}%
_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)  .$ Obviously,%
\[
u=\Pi\left(  \widetilde{K},\left[  u_{1},u_{2},...,u_{m}\right]  \right)
=\prod_{i=1}^{m}\left(  1+u_{i}T\right)  =1+\sum_{i=1}^{m}u_{i}\cdot T+\left(
\text{higher powers of }T\right)
\]
yields $\operatorname*{coeff}\nolimits_{1}u=\sum\limits_{i=1}^{m}u_{i}.$
Similarly, $\operatorname*{coeff}\nolimits_{1}v=\sum\limits_{j=1}^{n}v_{j}$.

By Theorem 5.3 \textbf{(a)}, there exists a finite-free extension ring
$\widetilde{K}_{u,v}$ of $K$ which contains both $\widetilde{K}_{u}$ and
$\widetilde{K}_{v}$ as subrings. Theorem 5.3 \textbf{(c)} yields%
\begin{align*}
u\widehat{\cdot}v  &  =\Pi\left(  \widetilde{K}_{u,v},\left[  u_{i}v_{j}%
\mid\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  \right]  \right)  =\prod_{\left(  i,j\right)  \in\left\{
1,2,...,m\right\}  \times\left\{  1,2,...,n\right\}  }\left(  1+u_{i}%
v_{j}T\right) \\
&  =1+\sum_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }u_{i}v_{j}\cdot T+\left(  \text{higher powers of
}T\right)  ,
\end{align*}
and thus%
\[
\operatorname*{coeff}\nolimits_{1}\left(  u\widehat{\cdot}v\right)
=\sum_{\left(  i,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  }u_{i}v_{j}=\sum_{i=1}^{m}\sum_{j=1}^{n}u_{i}v_{j}%
=\sum_{i=1}^{m}u_{i}\sum_{j=1}^{n}v_{j}=\operatorname*{coeff}\nolimits_{1}%
u\cdot\operatorname*{coeff}\nolimits_{1}v,
\]
so that (\ref{8.2.4}) is proven.

Besides,%
\begin{align*}
u\widehat{+}v  &  =uv=\Pi\left(  \widetilde{K}_{u},\left[  u_{1}%
,u_{2},...,u_{m}\right]  \right)  \cdot\Pi\left(  \widetilde{K}_{v},\left[
v_{1},v_{2},...,v_{n}\right]  \right) \\
&  =\prod_{i=1}^{m}\left(  1+u_{i}T\right)  \cdot\prod_{j=1}^{n}\left(
1+v_{j}T\right)  =1+\left(  \sum_{i=1}^{m}u_{i}+\sum_{j=1}^{n}v_{j}\right)
\cdot T+\left(  \text{higher powers of }T\right)  ,
\end{align*}
and consequently%
\[
\operatorname*{coeff}\nolimits_{1}\left(  u\widehat{+}v\right)  =\sum
_{i=1}^{m}u_{i}+\sum_{j=1}^{n}v_{j}=\operatorname*{coeff}\nolimits_{1}%
u+\operatorname*{coeff}\nolimits_{1}v,
\]
and (\ref{8.2.2}) is proven. Thus, $\operatorname*{coeff}\nolimits_{1}%
:\Lambda\left(  K\right)  \rightarrow K$ is a ring homomorphism, and Exercise
8.1 is solved.

\textit{Second solution (sketched):} In fact, (\ref{8.2.2}) is trivial using
$u\widehat{+}v=uv$, and (\ref{8.2.4}) follows from the definition of
$\widehat{\cdot}$ and the fact that $P_{1}\left(  a_{1},b_{1}\right)
=a_{1}\cdot b_{1}$.

\textit{Exercise 8.2: Hints to solution:} Let $y=x^{-1}$. We proceed as in the
proof of Theorem 8.3 \textbf{(b)}, except that we don't know that $\lambda
_{T}\left(  y\right)  =\Pi\left(  K,\left[  y\right]  \right)  $ and thus
cannot conclude anything from this. Instead, $xy=xx^{-1}=1$ yields%
\begin{align*}
\lambda_{T}\left(  xy\right)   &  =\lambda_{T}\left(  1\right)
=1+T\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\lambda_{T}:K\rightarrow\Lambda\left(  K\right)  \text{ is a ring
homomorphism,}\\
\text{and }1+T\text{ is the multiplicative unity of }\Lambda\left(  K\right)
\end{array}
\right) \\
&  =1+xyT=\Pi\left(  K,\left[  xy\right]  \right)  =\Pi\left(  K,\left[
x\right]  \right)  \widehat{\cdot}\Pi\left(  K,\left[  y\right]  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 5.3 \textbf{(c)}}\right) \\
&  =\lambda_{T}\left(  x\right)  \widehat{\cdot}\left(  1+yT\right)  .
\end{align*}
Together with $\lambda_{T}\left(  xy\right)  =\lambda_{T}\left(  x\right)
\widehat{\cdot}\lambda_{T}\left(  y\right)  $, this yields $\lambda_{T}\left(
x\right)  \widehat{\cdot}\lambda_{T}\left(  y\right)  =\lambda_{T}\left(
x\right)  \widehat{\cdot}\left(  1+yT\right)  $, so that $\lambda_{T}\left(
y\right)  =1+yT$ (since $\lambda_{T}\left(  x\right)  \in\Lambda\left(
K\right)  $ is invertible, because $x\in K$ is invertible and $\lambda
_{T}:K\rightarrow\Lambda\left(  K\right)  $ is a ring homomorphism), and
Theorem 8.3 \textbf{(a)} yields that $y$ is $1$-dimensional, qed.

\textit{Exercise 8.3: Hints to solution:} According to Exercise 6.4, we only
have to prove that (\ref{LkxyE}) and (\ref{LkLjxE}) hold. This is equivalent
to showing that%
\begin{align*}
\lambda_{T}\left(  xy\right)   &  =\lambda_{T}\left(  x\right)  \widehat{\cdot
}\lambda_{T}\left(  y\right)  \ \ \ \ \ \ \ \ \ \ \text{for every }x\in
E\text{ and }y\in E,\ \ \ \ \ \ \ \ \ \ \text{and}\\
\lambda_{T}\left(  \lambda^{j}\left(  x\right)  \right)   &  =\widehat{\lambda
}^{j}\left(  \lambda_{T}\left(  x\right)  \right)
\ \ \ \ \ \ \ \ \ \ \text{for every }j\in\mathbb{N}\text{ and }x\in E
\end{align*}
(because of the definitions of $\widehat{\cdot}$ and $\widehat{\lambda}^{j}$
and since two formal power series are equal if and only if their respective
coefficients are equal). But this is true, since%
\begin{align*}
\lambda_{T}\left(  xy\right)   &  =1+xyT\ \ \ \ \ \ \ \ \ \ \left(
\text{since }xy\text{ is }1\text{-dimensional by Theorem 8.3 \textbf{(b)}%
}\right) \\
&  =\Pi\left(  K,\left[  xy\right]  \right)  =\Pi\left(  K,\left[  x\right]
\right)  \widehat{\cdot}\Pi\left(  K,\left[  y\right]  \right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 5.3 \textbf{(c)}}\right) \\
&  =\left(  1+xT\right)  \cdot\left(  1+yT\right)  =\lambda_{T}\left(
x\right)  \widehat{\cdot}\lambda_{T}\left(  y\right)
\ \ \ \ \ \ \ \ \ \ \left(  \text{since }x\text{ and }y\text{ are
}1\text{-dimensional}\right)
\end{align*}
for every $x\in E$ and $y\in E,$ and%
\begin{align*}
&  \lambda_{T}\left(  \lambda^{j}\left(  x\right)  \right) \\
&  =\lambda_{T}\left(  \left\{
\begin{array}
[c]{c}%
1,\text{ if }j=0;\\
x,\text{ if }j=1;\\
0,\text{ if }j>1
\end{array}
\right.  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }x\text{ is
}1\text{-dimensional, so that }\lambda^{j}\left(  x\right)  =\left\{
\begin{array}
[c]{c}%
1,\text{ if }j=0;\\
x,\text{ if }j=1;\\
0,\text{ if }j>1
\end{array}
\right.  \right) \\
&  =\left\{
\begin{array}
[c]{c}%
\lambda_{T}\left(  1\right)  ,\text{ if }j=0;\\
\lambda_{T}\left(  x\right)  ,\text{ if }j=1;\\
\lambda_{T}\left(  0\right)  ,\text{ if }j>1
\end{array}
\right.  =\left\{
\begin{array}
[c]{c}%
1+T,\text{ if }j=0;\\
\lambda_{T}\left(  x\right)  ,\text{ if }j=1;\\
1,\text{ if }j>1
\end{array}
\right. \\
&  =\widehat{\lambda}^{j}\left(  \lambda_{T}\left(  x\right)  \right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{since }\lambda_{T}\left(  x\right)  \text{ is a }1\text{-dimensional
element of }\Lambda\left(  K\right)  \text{ by Theorem 8.3,}\\
\text{so that }\widehat{\lambda}^{j}\left(  \lambda_{T}\left(  x\right)
\right)  =\left\{
\begin{array}
[c]{c}%
1+T,\text{ if }j=0;\\
\lambda_{T}\left(  x\right)  ,\text{ if }j=1;\\
1,\text{ if }j>1
\end{array}
\right.
\end{array}
\right)
\end{align*}
for every $j\in\mathbb{N}$ and $x\in E.$

\subsection{To Section 9}

\textit{Exercise 9.1: Hints to solution:} As before, we use the $\widehat{\sum
}$ sign for summation inside the ring $\Lambda\left(  K\right)  $. We remember
that the addition inside the ring $\Lambda\left(  K\right)  $ was defined by
$u\widehat{+}v=uv$ for any $u\in\Lambda\left(  K\right)  $ and $v\in
\Lambda\left(  K\right)  $ (in other words, addition in $\Lambda\left(
K\right)  $ is the multiplication inherited from $K\left[  \left[  T\right]
\right]  $), so that $\widehat{\sum}=\prod.$ Now,
\[
u=\Pi\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)
=\prod_{i=1}^{m}\left(  1+u_{i}T\right)  =\widehat{\sum_{i=1}^{m}}\left(
1+u_{i}T\right)  .
\]
But since $1+u_{i}T$ is a $1$-dimensional element of $\Lambda\left(
\widetilde{K}_{u}\right)  $ for every $i\in\left\{  1,2,...,m\right\}  $ (by
Theorem 8.3 \textbf{(c)}), Theorem 9.4 (applied to $1+u_{i}T$ and
$\Lambda\left(  \widetilde{K}_{u}\right)  $ instead of $u_{i}$ and $K$) yields%
\[
\widehat{\psi}^{j}\left(  \widehat{\sum_{i=1}^{m}}\left(  1+u_{i}T\right)
\right)  =\widehat{\sum_{i=1}^{m}}\left(  1+u_{i}T\right)  ^{\widehat{j}},
\]
where $\left(  1+u_{i}T\right)  ^{\widehat{j}}$ means the $j$-th power of
$1+u_{i}T$ \textit{in the ring }$\Lambda\left(  \widetilde{K}_{u}\right)  $
(in other words, $\left(  1+u_{i}T\right)  ^{\widehat{j}}=\underbrace{\left(
1+u_{i}T\right)  \widehat{\cdot}\left(  1+u_{i}T\right)  \widehat{\cdot
}...\widehat{\cdot}\left(  1+u_{i}T\right)  }_{j\text{ times}},$ as opposed to
\newline$\left(  1+u_{i}T\right)  ^{j}=\underbrace{\left(  1+u_{i}T\right)
\cdot\left(  1+u_{i}T\right)  \cdot...\cdot\left(  1+u_{i}T\right)  }_{j\text{
times}}$ which is the $j$-th power of $1+u_{i}T$ \textit{in the ring
}$\widetilde{K}_{u}\left[  \left[  T\right]  \right]  $).

Hence,%
\begin{align*}
\widehat{\psi}^{j}\left(  u\right)   &  =\widehat{\psi}^{j}\left(
\widehat{\sum_{i=1}^{m}}\left(  1+u_{i}T\right)  \right)  =\widehat{\sum
_{i=1}^{m}}\left(  1+u_{i}T\right)  ^{\widehat{j}}=\widehat{\sum_{i=1}^{m}%
}\underbrace{\left(  \Pi\left(  \widetilde{K}_{u},\left[  u_{i}\right]
\right)  \right)  ^{\widehat{j}}}_{\substack{=\Pi\left(  \widetilde{K}%
_{u},\left[  u_{i}^{j}\right]  \right)  \text{ by}\\\text{Corollary 5.4
\textbf{(b)}}}}=\widehat{\sum_{i=1}^{m}}\Pi\left(  \widetilde{K}_{u},\left[
u_{i}^{j}\right]  \right) \\
&  =\Pi\left(  \widetilde{K}_{u},\left[  u_{1}^{j},u_{2}^{j},...,u_{m}%
^{j}\right]  \right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Corollary 5.4
\textbf{(a)}}\right)  .
\end{align*}


\textit{Exercise 9.2: Hints to solution:} \textbf{(a)} It is easy to see that
the map sends the zero $1$ of $\Lambda\left(  K\right)  $ to the zero $0$ of
$K$ and the multiplicative unity $1+T$ of $\Lambda\left(  K\right)  $ to the
multiplicative unity $1$ of $K$. So it only remains to prove that any two
power series $u\in\Lambda\left(  K\right)  $ and $v\in\Lambda\left(  K\right)
$ satisfy%
\begin{equation}
\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac
{d}{dT}\log\left(  u\widehat{+}v\right)  \right)  =\left(  -1\right)
^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log u\right)
+\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac
{d}{dT}\log v\right)  \label{9.2.plus}%
\end{equation}
and%
\begin{equation}
\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac
{d}{dT}\log\left(  u\widehat{\cdot}v\right)  \right)  =\left(  -1\right)
^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log u\right)
\cdot\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(
-T\dfrac{d}{dT}\log v\right)  . \label{9.2.times}%
\end{equation}
This needs to be verified for $u\in1+K\left[  T\right]  ^{+}$ and
$v\in1+K\left[  T\right]  ^{+}$ only (since the operations $\widehat{+}$ and
$\widehat{\cdot}$ and the mapping%
\begin{align*}
\Lambda\left(  K\right)   &  \rightarrow K,\\
u  &  \mapsto\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(
-T\dfrac{d}{dT}\log u\right)
\end{align*}
are continuous (where the topology on $K$ can be chosen arbitrarily), and
$1+K\left[  T\right]  ^{+}$ is a dense subset of $1+K\left[  \left[  T\right]
\right]  ^{+}=\Lambda\left(  K\right)  $)\ \ \ \ \footnote{At this point, we
are slightly cheating: This argument works only if the topological space $K$
is Hausdorff. Thus we are not completely free in choosing the topology on $K$.
However, there are still enough Hausdorff topologies on $K$ (for example, the
discrete topology) to choose from, and the argument works if we take any of
them.}. So let us assume that $u\in1+K\left[  T\right]  ^{+}$ and
$v\in1+K\left[  T\right]  ^{+}$. Then, there exists some $\left(
\widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)  \in
K^{\operatorname*{int}}$ such that $u=\Pi\left(  \widetilde{K}_{u},\left[
u_{1},u_{2},...,u_{m}\right]  \right)  $ and some $\left(  \widetilde{K}%
_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)  \in K^{\operatorname*{int}%
}$ such that $v=\Pi\left(  \widetilde{K}_{v},\left[  v_{1},v_{2}%
,...,v_{n}\right]  \right)  $. Then, Theorem 5.3 \textbf{(c)} yields that%
\[
u\widehat{\cdot}v=\Pi\left(  \widetilde{K}_{u,v},\left[  u_{\ell}v_{j}%
\mid\left(  \ell,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  \right]  \right)
\]
(here, we renamed the index $i$ as $\ell$ in Theorem 5.3 \textbf{(c)}, because
we are already using the label $i$ for a fixed element of $\mathbb{N}%
\setminus\left\{  0\right\}  $).

Now,%
\[
u=\Pi\left(  \widetilde{K}_{u},\left[  u_{1},u_{2},...,u_{m}\right]  \right)
=\prod_{k=1}^{m}\left(  1+u_{k}T\right)
\]
entails%
\begin{align*}
\dfrac{d}{dT}u  &  =\dfrac{d}{dT}\prod_{k=1}^{m}\left(  1+u_{k}T\right) \\
&  =\sum_{\tau=1}^{m}\underbrace{\prod_{k\in\left\{  1,2,...,m\right\}
\setminus\left\{  \tau\right\}  }\left(  1+u_{k}T\right)  }_{=\dfrac
{\prod\limits_{k=1}^{m}\left(  1+u_{k}T\right)  }{1+u_{\tau}T}}\cdot
\underbrace{\dfrac{d}{dT}\left(  1+u_{\tau}T\right)  }_{=u_{\tau}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the Leibniz rule}\right) \\
&  =\sum_{\tau=1}^{m}\left(  \underbrace{\prod\limits_{k=1}^{m}\left(
1+u_{k}T\right)  }_{=u}\right)  \cdot\dfrac{u_{\tau}}{1+u_{\tau}T}=u\sum
_{\tau=1}^{m}\dfrac{u_{\tau}}{1+u_{\tau}T}%
\end{align*}
and thus%
\begin{align*}
&  -T\dfrac{d}{dT}\log u\\
&  =-T\dfrac{\dfrac{d}{dT}u}{u}=-T\dfrac{u\sum\limits_{\tau=1}^{m}%
\dfrac{u_{\tau}}{1+u_{\tau}T}}{u}=-T\sum\limits_{\tau=1}^{m}\dfrac{u_{\tau}%
}{1+u_{\tau}T}=\sum\limits_{\tau=1}^{m}\left(  -u_{\tau}T\right)  \left(
1+u_{\tau}T\right)  ^{-1}\\
&  =\sum\limits_{\tau=1}^{m}\left(  -u_{\tau}T\right)  \sum_{\rho\in
\mathbb{N}}\left(  -1\right)  ^{\rho}\left(  u_{\tau}T\right)  ^{\rho}%
=\sum\limits_{\tau=1}^{m}\sum_{\rho\in\mathbb{N}}\left(  -1\right)  ^{\rho
+1}\left(  u_{\tau}T\right)  ^{\rho+1}=\sum\limits_{\tau=1}^{m}\sum
_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\left(  -1\right)  ^{i}\left(
u_{\tau}T\right)  ^{i}\\
&  =\sum\limits_{\tau=1}^{m}\sum_{i\in\mathbb{N}\setminus\left\{  0\right\}
}\left(  -1\right)  ^{i}u_{\tau}^{i}T^{i}=\sum_{i\in\mathbb{N}\setminus
\left\{  0\right\}  }\left(  -1\right)  ^{i}\sum\limits_{\tau=1}^{m}u_{\tau
}^{i}T^{i},
\end{align*}
so that $\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log
u\right)  =\left(  -1\right)  ^{i}\sum\limits_{\tau=1}^{m}u_{\tau}^{i}$
(because $i\in\mathbb{N}\setminus\left\{  0\right\}  $). In other words,
$\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac
{d}{dT}\log u\right)  =\sum\limits_{\tau=1}^{m}u_{\tau}^{i}$. Similarly,
$v=\Pi\left(  \widetilde{K}_{v},\left[  v_{1},v_{2},...,v_{n}\right]  \right)
$ yields $\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(
-T\dfrac{d}{dT}\log v\right)  =\sum\limits_{\sigma=1}^{n}v_{\sigma}^{i}$, and
$u\widehat{\cdot}v=\Pi\left(  \widetilde{K}_{u,v},\left[  u_{\ell}v_{j}%
\mid\left(  \ell,j\right)  \in\left\{  1,2,...,m\right\}  \times\left\{
1,2,...,n\right\}  \right]  \right)  $ yields $\left(  -1\right)
^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log\left(
u\widehat{\cdot}v\right)  \right)  =\sum\limits_{\tau=1}^{m}\sum
\limits_{\sigma=1}^{n}\left(  u_{\tau}v_{\sigma}\right)  ^{i}$. Thus,%
\begin{align*}
\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac
{d}{dT}\log\left(  u\widehat{\cdot}v\right)  \right)   &  =\sum\limits_{\tau
=1}^{m}\sum\limits_{\sigma=1}^{n}\left(  u_{\tau}v_{\sigma}\right)  ^{i}%
=\sum\limits_{\tau=1}^{m}\sum\limits_{\sigma=1}^{n}u_{\tau}^{i}v_{\sigma}%
^{i}\\
&  =\underbrace{\sum\limits_{\tau=1}^{m}u_{\tau}^{i}}_{=\left(  -1\right)
^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log u\right)
}\cdot\underbrace{\sum\limits_{\sigma=1}^{n}v_{\sigma}^{i}}_{=\left(
-1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log
v\right)  }\\
&  =\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(
-T\dfrac{d}{dT}\log u\right)  \cdot\left(  -1\right)  ^{i}%
\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log v\right)  ,
\end{align*}
and (\ref{9.2.times}) is thus proven. Similarly we can show (\ref{9.2.plus}).
This completes the proof.

\textbf{(b)} Using Exercise 9.2 \textbf{(a)}, we can easily prove the
following fact:

\textit{Assertion }$\mathcal{F}$\textit{:} If $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a special $\lambda$-ring, then,
for any $i\in\mathbb{N}\setminus\left\{  0\right\}  $, the $i$-th Adams
operation $\psi^{i}:K\rightarrow K$ is a ring homomorphism.

This assertion is a part of Theorem 9.3 \textbf{(b)}.

In order to prove Assertion $\mathcal{F}$ using Exercise 9.2 \textbf{(a)}, we
proceed as follows:

Every $x\in K$ satisfies%
\[
\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{i}\left(
x\right)  T^{i}=\widetilde{\psi}_{T}\left(  x\right)  =-T\dfrac{d}{dT}%
\log\lambda_{-T}\left(  x\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem
9.2 \textbf{(b)}}\right)  ,
\]
what (upon the substitution of $-T$ for $T$) becomes%
\[
\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{i}\left(
x\right)  \left(  -T\right)  ^{i}=-\left(  -T\right)  \dfrac{d}{d\left(
-T\right)  }\log\lambda_{-\left(  -T\right)  }\left(  x\right)  =-T\dfrac
{d}{dT}\log\lambda_{T}\left(  x\right)  ,
\]
what rewrites as $\sum\limits_{i\in\mathbb{N}\setminus\left\{  0\right\}
}\left(  -1\right)  ^{i}\psi^{i}\left(  x\right)  T^{i}=-T\dfrac{d}{dT}%
\log\lambda_{T}\left(  x\right)  $. Hence, for every $x\in K$ and
$i\in\mathbb{N}\setminus\left\{  0\right\}  $, we have $\left(  -1\right)
^{i}\psi^{i}\left(  x\right)  =\operatorname*{Coeff}\nolimits_{i}\left(
-T\dfrac{d}{dT}\log\lambda_{T}\left(  x\right)  \right)  $ and therefore
$\psi^{i}\left(  x\right)  =\left(  -1\right)  ^{i}\operatorname*{Coeff}%
\nolimits_{i}\left(  -T\dfrac{d}{dT}\log\lambda_{T}\left(  x\right)  \right)
$.

Now fix $i\in\mathbb{N}\setminus\left\{  0\right\}  $. We have shown that
every $x\in K$ satisfies $\psi^{i}\left(  x\right)  =\left(  -1\right)
^{i}\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log\lambda
_{T}\left(  x\right)  \right)  $. In other words, the map $\psi^{i}$ is the
composition of the map $\lambda_{T}:K\rightarrow\Lambda\left(  K\right)  $
(which is a ring homomorphism, since the $\lambda$-ring $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is special) with the map%
\begin{align*}
\Lambda\left(  K\right)   &  \rightarrow K,\\
u  &  \mapsto\left(  -1\right)  ^{i}\operatorname*{Coeff}\nolimits_{i}\left(
-T\dfrac{d}{dT}\log u\right)
\end{align*}
(which is a ring homomorphism according to Exercise 9.2 \textbf{(a)}). Thus,
$\psi^{i}$ is a ring homomorphism (since the composition of two ring
homomorphisms is a ring homomorphism). This proves Assertion $\mathcal{F}$.

\textit{Exercise 9.3: Hints to solution:} \textbf{(a)} We have solved Exercise
9.3 \textbf{(a)} in the 2nd step of the proof of Theorem 9.5 (with the only
difference that the index of summation that was called $i$ in Exercise 9.3
\textbf{(a)} was denoted by $j$ in the 2nd step of the proof of Theorem 9.5).

\begin{comment}
Here is an alternative solution of Exercise 9.3 \textbf{(a)} that makes of use
Theorem 9.5 \textbf{(b)}. Of course, this solution is pretty much useless as
long as our proof of Theorem 9.5 \textbf{(b)} includes a solution of Exercise
9.3 \textbf{(a)}, but if I should ever write up a different proof of Theorem
9.5 \textbf{(b)}, this solution might become useful once again.
But here is an alternative proof of Exercise 9.3 \textbf{(a)} using Theorem 9.5:
According to Theorem 9.5 \textbf{(b)}, we have $\widetilde{\psi}_{T}\left(
x\right)  =-T\cdot\dfrac{d}{dT}\log\lambda_{-T}\left(  x\right)
=-T\cdot\dfrac{\dfrac{d}{dT}\lambda_{-T}\left(  x\right)  }{\lambda
_{-T}\left(  x\right)  }$ for every $x\in K$, where the map $\widetilde{\psi
}_{T}:K\rightarrow K\left[  \left[  T\right]  \right]  $ is defined by
$\widetilde{\psi}_{T}\left(  x\right)  =\sum\limits_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}$ for every $x\in
K$. Here, $\lambda_{-T}\left(  x\right)  $ denotes $\operatorname*{ev}%
_{-T}\left(  \lambda_{T}\left(  x\right)  \right)  $. Therefore, if we denote
$\operatorname*{ev}_{-T}\left(  \widetilde{\psi}_{T}\left(  x\right)  \right)
$ by $\widetilde{\psi}_{-T}\left(  x\right)  ,$ then we have%
\begin{align*}
\widetilde{\psi}_{-T}\left(  x\right)   &  =\operatorname*{ev}\nolimits_{-T}%
\left(  \widetilde{\psi}_{T}\left(  x\right)  \right)  =\operatorname*{ev}%
\nolimits_{-T}\left(  -T\cdot\dfrac{\dfrac{d}{dT}\lambda_{-T}\left(  x\right)
}{\lambda_{-T}\left(  x\right)  }\right) \\
&  =-\left(  -T\right)  \cdot\dfrac{\dfrac{d}{d\left(  -T\right)  }%
\lambda_{-\left(  -T\right)  }\left(  x\right)  }{\lambda_{-\left(  -T\right)
}\left(  x\right)  }=-T\cdot\dfrac{\dfrac{d}{dT}\lambda_{T}\left(  x\right)
}{\lambda_{T}\left(  x\right)  }.
\end{align*}
Thus,%
\begin{equation}
\lambda_{T}\left(  x\right)  \cdot\widetilde{\psi}_{-T}\left(  x\right)
=-T\cdot\dfrac{d}{dT}\lambda_{T}\left(  x\right)  . \label{9.ex3.s1}%
\end{equation}
Now, $\widetilde{\psi}_{T}\left(  x\right)  =\sum\limits_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}$ yields
$\widetilde{\psi}_{-T}\left(  x\right)  =\sum\limits_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  \left(  -T\right)
^{j}=\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\left(
-1\right)  ^{j}\psi^{j}\left(  x\right)  T^{j}.$ Together with $\lambda
_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}}\lambda^{i}\left(
x\right)  T^{i}$, this yields%
\[
\lambda_{T}\left(  x\right)  \cdot\widetilde{\psi}_{-T}\left(  x\right)
=\sum_{n\in\mathbb{N}}\sum_{j=1}^{n}\left(  -1\right)  ^{j}\psi^{j}\left(
x\right)  \lambda^{n-j}\left(  x\right)  T^{n}.
\]
On the other hand, $\lambda_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}%
}\lambda^{i}\left(  x\right)  T^{i}=\sum\limits_{n\in\mathbb{N}}\lambda
^{n}\left(  x\right)  T^{n}$ yields $\dfrac{d}{dT}\lambda_{T}\left(  x\right)
=\sum\limits_{n\in\mathbb{N}}n\lambda^{n}\left(  x\right)  T^{n-1}$ and thus
$-T\cdot\dfrac{d}{dT}\lambda_{T}\left(  x\right)  =-\sum\limits_{n\in
\mathbb{N}}n\lambda^{n}\left(  x\right)  T^{n}$. Hence, (\ref{9.ex3.s1})
becomes%
\[
\sum_{n\in\mathbb{N}}\sum_{j=1}^{n}\left(  -1\right)  ^{j}\psi^{j}\left(
x\right)  \lambda^{n-j}\left(  x\right)  T^{n}=-\sum\limits_{n\in\mathbb{N}%
}n\lambda^{n}\left(  x\right)  T^{n}.
\]
Thus, for every $n\in\mathbb{N}$, we have%
\[
\sum_{j=1}^{n}\left(  -1\right)  ^{j}\psi^{j}\left(  x\right)  \lambda
^{n-j}\left(  x\right)  =-n\lambda^{n}\left(  x\right)  .
\]
Dividing this by $-1,$ this becomes%
\[
\sum_{j=1}^{n}\left(  -1\right)  ^{j-1}\psi^{j}\left(  x\right)  \lambda
^{n-j}\left(  x\right)  =n\lambda^{n}\left(  x\right)  ,
\]
which rewrites as%
\[
n\lambda^{n}\left(  x\right)  =\sum_{j=1}^{n}\left(  -1\right)  ^{j-1}\psi
^{j}\left(  x\right)  \lambda^{n-j}\left(  x\right)  =\sum_{i=1}^{n}\left(
-1\right)  ^{i-1}\psi^{i}\left(  x\right)  \lambda^{n-i}\left(  x\right)  ,
\]
which is exactly what Exercise 9.3 \textbf{(a)} claimed.
\end{comment}


\textbf{(b)} We will prove the equation $n!\lambda^{n}\left(  x\right)  =\det
A_{n}$ by induction over $n$.

The base case, $n=0$, is trivial (for $0!=1,$ $\lambda^{0}\left(  x\right)
=1$, and the determinant of a $0\times0$ matrix is $1$ by definition). If you
do not believe in $0\times0$ matrices, the $n=1$ case is trivial as well
(since $\lambda^{1}\left(  x\right)  =x$ and $\psi^{1}\left(  x\right)  =x$ by
Theorem 9.3 \textbf{(a)}\footnote{Here we are using the fact that Theorem 9.3
\textbf{(a)} holds for every $\lambda$-ring $\left(  K,\left(  \lambda
^{i}\right)  _{i\in\mathbb{N}}\right)  $ (not only for special ones). This is
very easy to see (but not really necessary because, as I said, we can just as
well take $n=0$ for the base case).}) and can equally serve as a base case.
The interesting part is the induction step.

For this step, we develop the determinant of the matrix $A_{n}$ along the
$n$-th row. We obtain%
\begin{equation}
\det A_{n}=\sum_{k=1}^{n}\left(  -1\right)  ^{n-k}\psi^{n-k+1}\left(
x\right)  \cdot\det\left(  A_{n}\left[  \dfrac{\sim k}{\sim n}\right]
\right)  , \label{9.ex3.s2}%
\end{equation}
where $A_{n}\left[  \dfrac{\sim k}{\sim n}\right]  $ is the matrix obtained
from $A_{n}$ by removing the $n$-th row and the $k$-th column.

Now, the matrix $A_{n}\left[  \dfrac{\sim k}{\sim n}\right]  $ turns out to be
a block-triangular matrix\footnote{Here, when I say "block-triangular matrix",
I always mean a block-triangular matrix whose diagonal blocks are square
matrices.}, with the left upper block (of size $\left(  k-1\right)
\times\left(  k-1\right)  $) being equal to $A_{k-1}$ and the right lower
block (of size $\left(  n-k\right)  \times\left(  n-k\right)  $) being a lower
triangular matrix with the numbers $k,$ $k+1,$ $...,$ $n-1$ on its diagonal.
Hence, $\det\left(  A_{n}\left[  \dfrac{\sim k}{\sim n}\right]  \right)  =\det
A_{k-1}\cdot\left(  k\left(  k+1\right)  ...\left(  n-1\right)  \right)  $
(since the determinant of any block-triangular matrix is known to equal the
product of the determinant of its diagonal blocks). Since we are proceeding by
induction over $n$, we can take $\det A_{k-1}=\left(  k-1\right)
!\lambda^{k-1}\left(  x\right)  $ for granted (since $k-1<n$), and thus obtain%
\begin{align*}
\det\left(  A_{n}\left[  \dfrac{\sim k}{\sim n}\right]  \right)   &  =\det
A_{k-1}\cdot\left(  k\left(  k+1\right)  ...\left(  n-1\right)  \right)
=\left(  k-1\right)  !\lambda^{k-1}\left(  x\right)  \cdot\left(  k\left(
k+1\right)  ...\left(  n-1\right)  \right) \\
&  =\underbrace{\left(  k-1\right)  !\cdot\left(  k\left(  k+1\right)
...\left(  n-1\right)  \right)  }_{=\left(  n-1\right)  !}\cdot\lambda
^{k-1}\left(  x\right)  =\left(  n-1\right)  !\cdot\lambda^{k-1}\left(
x\right)  .
\end{align*}


Thus, (\ref{9.ex3.s2}) becomes%
\begin{align*}
\det A_{n}  &  =\sum_{k=1}^{n}\left(  -1\right)  ^{n-k}\psi^{n-k+1}\left(
x\right)  \cdot\left(  n-1\right)  !\cdot\lambda^{k-1}\left(  x\right) \\
&  =\left(  n-1\right)  !\cdot\sum_{k=1}^{n}\left(  -1\right)  ^{n-k}%
\psi^{n-k+1}\left(  x\right)  \lambda^{k-1}\left(  x\right) \\
&  =\left(  n-1\right)  !\cdot\underbrace{\sum_{i=1}^{n}\left(  -1\right)
^{i-1}\psi^{i}\left(  x\right)  \lambda^{n-i}\left(  x\right)  }%
_{=n\lambda^{n}\left(  x\right)  \text{ by \textbf{(a)}}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here we substituted }i\text{ for
}n-k+1\text{ in the sum}\right) \\
&  =\underbrace{\left(  n-1\right)  !\cdot n}_{=n!}\lambda^{n}\left(
x\right)  =n!\lambda^{n}\left(  x\right)  ,
\end{align*}
completing the induction step, qed.

\textbf{(c)} The proof (by induction over $n$) is similar to that of part
\textbf{(b)}, but this time the induction step leads us through%
\begin{align*}
\det B_{n}  &  =\sum_{k=1}^{n}\left(  -1\right)  ^{n-k}\left\{
\begin{array}
[c]{c}%
\lambda^{n-k+1}\left(  x\right)  ,\text{ if }k>1;\\
n\lambda^{n}\left(  x\right)  ,\text{ if }k=1
\end{array}
\right.  \cdot\psi^{k-1}\left(  x\right) \\
&  =\sum_{i=0}^{n-1}\left(  -1\right)  ^{n-i-1}\left\{
\begin{array}
[c]{c}%
\lambda^{n-i}\left(  x\right)  ,\text{ if }i>0;\\
n\lambda^{n}\left(  x\right)  ,\text{ if }i=0
\end{array}
\right.  \cdot\psi^{i}\left(  x\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here we substituted }i\text{ for
}k-1\text{ in the sum}\right) \\
&  =\underbrace{\left(  -1\right)  ^{n-1}}_{=-\left(  -1\right)  ^{n}}%
n\lambda^{n}\left(  x\right)  \underbrace{\psi^{0}\left(  x\right)
}_{\substack{\text{we defined this}\\\text{to mean }1}}+\sum_{i=1}%
^{n-1}\underbrace{\left(  -1\right)  ^{n-i-1}}_{=\left(  -1\right)
^{n}\left(  -1\right)  ^{i-1}}\lambda^{n-i}\left(  x\right)  \psi^{i}\left(
x\right) \\
&  =-\left(  -1\right)  ^{n}n\lambda^{n}\left(  x\right)  +\sum_{i=1}%
^{n-1}\left(  -1\right)  ^{n}\left(  -1\right)  ^{i-1}\lambda^{n-i}\left(
x\right)  \psi^{i}\left(  x\right) \\
&  =\left(  -1\right)  ^{n}\left(  -n\lambda^{n}\left(  x\right)  +\sum
_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\lambda^{n-i}\left(  x\right)  \psi
^{i}\left(  x\right)  \right) \\
&  =\left(  -1\right)  ^{n}\underbrace{\left(  -\sum_{i=1}^{n}\left(
-1\right)  ^{i-1}\lambda^{n-i}\left(  x\right)  \psi^{i}\left(  x\right)
+\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\lambda^{n-i}\left(  x\right)
\psi^{i}\left(  x\right)  \right)  }_{=-\left(  -1\right)  ^{n-1}\lambda
^{n-n}\left(  x\right)  \psi^{n}\left(  x\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by part \textbf{(a)}}\right) \\
&  =\left(  -1\right)  ^{n}\left(  -\left(  -1\right)  ^{n-1}\lambda
^{n-n}\left(  x\right)  \psi^{n}\left(  x\right)  \right)
=\underbrace{\lambda^{n-n}\left(  x\right)  }_{=\lambda^{0}\left(  x\right)
=1}\psi^{n}\left(  x\right)  =\psi^{n}\left(  x\right)  ,
\end{align*}
what completes the proof.

\textit{Exercise 9.4: Hints to solution:} There are several ways to prove
this. Here is one:

We are going to prove that $\psi^{n}=\operatorname*{id}$ for all
$n\in\mathbb{N}\setminus\left\{  0\right\}  $. We will do this by strong
induction over $n$. Since a strong induction does not need an induction base,
let us start with the induction step:

Let $n\in\mathbb{N}\setminus\left\{  0\right\}  $. Assume (as the induction
hypothesis) that we have already proven $\psi^{i}=\operatorname*{id}$ for all
$i\in\mathbb{N}\setminus\left\{  0\right\}  $ satisfying $i<n$. We now must
prove that $\psi^{n}=\operatorname*{id}$.

Let $x\in K$. Exercise 9.3 \textbf{(a)} yields%
\[
n\lambda^{n}\left(  x\right)  =\sum_{i=1}^{n}\left(  -1\right)  ^{i-1}%
\lambda^{n-i}\left(  x\right)  \psi^{i}\left(  x\right)  .
\]
Since $\lambda^{n}\left(  x\right)  =\dbinom{x}{n}$ (since $\left(  K,\left(
\lambda^{i}\right)  _{i\in\mathbb{N}}\right)  $ is a binomial $\lambda$-ring)
and $\lambda^{n-i}\left(  x\right)  =\dbinom{x}{n-i}$ for every $i\in\left\{
1,2,...,n\right\}  $ (for the very same reason), this rewrites as%
\begin{align*}
n\dbinom{x}{n}  &  =\sum_{i=1}^{n}\left(  -1\right)  ^{i-1}\dbinom{x}{n-i}%
\psi^{i}\left(  x\right) \\
&  =\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x}{n-i}\underbrace{\psi
^{i}}_{\substack{=\operatorname*{id}\\\text{(since }i<n\text{)}}}\left(
x\right)  +\left(  -1\right)  ^{n-1}\underbrace{\dbinom{n}{n-n}}_{=\dbinom
{n}{0}=1}\psi^{n}\left(  x\right) \\
&  =\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x}{n-i}%
\underbrace{\operatorname*{id}\left(  x\right)  }_{=x}+\left(  -1\right)
^{n-1}\psi^{n}\left(  x\right) \\
&  =\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x}{n-i}x+\left(
-1\right)  ^{n-1}\psi^{n}\left(  x\right)  .
\end{align*}
Since%
\begin{align*}
&  \sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x}{n-i}\\
&  =\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\left(  \dbinom{x-1}{n-i}%
+\dbinom{x-1}{n-i-1}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{because }\dbinom{x}{n-i}=\dbinom{x-1}{n-i}+\dbinom{x-1}{n-i-1}\\
\text{by the recurrence equation of the binomial coefficients}%
\end{array}
\right) \\
&  =\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x-1}{n-i}+\sum
_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x-1}{n-i-1}\\
&  =\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x-1}{n-i}+\sum_{i=2}%
^{n}\underbrace{\left(  -1\right)  ^{\left(  i-1\right)  -1}}_{=-\left(
-1\right)  ^{i-1}}\underbrace{\dbinom{x-1}{n-\left(  i-1\right)  -1}%
}_{=\dbinom{x-1}{n-i}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{here, we substituted }i-1\text{ for
}i\text{ in the second sum}\right) \\
&  =\underbrace{\sum_{i=1}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x-1}{n-i}%
}_{=\left(  -1\right)  ^{1-1}\dbinom{x-1}{n-1}+\sum\limits_{i=2}^{n-1}\left(
-1\right)  ^{i-1}\dbinom{x-1}{n-i}}+\underbrace{\sum_{i=2}^{n}\left(  -\left(
-1\right)  ^{i-1}\right)  \dbinom{x-1}{n-i}}_{=\sum\limits_{i=2}^{n-1}\left(
-\left(  -1\right)  ^{i-1}\right)  \dbinom{x-1}{n-i}+\left(  -\left(
-1\right)  ^{n-1}\right)  \dbinom{x-1}{n-n}}\\
&  =\underbrace{\left(  -1\right)  ^{1-1}}_{=1}\dbinom{x-1}{n-1}%
+\underbrace{\sum\limits_{i=2}^{n-1}\left(  -1\right)  ^{i-1}\dbinom{x-1}%
{n-i}+\sum\limits_{i=2}^{n-1}\left(  -\left(  -1\right)  ^{i-1}\right)
\dbinom{x-1}{n-i}}_{=\sum\limits_{i=2}^{n-1}\left(  -1\right)  ^{i-1}%
\dbinom{x-1}{n-i}-\sum\limits_{i=2}^{n-1}\left(  -1\right)  ^{i-1}\dbinom
{x-1}{n-i}=0}+\left(  -\left(  -1\right)  ^{n-1}\right)  \underbrace{\dbinom
{x-1}{n-n}}_{=\dbinom{x-1}{0}=1}\\
&  =1\dbinom{x-1}{n-1}+0+\left(  -\left(  -1\right)  ^{n-1}\right)
1=\dbinom{x-1}{n-1}-\left(  -1\right)  ^{n-1},
\end{align*}
this becomes%
\begin{align*}
n\dbinom{x}{n}  &  =\left(  \dbinom{x-1}{n-1}-\left(  -1\right)
^{n-1}\right)  x+\left(  -1\right)  ^{n-1}\psi^{n}\left(  x\right) \\
&  =\dbinom{x-1}{n-1}x-\left(  -1\right)  ^{n-1}x+\left(  -1\right)
^{n-1}\psi^{n}\left(  x\right)  .
\end{align*}
Since%
\begin{align*}
\dbinom{x-1}{n-1}x  &  =\dfrac{\left(  x-1\right)  \cdot\left(  x-2\right)
\cdot...\cdot\left(  \left(  x-1\right)  -\left(  n-1\right)  +1\right)
}{\left(  n-1\right)  !}x\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{because }\dbinom{x-1}{n-1}=\dfrac{\left(
x-1\right)  \cdot\left(  x-2\right)  \cdot...\cdot\left(  \left(  x-1\right)
-\left(  n-1\right)  +1\right)  }{\left(  n-1\right)  !}\right) \\
&  =\dfrac{\left(  x-1\right)  \cdot\left(  x-2\right)  \cdot...\cdot\left(
x-n+1\right)  }{\left(  n-1\right)  !}x=\dfrac{x\cdot\left(  \left(
x-1\right)  \cdot\left(  x-2\right)  \cdot...\cdot\left(  x-n+1\right)
\right)  }{\left(  n-1\right)  !}\\
&  =\dfrac{x\cdot\left(  x-1\right)  \cdot...\cdot\left(  x-n+1\right)
}{\left(  n-1\right)  !}=\dfrac{x\cdot\left(  x-1\right)  \cdot...\cdot\left(
x-n+1\right)  }{n!\diagup n}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\left(
n-1\right)  !=n!\diagup n\right) \\
&  =n\underbrace{\dfrac{x\cdot\left(  x-1\right)  \cdot...\cdot\left(
x-n+1\right)  }{n!}}_{=\dbinom{x}{n}}=n\dbinom{x}{n},
\end{align*}
this transforms into%
\[
n\dbinom{x}{n}=n\dbinom{x}{n}-\left(  -1\right)  ^{n-1}x+\left(  -1\right)
^{n-1}\psi^{n}\left(  x\right)  .
\]
This simplifies to $\left(  -1\right)  ^{n-1}x=\left(  -1\right)  ^{n-1}%
\psi^{n}\left(  x\right)  $. In other words, $\psi^{n}\left(  x\right)  =x$.
Since this holds for every $x\in K$, this shows that $\psi^{n}%
=\operatorname*{id}$. This completes the induction step. Thus, $\psi
^{n}=\operatorname*{id}$ for every $n\in\mathbb{N}\setminus\left\{  0\right\}
$, and Exercise 9.4 is solved.

\textit{Exercise 9.5: Solution:} \textit{1st step:} Any two power series
$u\in1+K\left[  \left[  T\right]  \right]  ^{+}$ and $v\in1+K\left[  \left[
T\right]  \right]  ^{+}$ satisfy%
\begin{equation}
-T\dfrac{d}{dT}\log\left(  uv\right)  =\left(  -T\dfrac{d}{dT}\log u\right)
+\left(  -T\dfrac{d}{dT}\log v\right)  . \label{9.ex5.s1}%
\end{equation}


\textit{First proof of (\ref{9.ex5.s1}).} Let $u\in1+K\left[  \left[
T\right]  \right]  ^{+}$ and $v\in1+K\left[  \left[  T\right]  \right]  ^{+}$.
Let us work with the notations of Exercise 9.2. For every $i\in\mathbb{N}%
\setminus\left\{  0\right\}  $, we have
\begin{align*}
\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log\left(
uv\right)  \right)   &  =\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac
{d}{dT}\log\left(  u\widehat{+}v\right)  \right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }uv=u\widehat{+}v\right) \\
&  =\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log u\right)
+\operatorname*{Coeff}\nolimits_{i}\left(  -T\dfrac{d}{dT}\log v\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{9.2.plus}), divided by }\left(
-1\right)  ^{i}\right) \\
&  =\operatorname*{Coeff}\nolimits_{i}\left(  \left(  -T\dfrac{d}{dT}\log
u\right)  +\left(  -T\dfrac{d}{dT}\log v\right)  \right)  .
\end{align*}
In other words, the coefficients of the power series $-T\dfrac{d}{dT}%
\log\left(  uv\right)  $ before $T^{1}$, $T^{2}$, $T^{3}$, $...$ are equal to
the respective coefficients of the power series $\left(  -T\dfrac{d}{dT}\log
u\right)  +\left(  -T\dfrac{d}{dT}\log v\right)  $. Since the same holds for
the coefficients before $T^{0}$ (in fact, both power series $-T\dfrac{d}%
{dT}\log\left(  uv\right)  $ and $\left(  -T\dfrac{d}{dT}\log u\right)
+\left(  -T\dfrac{d}{dT}\log v\right)  $ are divisible by $T$ and thus have
the coefficient $0$ before $T^{0}$), this yields that the power series
$-T\dfrac{d}{dT}\log\left(  uv\right)  $ and $\left(  -T\dfrac{d}{dT}\log
u\right)  +\left(  -T\dfrac{d}{dT}\log v\right)  $ are identic. Thus,
(\ref{9.ex5.s1}) is proven.

\textit{Second proof of (\ref{9.ex5.s1}).} Let $u\in1+K\left[  \left[
T\right]  \right]  ^{+}$ and $v\in1+K\left[  \left[  T\right]  \right]  ^{+}$.
We have%
\begin{align*}
-T\underbrace{\dfrac{d}{dT}\log\left(  uv\right)  }_{=\dfrac{\dfrac{d}%
{dT}\left(  uv\right)  }{uv}}  &  =-T\dfrac{\dfrac{d}{dT}\left(  uv\right)
}{uv}=-T\underbrace{\dfrac{\left(  \dfrac{d}{dT}u\right)  v+u\left(  \dfrac
{d}{dT}v\right)  }{uv}}_{=\dfrac{\dfrac{d}{dT}u}{u}+\dfrac{\dfrac{d}{dT}v}{v}%
}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\dfrac{d}{dT}\left(  uv\right)
=\left(  \dfrac{d}{dT}u\right)  v+u\left(  \dfrac{d}{dT}v\right)  \text{ by
the Leibniz identity}\right) \\
&  =-T\left(  \underbrace{\dfrac{\dfrac{d}{dT}u}{u}}_{=\dfrac{d}{dT}\log
u}+\underbrace{\dfrac{\dfrac{d}{dT}v}{v}}_{=\dfrac{d}{dT}\log v}\right)
=-T\left(  \dfrac{d}{dT}\log u+\dfrac{d}{dT}\log v\right) \\
&  =\left(  -T\dfrac{d}{dT}\log u\right)  +\left(  -T\dfrac{d}{dT}\log
v\right)  .
\end{align*}
This proves (\ref{9.ex5.s1}).

\textit{2nd step:} For every $x\in K$ and $y\in K$, we have $\widetilde{\psi
}_{T}\left(  x+y\right)  =\widetilde{\psi}_{T}\left(  x\right)
+\widetilde{\psi}_{T}\left(  y\right)  $, where the map $\widetilde{\psi}_{T}$
is defined as in Theorem 9.5.

\textit{Proof.} Let $x\in K$ and $y\in K$. By Theorem 9.5 \textbf{(b)}, we
have $\widetilde{\psi}_{T}\left(  x\right)  =-T\cdot\dfrac{d}{dT}\log
\lambda_{-T}\left(  x\right)  $. By Theorem 9.5 \textbf{(b)} (applied to $y$
instead of $x$), we have $\widetilde{\psi}_{T}\left(  y\right)  =-T\cdot
\dfrac{d}{dT}\log\lambda_{-T}\left(  y\right)  $. By Theorem 9.5 \textbf{(b)}
(applied to $x+y$ instead of $x$), we have $\widetilde{\psi}_{T}\left(
x+y\right)  =-T\cdot\dfrac{d}{dT}\log\lambda_{-T}\left(  x+y\right)  $.

By Theorem 2.1 \textbf{(b)}, we have $\lambda_{T}\left(  x\right)
\cdot\lambda_{T}\left(  y\right)  =\lambda_{T}\left(  x+y\right)  $. Now,%
\begin{align*}
&  \underbrace{\lambda_{-T}\left(  x\right)  }_{=\operatorname*{ev}%
\nolimits_{-T}\left(  \lambda_{T}\left(  x\right)  \right)  }\cdot
\underbrace{\lambda_{-T}\left(  y\right)  }_{=\operatorname*{ev}%
\nolimits_{-T}\left(  \lambda_{T}\left(  y\right)  \right)  }\\
&  =\operatorname*{ev}\nolimits_{-T}\left(  \lambda_{T}\left(  x\right)
\right)  \cdot\operatorname*{ev}\nolimits_{-T}\left(  \lambda_{T}\left(
y\right)  \right)  =\operatorname*{ev}\nolimits_{-T}\left(
\underbrace{\lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)
}_{=\lambda_{T}\left(  x+y\right)  }\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\operatorname*{ev}\nolimits_{-T}\text{ is a ring homomorphism}%
\right) \\
&  =\operatorname*{ev}\nolimits_{-T}\left(  \lambda_{T}\left(  x+y\right)
\right)  =\lambda_{-T}\left(  x+y\right)  \ \ \ \ \ \ \ \ \ \ \left(
\text{since }\lambda_{-T}\left(  x+y\right)  \text{ is defined as
}\operatorname*{ev}\nolimits_{-T}\left(  \lambda_{T}\left(  x+y\right)
\right)  \right)  .
\end{align*}
Now,%
\begin{align*}
\widetilde{\psi}_{T}\left(  x+y\right)   &  =-T\cdot\dfrac{d}{dT}%
\log\underbrace{\lambda_{-T}\left(  x+y\right)  }_{=\lambda_{-T}\left(
x\right)  \cdot\lambda_{-T}\left(  y\right)  }=-T\dfrac{d}{dT}\log\left(
\lambda_{-T}\left(  x\right)  \cdot\lambda_{-T}\left(  y\right)  \right) \\
&  =\underbrace{\left(  -T\dfrac{d}{dT}\log\lambda_{-T}\left(  x\right)
\right)  }_{=\widetilde{\psi}_{T}\left(  x\right)  }+\underbrace{\left(
-T\dfrac{d}{dT}\log\lambda_{-T}\left(  y\right)  \right)  }_{=\widetilde{\psi
}_{T}\left(  y\right)  }\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{9.ex5.s1}), applied to
}u=\lambda_{-T}\left(  x\right)  \text{ and }v=\lambda_{-T}\left(  y\right)
\right) \\
&  =\widetilde{\psi}_{T}\left(  x\right)  +\widetilde{\psi}_{T}\left(
y\right)  .
\end{align*}
This proves the 2nd step.

\textit{3rd step:} For every $x\in K$ and $y\in K$, we have $\psi^{j}\left(
x+y\right)  =\psi^{j}\left(  x\right)  +\psi^{j}\left(  y\right)  $ for every
$j\in\mathbb{N}\setminus\left\{  0\right\}  $.

\textit{Proof.} Let $x\in K$ and $y\in K$. By the definition of
$\widetilde{\psi}_{T}$, we have $\widetilde{\psi}_{T}\left(  x\right)
=\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(
x\right)  T^{j}$, $\widetilde{\psi}_{T}\left(  y\right)  =\sum\limits_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  y\right)  T^{j}$ and
$\widetilde{\psi}_{T}\left(  x+y\right)  =\sum\limits_{j\in\mathbb{N}%
\setminus\left\{  0\right\}  }\psi^{j}\left(  x+y\right)  T^{j}$. Now,%
\begin{align*}
\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(
x+y\right)  T^{j}  &  =\widetilde{\psi}_{T}\left(  x+y\right)
=\underbrace{\widetilde{\psi}_{T}\left(  x\right)  }_{=\sum\limits_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  x\right)  T^{j}%
}+\underbrace{\widetilde{\psi}_{T}\left(  y\right)  }_{=\sum\limits_{j\in
\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(  y\right)  T^{j}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{by the 2nd step}\right) \\
&  =\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }\psi^{j}\left(
x\right)  T^{j}+\sum\limits_{j\in\mathbb{N}\setminus\left\{  0\right\}  }%
\psi^{j}\left(  y\right)  T^{j}=\sum\limits_{j\in\mathbb{N}\setminus\left\{
0\right\}  }\left(  \psi^{j}\left(  x\right)  +\psi^{j}\left(  y\right)
\right)  T^{j}.
\end{align*}
Comparing coefficients before $T^{j}$ in this identity of power series, we
conclude that $\psi^{j}\left(  x+y\right)  =\psi^{j}\left(  x\right)
+\psi^{j}\left(  y\right)  $ for every $j\in\mathbb{N}\setminus\left\{
0\right\}  $. This proves the 3rd step.

\textit{4th step:} For every $j\in\mathbb{N}\setminus\left\{  0\right\}  $, we
have $\psi^{j}\left(  0\right)  =0$.

\textit{Proof.} Let $j\in\mathbb{N}\setminus\left\{  0\right\}  $. The 3rd
step yields that $\psi^{j}\left(  x+y\right)  =\psi^{j}\left(  x\right)
+\psi^{j}\left(  y\right)  $ for every $x\in K$ and $y\in K$. Applying this to
$x=0$ and $y=0$, we obtain $\psi^{j}\left(  0+0\right)  =\psi^{j}\left(
0\right)  +\psi^{j}\left(  0\right)  $. In other words, $\psi^{j}\left(
0\right)  =\psi^{j}\left(  0\right)  +\psi^{j}\left(  0\right)  $. This
simplifies to $\psi^{j}\left(  0\right)  =0$. Thus, the 4th step is proven.

\textit{5th step:} The map $\psi^{j}:K\rightarrow K$ is a homomorphism of
additive groups for every $j\in\mathbb{N}\setminus\left\{  0\right\}  $.

\textit{Proof.} This follows from the 3rd and 4th steps. This completes the
5th step and thus solves the problem.

\textit{Exercise 9.6:} \textit{Hints to solution:} \textbf{(a)} Corollary 9.7
yields%
\[
n\alpha_{n}=\sum\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}\alpha_{n-j}%
N_{j}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j}\right)  .
\]
Since we identify the polynomial $N_{j}\left(  \alpha_{1},\alpha
_{2},...,\alpha_{j}\right)  $ with the polynomial $N_{j}$ (because we view the
polynomial ring $\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{j}\right]  $ as a subring of $\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{n}\right]  $), this becomes%
\[
n\alpha_{n}=\sum\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}\alpha
_{n-j}\underbrace{N_{j}\left(  \alpha_{1},\alpha_{2},...,\alpha_{j}\right)
}_{=N_{j}}=\sum\limits_{j=1}^{n}\left(  -1\right)  ^{j-1}\alpha_{n-j}%
N_{j}=\sum_{i=1}^{n}\left(  -1\right)  ^{i-1}\alpha_{n-i}N_{i}%
\]
(here, we renamed the index $j$ as $i$). This solves Exercise 9.6 \textbf{(a)}.

\textbf{(b), (c)} To obtain a solution to Exercises 9.6 \textbf{(b)} and
\textbf{(c)}, we only have to make the following changes to the solution to
Exercises 9.3 \textbf{(b)} and \textbf{(c)}:

\begin{itemize}
\item Replace every occurence of $\lambda^{\ell}\left(  x\right)  $ (where
$\ell$ is any nonnegative integer) by $\alpha_{\ell}$.

\item Replace every occurence of $\psi^{\ell}\left(  x\right)  $ (where $\ell$
is any nonnegative integer) by $N_{\ell}$.

\item Replace the equalities $\lambda^{1}\left(  x\right)  =x$ and $\psi
^{1}\left(  x\right)  =x$ by $\alpha_{1}=\alpha_{1}$ and $N_{1}=\alpha_{1}$
(this is very easy to prove).

\item Replace every reference to Exercise 9.3 \textbf{(a)} by a reference to
Exercise 9.6 \textbf{(a)}.
\end{itemize}

This solves Exercises 9.6 \textbf{(b)} and \textbf{(c)}.

\textbf{(d)} Let $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ be a $\lambda$-ring. Let $x\in K$. Let $n\in\mathbb{N}$. By the
universal property of a polynomial ring, there exists a $\mathbb{Z}$-algebra
homomorphism $\varrho:\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{n}\right]  \rightarrow K$ which maps $\alpha_{i}$ to $\lambda^{i}\left(
x\right)  $ for every $i\in\left\{  1,2,...,n\right\}  $. Consider this
homomorphism $\varrho$. By its construction, this homomorphism $\varrho$ maps
every polynomial $P\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha
_{n}\right]  $ to its value $P\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{n}\left(  x\right)  \right)  $.

Every $i\in\left\{  0,1,...,n\right\}  $ satisfies
\begin{equation}
\varrho\left(  \alpha_{i}\right)  =\lambda^{i}\left(  x\right)
\ \ \ \ \ \ \ \ \ \ \text{and}\ \ \ \ \ \ \ \ \ \ \varrho\left(  N_{i}\right)
=\psi^{i}\left(  x\right)  . \label{9.6.sol.1}%
\end{equation}
\footnote{\textit{Proof of (\ref{9.6.sol.1}).} We distinguish between two
cases:
\par
\textit{Case 1:} We have $i=0$.
\par
\textit{Case 2:} We have $i>0$.
\par
First consider Case 1: In this case, $\alpha_{i}=\alpha_{0}=1$, $\lambda
^{i}\left(  x\right)  =\lambda^{0}\left(  x\right)  =1$, $\psi^{i}\left(
x\right)  =\psi^{0}\left(  x\right)  =1$ and $N_{i}=N_{0}=1$. Also,
$\varrho\left(  1\right)  =1$ (since $\varrho$ is a $\mathbb{Z}$-algebra
homomorphism). Thus, $\varrho\left(  \underbrace{\alpha_{i}}_{=1}\right)
=\varrho\left(  1\right)  =1=\lambda^{i}\left(  x\right)  $ and $\varrho
\left(  \underbrace{N_{i}}_{=1}\right)  =\varrho\left(  1\right)  =1=\psi
^{i}\left(  x\right)  $.
\par
We have thus proven (\ref{9.6.sol.1}) in Case 1.
\par
Now let us consider Case 2: In this case, $i>0$ and $i\in\left\{
0,1,...,n\right\}  $, so that $i\in\left\{  1,2,...,n\right\}  $. Hence, by
the definition of $\varrho$, we know that $\varrho$ maps $\alpha_{i}$ to
$\lambda^{i}\left(  x\right)  $. In other words, $\varrho\left(  \alpha
_{i}\right)  =\lambda^{i}\left(  x\right)  $. Besides, we know that $\varrho$
maps every polynomial $P\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{n}\right]  $ to its value $P\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{n}\left(  x\right)  \right)  $.
Hence, $\varrho$ maps $N_{i}$ to $N_{i}\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{n}\left(  x\right)  \right)
=\psi^{i}\left(  x\right)  $. In other words, $\varrho\left(  N_{i}\right)
=\psi^{i}\left(  x\right)  $.
\par
We have thus proven (\ref{9.6.sol.1}) in Case 2.
\par
So we have proven (\ref{9.6.sol.1}) in both possible cases, qed.}

Now, let us derive Exercise 9.3 \textbf{(a)} from Exercise 9.6 \textbf{(a)}:
According to Exercise 9.6 \textbf{(a)}, the equality%
\[
n\alpha_{n}=\sum_{i=1}^{n}\left(  -1\right)  ^{i-1}\alpha_{n-i}N_{i}%
\]
holds. Applying $\varrho$ to both sides of the equation, we get $\varrho
\left(  n\alpha_{n}\right)  =\varrho\left(  \sum\limits_{i=1}^{n}\left(
-1\right)  ^{i-1}\alpha_{n-i}N_{i}\right)  $. Since%
\begin{align*}
\varrho\left(  n\alpha_{n}\right)   &  =n\underbrace{\varrho\left(  \alpha
_{n}\right)  }_{=\lambda^{n}\left(  x\right)  \text{ (by (\ref{9.6.sol.1}))}%
}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }\varrho\text{ is a }\mathbb{Z}%
\text{-algebra homomorphism}\right) \\
&  =n\lambda^{n}\left(  x\right)
\end{align*}
and%
\begin{align*}
\varrho\left(  \sum\limits_{i=1}^{n}\left(  -1\right)  ^{i-1}\alpha_{n-i}%
N_{i}\right)   &  =\sum\limits_{i=1}^{n}\left(  -1\right)  ^{i-1}%
\underbrace{\varrho\left(  \alpha_{n-i}\right)  }_{=\lambda^{n-i}\left(
x\right)  \text{ (by (\ref{9.6.sol.1}))}}\underbrace{\varrho\left(
N_{i}\right)  }_{=\psi^{i}\left(  x\right)  \text{ (by (\ref{9.6.sol.1}))}}\\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since }\varrho\text{ is a }%
\mathbb{Z}\text{-algebra homomorphism}\right) \\
&  =\sum\limits_{i=1}^{n}\left(  -1\right)  ^{i-1}\lambda^{n-i}\left(
x\right)  \psi^{i}\left(  x\right)  ,
\end{align*}
this becomes%
\[
n\lambda^{n}\left(  x\right)  =\sum\limits_{i=1}^{n}\left(  -1\right)
^{i-1}\lambda^{n-i}\left(  x\right)  \psi^{i}\left(  x\right)  .
\]
Thus we have proved Exercise 9.3 \textbf{(a)} by means of Exercise 9.6
\textbf{(a)}. Similarly, we can derive Exercise 9.3 \textbf{(b)} and
\textbf{(c)} from Exercise 9.6 \textbf{(b)} and \textbf{(c)} (again, by
applying $\varrho$).

\textit{Exercise 9.7:} \textit{Detailed solution:} First, we will prove that
$\alpha_{1}^{p}-N_{p}\in p\mathbb{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{p}\right]  $ (where $N_{p}$ is the $p$-th Hirzebruch polynomial
as defined in the beginning of Section 9). Due to our implicit construction of
$N_{p}$, this is not easy to prove directly. Instead, we will prove this by
defining a "universal" polynomial similar to our Hirzebruch polynomials, and
then prove that this polynomial actually is $\dfrac{\alpha_{1}^{p}-N_{p}}{p}$.

\textit{1st step:} Let $m\in\mathbb{N}$. The polynomial $\dfrac{1}{p}\left(
\left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}-\left(  U_{1}^{p}+U_{2}%
^{p}+...+U_{m}^{p}\right)  \right)  \in\mathbb{Q}\left[  U_{1},U_{2}%
,...,U_{m}\right]  $ actually lies in $\mathbb{Z}\left[  U_{1},U_{2}%
,...,U_{m}\right]  $.

\textit{Proof.} We need the following fact as a lemma:%
\begin{equation}
\left(
\begin{array}
[c]{c}%
\text{If }m\in\mathbb{N}\text{, if }A\text{ is a commutative ring with unity
such that }p\cdot1_{A}=0\text{, and}\\
\text{if }x_{1}\text{, }x_{2}\text{, }...\text{, }x_{m}\text{ are }m\text{
elements of }A\text{, then }\left(  x_{1}+x_{2}+...+x_{m}\right)  ^{p}%
=x_{1}^{p}+x_{2}^{p}+...+x_{m}^{p}%
\end{array}
\right)  . \label{9.7.sol.idiotbinom}%
\end{equation}
\footnote{\textit{Proof of (\ref{9.7.sol.idiotbinom}):} Let $m\in\mathbb{N}$.
Let $A$ be a commutative ring with unity such that $p\cdot1_{A}=0$. Let
$x_{1}$, $x_{2}$, $...$, $x_{m}$ be $m$ elements of $A$.
\par
Let $\Phi:A\rightarrow A$ be the map defined by $\left(  \Phi\left(  y\right)
=y^{p}\text{ for every }y\in A\right)  $. Then, $\Phi$ is known to be a ring
homomorphism (since $p\cdot1_{A}=0$). Thus,
\[
\Phi\left(  x_{1}+x_{2}+...+x_{m}\right)  =\Phi\left(  x_{1}\right)
+\Phi\left(  x_{2}\right)  +...+\Phi\left(  x_{m}\right)  =\sum\limits_{i=1}%
^{m}\underbrace{\Phi\left(  x_{i}\right)  }_{\substack{=x_{i}^{p}\\\text{(by
the definition of }\Phi\text{)}}}=\sum\limits_{i=1}^{m}x_{i}^{p}=x_{1}%
^{p}+x_{2}^{p}+...+x_{m}^{p}.
\]
Compared with $\Phi\left(  x_{1}+x_{2}+...+x_{m}\right)  =\left(  x_{1}%
+x_{2}+...+x_{m}\right)  ^{p}$ (by the definition of $\Phi$), this yields
$\left(  x_{1}+x_{2}+...+x_{m}\right)  ^{p}=x_{1}^{p}+x_{2}^{p}+...+x_{m}^{p}%
$. This proves (\ref{9.7.sol.idiotbinom}).}

Now, let $A$ be the ring $\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  \right)  \diagup\left(  p\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  \right)  $. For every $u\in\mathbb{Z}\left[  U_{1},U_{2}%
,...,U_{m}\right]  $, let $\overline{u}$ denote the residue class of $u$
modulo the ideal $p\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $; this
$\overline{u}$ lies in $\left(  \mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  \right)  \diagup\left(  p\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  \right)  =A$. Since $p\cdot1_{\mathbb{Z}\left[  U_{1},U_{2}%
,...,U_{m}\right]  }\in p\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $, we
have $\overline{p\cdot1_{\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  }}%
=0$. Since $\overline{p\cdot1_{\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]
}}=p\cdot1_{A}$, this rewrites as $p\cdot1_{A}=0$. Thus,
(\ref{9.7.sol.idiotbinom}) (applied to $x_{i}=\overline{U_{i}}$) yields
$\left(  \overline{U_{1}}+\overline{U_{2}}+...+\overline{U_{m}}\right)
^{p}=\overline{U_{1}}^{p}+\overline{U_{2}}^{p}+...+\overline{U_{m}}^{p}$.
Since $\left(  \overline{U_{1}}+\overline{U_{2}}+...+\overline{U_{m}}\right)
^{p}=\overline{\left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}}$ and $\overline
{U_{1}}^{p}+\overline{U_{2}}^{p}+...+\overline{U_{m}}^{p}=\overline{U_{1}%
^{p}+U_{2}^{p}+...+U_{m}^{p}}$, this rewrites as $\overline{\left(
U_{1}+U_{2}+...+U_{m}\right)  ^{p}}=\overline{U_{1}^{p}+U_{2}^{p}%
+...+U_{m}^{p}}$. In other words,%
\[
\left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}\equiv U_{1}^{p}+U_{2}^{p}%
+...+U_{m}^{p}\operatorname{mod}p\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}%
\right]  .
\]
In other words, $\left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}-\left(  U_{1}%
^{p}+U_{2}^{p}+...+U_{m}^{p}\right)  \in p\mathbb{Z}\left[  U_{1}%
,U_{2},...,U_{m}\right]  $. Thus, $\dfrac{1}{p}\left(  \left(  U_{1}%
+U_{2}+...+U_{m}\right)  ^{p}-\left(  U_{1}^{p}+U_{2}^{p}+...+U_{m}%
^{p}\right)  \right)  \in\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $.
This proves the 1st step.

\textit{2nd step:} Until now, $m$ could be any nonnegative integer. From now
on, set $m=p$.

The polynomial $\dfrac{1}{p}\left(  \left(  U_{1}+U_{2}+...+U_{m}\right)
^{p}-\left(  U_{1}^{p}+U_{2}^{p}+...+U_{m}^{p}\right)  \right)  $ lies in
$\mathbb{Z}\left[  U_{1},U_{2},...,U_{m}\right]  $ (due to the 1st step) and
is symmetric (since it is a $\mathbb{Q}$-linear combination of the polynomials
$\left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}$ and $U_{1}^{p}+U_{2}%
^{p}+...+U_{m}^{p}$, both of which are symmetric). Thus, Theorem 4.1
\textbf{(a)} (applied to $P=\dfrac{1}{p}\left(  \left(  U_{1}+U_{2}%
+...+U_{m}\right)  ^{p}-\left(  U_{1}^{p}+U_{2}^{p}+...+U_{m}^{p}\right)
\right)  $) yields that there exists one and only one polynomial
$Q\in\mathbb{Z}\left[  \alpha_{1},\alpha_{2},...,\alpha_{m}\right]  $ such
that%
\begin{equation}
\dfrac{1}{p}\left(  \left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}-\left(
U_{1}^{p}+U_{2}^{p}+...+U_{m}^{p}\right)  \right)  =Q\left(  X_{1}%
,X_{2},...,X_{m}\right)  . \label{9.7.sol.Q}%
\end{equation}
Consider this $Q$. Note that $Q\in\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{m}\right]  =\mathbb{Z}\left[  \alpha_{1},\alpha
_{2},...,\alpha_{p}\right]  $ (since $m=p$).

For every $i\in\mathbb{N}$, let $X_{i}$ be defined as in Theorem 4.1. For
every $j\in\mathbb{N}\setminus\left\{  0\right\}  $, define $N_{j}$ as in the
beginning of Section 9. Applying (\ref{Nj1}) to $j=p$, we obtain%
\[
\sum_{i=1}^{m}U_{i}^{p}=N_{p}\underbrace{\left(  X_{1},X_{2},...,X_{p}\right)
}_{\substack{=\left(  X_{1},X_{2},...,X_{m}\right)  \\\text{(since
}p=m\text{)}}}=N_{p}\left(  X_{1},X_{2},...,X_{m}\right)  .
\]
On the other hand, $X_{1}=U_{1}+U_{2}+...+U_{m}$ (because $X_{1}$ is the
$1$-st elementary symmetric polynomial in the variables $U_{1}$, $U_{2}$,
$...$, $U_{m}$), so that $X_{1}^{p}=\left(  U_{1}+U_{2}+...+U_{m}\right)
^{p}$. Now,%
\begin{align*}
\left(  \alpha_{1}^{p}-N_{p}\right)  \left(  X_{1},X_{2},...,X_{m}\right)   &
=\underbrace{X_{1}^{p}}_{=\left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}%
}-\underbrace{N_{p}\left(  X_{1},X_{2},...,X_{m}\right)  }_{=\sum
\limits_{i=1}^{m}U_{i}^{p}=U_{1}^{p}+U_{2}^{p}+...+U_{m}^{p}}\\
&  =\left(  U_{1}+U_{2}+...+U_{m}\right)  ^{p}-\left(  U_{1}^{p}+U_{2}%
^{p}+...+U_{m}^{p}\right) \\
&  =p\cdot\underbrace{\dfrac{1}{p}\left(  \left(  U_{1}+U_{2}+...+U_{m}%
\right)  ^{p}-\left(  U_{1}^{p}+U_{2}^{p}+...+U_{m}^{p}\right)  \right)
}_{\substack{=Q\left(  X_{1},X_{2},...,X_{m}\right)  \\\text{(by
(\ref{9.7.sol.Q}))}}}\\
&  =pQ\left(  X_{1},X_{2},...,X_{m}\right)  =\left(  pQ\right)  \left(
X_{1},X_{2},...,X_{m}\right)  .
\end{align*}
Since the elements $X_{1},$ $X_{2},$ $...,$ $X_{m}$ of $\mathbf{Z}\left[
U_{1},U_{2},...,U_{m}\right]  $ are algebraically independent (by Theorem 4.1
\textbf{(a)}), this yields $\alpha_{1}^{p}-N_{p}=pQ$. This shows that
$\alpha_{1}^{p}-N_{p}\in p\mathbb{Z}\left[  \alpha_{1},\alpha_{2}%
,...,\alpha_{p}\right]  $.

\textit{3rd step:} Let $x\in K$. Applying (\ref{PsiDef}) to $j=p$, we obtain%
\[
\psi^{p}\left(  x\right)  =N_{p}\left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{p}\left(  x\right)  \right)  .
\]
Now, we recall that $\alpha_{1}^{p}-N_{p}=pQ$, so that%
\begin{align*}
\left(  \alpha_{1}^{p}-N_{p}\right)  \left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{p}\left(  x\right)  \right)   &
=\left(  pQ\right)  \left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{p}\left(  x\right)  \right) \\
&  =p\underbrace{Q\left(  \lambda^{1}\left(  x\right)  ,\lambda^{2}\left(
x\right)  ,...,\lambda^{p}\left(  x\right)  \right)  }_{\in K}\in pK.
\end{align*}
Since%
\begin{align*}
\left(  \alpha_{1}^{p}-N_{p}\right)  \left(  \lambda^{1}\left(  x\right)
,\lambda^{2}\left(  x\right)  ,...,\lambda^{p}\left(  x\right)  \right)   &
=\underbrace{\alpha_{1}^{p}\left(  \lambda^{1}\left(  x\right)  ,\lambda
^{2}\left(  x\right)  ,...,\lambda^{p}\left(  x\right)  \right)  }_{=\left(
\lambda^{1}\left(  x\right)  \right)  ^{p}}-\underbrace{N_{p}\left(
\lambda^{1}\left(  x\right)  ,\lambda^{2}\left(  x\right)  ,...,\lambda
^{p}\left(  x\right)  \right)  }_{=\psi^{p}\left(  x\right)  }\\
&  =\left(  \underbrace{\lambda^{1}\left(  x\right)  }%
_{\substack{=x\\\text{(by the definition}\\\text{of a }\lambda\text{-ring)}%
}}\right)  ^{p}-\psi^{p}\left(  x\right)  =x^{p}-\psi^{p}\left(  x\right)  ,
\end{align*}
this rewrites as $x^{p}-\psi^{p}\left(  x\right)  \in pK$. In other words,
$\psi^{p}\left(  x\right)  \equiv x^{p}\operatorname{mod}pK$. Exercise 9.7 is solved.

\subsection{To Section 10}

\textit{Exercise 10.1: Detailed solution:} \textbf{(a)} We know that
$\operatorname*{Coeff}\nolimits_{0}$ is a $K$-linear map (for obvious
reasons). Now let us show that $\operatorname*{Coeff}\nolimits_{0}$ is a
$K$-algebra homomorphism.

The unity of the ring $K\left[  \left[  T\right]  \right]  $ is $1$, so that
$\operatorname*{Coeff}\nolimits_{0}$ sends the unity of the ring $K\left[
\left[  T\right]  \right]  $ to $\operatorname*{Coeff}\nolimits_{0}\left(
1\right)  =1$, which is the unity of $K$.

Let $\varphi\in K\left[  \left[  T\right]  \right]  $ and $\psi\in K\left[
\left[  T\right]  \right]  $ be two power series. Then, by the definition of
the product of two power series, we have%
\begin{equation}
\operatorname*{Coeff}\nolimits_{n}\left(  \varphi\psi\right)  =\sum_{k=0}%
^{n}\operatorname*{Coeff}\nolimits_{k}\varphi\cdot\operatorname*{Coeff}%
\nolimits_{n-k}\psi\ \ \ \ \ \ \ \ \ \ \text{for every }n\in\mathbb{N}\text{.}
\label{10.1.sol.0}%
\end{equation}
Applied to $n=0$, this yields%
\[
\operatorname*{Coeff}\nolimits_{0}\left(  \varphi\psi\right)  =\sum_{k=0}%
^{0}\operatorname*{Coeff}\nolimits_{k}\varphi\cdot\operatorname*{Coeff}%
\nolimits_{0-k}\psi=\operatorname*{Coeff}\nolimits_{0}\varphi\cdot
\operatorname*{Coeff}\nolimits_{0}\psi.
\]
This yields that $\operatorname*{Coeff}\nolimits_{0}$ is a $K$-algebra
homomorphism from $K\left[  \left[  T\right]  \right]  $ to $K$ (because we
also know that $\operatorname*{Coeff}\nolimits_{0}$ is a $K$-linear map and
sends the unity of the ring $K\left[  \left[  T\right]  \right]  $ to the
unity of $K$). Hence, $\operatorname*{Coeff}\nolimits_{0}\left(
\prod\limits_{i=1}^{m}\Phi_{i}\right)  =\prod\limits_{i=1}^{m}%
\operatorname*{Coeff}\nolimits_{0}\left(  \Phi_{i}\right)  $. This solves
Exercise 10.1 \textbf{(a)}.

\textbf{(b)} Exercise 10.1 \textbf{(a)} yields $\operatorname*{Coeff}%
\nolimits_{0}\left(  \prod\limits_{i=1}^{m}\Phi_{i}\right)  =\prod
\limits_{i=1}^{m}\underbrace{\operatorname*{Coeff}\nolimits_{0}\left(
\Phi_{i}\right)  }_{=1}=\prod\limits_{i=1}^{m}1=1$.

Now let us prove that every $\mu\in\left\{  0,1,...,m\right\}  $ satisfies%
\begin{equation}
\operatorname*{Coeff}\nolimits_{1}\left(  \prod\limits_{i=1}^{\mu}\Phi
_{i}\right)  =\sum\limits_{i=1}^{\mu}\operatorname*{Coeff}\nolimits_{1}\left(
\Phi_{i}\right)  . \label{10.1.sol.1}%
\end{equation}


\textit{Proof of (\ref{10.1.sol.1}).} We will prove (\ref{10.1.sol.1}) by
induction over $\mu$:

\textit{Induction base:} If $\mu=0$, then $\prod\limits_{i=1}^{\mu}\Phi
_{i}=\left(  \text{empty product}\right)  =1$ and thus $\operatorname*{Coeff}%
\nolimits_{1}\left(  \prod\limits_{i=1}^{\mu}\Phi_{i}\right)
=\operatorname*{Coeff}\nolimits_{1}1=0$, which rewrites as
$\operatorname*{Coeff}\nolimits_{1}\left(  \prod\limits_{i=1}^{\mu}\Phi
_{i}\right)  =\sum\limits_{i=1}^{\mu}\operatorname*{Coeff}\nolimits_{1}\left(
\Phi_{i}\right)  $ (because for $\mu=0$ we also have $\sum\limits_{i=1}^{\mu
}\operatorname*{Coeff}\nolimits_{1}\left(  \Phi_{i}\right)  =\left(
\text{empty sum}\right)  =0$). Thus, (\ref{10.1.sol.1}) holds for $\mu=0$. The
induction base is thus complete.

\textit{Induction step:} Let $M\in\left\{  0,1,...,m-1\right\}  $ be such that
(\ref{10.1.sol.1}) holds for $\mu=M$. We must prove that (\ref{10.1.sol.1})
holds for $\mu=M+1$ as well.

Since (\ref{10.1.sol.1}) holds for $\mu=M$, we have $\operatorname*{Coeff}%
\nolimits_{1}\left(  \prod\limits_{i=1}^{M}\Phi_{i}\right)  =\sum
\limits_{i=1}^{M}\operatorname*{Coeff}\nolimits_{1}\left(  \Phi_{i}\right)  $.
Let $\varphi=\prod\limits_{i=1}^{M}\Phi_{i}$ and $\psi=\Phi_{M+1}$. Then,
$\varphi\psi=\left(  \prod\limits_{i=1}^{M}\Phi_{i}\right)  \Phi_{M+1}%
=\prod\limits_{i=1}^{M+1}\Phi_{i}$. Since $\varphi=\prod\limits_{i=1}^{M}%
\Phi_{i}$, we have
\begin{align*}
\operatorname*{Coeff}\nolimits_{0}\varphi &  =\operatorname*{Coeff}%
\nolimits_{0}\left(  \prod\limits_{i=1}^{M}\Phi_{i}\right)  =\prod
\limits_{i=1}^{M}\underbrace{\operatorname*{Coeff}\nolimits_{0}\left(
\Phi_{i}\right)  }_{=1}\ \ \ \ \ \ \ \ \ \ \left(  \text{since }%
\operatorname*{Coeff}\nolimits_{0}\text{ is a }K\text{-algebra homomorphism}%
\right) \\
&  =\prod\limits_{i=1}^{M}1=1
\end{align*}
and%
\[
\operatorname*{Coeff}\nolimits_{1}\varphi=\operatorname*{Coeff}\nolimits_{1}%
\left(  \prod\limits_{i=1}^{M}\Phi_{i}\right)  =\sum\limits_{i=1}%
^{M}\operatorname*{Coeff}\nolimits_{1}\left(  \Phi_{i}\right)  .
\]
Since $\psi=\Phi_{M+1}$, we have $\operatorname*{Coeff}\nolimits_{0}%
\psi=\operatorname*{Coeff}\nolimits_{0}\left(  \Phi_{M+1}\right)  =1$ (because
$\operatorname*{Coeff}\nolimits_{0}\left(  \Phi_{i}\right)  =1$ for every
$i\in\left\{  1,2,...,m\right\}  $). On the other hand, (\ref{10.1.sol.0})
(applied to $n=1$) yields%
\begin{align*}
\operatorname*{Coeff}\nolimits_{1}\left(  \varphi\psi\right)   &  =\sum
_{k=0}^{1}\operatorname*{Coeff}\nolimits_{k}\varphi\cdot\operatorname*{Coeff}%
\nolimits_{1-k}\psi=\underbrace{\operatorname*{Coeff}\nolimits_{0}\varphi
}_{=1}\cdot\operatorname*{Coeff}\nolimits_{1}\underbrace{\psi}_{=\Phi_{M+1}%
}+\underbrace{\operatorname*{Coeff}\nolimits_{1}\varphi}_{=\sum\limits_{i=1}%
^{M}\operatorname*{Coeff}\nolimits_{1}\left(  \Phi_{i}\right)  }%
\cdot\underbrace{\operatorname*{Coeff}\nolimits_{0}\psi}_{=1}\\
&  =1\cdot\operatorname*{Coeff}\nolimits_{1}\left(  \Phi_{M+1}\right)
+\sum\limits_{i=1}^{M}\operatorname*{Coeff}\nolimits_{1}\left(  \Phi
_{i}\right)  \cdot1\\
&  =\operatorname*{Coeff}\nolimits_{1}\left(  \Phi_{M+1}\right)
+\sum\limits_{i=1}^{M}\operatorname*{Coeff}\nolimits_{1}\left(  \Phi
_{i}\right)  =\sum\limits_{i=1}^{M+1}\operatorname*{Coeff}\nolimits_{1}\left(
\Phi_{i}\right)  .
\end{align*}
Since $\varphi\psi=\prod\limits_{i=1}^{M+1}\Phi_{i}$, this rewrites as
$\operatorname*{Coeff}\nolimits_{1}\left(  \prod\limits_{i=1}^{M+1}\Phi
_{i}\right)  =\sum\limits_{i=1}^{M+1}\operatorname*{Coeff}\nolimits_{1}\left(
\Phi_{i}\right)  $. In other words, (\ref{10.1.sol.1}) holds for $\mu=M+1$.
This completes the induction step.

We have thus proven (\ref{10.1.sol.1}) by induction. Applying
(\ref{10.1.sol.1}) to $\mu=m$, we get $\operatorname*{Coeff}\nolimits_{1}%
\left(  \prod\limits_{i=1}^{m}\Phi_{i}\right)  =\sum\limits_{i=1}%
^{m}\operatorname*{Coeff}\nolimits_{1}\left(  \Phi_{i}\right)  $. This
concludes the solution of Exercise 10.1 \textbf{(b)}.

\textit{Exercise 10.2: Solution:} \textit{Proof of Proposition 10.29.} Let
$x\in K$. Then, $\lambda_{T}\left(  x\right)  =\sum\limits_{i\in\mathbb{N}%
}\lambda^{i}\left(  x\right)  T^{i}$, so that%
\[
\iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(  x\right)
\right)  =\iota\left[  \left[  T\right]  \right]  \left(  \sum\limits_{i\in
\mathbb{N}}\lambda^{i}\left(  x\right)  T^{i}\right)  =\sum\limits_{i\in
\mathbb{N}}\underbrace{\iota\left(  \lambda^{i}\left(  x\right)  \right)
}_{\substack{=\lambda^{i}\left(  x\right)  \otimes1\\\text{(by the definition
of }\iota\text{)}}}T^{i}=\sum\limits_{i\in\mathbb{N}}\left(  \lambda
^{i}\left(  x\right)  \otimes1\right)  T^{i}.
\]
Hence, every $k\in\mathbb{N}$ satisfies $\operatorname*{Coeff}\nolimits_{k}%
\left(  \iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(
x\right)  \right)  \right)  =\operatorname*{Coeff}\nolimits_{k}\left(
\sum\limits_{i\in\mathbb{N}}\left(  \lambda^{i}\left(  x\right)
\otimes1\right)  T^{i}\right)  =\lambda^{k}\left(  x\right)  \otimes1$ (by the
definition of $\operatorname*{Coeff}\nolimits_{k}$). Thus,
\begin{align}
&  \left(  \operatorname*{Coeff}\nolimits_{1}\left(  \iota\left[  \left[
T\right]  \right]  \left(  \lambda_{T}\left(  x\right)  \right)  \right)
,\operatorname*{Coeff}\nolimits_{2}\left(  \iota\left[  \left[  T\right]
\right]  \left(  \lambda_{T}\left(  x\right)  \right)  \right)
,...,\operatorname*{Coeff}\nolimits_{j}\left(  \iota\left[  \left[  T\right]
\right]  \left(  \lambda_{T}\left(  x\right)  \right)  \right)  \right)
\nonumber\\
&  =\left(  \lambda^{1}\left(  x\right)  \otimes1,\lambda^{2}\left(  x\right)
\otimes1,...,\lambda^{j}\left(  x\right)  \otimes1\right)  \label{10.29.pf.1}%
\end{align}
for every $j\in\mathbb{N}$. Now, (\ref{ToddFrak}) (applied to $p=\iota\left[
\left[  T\right]  \right]  \left(  \lambda_{T}\left(  x\right)  \right)  $)
yields%
\begin{align*}
&  \mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]
\left(  \lambda_{T}\left(  x\right)  \right)  \right) \\
&  =\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\operatorname*{Coeff}\nolimits_{1}\left(  \iota\left[  \left[  T\right]
\right]  \left(  \lambda_{T}\left(  x\right)  \right)  \right)
,\operatorname*{Coeff}\nolimits_{2}\left(  \iota\left[  \left[  T\right]
\right]  \left(  \lambda_{T}\left(  x\right)  \right)  \right)
,...,\operatorname*{Coeff}\nolimits_{j}\left(  \iota\left[  \left[  T\right]
\right]  \left(  \lambda_{T}\left(  x\right)  \right)  \right)  \right)
T^{j}\\
&  =\sum\limits_{j\in\mathbb{N}}\operatorname*{Td}\nolimits_{\varphi,j}\left(
\lambda^{1}\left(  x\right)  \otimes1,\lambda^{2}\left(  x\right)
\otimes1,...,\lambda^{j}\left(  x\right)  \otimes1\right)  T^{j}%
\ \ \ \ \ \ \ \ \ \ \left(  \text{by (\ref{10.29.pf.1})}\right) \\
&  =\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(
x\right)  .
\end{align*}
This proves Proposition 10.29.

\textit{Proof of Proposition 10.30.} Let $\iota:K\rightarrow K\otimes
_{\mathbf{Z}}\mathbf{Z}^{\prime}$ be the canonical map (mapping every $\xi\in
K$ to $\xi\otimes1\in K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}$). Proposition
10.29 (applied to $\varphi=1+ut$) yields%
\begin{align*}
\operatorname*{td}\nolimits_{1+ut,T,\mathbf{Z}^{\prime}}\left(  x\right)   &
=\mathfrak{Todd}_{1+ut}\left(  \iota\left[  \left[  T\right]  \right]  \left(
\lambda_{T}\left(  x\right)  \right)  \right)  =\underbrace{\operatorname*{ev}%
\nolimits_{uT}}_{\substack{=\operatorname*{ev}\nolimits_{\left(  1\otimes
u\right)  T}\\\text{(since }uT=\left(  1\otimes u\right)  T\\\text{in }\left(
K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  \left[  \left[  T\right]
\right]  \text{)}}}\left(  \iota\left[  \left[  T\right]  \right]  \left(
\lambda_{T}\left(  x\right)  \right)  \right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Proposition 10.12, applied to }\mathbf{Z}^{\prime}\text{, }%
K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\text{ and }\iota\left[  \left[
T\right]  \right]  \left(  \lambda_{T}\left(  x\right)  \right) \\
\text{instead of }\mathbf{Z}\text{, }K\text{ and }p
\end{array}
\right) \\
&  =\operatorname*{ev}\nolimits_{\left(  1\otimes u\right)  T}\left(
\iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(  x\right)
\right)  \right)  =\left(  \operatorname*{ev}\nolimits_{\left(  1\otimes
u\right)  T}\circ\iota\left[  \left[  T\right]  \right]  \right)  \left(
\lambda_{T}\left(  x\right)  \right)  .
\end{align*}
But the diagram%
\[
\xymatrixcolsep{5pc}\xymatrix{
K \left[\left[T\right]\right] \ar[r]^{\iota \left[\left[T\right]\right]} \ar[dr]_{\operatorname*{ev}_{\left(1\otimes u\right)T}} & \left(K \otimes_{\mathbf Z} \mathbf Z^{\prime}\right) \left[\left[T\right]\right] \ar[d]^{\operatorname*{ev}_{\left(1\otimes u\right)T}} \\
&  \left(K \otimes_{\mathbf Z} \mathbf Z^{\prime}\right) \left[\left[T\right]\right]
}
\]
commutes (since the definition of the map $\operatorname*{ev}\nolimits_{\mu
T}:K\left[  \left[  T\right]  \right]  \rightarrow L\left[  \left[  T\right]
\right]  $ for any ring $K$, any $K$-algebra $L$ and any element $\mu$ of $L$
was canonical with respect to $K$). Thus, $\operatorname*{ev}%
\nolimits_{\left(  1\otimes u\right)  T}\circ\iota\left[  \left[  T\right]
\right]  =\operatorname*{ev}\nolimits_{\left(  1\otimes u\right)  T}$. Now,%
\[
\operatorname*{td}\nolimits_{1+ut,T,\mathbf{Z}^{\prime}}\left(  x\right)
=\underbrace{\left(  \operatorname*{ev}\nolimits_{\left(  1\otimes u\right)
T}\circ\iota\left[  \left[  T\right]  \right]  \right)  }_{=\operatorname*{ev}%
\nolimits_{\left(  1\otimes u\right)  T}}\left(  \lambda_{T}\left(  x\right)
\right)  =\operatorname*{ev}\nolimits_{\left(  1\otimes u\right)  T}\left(
\lambda_{T}\left(  x\right)  \right)  .
\]
This proves Proposition 10.30.

Alternatively, we could have proven Proposition 10.30 by repeating the proof
of Proposition 10.3 with some minor changes.

We could derive Proposition 10.31 from Proposition 10.13 (just as we derived
Proposition 10.30 from Proposition 10.12) using Proposition 10.29, but let us
instead prove it directly:

\textit{Proof of Proposition 10.31.} Let $x\in K$.

\textbf{(a)} We have%
\begin{align*}
&  \operatorname*{Coeff}\nolimits_{0}\left(  \operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)  \right) \\
&  =\operatorname*{Coeff}\nolimits_{0}\left(  \sum_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  \lambda^{1}\left(  x\right)
\otimes1,\lambda^{2}\left(  x\right)  \otimes1,...,\lambda^{j}\left(
x\right)  \otimes1\right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{ToddDefZ'})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,0}\left(  \lambda^{1}\left(
x\right)  \otimes1,\lambda^{2}\left(  x\right)  \otimes1,...,\lambda
^{0}\left(  x\right)  \otimes1\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
the definition of }\operatorname*{Coeff}\nolimits_{0}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,0}=1\ \ \ \ \ \ \ \ \ \ \left(
\text{by Proposition 10.6 \textbf{(a)}, applied to }\mathbf{Z}^{\prime}\text{
instead of }\mathbf{Z}\right)  .
\end{align*}


\textbf{(b)} We have%
\begin{align*}
&  \operatorname*{Coeff}\nolimits_{1}\left(  \operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)  \right) \\
&  =\operatorname*{Coeff}\nolimits_{1}\left(  \sum_{j\in\mathbb{N}%
}\operatorname*{Td}\nolimits_{\varphi,j}\left(  \lambda^{1}\left(  x\right)
\otimes1,\lambda^{2}\left(  x\right)  \otimes1,...,\lambda^{j}\left(
x\right)  \otimes1\right)  T^{j}\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
(\ref{ToddDefZ'})}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,1}\left(  \lambda^{1}\left(
x\right)  \otimes1,\lambda^{2}\left(  x\right)  \otimes1,...,\lambda
^{1}\left(  x\right)  \otimes1\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by
the definition of }\operatorname*{Coeff}\nolimits_{1}\right) \\
&  =\operatorname*{Td}\nolimits_{\varphi,1}\left(  \underbrace{\lambda
^{1}\left(  x\right)  }_{=x}\otimes1\right)  =\operatorname*{Td}%
\nolimits_{\varphi,1}\left(  x\otimes1\right)  =\varphi_{1}\left(
x\otimes1\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{since Proposition 10.6 \textbf{(b)}
(applied to }\mathbf{Z}^{\prime}\text{ instead of }\mathbf{Z}\text{) yields
}\operatorname*{Td}\nolimits_{\varphi,1}=\varphi_{1}\alpha_{1}\right)  .
\end{align*}


Proposition 10.31 is now proven.

\textit{Proof of Proposition 10.32.} To obtain a proof of Proposition 10.32,
read the proof of Proposition 10.7, doing the following replacements:

\begin{itemize}
\item Replace every $\lambda^{k}\left(  x\right)  $ by $\lambda^{k}\left(
x\right)  \otimes1$ for $k$ any nonnegative integer (that is, replace
$\lambda^{1}\left(  x\right)  $ by $\lambda^{1}\left(  x\right)  \otimes1$,
replace $\lambda^{2}\left(  x\right)  $ by $\lambda^{2}\left(  x\right)
\otimes1$, etc.).

\item Replace every $\operatorname*{td}\nolimits_{\varphi,T}$ by
$\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}$.

\item Replace every $\operatorname*{td}\nolimits_{\psi,T}$ by
$\operatorname*{td}\nolimits_{\psi,T,\mathbf{Z}^{\prime}}$.

\item Replace every $\operatorname*{td}\nolimits_{\varphi\psi,T}$ by
$\operatorname*{td}\nolimits_{\varphi\psi,T,\mathbf{Z}^{\prime}}$.

\item Replace all references to Proposition 10.7 by references to Proposition 10.32.

\item Replace all references to (\ref{ToddDef}) by references to
(\ref{ToddDefZ'}).
\end{itemize}

\textit{Proof of Proposition 10.33.} This can be proven by induction over $m$.
The induction base (the case $m=0$) requires showing that $\operatorname*{td}%
\nolimits_{1,T,\mathbf{Z}^{\prime}}\left(  x\right)  =1$, but this follows
from Proposition 10.14\footnote{In fact, Proposition 10.30 (applied to $u=0$)
yields $\operatorname*{td}\nolimits_{1+0t,T,\mathbf{Z}^{\prime}}\left(
x\right)  =\lambda_{\left(  1\otimes0\right)  T}\left(  x\right)  $. Now
$\lambda_{\left(  1\otimes0\right)  T}\left(  x\right)  =\operatorname*{ev}%
\nolimits_{\left(  1\otimes0\right)  T}\left(  \lambda_{T}\left(  x\right)
\right)  $. Since $\operatorname*{ev}\nolimits_{\left(  1\otimes0\right)
T}=\operatorname*{ev}\nolimits_{0T}$ is the map $K\left[  \left[  T\right]
\right]  \rightarrow\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)
\left[  \left[  T\right]  \right]  $ which sends every power series to its
constant term tensored with $1$ (viewed as a constant power series over
$K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}$), we have $\operatorname*{ev}%
\nolimits_{\left(  1\otimes0\right)  T}\left(  \lambda_{T}\left(  x\right)
\right)  =\underbrace{\left(  \text{constant term of the power series }%
\lambda_{T}\left(  x\right)  \right)  }_{=1}\otimes1=1\otimes1=1$. Thus,
$\operatorname*{td}\nolimits_{1,T,\mathbf{Z}^{\prime}}\left(  x\right)
=\operatorname*{td}\nolimits_{1+0t,T,\mathbf{Z}^{\prime}}\left(  x\right)
=\lambda_{\left(  1\otimes0\right)  T}\left(  x\right)  =\operatorname*{ev}%
\nolimits_{\left(  1\otimes0\right)  T}\left(  \lambda_{T}\left(  x\right)
\right)  =1$.}. The induction step is a straightforward application of
Proposition 10.32. Thus Proposition 10.33 is proven.

\textit{Proof of Theorem 10.34.} Theorem 2.1 \textbf{(a)} yields $\lambda
_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)  =\lambda_{T}\left(
x+y\right)  $ (since $\left(  K,\left(  \lambda^{i}\right)  _{i\in\mathbb{N}%
}\right)  $ is a $\lambda$-ring).

Let $\iota:K\rightarrow K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}$ be the
canonical map (mapping every $\xi\in K$ to $\xi\otimes1\in K\otimes
_{\mathbf{Z}}\mathbf{Z}^{\prime}$). Then, Proposition 10.29 yields
$\operatorname*{td}_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)
=\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]
\left(  \lambda_{T}\left(  x\right)  \right)  \right)  $. Proposition 10.29
(applied to $y$ instead of $x$) yields $\operatorname*{td}_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  y\right)  =\mathfrak{Todd}_{\varphi}\left(
\iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(  y\right)
\right)  \right)  $. Hence,%
\begin{align*}
&  \underbrace{\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}%
}\left(  x\right)  }_{=\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[
T\right]  \right]  \left(  \lambda_{T}\left(  x\right)  \right)  \right)
}\cdot\underbrace{\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}%
}\left(  y\right)  }_{=\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[
T\right]  \right]  \left(  \lambda_{T}\left(  y\right)  \right)  \right)  }\\
&  =\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]
\left(  \lambda_{T}\left(  x\right)  \right)  \right)  \cdot\mathfrak{Todd}%
_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]  \left(  \lambda
_{T}\left(  y\right)  \right)  \right)  =\mathfrak{Todd}_{\varphi}\left(
\underbrace{\iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(
x\right)  \right)  \cdot\iota\left[  \left[  T\right]  \right]  \left(
\lambda_{T}\left(  y\right)  \right)  }_{\substack{=\iota\left[  \left[
T\right]  \right]  \left(  \lambda_{T}\left(  x\right)  \cdot\lambda
_{T}\left(  y\right)  \right)  \\\text{(since }\iota\left[  \left[  T\right]
\right]  \text{ is a ring homomorphism)}}}\right) \\
&  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 10.16, applied to }%
p=\iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(  x\right)
\right)  \text{ and }q=\iota\left[  \left[  T\right]  \right]  \left(
\lambda_{T}\left(  y\right)  \right)  \right) \\
&  =\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]
\left(  \lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)
\right)  \right)  .
\end{align*}
Proposition 10.29 (applied to $x+y$ instead of $x$) yields%
\[
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x+y\right)
=\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]
\left(  \underbrace{\lambda_{T}\left(  x+y\right)  }_{\substack{=\lambda
_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)  }}\right)  \right)
=\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]
\left(  \lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(  y\right)
\right)  \right)  .
\]
Thus,%
\[
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)
\cdot\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(
y\right)  =\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]
\right]  \left(  \lambda_{T}\left(  x\right)  \cdot\lambda_{T}\left(
y\right)  \right)  \right)  =\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  x+y\right)  .
\]
Theorem 10.34 is thus proven.

\textit{Proof of Corollary 10.35.} Every $x\in K$ satisfies
$\operatorname*{td}_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)
\in\Lambda\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $ (since
Proposition 10.31 \textbf{(a)} says that $\operatorname*{Coeff}\nolimits_{0}%
\left(  \operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(
x\right)  \right)  =1$, so that the power series $\operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x\right)  $ has the constant
term $1$, and thus $\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime
}}\left(  x\right)  \in1+\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime
}\right)  \left[  \left[  T\right]  \right]  ^{+}=\Lambda\left(
K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $). In other words,
$\operatorname*{td}_{\varphi,T,\mathbf{Z}^{\prime}}\left(  K\right)
\subseteq\Lambda\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $.

Now we are going to prove that $\operatorname*{td}_{\varphi,T,\mathbf{Z}%
^{\prime}}:K\rightarrow\Lambda\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime
}\right)  $ is a homomorphism of additive groups.

Theorem 10.34 (applied to $x=0$ and $y=0$) yields $\operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  0\right)  \cdot
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  0\right)
=\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(
0+0\right)  =\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}%
}\left(  0\right)  $. Since $\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  0\right)  $ is an invertible element of
$\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  \left[  \left[
T\right]  \right]  $ (because $\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  0\right)  $ is a power series with constant
term $1$\ \ \ \ \footnote{since $\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  0\right)  \in\operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  K\right)  \subseteq
\Lambda\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  =1+\left(
K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  \left[  \left[  T\right]
\right]  ^{+}$}, and every such power series is an invertible element of
$\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  \left[  \left[
T\right]  \right]  $), we can cancel $\operatorname*{td}\nolimits_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  0\right)  $ from this equation, and obtain
$\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  0\right)
=1$. Since $0$ is the neutral element of the additive group $K$, while $1$ is
the neutral element of the additive group $\Lambda\left(  K\otimes
_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $, this yields that the map
$\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}$ respects the
neutral elements of the additive groups $K$ and $\Lambda\left(  K\otimes
_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $.

Any $x\in K$ and $y\in K$ satisfy%
\begin{align*}
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  x+y\right)
&  =\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(
x\right)  \cdot\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}%
}\left(  y\right)  \ \ \ \ \ \ \ \ \ \ \left(  \text{by Theorem 10.34}\right)
\\
&  =\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(
x\right)  \widehat{+}\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}%
^{\prime}}\left(  y\right)
\end{align*}
(since multiplication of power series in $1+\left(  K\otimes_{\mathbf{Z}%
}\mathbf{Z}^{\prime}\right)  \left[  \left[  T\right]  \right]  ^{+}$ is
addition in the ring $\Lambda\left(  K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime
}\right)  $). Combined with the fact that the map $\operatorname*{td}%
\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}$ respects the neutral elements of
the additive groups $K$ and $\Lambda\left(  K\otimes_{\mathbf{Z}}%
\mathbf{Z}^{\prime}\right)  $, this yields: The map $\operatorname*{td}%
_{\varphi,T,\mathbf{Z}^{\prime}}:K\rightarrow\Lambda\left(  K\otimes
_{\mathbf{Z}}\mathbf{Z}^{\prime}\right)  $ is a homomorphism of additive
groups. Corollary 10.35 is proven.

\textit{Proof of Proposition 10.36.} Let $\iota:K\rightarrow K\otimes
_{\mathbf{Z}}\mathbf{Z}^{\prime}$ be the canonical map (mapping every $\xi\in
K$ to $\xi\otimes1\in K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}$). Then,
$\iota\left[  \left[  T\right]  \right]  \left(  1+uT\right)  =1+\left(
u\otimes1\right)  T$.

Proposition 10.29 (applied to $x=u$) yields $\operatorname*{td}_{\varphi
,T,\mathbf{Z}^{\prime}}\left(  u\right)  =\mathfrak{Todd}_{\varphi}\left(
\iota\left[  \left[  T\right]  \right]  \left(  \lambda_{T}\left(  u\right)
\right)  \right)  $. But Theorem 8.3 \textbf{(a)} (applied to $x=u$) yields
that $\lambda_{T}\left(  u\right)  =1+uT$ (since the element $u$ is
$1$-dimensional). Thus,%
\begin{align*}
\operatorname*{td}\nolimits_{\varphi,T,\mathbf{Z}^{\prime}}\left(  u\right)
&  =\mathfrak{Todd}_{\varphi}\left(  \iota\left[  \left[  T\right]  \right]
\left(  \underbrace{\lambda_{T}\left(  u\right)  }_{=1+uT}\right)  \right)
=\mathfrak{Todd}_{\varphi}\left(  \underbrace{\iota\left[  \left[  T\right]
\right]  \left(  1+uT\right)  }_{=1+\left(  u\otimes1\right)  T}\right)
=\mathfrak{Todd}_{\varphi}\left(  1+\left(  u\otimes1\right)  T\right) \\
&  =\varphi\left(  \left(  u\otimes1\right)  T\right)
\ \ \ \ \ \ \ \ \ \ \left(
\begin{array}
[c]{c}%
\text{by Proposition 10.26, applied to}\\
\mathbf{Z}^{\prime}\text{, }K\otimes_{\mathbf{Z}}\mathbf{Z}^{\prime}\text{ and
}u\otimes1\text{ instead of }\mathbf{Z}\text{, }K\text{ and }u
\end{array}
\right)  .
\end{align*}
This proves Proposition 10.36.

\textit{Proof of Theorem 10.37.} Theorem 10.37 can be proven with the help of
Proposition 10.36 in the same way as we proved Theorem 10.27 with the help of
Proposition 10.24. We leave the details to the reader.

\section*{References}

[1] William Fulton, Serge Lang, \textit{Riemann-Roch algebra}, New York 1985.

[2] Donald Knutson, $\lambda$\textit{-Rings and the Representation Theory of
the Symmetric Group}, New York 1973.

[3] M. F. Atiyah, I. G. Macdonald, \textit{Introduction to Commutative
Algebra}, Addison-Wesley 1969.

[4] Robin Hartshorne, \textit{Algebraic Geometry}, Springer 1977.

[5] Michiel Hazewinkel, \textit{Niceness theorems}, arXiv:0810.5691v1
[math.HO], 2008.\newline\texttt{http://arxiv.org/abs/0810.5691}

[6] Michiel Hazewinkel, \textit{Witt vectors. Part 1}, arXiv:0804.3888v1
[math.RA], 2008.\newline\texttt{http://arxiv.org/abs/0804.3888}

[7] Wolfang K. Seiler, $\lambda$\textit{-rings and Adams operations in
algebraic K-Theory}, in: M. Rapoport, N. Schappacher, P. Schneider (eds.),
\textit{Beilinson's Conjectures on Special Values of }$L$\textit{-functions},
Academic Press 1988, pp. 93-102.

[8] Darij Grinberg, \textit{Witt\#4a: Equigraded power series}.\newline%
\texttt{www.cip.ifi.lmu.de/\symbol{126}grinberg/algebra/witt4a.pdf}

[9] John R. Hopkinson, \textit{Universal Polynomials in Lambda rings and the
K-theory of the infinite loop space }$tmf$, PhD thesis at MIT, June
2006.\newline\texttt{http://dspace.mit.edu/handle/1721.1/34544}

[10] Donald Yau, \textit{Lambda-rings}, World Scientific 2010.\newline%
\texttt{http://www.worldscientific.com/worldscibooks/10.1142/7664}%
\newline(includes downloadable Chapter 1).


\end{document}